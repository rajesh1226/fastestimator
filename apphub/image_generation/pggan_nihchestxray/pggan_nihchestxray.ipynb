{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Chest X-Ray Image Generation with PGGAN\n",
    "In this notebook, we will demonstrate the functionality of ``Scheduler`` which enables advanced training schemes such as a progressive training method as described in [Karras et al.](https://arxiv.org/pdf/1710.10196.pdf). \n",
    "We will train a PGGAN to produce high resolution synthetic frontal chest X-ray images where both the generator and the discriminator grows from $4\\times4$ to $1024\\times1024$.\n",
    "\n",
    "\n",
    "Stably training a GAN to produce realistic high resolution synthetic images is challenging.\n",
    "The discriminator can easily tell apart real images from generated images in the high resolution setting.\n",
    "This leads to instability in the training.\n",
    "\n",
    "### Progressive Growing Strategy\n",
    "[Karras et al.](https://arxiv.org/pdf/1710.10196.pdf) propose a training scheme in which both the generator and the discriminator progressively grow from a low resolution to a high resolution.\n",
    "Both networks first start out training based on images of $4\\times4$ as illustrated below.\n",
    "![4x4](./Figure/pggan_4x4.png)\n",
    "Then, both networks progress from $4\\times4$ to $8\\times8$ by an adding additional block that contains a couple of convolutional layers.\n",
    "![8x8](./Figure/pggan_8x8.png)\n",
    "Both the generator and the discriminator progressively grow until reaching the desired resolution of $1024\\times 1024$.\n",
    "![1024x1024](./Figure/pggan_1024x1024.png)\n",
    "*Image Credit: [Presentation slide](https://drive.google.com/open?id=1jYlrX4DgTs2VAfRcyl3pcNI4ONkBg3-g)*\n",
    "\n",
    "### Smooth Transition between Resolutions\n",
    "However, when growing the networks, the new blocks are slowly faded into the networks in order to smoothly transition between different resolutions.\n",
    "For example, when growing the generator from $16\\times16$ to $32\\times32$, the newly added block of $32\\times32$ is slowly faded into the already well trained $16\\times16$ network by linearly increasing $\\alpha$ from $0$ to $1$.\n",
    "Once the network is fully transitioned to $32\\times32$, the network is trained on a bit further to stabilize before growing to $64\\times64$.\n",
    "![grow](./Figure/pggan_smooth_grow.png)\n",
    "*Image Credit: [PGGAN Paper](https://arxiv.org/pdf/1710.10196.pdf)*\n",
    "\n",
    "With this progressive training strategy, PGGAN has achieved the state-of-the-art in producing synthetic images of high fidelity.\n",
    "\n",
    "## Problem Setting\n",
    "In this PGGAN example, we decide the following:\n",
    "* 560K images will be used when transitioning from a lower resolution to a higher resolution.\n",
    "* 560K images will be used when stabilizing the fully transitioned network.\n",
    "* Initial resolution will be $4\\times4$.\n",
    "* Final resolution will be $1024\\times1024$.\n",
    "\n",
    "The number of images for both transitioning and stabilizing is equivalent to 5 epochs; the networks would smoothly grow over 5 epochs and would stabilize for 5 epochs.\n",
    "This yields the following schedule of growing both networks:\n",
    "\n",
    "* Until $4^{th}$ epoch: train $4\\times4$ resolution\n",
    "* From $5^{th}$ epoch to $9^{th}$ epoch: transition from $4\\times4$ to $8\\times8$\n",
    "* From $10^{th}$ epoch to $14^{th}$ epoch: stabilize $8\\times8$\n",
    "* From $15^{th}$ epoch to $19^{th}$ epoch: transition from $8\\times8$ to $16\\times16$\n",
    "* From $20^{th}$ epoch to $24^{th}$ epoch: stabilize $16\\times16$\n",
    "\n",
    "$\\cdots$\n",
    "\n",
    "* From $80^{th}$ epoch to $84^{th}$ epoch: stabilize $1024\\times1024$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "import fastestimator as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Input Pipeline\n",
    "\n",
    "First, we need to download chest frontal X-ray dataset from the National Institute of Health (NIH); the dataset has over 112,000 images of $1024\\times1024$. \n",
    "We use ``fastestimator.dataset.nih_chestxray.load_data`` to download images and create a csv file that contains relative paths to the training images. \n",
    "The parent path to the images returned in ``data_path`` .\n",
    "A detailed description of the dataset is available [here](https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community).\n",
    "\n",
    "### Note: Please make sure to have a stable internet connection when downloading the dataset for the first time since the size of the dataset is over 40GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.dataset.nih_chestxray import load_data\n",
    "train_csv, data_path = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two instances of ``RecordWriter`` objects to create two sets of tfrecords to use throughout the training.\n",
    "``writer_128`` would contain training images of $128 \\times 128$ to be used for the early phase of the training, and ``writer_1024`` would contain training images of $1024 \\times 1024$ to be used for the later phase of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.numpyop import ImageReader\n",
    "from fastestimator.op.numpyop import Resize as ResizeRecord\n",
    "from fastestimator.util.record_writer import RecordWriter\n",
    "\n",
    "imreader = ImageReader(inputs=\"x\", parent_path=data_path, grey_scale=True)\n",
    "\n",
    "writer_128 = RecordWriter(save_dir=os.path.join(data_path, \"tfrecord_128\"),\n",
    "                          train_data=train_csv,\n",
    "                          ops=[imreader, ResizeRecord(target_size=(128, 128), outputs=\"x\")])\n",
    "\n",
    "writer_1024 = RecordWriter(save_dir=os.path.join(data_path, \"tfrecord_1024\"),\n",
    "                           train_data=train_csv,\n",
    "                           ops=[imreader, ResizeRecord(target_size=(1024, 1024), outputs=\"x\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the following two custom ``TensorOp`` to process input images prior to feeding them to the network.\n",
    "* ``Rescale`` operation to rescale pixels values from $[0, 255]$ to $[-1, 1]$.\n",
    "* ``CreateLowRes`` operation to create images that are downsampled by a factor of 2 and upsampled by a factor of 2. The resulting images will be used for smooth transitioning between different resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op import TensorOp\n",
    "\n",
    "class Rescale(TensorOp):\n",
    "    \"\"\"Scale image values from uint8 to float32 between -1 and 1.\"\"\"\n",
    "    def forward(self, data, state):\n",
    "        data = tf.cast(data, tf.float32)\n",
    "        data = (data - 127.5) / 127.5\n",
    "        return data\n",
    "\n",
    "class CreateLowRes(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        data_shape = tf.shape(data)\n",
    "        height = data_shape[0]\n",
    "        width = data_shape[1]\n",
    "        data = tf.image.resize(data, (height / 2, width / 2))\n",
    "        data = tf.image.resize(data, (height, width))\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolution of images change at epoch $0$, $5$, $15$, $25$, $35$, $45$, $55$, and $65$ throughout the training.\n",
    "We can accomplish this using ``Scheduler`` which takes a dictionary as an input to express which operation (value) to perform at which epoch (key). Therefore, we specify to perform ``Resize`` operation to change the image resolution at those epoch. We resize images of $128\\times128$ from the first set of tfrecords for the early training. Then, we resize $1024\\times1024$ images for the later training.\n",
    "\n",
    "In addition, we wil define another ``Scheduler`` to denote how we change the batch size alongside the image resolution. \n",
    "The batch size will progressively decrease as the resolution of image grows; the batch size will decrease from $128$ for $4\\times4$ images to $1$ for $1024\\times1024$.\n",
    "Note that the batch size we specify here is the batch size per device. Therefore, the global batch size for $1024\\times1024$ for 4 gpu machine will be $4$ whereas it will be $8$ for 8 gpu machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.schedule import Scheduler\n",
    "from fastestimator.op.tensorop import Resize\n",
    "# resize ops\n",
    "resize_scheduler_128 = Scheduler({\n",
    "    0: Resize(inputs=\"x\", size=(4, 4), outputs=\"x\"),\n",
    "    5: Resize(inputs=\"x\", size=(8, 8), outputs=\"x\"),\n",
    "    15: Resize(inputs=\"x\", size=(16, 16), outputs=\"x\"),\n",
    "    25: Resize(inputs=\"x\", size=(32, 32), outputs=\"x\"),\n",
    "    35: Resize(inputs=\"x\", size=(64, 64), outputs=\"x\"),\n",
    "    45: None\n",
    "})\n",
    "resize_scheduler_1024 = Scheduler({\n",
    "    55: Resize(inputs=\"x\", size=(256, 256), outputs=\"x\"),\n",
    "    65: Resize(inputs=\"x\", size=(512, 512), outputs=\"x\"),\n",
    "    75: None\n",
    "})\n",
    "\n",
    "# We create a scheduler for batch_size with the epochs at which it will change and corresponding values.\n",
    "batchsize_scheduler_128 = Scheduler({0: 128, 5: 64, 15: 32, 25: 16, 35: 8, 45: 4})\n",
    "batchsize_scheduler_1024 = Scheduler({55: 4, 65: 2, 75: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define two instances of ``Pipeline`` for each ``RecordWriter`` objects.\n",
    "Each ``Pipeline`` will perform the following operations:\n",
    "* Resize train images according to ``Scheduler`` defined above\n",
    "* Create lower resolution version of images\n",
    "* Rescale resized image\n",
    "* Rescale lower resolution image\n",
    "\n",
    "Then, we create another ``Scheduler`` to control which tfrecords to use throughout the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowres_op = CreateLowRes(inputs=\"x\", outputs=\"x_lowres\")\n",
    "rescale_x = Rescale(inputs=\"x\", outputs=\"x\")\n",
    "rescale_lowres = Rescale(inputs=\"x_lowres\", outputs=\"x_lowres\")\n",
    "\n",
    "pipeline_128 = fe.Pipeline(batch_size=batchsize_scheduler_128,\n",
    "                           data=writer_128,\n",
    "                           ops=[resize_scheduler_128, lowres_op, rescale_x, rescale_lowres])\n",
    "pipeline_1024 = fe.Pipeline(batch_size=batchsize_scheduler_1024,\n",
    "                            data=writer_1024,\n",
    "                            ops=[resize_scheduler_1024, lowres_op, rescale_x, rescale_lowres])\n",
    "\n",
    "pipeline_scheduler = Scheduler({0: pipeline_128, 55: pipeline_1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how ``Pipeline``s change image resolutions at different epochs we specified in ``Scheduler``.\n",
    "We provide ``show_results`` methods to visaulize the resulting images of ``Pipeline``.\n",
    "In order to correctly visualize the output of ``Pipeline``, we need to provide epoch numbers to ``show_results`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_pipeline_result(pipeline, epoch, reuse, batch_idx=0, img_key=\"x\"):\n",
    "    batch = pipeline.show_results(current_epoch=epoch, reuse=reuse)[0]\n",
    "    img = batch[img_key][batch_idx].numpy()\n",
    "    img = (img + 1) * 0.5    \n",
    "    return img[..., 0]\n",
    "\n",
    "# Visualizing pipeline_128\n",
    "batch_idx = 0\n",
    "epochs_128 = [0, 5, 15, 25, 35, 45]\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "for i, epoch in enumerate(epochs_128):\n",
    "    img_128 = display_pipeline_result(pipeline_128, epoch, epoch != epochs_128[-1])\n",
    "    plt.subplot(1, 9, i+1)\n",
    "    plt.imshow(img_128, cmap='gray')\n",
    "\n",
    "# Visualizing pipeline_1024\n",
    "epochs_1024 = [55, 65, 75]\n",
    "for i, epoch in enumerate(epochs_1024):\n",
    "    img_1024 = display_pipeline_result(pipeline_1024, epoch, epoch != epochs_1024[-1])\n",
    "    plt.subplot(1, 9, i+7)\n",
    "    plt.imshow(img_1024, cmap='gray')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Network\n",
    "### Defining the generator and the discriminator\n",
    "To express the progressive growing of networks, we return a list of models that progressively grow from $4 \\times 4$ to $1024 \\times 1024$ such that $i^{th}$ model in the list is the superset previous models.\n",
    "We define a ``tf.Variable`` to allow models to grow smoothly.\n",
    "``fe.build`` bundles each model, optimizer, the name of the model, and the associated loss name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.architecture.pggan import build_G, build_D\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "fade_in_alpha = tf.Variable(initial_value=1.0, dtype='float32', trainable=False)\n",
    "\n",
    "d2, d3, d4, d5, d6, d7, d8, d9, d10 = fe.build(\n",
    "    model_def=lambda: build_D(fade_in_alpha=fade_in_alpha, target_resolution=10, num_channels=1),\n",
    "    model_name=[\"d2\", \"d3\", \"d4\", \"d5\", \"d6\", \"d7\", \"d8\", \"d9\", \"d10\"],\n",
    "    optimizer=[optimizer]*9,\n",
    "    loss_name=[\"dloss\"]*9)\n",
    "\n",
    "g2, g3, g4, g5, g6, g7, g8, g9, g10, G = fe.build(\n",
    "    model_def=lambda: build_G(fade_in_alpha=fade_in_alpha, target_resolution=10, num_channels=1),\n",
    "    model_name=[\"g2\", \"g3\", \"g4\", \"g5\", \"g6\", \"g7\", \"g8\", \"g9\", \"g10\", \"G\"],\n",
    "    optimizer=[optimizer]*10,\n",
    "    loss_name=[\"gloss\"]*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the following ``TensorOp``:\n",
    "* ``RandomInput`` to produce random variables drawn from  $\\mathcal{N}(0,\\,1)$\n",
    "* ``ImageBlender`` to blend real images of $2^{i} \\times 2^{i}$ and $2^{i-1} \\times 2^{i-1}$ to allow smooth transition when growing from $2^{i-1} \\times 2^{i-1}$ to $2^{i} \\times 2^{i}$\n",
    "* ``Interpolate`` to interpolate between real images and generated images\n",
    "* ``GradientPenalty`` to compute the gradient penalty using the result of the previous TensorOp ``Interpolate``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomInput(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        latent_dim = data\n",
    "        batch_size = state[\"local_batch_size\"]\n",
    "        random_vector = tf.random.normal([batch_size, latent_dim])\n",
    "        return random_vector\n",
    "\n",
    "\n",
    "class ImageBlender(TensorOp):\n",
    "    def __init__(self, alpha, inputs=None, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        image, image_lowres = data\n",
    "        new_img = self.alpha * image + (1 - self.alpha) * image_lowres\n",
    "        return new_img\n",
    "\n",
    "\n",
    "class Interpolate(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        fake, real = data\n",
    "        batch_size = state[\"local_batch_size\"]\n",
    "        coeff = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
    "        return real + (fake - real) * coeff\n",
    "\n",
    "\n",
    "class GradientPenalty(TensorOp):\n",
    "    def __init__(self, inputs, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        x_interp, interp_score = data\n",
    "        interp_score = tf.reshape(interp_score, [-1])\n",
    "        tape = state['tape']\n",
    "        gradient_x_interp = tape.gradient(tf.reduce_sum(interp_score), x_interp)\n",
    "        grad_l2 = tf.math.sqrt(tf.reduce_sum(tf.math.square(gradient_x_interp), axis=[1, 2, 3]))\n",
    "        gp = tf.math.square(grad_l2 - 1.0)\n",
    "        return gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define loss functions for the genrator and the discriminator.\n",
    "The loss functions are modified version of the [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf); the discriminator's loss function has an additional term to penalize the discriminator's output on real images deviating too much from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop import Loss\n",
    "\n",
    "class GLoss(Loss):\n",
    "    def forward(self, data, state):\n",
    "        return -data\n",
    "\n",
    "\n",
    "class DLoss(Loss):\n",
    "    \"\"\"Compute discriminator loss.\"\"\"\n",
    "    def __init__(self, inputs, outputs=None, mode=None, wgan_lambda=10, wgan_epsilon=0.001):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.wgan_lambda = wgan_lambda\n",
    "        self.wgan_epsilon = wgan_epsilon\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        real_score, fake_score, gp = data\n",
    "        loss = fake_score - real_score + self.wgan_lambda * gp + self.wgan_epsilon * tf.math.square(real_score)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the losses defined, we need to specify the forward pass of the networks.\n",
    "We utilize ``Scheduler`` to progressively train the generator and the discriminator from $4\\times4$ to $1024\\times1024$.\n",
    "The foward pass schedule throughout the training ia as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.op.tensorop import ModelOp\n",
    "\n",
    "g_scheduler = Scheduler({\n",
    "    0: ModelOp(model=g2, outputs=\"x_fake\"),\n",
    "    5: ModelOp(model=g3, outputs=\"x_fake\"),\n",
    "    15: ModelOp(model=g4, outputs=\"x_fake\"),\n",
    "    25: ModelOp(model=g5, outputs=\"x_fake\"),\n",
    "    35: ModelOp(model=g6, outputs=\"x_fake\"),\n",
    "    45: ModelOp(model=g7, outputs=\"x_fake\"),\n",
    "    55: ModelOp(model=g8, outputs=\"x_fake\"),\n",
    "    65: ModelOp(model=g9, outputs=\"x_fake\"),\n",
    "    75: ModelOp(model=g10, outputs=\"x_fake\")\n",
    "})\n",
    "\n",
    "fake_score_scheduler = Scheduler({\n",
    "    0: ModelOp(inputs=\"x_fake\", model=d2, outputs=\"fake_score\"),\n",
    "    5: ModelOp(inputs=\"x_fake\", model=d3, outputs=\"fake_score\"),\n",
    "    15: ModelOp(inputs=\"x_fake\", model=d4, outputs=\"fake_score\"),\n",
    "    25: ModelOp(inputs=\"x_fake\", model=d5, outputs=\"fake_score\"),\n",
    "    35: ModelOp(inputs=\"x_fake\", model=d6, outputs=\"fake_score\"),\n",
    "    45: ModelOp(inputs=\"x_fake\", model=d7, outputs=\"fake_score\"),\n",
    "    55: ModelOp(inputs=\"x_fake\", model=d8, outputs=\"fake_score\"),\n",
    "    65: ModelOp(inputs=\"x_fake\", model=d9, outputs=\"fake_score\"),\n",
    "    75: ModelOp(inputs=\"x_fake\", model=d10, outputs=\"fake_score\")\n",
    "})\n",
    "\n",
    "real_score_scheduler = Scheduler({\n",
    "    0: ModelOp(model=d2, outputs=\"real_score\"),\n",
    "    5: ModelOp(model=d3, outputs=\"real_score\"),\n",
    "    15: ModelOp(model=d4, outputs=\"real_score\"),\n",
    "    25: ModelOp(model=d5, outputs=\"real_score\"),\n",
    "    35: ModelOp(model=d6, outputs=\"real_score\"),\n",
    "    45: ModelOp(model=d7, outputs=\"real_score\"),\n",
    "    55: ModelOp(model=d8, outputs=\"real_score\"),\n",
    "    65: ModelOp(model=d9, outputs=\"real_score\"),\n",
    "    75: ModelOp(model=d10, outputs=\"real_score\")\n",
    "})\n",
    "\n",
    "interp_score_scheduler = Scheduler({\n",
    "    0: ModelOp(inputs=\"x_interp\", model=d2, outputs=\"interp_score\", track_input=True),\n",
    "    5: ModelOp(inputs=\"x_interp\", model=d3, outputs=\"interp_score\", track_input=True),\n",
    "    15: ModelOp(inputs=\"x_interp\", model=d4, outputs=\"interp_score\", track_input=True),\n",
    "    25: ModelOp(inputs=\"x_interp\", model=d5, outputs=\"interp_score\", track_input=True),\n",
    "    35: ModelOp(inputs=\"x_interp\", model=d6, outputs=\"interp_score\", track_input=True),\n",
    "    45: ModelOp(inputs=\"x_interp\", model=d7, outputs=\"interp_score\", track_input=True),\n",
    "    55: ModelOp(inputs=\"x_interp\", model=d8, outputs=\"interp_score\", track_input=True),\n",
    "    65: ModelOp(inputs=\"x_interp\", model=d9, outputs=\"interp_score\", track_input=True),\n",
    "    75: ModelOp(inputs=\"x_interp\", model=d10, outputs=\"interp_score\", track_input=True)\n",
    "})\n",
    "\n",
    "network = fe.Network(ops=[\n",
    "    RandomInput(inputs=lambda: 512),\n",
    "    g_scheduler,\n",
    "    fake_score_scheduler,\n",
    "    ImageBlender(inputs=(\"x\", \"x_lowres\"), alpha=fade_in_alpha),\n",
    "    real_score_scheduler,\n",
    "    Interpolate(inputs=(\"x_fake\", \"x\"), outputs=\"x_interp\"),\n",
    "    interp_score_scheduler,\n",
    "    GradientPenalty(inputs=(\"x_interp\", \"interp_score\"), outputs=\"gp\"),\n",
    "    GLoss(inputs=\"fake_score\", outputs=\"gloss\"),\n",
    "    DLoss(inputs=(\"real_score\", \"fake_score\", \"gp\"), outputs=\"dloss\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Trace\n",
    "Given that ``Pipeline`` and ``Network`` are properly defined, we need to define the following ``Trace``s:\n",
    "* ``AlphaController`` to allow smooth transition from different resolutions.\n",
    "* ``ImageSaving`` to save intermediate outputs of the generator\n",
    "* ``ModelSaving`` to save the final generator model\n",
    "* ``ResetOptimizer`` to reset the internal state of the optimizer once the resolution is fully transitioned\n",
    "\n",
    "``AlphaController`` facilitates both the generator and the discriminator to smoothly grow by controlling the value of ``fade_in_alpha`` tensor created previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.trace import Trace\n",
    "\n",
    "class AlphaController(Trace):\n",
    "    def __init__(self, alpha, fade_start, duration):\n",
    "        super().__init__(inputs=None, outputs=None, mode=\"train\")\n",
    "        self.alpha = alpha\n",
    "        self.fade_start = fade_start\n",
    "        self.duration = duration\n",
    "        self.change_alpha = False\n",
    "        self._idx = 0\n",
    "\n",
    "    def on_epoch_begin(self, state):\n",
    "        # check whetehr the current epoch is in smooth transition of resolutions\n",
    "        fade_epoch = self.fade_start[self._idx]\n",
    "        if state[\"epoch\"] == fade_epoch:\n",
    "            self.nimg_total = self.duration[self._idx] * state[\"num_examples\"]\n",
    "            self.change_alpha = True\n",
    "            self.nimg_so_far = 0\n",
    "            print(\"FastEstimator-Alpha: Started fading in for size {}\".format(2**(self._idx + 3)))\n",
    "        elif state[\"epoch\"] == fade_epoch + self.duration[self._idx]:\n",
    "            print(\"FastEstimator-Alpha: Finished fading in for size {}\".format(2**(self._idx + 3)))\n",
    "            self.change_alpha = False\n",
    "            self._idx += 1\n",
    "            backend.set_value(self.alpha, 1.0)\n",
    "\n",
    "    def on_batch_begin(self, state):\n",
    "        # if in resolution transition, smoothly change the alpha from 0 to 1\n",
    "        if self.change_alpha:\n",
    "            self.nimg_so_far += state[\"batch_size\"]\n",
    "            current_alpha = np.float32(self.nimg_so_far / self.nimg_total)\n",
    "            backend.set_value(self.alpha, current_alpha)\n",
    "\n",
    "\n",
    "class ImageSaving(Trace):\n",
    "    def __init__(self, epoch_model, save_dir, num_sample=16, latent_dim=512, num_channels=3):\n",
    "        super().__init__(inputs=None, outputs=None, mode=\"train\")\n",
    "        self.epoch_model = epoch_model\n",
    "        self.save_dir = save_dir\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_sample = num_sample\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = 1e-8\n",
    "\n",
    "    def on_epoch_end(self, state):\n",
    "        if state[\"epoch\"] in self.epoch_model:\n",
    "            model = self.epoch_model[state[\"epoch\"]]\n",
    "            for i in range(self.num_sample):\n",
    "                random_vectors = tf.random.normal([1, self.latent_dim])\n",
    "                pred = model(random_vectors)\n",
    "                disp_img = pred.numpy()\n",
    "                disp_img = np.squeeze(disp_img)\n",
    "                disp_img -= disp_img.min()\n",
    "                disp_img /= (disp_img.max() + self.eps)\n",
    "                disp_img = np.uint8(disp_img * 255)\n",
    "                cv2.imwrite(os.path.join(self.save_dir, 'image_at_{:08d}_{}.png').format(state[\"epoch\"], i), disp_img)\n",
    "            print(\"on epoch {}, saving image to {}\".format(state[\"epoch\"], self.save_dir))\n",
    "\n",
    "\n",
    "class ModelSaving(Trace):\n",
    "    def __init__(self, epoch_model, save_dir):\n",
    "        super().__init__(inputs=None, outputs=None, mode=\"train\")\n",
    "        self.epoch_model = epoch_model\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def on_epoch_end(self, state):\n",
    "        if state[\"epoch\"] in self.epoch_model:\n",
    "            model = self.epoch_model[state[\"epoch\"]]\n",
    "            save_path = os.path.join(self.save_dir, model.model_name + \".h5\")\n",
    "            model.save(save_path, include_optimizer=False)\n",
    "            print(\"FastEstimator-ModelSaver: Saving model to {}\".format(save_path))\n",
    "\n",
    "\n",
    "class ResetOptimizer(Trace):\n",
    "    def __init__(self, reset_epochs, optimizer):\n",
    "        super().__init__(inputs=None, outputs=None, mode=\"train\")\n",
    "        self.reset_epochs = reset_epochs\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def on_epoch_begin(self, state):\n",
    "        if state[\"epoch\"] in self.reset_epochs:\n",
    "            for weight in self.optimizer.weights:\n",
    "                backend.set_value(weight, weight - weight)\n",
    "            print(\"Resetting optimizer on epoch {}\".format(state[\"epoch\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Estimator\n",
    "\n",
    "We can now define ``Estimator`` putting ``Pipeline``, ``Network``, and ``Trace`` together.\n",
    "We will create an intermediate directory to save the intermediate outputs of the generator to keep track of the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(str(Path.home()), 'fastestimator_results', 'NIH_CXR_PGGAN')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "traces = [AlphaController(alpha=fade_in_alpha,\n",
    "                          fade_start=[5, 15, 25, 35, 45, 55, 65, 75, 85],\n",
    "                          duration=[5, 5, 5, 5, 5, 5, 5, 5, 5]),\n",
    "          ResetOptimizer(reset_epochs=[5, 15, 25, 35, 45, 55, 65, 75], optimizer=optimizer),\n",
    "          ImageSaving(epoch_model={4: g2, 14: g3, 24: g4, 34: g5, 44: g6, 54: g7, 64: g8, 74: g9, 84: G},\n",
    "                      save_dir=save_dir,\n",
    "                      num_channels=1),\n",
    "          ModelSaving(epoch_model={84: G}, save_dir=save_dir)]\n",
    "\n",
    "estimator = fe.Estimator(network=network,\n",
    "                         pipeline=pipeline_scheduler,\n",
    "                         epochs=85,\n",
    "                         traces=traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start training by calling ``fit`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
