{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import tempfile\n",
    "import tarfile\n",
    "from zipfile import ZipFile\n",
    "from glob import glob \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.estimator.estimator import Estimator\n",
    "from fastestimator.network.loss import Loss\n",
    "from fastestimator.network.model import ModelOp, FEModel\n",
    "from fastestimator.network.network import Network\n",
    "from fastestimator.pipeline.pipeline import Pipeline\n",
    "from fastestimator.pipeline.processing import Minmax\n",
    "from fastestimator.record.preprocess import ImageReader, Resize\n",
    "from fastestimator.record.record import RecordWriter\n",
    "from fastestimator.util.op import NumpyOp, TensorOp\n",
    "from fastestimator.estimator.trace import MeanAveragePrecision, LRController, ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastestimator.util.compute_overlap import compute_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, models\n",
    "\n",
    "def classification_sub_net(num_classes, num_anchor=9):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01), bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01), bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01), bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01), bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(num_classes * num_anchor,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='sigmoid',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer=tf.initializers.constant(np.log(1 / 99))))\n",
    "    model.add(layers.Reshape((-1, num_classes)))  # the output dimension is [batch, #anchor, #classes]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_sub_net(num_anchor=9):\n",
    "    model = models.Sequential()\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer='zeros')) \n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(256,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer='zeros'))\n",
    "    model.add(\n",
    "        layers.Conv2D(4 * num_anchor,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                      bias_initializer='zeros'))\n",
    "    model.add(layers.Reshape((-1, 4)))  # the output dimension is [batch, #anchor, 4]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetinaNet(input_shape, num_classes, num_anchor=9):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # FPN\n",
    "#     weights = '/home/ubuntu/ResNet-50-model.keras.h5'\n",
    "    resnet50 = tf.keras.applications.ResNet50(weights= \"imagenet\", include_top=False, input_tensor=inputs, pooling=None)\n",
    "#     resnet50.load_weights(weights, by_name=True)\n",
    "    assert resnet50.layers[80].name == \"conv3_block4_out\"\n",
    "    C3 = resnet50.layers[80].output\n",
    "    assert resnet50.layers[142].name == \"conv4_block6_out\"\n",
    "    C4 = resnet50.layers[142].output\n",
    "    assert resnet50.layers[-1].name == \"conv5_block3_out\"\n",
    "    C5 = resnet50.layers[-1].output\n",
    "    P5 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same')(C5)\n",
    "    P5_upsampling = layers.UpSampling2D()(P5)\n",
    "    P4 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same')(C4)\n",
    "    P4 = layers.Add()([P5_upsampling, P4])\n",
    "    P4_upsampling = layers.UpSampling2D()(P4)\n",
    "    P3 = layers.Conv2D(256, kernel_size=1, strides=1, padding='same')(C3)\n",
    "    P3 = layers.Add()([P4_upsampling, P3])\n",
    "    P6 = layers.Conv2D(256, kernel_size=3, strides=2, padding='same', name=\"P6\")(C5)\n",
    "    P7 = layers.Activation('relu')(P6)\n",
    "    P7 = layers.Conv2D(256, kernel_size=3, strides=2, padding='same', name=\"P7\")(P7)\n",
    "    P5 = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', name=\"P5\")(P5)\n",
    "    P4 = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', name=\"P4\")(P4)\n",
    "    P3 = layers.Conv2D(256, kernel_size=3, strides=1, padding='same', name=\"P3\")(P3)\n",
    "    # classification subnet\n",
    "    cls_subnet = classification_sub_net(num_classes=num_classes, num_anchor=num_anchor)\n",
    "    P3_cls = cls_subnet(P3)\n",
    "    P4_cls = cls_subnet(P4)\n",
    "    P5_cls = cls_subnet(P5)\n",
    "    P6_cls = cls_subnet(P6)\n",
    "    P7_cls = cls_subnet(P7)\n",
    "    cls_output = layers.Concatenate(axis=-2)([P3_cls, P4_cls, P5_cls, P6_cls, P7_cls])\n",
    "    # localization subnet\n",
    "    loc_subnet = regression_sub_net(num_anchor=num_anchor)\n",
    "    P3_loc = loc_subnet(P3)\n",
    "    P4_loc = loc_subnet(P4)\n",
    "    P5_loc = loc_subnet(P5)\n",
    "    P6_loc = loc_subnet(P6)\n",
    "    P7_loc = loc_subnet(P7)\n",
    "    loc_output = layers.Concatenate(axis=-2)([P3_loc, P4_loc, P5_loc, P6_loc, P7_loc])\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[cls_output, loc_output])\n",
    "\n",
    "\n",
    "\n",
    "# def get_loc_offset(box_gt, box_anchor):\n",
    "#     mean = 0 \n",
    "#     std = 0.2\n",
    "#     gt_x1, gt_y1, gt_x2, gt_y2 = tuple(box_gt)\n",
    "#     ac_x1, ac_y1, ac_x2, ac_y2 = tuple(box_anchor)\n",
    "#     anchor_width = ac_x2 - ac_x1\n",
    "#     anchor_height = ac_y2 - ac_y1\n",
    "#     dx1 = (gt_x1 - ac_x1) / anchor_width\n",
    "#     dx1 = dx1 / std\n",
    "#     dy1 = (gt_y1 - ac_y1) / anchor_height\n",
    "#     dy1 = dy1 / std\n",
    "#     dx2 = (gt_x2 - ac_x2) / anchor_width\n",
    "#     dx2 = dx2 / std\n",
    "#     dy2 = (gt_y2 - ac_y2) / anchor_height\n",
    "#     dy2 = dy2 /std\n",
    "#     return dx1, dy1, dx2, dy2\n",
    "\n",
    "\n",
    "def get_loc_offset(box_gt, box_anchor):\n",
    "    mean = 0 \n",
    "    std = 0.2\n",
    "    anchor_width_height = np.tile(box_anchor[:,2:] - box_anchor[:,:2],[1,2])\n",
    "    delta =  (box_gt - box_anchor)/ anchor_width_height\n",
    "    return delta/std\n",
    "\n",
    "\n",
    "def get_iou(box1, box2):\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = tuple(box1)\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = tuple(box2)\n",
    "    xA = max(b1_x1, b2_x1)\n",
    "    yA = max(b1_y1, b2_y1)\n",
    "    xB = min(b1_x2, b2_x2)\n",
    "    yB = min(b1_y2, b2_y2)\n",
    "    \n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if interArea == 0:\n",
    "        iou = 0\n",
    "    else:\n",
    "        box1Area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "        box2Area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "        iou = interArea / (box1Area + box2Area - interArea)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "# SHAPE=(288*2,288*2,3)\n",
    "\n",
    "class ResnetPreprocess(NumpyOp):\n",
    "    def forward(self, data, state):\n",
    "        image = data\n",
    "        image = image.astype(np.float64)\n",
    "        image[..., 0] -= 103.939\n",
    "        image[..., 1] -= 116.779\n",
    "        image[..., 2] -= 123.68\n",
    "        return image        \n",
    "\n",
    "class String2FloatArray(NumpyOp):\n",
    "    # this thing converts '[1, 2, 3]' into np.array([1, 2, 3])\n",
    "    def forward(self, data, state):\n",
    "        for idx, elem in enumerate(data):\n",
    "            elem = literal_eval(elem)\n",
    "            data[idx] = np.array(elem, dtype=np.int32)\n",
    "#             data[idx] = np.array([float(x) for x in elem[1:-1].split(',')])\n",
    "        return data\n",
    "    \n",
    "class String2IntArray(NumpyOp):\n",
    "    # this thing converts '[1, 2, 3]' into np.array([1, 2, 3])\n",
    "    def forward(self, data, state):\n",
    "        for idx, elem in enumerate(data):\n",
    "            elem = literal_eval(elem)\n",
    "            data[idx] = np.array(elem ,dtype=np.int32)\n",
    "#             data[idx] = np.array([int(x) for x in elem[1:-1].split(',')])\n",
    "        return data\n",
    "    \n",
    "    \n",
    "class RelativeCoordinate(NumpyOp):\n",
    "    def forward(self, data, state):\n",
    "        image, x1, y1, x2, y2 = data\n",
    "        height, width = image.shape[0], image.shape[1]\n",
    "        x1, y1, x2, y2 = x1 / width, y1 / height, x2 / width, y2 / height\n",
    "        return x1, y1, x2, y2\n",
    "    \n",
    "class ImageAdjustedBatchMax(TensorOp):\n",
    "    def forward(self, data, state):\n",
    "        images = data\n",
    "        batch_size = len(images)\n",
    "        max_shape = tuple(max(image.shape[idx] for image in images) for idx in range(3) )\n",
    "        images_max_shape = np.zeros((batch_size,)+max_shape)\n",
    "        for id, image in enumerate(images):\n",
    "            images_max_shape[idx, :image.shape[0], :image.shape[1], :image.shape[2] ] = image\n",
    "        return image_max_shape\n",
    "    \n",
    "class ResizeCocoStyle(Resize):\n",
    "    def __init__(self, target_size, keep_ratio=False, inputs=None, outputs=None, mode=None):\n",
    "        super().__init__(target_size, keep_ratio=keep_ratio, inputs=inputs, outputs=outputs, mode=mode)\n",
    "        \n",
    "        \n",
    "    def forward(self, data, state):\n",
    "        img, x1, y1, x2, y2 = data \n",
    "        if self.keep_ratio:\n",
    "            original_ratio = img.shape[1] / img.shape[0]\n",
    "            target_ratio = self.target_size[1] / self.target_size[0]\n",
    "            if original_ratio >= target_ratio:\n",
    "                pad = (img.shape[1] / target_ratio - img.shape[0]) / 2\n",
    "                pad_boarder = (np.ceil(pad).astype(np.int), np.floor(pad).astype(np.int), 0, 0)\n",
    "                y1 += np.ceil(pad).astype(np.int)\n",
    "                y2 += np.ceil(pad).astype(np.int)\n",
    "            else:\n",
    "                pad = (img.shape[0] * target_ratio - img.shape[1]) / 2\n",
    "                pad_boarder = (0, 0, np.ceil(pad).astype(np.int), np.floor(pad).astype(np.int))\n",
    "                x1 += np.ceil(pad).astype(np.int)\n",
    "                x2 += np.ceil(pad).astype(np.int)\n",
    "                \n",
    "            img = self._cv2.copyMakeBorder(img, *pad_boarder, self._cv2.BORDER_CONSTANT)\n",
    "        img_resize = self._cv2.resize(img, (self.target_size[1], self.target_size[0]), self.resize_method)\n",
    "        x1 = x1 * self.target_size[1]/img.shape[1]\n",
    "        x2 = x2 * self.target_size[1]/img.shape[1]\n",
    "        y1 = y1 * self.target_size[0]/img.shape[0]\n",
    "        y2 = y2 * self.target_size[0]/img.shape[0]\n",
    "        return img_resize, x1,y1,x2,y2\n",
    "        \n",
    "            \n",
    "    \n",
    "class GenerateTarget(NumpyOp):\n",
    "    def __init__(self, inputs=None, outputs=None, mode=None, input_shape=(800,800,3)):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.pyramid_levels = [3,4,5,6,7]\n",
    "        self.sizes   = [32, 64, 128, 256, 512]\n",
    "        self.strides = [8, 16, 32, 64, 128]\n",
    "        self.ratios  = np.array([0.5, 1, 2], dtype=np.float)\n",
    "        self.scales  = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)], dtype=np.float)\n",
    "        \n",
    "        \n",
    "        self.anchors_list = np.zeros((0,4))\n",
    "        image_shapes = [(np.array(input_shape[:2]) + 2**pyra_level-1)//(2**pyra_level) for pyra_level in self.pyramid_levels]\n",
    "        for idx, pyra_level in enumerate(self.pyramid_levels) :\n",
    "            base_size=self.sizes[idx]\n",
    "            ratios=self.ratios\n",
    "            scales=self.scales\n",
    "            image_shape = image_shapes[idx]\n",
    "            strides = self.strides[idx]\n",
    "            anchors = self.generate_anchors_core(base_size, ratios, scales)\n",
    "            shifted_anchors = self.shift(image_shape, strides, anchors)\n",
    "            self.anchors_list = np.append(self.anchors_list, shifted_anchors, axis=0)\n",
    "        \n",
    "        \n",
    "    def forward(self, data, state):\n",
    "        label, x1, y1, x2, y2, image = data\n",
    "        target_cls, target_loc = self.get_target(self.anchors_list, label, x1, y1, x2, y2, num_classes=81)\n",
    "        return target_cls, target_loc, self.anchors_list\n",
    "        \n",
    "        \n",
    "#     def get_target(self, anchorbox, label, x1, y1, x2, y2, num_classes=20):\n",
    "#         bg_index = num_classes - 1\n",
    "#         num_anchor = anchorbox.shape[0]\n",
    "#         target_cls = np.zeros(shape=(num_anchor), dtype=np.int64) + (bg_index)  #initializing with bg_index\n",
    "#         target_loc = np.zeros(shape=(num_anchor, 4), dtype=np.float32)\n",
    "#         target_iou = np.zeros(shape=(num_anchor), dtype=np.float32)\n",
    "#         for _label, _x1, _y1, _x2, _y2 in zip(label, x1, y1, x2, y2):\n",
    "#             best_iou = 0.0\n",
    "#             for anchor_idx in range(num_anchor):\n",
    "#                 iou = get_iou((_x1, _y1, _x2, _y2), anchorbox[anchor_idx])\n",
    "\n",
    "#                 if iou > best_iou:\n",
    "#                     best_iou = iou\n",
    "#                     best_anchor_idx = anchor_idx\n",
    "#                 if iou > target_iou[anchor_idx]:    \n",
    "#                     if iou > 0.5 :\n",
    "#                         target_cls[anchor_idx] = _label\n",
    "#                         target_loc[anchor_idx] = get_loc_offset((_x1, _y1, _x2, _y2), anchorbox[anchor_idx])\n",
    "#                         target_iou[anchor_idx] = iou\n",
    "#                     elif iou >0.4:\n",
    "#                         target_cls[anchor_idx] = -2 #ignore this example\n",
    "#                         target_iou[anchor_idx] = iou\n",
    "#                     else:\n",
    "#                         target_cls[anchor_idx] = bg_index\n",
    "#                         target_iou[anchor_idx] = iou\n",
    "#             if best_iou > 0 and best_iou < 0.5: #if gt has no >0.5 iou with any anchor\n",
    "#                 target_cls[best_anchor_idx] = _label\n",
    "#                 target_loc[best_anchor_idx] = get_loc_offset((_x1, _y1, _x2, _y2), anchorbox[best_anchor_idx])\n",
    "#                 target_iou[best_anchor_idx] = 1.0  # \n",
    "#         return target_cls, target_loc\n",
    "        \n",
    "        \n",
    "    def get_target(self, anchorbox, label, x1, y1, x2, y2, num_classes=20):\n",
    "        bg_index = num_classes -1\n",
    "        query_box= np.zeros((0,4))\n",
    "        query_label = np.zeros((0))\n",
    "        for _x1, _y1, _x2, _y2,_label in zip(x1, y1, x2, y2, label):\n",
    "            query_box = np.append(query_box, np.array([[_x1,_y1,_x2,_y2]]), axis=0)\n",
    "            query_label = np.append(query_label, _label)\n",
    "        \n",
    "        overlap = compute_overlap(anchorbox.astype(np.float64), query_box.astype(np.float64))\n",
    "        argmax_overlaps_inds = np.argmax(overlap, axis=1)\n",
    "        max_overlaps = overlap[ np.arange(overlap.shape[0]) , argmax_overlaps_inds]\n",
    "        positive_index = (max_overlaps > 0.5)\n",
    "        ignore_index = (max_overlaps > 0.4)  & ~positive_index\n",
    "        negative_index = (max_overlaps <= 0.4)\n",
    "        \n",
    "        target_loc = get_loc_offset(query_box[ argmax_overlaps_inds, :], anchorbox)\n",
    "        target_cls = query_label[argmax_overlaps_inds]\n",
    "        target_cls[negative_index] = bg_index\n",
    "        target_cls[ignore_index] = -2 # ignore this example\n",
    "        \n",
    "        return target_cls, target_loc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_anchors_core(self, base_size, ratios, scales):\n",
    "        num_anchors = len(ratios) * len(scales)\n",
    "        # initialize output anchors\n",
    "        anchors = np.zeros((num_anchors, 4))\n",
    "        # scale base_size\n",
    "        anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T\n",
    "\n",
    "        # compute areas of anchors\n",
    "        areas = anchors[:, 2] * anchors[:, 3]\n",
    "\n",
    "        # correct for ratios\n",
    "        anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales)))\n",
    "        anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales))\n",
    "\n",
    "        # transform from (x_ctr, y_ctr, w, h) -> (x1, y1, x2, y2)\n",
    "        anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\n",
    "        anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\n",
    "\n",
    "        return anchors\n",
    "    \n",
    "    def shift(self, image_shape, stride, anchors):\n",
    "        shift_x = (np.arange(0, image_shape[1]) + 0.5) * stride\n",
    "        shift_y = (np.arange(0, image_shape[0]) + 0.5) * stride\n",
    "        shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n",
    "\n",
    "        shifts = np.vstack((\n",
    "            shift_x.ravel(), shift_y.ravel(),\n",
    "            shift_x.ravel(), shift_y.ravel()\n",
    "        )).transpose()\n",
    "\n",
    "        A = anchors.shape[0]\n",
    "        K = shifts.shape[0]\n",
    "        all_anchors = (anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2)))\n",
    "        all_anchors = all_anchors.reshape((K * A, 4))\n",
    "\n",
    "        return all_anchors\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sample_array = np.zeros((0, 4))\n",
    "# sample_array\n",
    "# for i in range(2):\n",
    "#     sample_array = np.append(sample_array,np.array([[i,i,i,i]]), axis=0)\n",
    "# sample_array\n",
    "\n",
    "# sample_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaLoss(Loss):\n",
    "    def focal_loss(self, cls_gt_example, cls_pred_example, num_classes, alpha=0.25, gamma=2.0):\n",
    "        bg_index = num_classes - 1 \n",
    "        # cls_gt has shape [A], cls_pred is in [A, K]\n",
    "        # gather the objects and background, discard the rest\n",
    "        obj_idx = tf.where(tf.logical_and( tf.greater_equal(cls_gt_example, 0), tf.less(cls_gt_example, bg_index)))\n",
    "        obj_bg_idx = tf.where(tf.greater_equal(cls_gt_example, 0))\n",
    "        obj_bg_count = tf.cast(tf.shape(obj_bg_idx)[0], tf.float32)\n",
    "        obj_count = tf.cast(tf.maximum(tf.shape(obj_idx)[0],1), tf.float32)\n",
    "        cls_gt_example = tf.one_hot(cls_gt_example, num_classes)\n",
    "        cls_gt_example = tf.gather_nd(cls_gt_example, obj_bg_idx)\n",
    "        cls_pred_example = tf.gather_nd(cls_pred_example, obj_bg_idx)\n",
    "        cls_gt_example = tf.reshape(cls_gt_example, (-1, 1))\n",
    "        cls_pred_example = tf.reshape(cls_pred_example, (-1, 1))\n",
    "        # compute the focal weight on each selected anchor box\n",
    "        alpha_factor = tf.ones_like(cls_gt_example) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(cls_gt_example, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = tf.where(tf.equal(cls_gt_example, 1), 1 - cls_pred_example, cls_pred_example)\n",
    "#         print(f'obj_count: {obj_count}')\n",
    "        focal_weight = alpha_factor * focal_weight**gamma / obj_count\n",
    "        cls_loss = tf.losses.BinaryCrossentropy(reduction='sum')(cls_gt_example, cls_pred_example, sample_weight=focal_weight)\n",
    "        return cls_loss, obj_idx\n",
    "\n",
    "    def smooth_l1(self, loc_gt_example, loc_pred_example, obj_idx):\n",
    "        # loc_gt anf loc_pred has shape [A, 4]\n",
    "        sigma= 3\n",
    "        sigma_squared = sigma ** 3\n",
    "        obj_count = tf.cast(tf.maximum(tf.shape(obj_idx)[0],1), tf.float32)\n",
    "        loc_gt = tf.gather_nd(loc_gt_example, obj_idx)\n",
    "        loc_pred = tf.gather_nd(loc_pred_example, obj_idx)\n",
    "        loc_gt = tf.reshape(loc_gt, (-1, 1))\n",
    "        loc_pred = tf.reshape(loc_pred, (-1, 1))\n",
    "        loc_diff = tf.abs(loc_gt - loc_pred)\n",
    "        smooth_l1_loss = tf.where(tf.less(loc_diff, 1/sigma_squared), 0.5 * loc_diff**2 * sigma_squared, \n",
    "                                  loc_diff - 0.5/sigma_squared)\n",
    "        smooth_l1_loss = tf.reduce_sum(smooth_l1_loss)/ obj_count\n",
    "        return smooth_l1_loss\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        cls_gt, loc_gt, cls_pred, loc_pred = data\n",
    "        cls_gt = tf.cast(cls_gt, tf.int32 )\n",
    "        batch_size = state[\"batch_size_per_device\"]\n",
    "        total_loss = []\n",
    "        for idx in range(batch_size):\n",
    "            cls_gt_example = cls_gt[idx]\n",
    "            loc_gt_example = loc_gt[idx]\n",
    "            cls_pred_example = cls_pred[idx]\n",
    "            loc_pred_example = loc_pred[idx]\n",
    "            focal_loss, obj_idx = self.focal_loss(cls_gt_example, cls_pred_example, num_classes=80+1)\n",
    "            smooth_l1_loss = self.smooth_l1(loc_gt_example, loc_pred_example, obj_idx)\n",
    "            total_loss.append(focal_loss + smooth_l1_loss)\n",
    "#             print(f'focal loss {focal_loss}')\n",
    "#             print(f'smooth loss: {smooth_l1_loss}')\n",
    "        total_loss = tf.convert_to_tensor(total_loss)\n",
    "        return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictBox(TensorOp):\n",
    "    def __init__(self, num_classes, inputs=None, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.num_classes = num_classes\n",
    "        self.bg_index = num_classes - 1\n",
    "                   \n",
    "    def forward(self, data, state):\n",
    "        cls_pred, loc_pred, loc_base = data\n",
    "        input_width = 1280\n",
    "        input_height = 800\n",
    "        top_n = 300\n",
    "        score_threshold = 0.05   \n",
    "        std = 0.2\n",
    "        mean = 0\n",
    "        # convert the residual prediction to absolute prediction in (x1, y1, x2, y2)\n",
    "        anchor_w_h = tf.tile(loc_base[:,:, 2:], [1, 1, 2]) - tf.tile(loc_base[:,:,:2], [1, 1, 2])\n",
    "        anchorbox =  loc_base\n",
    "        loc_pred_abs = tf.map_fn(lambda x: (x[0]*std+mean) * x[1] + x[2],\n",
    "                             elems=(loc_pred, anchor_w_h, anchorbox),\n",
    "                             dtype=tf.float32,\n",
    "                             back_prop=False)\n",
    "        x1 = tf.clip_by_value(loc_pred_abs[:, :, 0], 0, input_width)\n",
    "        y1 = tf.clip_by_value(loc_pred_abs[:, :, 1], 0, input_height)\n",
    "        x2 = tf.clip_by_value(loc_pred_abs[:, :, 2], 0, input_width)\n",
    "        y2 = tf.clip_by_value(loc_pred_abs[:, :, 3], 0, input_height)\n",
    "        loc_pred_abs = tf.stack([x1, y1, x2, y2] ,axis=2)\n",
    "        \n",
    "        num_batch, num_anchor, _ = loc_pred_abs.shape\n",
    "        cls_best_score = tf.reduce_max(cls_pred, axis=-1)\n",
    "        cls_best_class = tf.argmax(cls_pred, axis=-1)\n",
    "        \n",
    "        cls_best_score = tf.where(tf.not_equal(cls_best_class, self.bg_index), cls_best_score,0)\n",
    "        \n",
    "        # select top n anchor boxes to proceed\n",
    "        # Padded Nonmax suppression with threshold\n",
    "        selected_indices_padded = tf.map_fn(\n",
    "            lambda x: tf.image.non_max_suppression_padded(\n",
    "                x[0], x[1], top_n, pad_to_max_output_size=True, score_threshold=score_threshold).selected_indices,\n",
    "            (loc_pred_abs, cls_best_score),\n",
    "            dtype=tf.int32,\n",
    "            back_prop=False)\n",
    "        valid_outputs = tf.map_fn(\n",
    "            lambda x: tf.image.non_max_suppression_padded(\n",
    "                x[0], x[1], top_n, pad_to_max_output_size=True, score_threshold=score_threshold).valid_outputs,\n",
    "            (loc_pred_abs, cls_best_score),\n",
    "            dtype=tf.int32,\n",
    "            back_prop=False)\n",
    "        return loc_pred_abs, selected_indices_padded, valid_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/coco/'\n",
    "train_csv = os.path.join(path,'train_coco10k.csv')\n",
    "val_csv = os.path.join(path,'val_coco10k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32*40, 32*25\n",
    "writer = RecordWriter(\n",
    "        train_data=train_csv,\n",
    "        save_dir = '/home/ubuntu/coco/tf_records',\n",
    "        validation_data=val_csv,\n",
    "        ops=[\n",
    "                ImageReader(inputs=\"image\", parent_path=path, outputs=\"image\"),\n",
    "                String2IntArray(inputs=[\"label\"], outputs=[\"label\"]),\n",
    "                String2FloatArray(inputs=[\"x1\", \"y1\", \"x2\", \"y2\"], outputs=[\"x1\", \"y1\", \"x2\", \"y2\"]),\n",
    "                ResnetPreprocess(inputs=\"image\", outputs=\"image\"), \n",
    "                ResizeCocoStyle((800, 1280), keep_ratio=True, inputs=[\"image\", \"x1\", \"y1\", \"x2\", \"y2\" ] , outputs=[\"image\",\"x1\",\"y1\",\"x2\",\"y2\"]),\n",
    "                GenerateTarget(inputs=[\"label\",\"x1\",\"y1\",\"x2\",\"y2\",\"image\"], outputs=[\"target_cls\",\"target_loc\",\"base_loc\"], input_shape=(800,1280,3))\n",
    "        ])\n",
    "\n",
    "pipeline = Pipeline(batch_size=2, data=writer, read_feature=[\"image\",\"image_id\", \"target_cls\", \"target_loc\",\"base_loc\"])\n",
    "# pipeline = Pipeline(batch_size=2, data=writer, read_feature=[\"image\",\"image_id\", \"x1\",\"y1\",\"x2\",\"y2\"], padded_batch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator: Reading non-empty directory: /home/ubuntu/coco/tf_records\n",
      "FastEstimator: Found 10000 examples for train in /home/ubuntu/coco/tf_records/train_summary0.json\n",
      "FastEstimator: Found 1000 examples for eval in /home/ubuntu/coco/tf_records/eval_summary0.json\n"
     ]
    }
   ],
   "source": [
    "show_batch = pipeline.show_results(mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1,2,2],[2,2,3,3],[3,3,4,4],[4,4,5,5]])\n",
    "b = np.array([2,2,2,2])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.tile(a[:,2:]-a[:,:2],[1,2])\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=475, shape=(8, 191970), dtype=float32, numpy=\n",
       "array([[80., 80., 80., ..., 80., 80., 80.],\n",
       "       [80., 80., 80., ..., 80., 80., 80.],\n",
       "       [80., 80., 80., ..., 80., 80., 80.],\n",
       "       ...,\n",
       "       [80., 80., 80., ..., 80., 80., 80.],\n",
       "       [80., 80., 80., ..., 80., 80., 80.],\n",
       "       [80., 80., 80., ..., 80., 80., 80.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_batch[0]['target_cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=476, shape=(8, 191970, 4), dtype=float32, numpy=\n",
       "array([[[ 6.89017487e+01,  7.49047852e+01,  1.00914368e+02,\n",
       "          1.15572098e+02],\n",
       "        [ 5.52031021e+01,  5.99677200e+01,  7.95800400e+01,\n",
       "          9.12138901e+01],\n",
       "        [ 4.43304787e+01,  4.81121597e+01,  6.26469688e+01,\n",
       "          7.18807602e+01],\n",
       "        ...,\n",
       "        [-5.93832493e+00, -9.54971611e-01, -6.31174755e+00,\n",
       "         -4.52786827e+00],\n",
       "        [-4.19750309e+00, -2.42212787e-01, -5.52538586e+00,\n",
       "         -4.10951996e+00],\n",
       "        [-2.81581163e+00,  3.23504269e-01, -4.90125036e+00,\n",
       "         -3.77747679e+00]],\n",
       "\n",
       "       [[ 9.70755310e+01,  7.85876389e+01,  1.01835075e+02,\n",
       "          9.45798721e+01],\n",
       "        [ 7.75646515e+01,  6.28907967e+01,  8.03108063e+01,\n",
       "          7.45523453e+01],\n",
       "        [ 6.20788536e+01,  5.04322052e+01,  6.32269821e+01,\n",
       "          5.86564865e+01],\n",
       "        ...,\n",
       "        [-2.41660190e+00, -8.39882612e-01, -6.19665861e+00,\n",
       "         -5.18387556e+00],\n",
       "        [-1.40230942e+00, -1.50866583e-01, -5.43403959e+00,\n",
       "         -4.63019323e+00],\n",
       "        [-5.97265065e-01,  3.96005780e-01, -4.82874870e+00,\n",
       "         -4.19073534e+00]],\n",
       "\n",
       "       [[ 5.25130730e+01,  2.15034943e+01,  6.99784470e+01,\n",
       "          1.00104141e+02],\n",
       "        [ 4.21954041e+01,  1.75830841e+01,  5.50261803e+01,\n",
       "          7.89369583e+01],\n",
       "        [ 3.40062637e+01,  1.44714518e+01,  4.31585579e+01,\n",
       "          6.21365585e+01],\n",
       "        ...,\n",
       "        [-7.98690939e+00, -2.62376213e+00, -1.01787376e+01,\n",
       "         -5.01124191e+00],\n",
       "        [-5.82346535e+00, -1.56673265e+00, -8.59461784e+00,\n",
       "         -4.49317408e+00],\n",
       "        [-4.10633898e+00, -7.27767825e-01, -7.33730173e+00,\n",
       "         -4.08198309e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.71014233e+01,  4.69151459e+01,  3.79376678e+01,\n",
       "          8.20581894e+01],\n",
       "        [ 2.20261631e+01,  3.77523232e+01,  2.95953999e+01,\n",
       "          6.46138763e+01],\n",
       "        [ 1.79979248e+01,  3.04797878e+01,  2.29741344e+01,\n",
       "          5.07683182e+01],\n",
       "        ...,\n",
       "        [ 1.22021043e+00, -5.98195732e-01, -3.08925557e+00,\n",
       "         -4.73502827e+00],\n",
       "        [ 1.48423028e+00,  4.09604199e-02, -2.96769261e+00,\n",
       "         -4.27394295e+00],\n",
       "        [ 1.69378304e+00,  5.48259020e-01, -2.87120771e+00,\n",
       "         -3.90797949e+00]],\n",
       "\n",
       "       [[ 7.11114578e+01,  9.27666016e+01,  6.94260178e+01,\n",
       "          9.13573761e+01],\n",
       "        [ 5.69569473e+01,  7.41446457e+01,  5.45877190e+01,\n",
       "          7.19946518e+01],\n",
       "        [ 4.57225075e+01,  5.93643951e+01,  4.28105507e+01,\n",
       "          5.66264420e+01],\n",
       "        ...,\n",
       "        [-5.66211128e+00, -3.96789998e-01, -1.02477913e+01,\n",
       "         -5.28457832e+00],\n",
       "        [-3.97827220e+00,  2.00816259e-01, -8.64942551e+00,\n",
       "         -4.71012115e+00],\n",
       "        [-2.64180803e+00,  6.75136685e-01, -7.38080263e+00,\n",
       "         -4.25417423e+00]],\n",
       "\n",
       "       [[ 3.02318439e+01,  8.59533310e+01,  4.67765045e+01,\n",
       "          1.12257538e+02],\n",
       "        [ 2.45107784e+01,  6.87369537e+01,  3.66107864e+01,\n",
       "          8.85831146e+01],\n",
       "        [ 1.99699669e+01,  5.50723038e+01,  2.85422516e+01,\n",
       "          6.97927170e+01],\n",
       "        ...,\n",
       "        [-1.07720633e+01, -6.09704614e-01, -1.30789804e+01,\n",
       "         -4.63144827e+00],\n",
       "        [-8.03404331e+00,  3.18258032e-02, -1.08965425e+01,\n",
       "         -4.19173145e+00],\n",
       "        [-5.86087561e+00,  5.41008830e-01, -9.16434002e+00,\n",
       "         -3.84272814e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_batch[0]['target_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(show_batch))\n",
    "# show_batch[0].keys()\n",
    "\n",
    "# show_batch[0]['base_loc'][0]\n",
    "\n",
    "# batch_idx=0\n",
    "# high = len(show_batch[batch_idx]['image_id'])\n",
    "# idx = np.random.randint(low=0,high=high)\n",
    "# print('selected index', idx)\n",
    "# image = show_batch[batch_idx]['image'][idx]\n",
    "# target_cls = show_batch[batch_idx]['target_cls'][idx]\n",
    "# target_loc = show_batch[batch_idx]['target_loc'][idx]\n",
    "# base_loc = show_batch[batch_idx]['base_loc'][idx]\n",
    "\n",
    "# bg_index = 80\n",
    "# obj_idx = tf.where(tf.logical_and( tf.greater(target_cls, 0), tf.less(target_cls, bg_index)))\n",
    "# # obj_bg_idx = tf.where(tf.greater_equal(target_cls, 0))\n",
    "# target_cls_filt = tf.gather_nd(target_cls, obj_idx)\n",
    "# target_loc_filt = tf.gather_nd(target_loc, obj_idx)\n",
    "\n",
    "# print(target_loc_filt)\n",
    "# print(target_cls_filt)\n",
    "# print(base_loc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.84s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# prepare model\n",
    "model = FEModel(model_def=lambda: RetinaNet(input_shape=(800, 1280, 3), num_classes=80+1),\n",
    "                model_name=\"retinanet\",\n",
    "                optimizer=tf.optimizers.Adam(learning_rate=0.0001))\n",
    "network = Network(ops=[\n",
    "    ModelOp(inputs=\"image\", model=model, outputs=[\"pred_cls\", \"pred_loc\"]),\n",
    "    PredictBox(80+1, inputs=[\"pred_cls\",\"pred_loc\",\"base_loc\"], outputs=(\"abs_loc\",\"selected_indices_padded\", \"valid_outputs\"), mode=\"eval\"),\n",
    "    RetinaLoss(inputs=(\"target_cls\", \"target_loc\", \"pred_cls\", \"pred_loc\"), outputs=\"loss\"),\n",
    "])\n",
    "# prepare estimator\n",
    "model_dir = '/home/ubuntu/coco/bestmodel'\n",
    "traces = [MeanAveragePrecision('selected_indices_padded','valid_outputs','image_id','pred_cls', 'abs_loc',\n",
    "                                coco_path='/home/ubuntu/coco',coco_ds_year=2014 ), \n",
    "            LRController(model_name=\"retinanet\", reduce_on_eval=True, reduce_patience=3, min_lr=1e-09,  reduce_factor=0.33),\n",
    "            ModelSaver(model_name=\"retinanet\", save_dir=model_dir, save_best=True)\n",
    "         ]\n",
    "estimator = Estimator(network=network, pipeline=pipeline, epochs=100, log_steps=10, traces=traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator: Reading non-empty directory: /home/ubuntu/coco/tf_records\n",
      "FastEstimator: Found 10000 examples for train in /home/ubuntu/coco/tf_records/train_summary0.json\n",
      "FastEstimator: Found 1000 examples for eval in /home/ubuntu/coco/tf_records/eval_summary0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 04:55:54.132895 139906083018560 mirrored_strategy.py:659] Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "W1015 04:55:59.247574 139888108467968 deprecation.py:323] From /home/ubuntu/anaconda3/envs/fastesti2/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py:477: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1015 04:56:18.502044 139906083018560 mirrored_strategy.py:659] Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "W1015 04:56:19.832570 139906083018560 mirrored_strategy.py:659] Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Start: step: 0; retinanet_lr: 1e-04; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 04:56:29.538000 139906083018560 mirrored_strategy.py:659] Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 0; loss: 4489.444; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 04:56:32.200864 139906083018560 mirrored_strategy.py:659] Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 10; loss: 41.88887; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 20; loss: 21.290192; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 30; loss: 20.340519; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 40; loss: 18.5518; examples/sec: 2.96; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 50; loss: 17.885147; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 60; loss: 18.988167; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 70; loss: 28.021763; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 80; loss: 20.092094; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 90; loss: 18.96027; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 100; loss: 18.66523; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 110; loss: 18.218472; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 120; loss: 18.01212; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 130; loss: 18.600708; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 140; loss: 207.08316; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 150; loss: 19.559128; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 160; loss: 17.534096; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 170; loss: 17.406303; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 180; loss: 666.4816; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 190; loss: 17.916023; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 200; loss: 117.77456; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 210; loss: 14.411619; examples/sec: 2.97; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 220; loss: 14.436371; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 230; loss: 16.735298; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 240; loss: 97.684265; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 250; loss: 15.58795; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 260; loss: 62.332676; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 270; loss: 17.05587; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 280; loss: 10.592911; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 290; loss: 9.344311; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 300; loss: 9.488419; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 310; loss: 10.054091; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 320; loss: 9.065732; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 330; loss: 9.024427; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 340; loss: 21.96874; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 350; loss: 7.493613; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 360; loss: 32.94456; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 370; loss: 17.903097; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 380; loss: 8.115; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 390; loss: 8.381969; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 400; loss: 6.600794; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 410; loss: 23.553942; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 420; loss: 7.2466497; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 430; loss: 7.0756354; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 440; loss: 6.7674403; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 450; loss: 147.75146; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 460; loss: 10.9223385; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 470; loss: 7.7695746; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 480; loss: 6.466339; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 490; loss: 12.785761; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 500; loss: 6.565401; examples/sec: 3.11; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 510; loss: 6.0616903; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 520; loss: 7.4282618; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 530; loss: 15.10935; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 540; loss: 5.551008; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 550; loss: 5.0353756; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 560; loss: 97.417366; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 570; loss: 6.7392445; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 580; loss: 8.2645855; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 590; loss: 6.396163; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 600; loss: 6.4477043; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 610; loss: 5.3488417; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 620; loss: 14.480638; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 630; loss: 5.3951335; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 640; loss: 5.3537254; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 650; loss: 5.02545; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 660; loss: 6.380514; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 670; loss: 5.3061295; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 680; loss: 6.034152; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 690; loss: 4.946086; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 700; loss: 8.219741; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 710; loss: 5.1230783; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 720; loss: 9.175847; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 730; loss: 7.042897; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 740; loss: 6.655839; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 750; loss: 6.882744; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 760; loss: 7.3112874; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 770; loss: 5.0844955; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 780; loss: 5.5778275; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 790; loss: 14.900836; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 800; loss: 5.4029474; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 810; loss: 12.055637; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 820; loss: 10.649316; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 830; loss: 5.358068; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 840; loss: 5.703207; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 850; loss: 4.8698106; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 860; loss: 16.02026; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 870; loss: 144.9375; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 880; loss: 6.189679; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 890; loss: 6.149572; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 900; loss: 5.40114; examples/sec: 3.09; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 910; loss: 5.440198; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 920; loss: 4.9184494; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 930; loss: 5.280037; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 940; loss: 6.096467; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 950; loss: 6.1150527; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 960; loss: 6.012212; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 970; loss: 5.2539234; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 980; loss: 4.6696987; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 990; loss: 5.8254013; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1000; loss: 5.344635; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1010; loss: 4.793793; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1020; loss: 4.502322; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1030; loss: 4.7385473; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1040; loss: 9.385349; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1050; loss: 4.440667; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1060; loss: 4.7261424; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1070; loss: 4.539055; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1080; loss: 4.652816; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1090; loss: 4.7205915; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1100; loss: 4.6103215; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1110; loss: 38.655052; examples/sec: 3.06; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1120; loss: 5.4046454; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1130; loss: 4.90641; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1140; loss: 4.818348; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1150; loss: 26.341724; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1160; loss: 4.900552; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1170; loss: 5.5187826; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1180; loss: 15.847948; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1190; loss: 4.3777475; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1200; loss: 7.1868362; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1210; loss: 4.399871; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1220; loss: 4.9603043; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1230; loss: 4.8570623; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1240; loss: 7.888263; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 1250; epoch: 0; loss: 7.780156; min_loss: 7.780156; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 1250; loss: 6.0472403; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1260; loss: 4.3276076; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1270; loss: 4.7589803; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1280; loss: 4.4095573; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1290; loss: 11.14818; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1300; loss: 4.709404; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1310; loss: 4.362582; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1320; loss: 6.417455; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1330; loss: 5.248095; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1340; loss: 4.073676; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1350; loss: 4.4450903; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1360; loss: 4.7585087; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1370; loss: 6.3875594; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1380; loss: 5.1945915; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1390; loss: 4.428787; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1400; loss: 7.0969925; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1410; loss: 4.155261; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1420; loss: 4.3028083; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1430; loss: 4.1327505; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1440; loss: 4.572501; examples/sec: 2.96; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1450; loss: 4.3070602; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1460; loss: 4.4164076; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1470; loss: 4.27697; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1480; loss: 4.113241; examples/sec: 3.11; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1490; loss: 8.624647; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1500; loss: 4.5290675; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1510; loss: 4.595063; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1520; loss: 4.5729; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1530; loss: 6.714815; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1540; loss: 3.8787346; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1550; loss: 13.96069; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1560; loss: 4.5298057; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1570; loss: 3.4569561; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1580; loss: 3.4709787; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1590; loss: 4.1439023; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1600; loss: 4.0546794; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1610; loss: 6.2467413; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1620; loss: 4.204337; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1630; loss: 4.42619; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1640; loss: 4.426407; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1650; loss: 4.3508806; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1660; loss: 4.774944; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1670; loss: 4.654893; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1680; loss: 5.1438246; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1690; loss: 4.2831864; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1700; loss: 3.7984114; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1710; loss: 4.9358797; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1720; loss: 3.9955487; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1730; loss: 4.0869236; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1740; loss: 3.9396238; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1750; loss: 16.520094; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1760; loss: 5.127453; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1770; loss: 4.284; examples/sec: 3.04; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 1780; loss: 4.163662; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1790; loss: 5.3557796; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1800; loss: 5.7527184; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1810; loss: 4.032273; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1820; loss: 4.9272623; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1830; loss: 9.682792; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1840; loss: 6.2424774; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1850; loss: 4.765012; examples/sec: 3.11; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1860; loss: 3.9877264; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1870; loss: 27.579454; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1880; loss: 5.2553997; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1890; loss: 4.149248; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1900; loss: 4.470192; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1910; loss: 4.4962234; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1920; loss: 4.043618; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1930; loss: 4.678266; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1940; loss: 4.6697516; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1950; loss: 4.8093996; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1960; loss: 3.7824888; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1970; loss: 6.332826; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1980; loss: 25.186016; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 1990; loss: 74.238976; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2000; loss: 4.3039646; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2010; loss: 7.9811316; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2020; loss: 6.8186755; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2030; loss: 6.3067274; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2040; loss: 11.724069; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2050; loss: 5.382831; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2060; loss: 5.716633; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2070; loss: 6.389847; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2080; loss: 5.625635; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2090; loss: 5.815558; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2100; loss: 6.410378; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2110; loss: 4.796208; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2120; loss: 6.3750305; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2130; loss: 104.45268; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2140; loss: 21.577888; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2150; loss: 10.336812; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2160; loss: 7.57047; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2170; loss: 7.47907; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2180; loss: 5.4078054; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2190; loss: 12.142899; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2200; loss: 5.1460505; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2210; loss: 4.4411526; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2220; loss: 4.208402; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2230; loss: 15.47114; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2240; loss: 6.1568327; examples/sec: 3.11; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2250; loss: 18.253628; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2260; loss: 119.897675; examples/sec: 3.06; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2270; loss: 16.337048; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2280; loss: 15.082058; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2290; loss: 20.841629; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2300; loss: 13.033529; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2310; loss: 14.999244; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2320; loss: 28.522644; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2330; loss: 18.584518; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2340; loss: 12.427031; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2350; loss: 10.391407; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2360; loss: 12.131235; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2370; loss: 8.644947; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2380; loss: 18.638018; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2390; loss: 10.163973; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2400; loss: 32.346466; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2410; loss: 8.979204; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2420; loss: 11.332895; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2430; loss: 12.190576; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2440; loss: 9.583313; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2450; loss: 12.534565; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2460; loss: 14.537836; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2470; loss: 10.332466; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2480; loss: 8.679365; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2490; loss: 84.94121; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-Eval: step: 2500; epoch: 1; loss: 24.661833; min_loss: 7.780156; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 2500; loss: 19.434875; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2510; loss: 33.516136; examples/sec: 2.97; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2520; loss: 10.244616; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2530; loss: 16.240435; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2540; loss: 54.67668; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2550; loss: 50.28799; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2560; loss: 12.097826; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2570; loss: 10.440954; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2580; loss: 16.471806; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2590; loss: 9.302669; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2600; loss: 16.588337; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2610; loss: 17.467655; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2620; loss: 17.15361; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2630; loss: 16.413366; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2640; loss: 16.80757; examples/sec: 3.03; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 2650; loss: 16.181946; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2660; loss: 6972.3467; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2670; loss: 12.169367; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2680; loss: 78.73511; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2690; loss: 12.3748; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2700; loss: 12.6902275; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2710; loss: 15.327547; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2720; loss: 23.978071; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2730; loss: 37.404625; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2740; loss: 13.902098; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2750; loss: 15.029528; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2760; loss: 26.701624; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2770; loss: 10.696594; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2780; loss: 14.591568; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2790; loss: 12.881088; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2800; loss: 10.892799; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2810; loss: 8.610872; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2820; loss: 9.721832; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2830; loss: 14.705788; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2840; loss: 10.362549; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2850; loss: 11.962384; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2860; loss: 11.818657; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2870; loss: 10.582663; examples/sec: 3.12; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2880; loss: 23.263111; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2890; loss: 12.229139; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2900; loss: 12.798239; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2910; loss: 6.90872; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2920; loss: 12.459452; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2930; loss: 10.211454; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2940; loss: 7.6636333; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2950; loss: 10.838106; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2960; loss: 14.298096; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2970; loss: 7.745882; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2980; loss: 11.0952215; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 2990; loss: 8.153378; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3000; loss: 11.640554; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3010; loss: 10.275433; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3020; loss: 8.092449; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3030; loss: 11.613098; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3040; loss: 6.7718725; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3050; loss: 9.090686; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3060; loss: 12.336689; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3070; loss: 9.462702; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3080; loss: 9.617606; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3090; loss: 9.695899; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3100; loss: 8.974597; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3110; loss: 11.567245; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3120; loss: 29.655272; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3130; loss: 67.85331; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3140; loss: 7.5118585; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3150; loss: 10.996997; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3160; loss: 49.959152; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3170; loss: 7.853673; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3180; loss: 11.561026; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3190; loss: 11.654339; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3200; loss: 8.85068; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3210; loss: 10.257657; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3220; loss: 9.311628; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3230; loss: 10.749089; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3240; loss: 8.496828; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3250; loss: 11.564298; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3260; loss: 9.349061; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3270; loss: 8.801697; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3280; loss: 9.6964855; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3290; loss: 7.5795918; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3300; loss: 83.49814; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3310; loss: 10.74153; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3320; loss: 41.461536; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3330; loss: 7.736828; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3340; loss: 10.227506; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3350; loss: 7.1027937; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3360; loss: 7.914758; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3370; loss: 10.586737; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3380; loss: 8.606363; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3390; loss: 6.969095; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3400; loss: 8.851374; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3410; loss: 15.982668; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3420; loss: 12.262482; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3430; loss: 6.9875426; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3440; loss: 6.5624447; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3450; loss: 7.393355; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3460; loss: 9.728826; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3470; loss: 10.188824; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3480; loss: 5.172201; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3490; loss: 6.915118; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3500; loss: 6.870988; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3510; loss: 215.79256; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3520; loss: 42.132202; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3530; loss: 6.7878213; examples/sec: 3.01; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 3540; loss: 11.409915; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3550; loss: 138.16571; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3560; loss: 12.52142; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3570; loss: 9.488941; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3580; loss: 9.086489; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3590; loss: 11.388371; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3600; loss: 35.45281; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3610; loss: 11.353226; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3620; loss: 12.592395; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3630; loss: 9.648742; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3640; loss: 8.470264; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3650; loss: 8.014986; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3660; loss: 14.006178; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3670; loss: 10.097721; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3680; loss: 32.755703; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3690; loss: 7.5135946; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3700; loss: 144.52193; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3710; loss: 54.923748; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3720; loss: 10.263643; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3730; loss: 12.806387; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3740; loss: 12.838818; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-Eval: step: 3750; epoch: 2; loss: 16.35761; min_loss: 7.780156; since_best_loss: 2; \n",
      "FastEstimator-Train: step: 3750; loss: 7.2017; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3760; loss: 9.047017; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3770; loss: 13.372565; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3780; loss: 117.330666; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3790; loss: 19.541836; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3800; loss: 12.071498; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3810; loss: 8.387306; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3820; loss: 13.574269; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3830; loss: 8.201719; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3840; loss: 7.748065; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3850; loss: 7.5954213; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3860; loss: 9.170921; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3870; loss: 15.3590975; examples/sec: 2.97; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3880; loss: 9.980953; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3890; loss: 12.346842; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3900; loss: 9.354912; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3910; loss: 9.230366; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3920; loss: 8.734276; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3930; loss: 9.521465; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3940; loss: 11.532396; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3950; loss: 10.336705; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3960; loss: 9.541914; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3970; loss: 12.940582; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3980; loss: 26.32716; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 3990; loss: 8.524166; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4000; loss: 8.02888; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4010; loss: 10.836971; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4020; loss: 9.387552; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4030; loss: 9.704196; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4040; loss: 9.692099; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4050; loss: 41.362514; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4060; loss: 19.015821; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4070; loss: 10.336496; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4080; loss: 8.723789; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4090; loss: 9.341402; examples/sec: 3.06; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4100; loss: 9.8201885; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4110; loss: 7.521591; examples/sec: 3.11; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4120; loss: 7.0816045; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4130; loss: 8.633989; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4140; loss: 10.062338; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4150; loss: 7.7015057; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4160; loss: 10.685118; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4170; loss: 7.9462185; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4180; loss: 9.580489; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4190; loss: 6.806529; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4200; loss: 10.3319; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4210; loss: 12.43558; examples/sec: 3.03; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4220; loss: 8.910368; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4230; loss: 56.85907; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4240; loss: 9.960823; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4250; loss: 12.674911; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4260; loss: 11.442017; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4270; loss: 7.0540533; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4280; loss: 11.265184; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4290; loss: 12.000652; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4300; loss: 8.788856; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4310; loss: 8.053377; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4320; loss: 8.787866; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4330; loss: 100.03717; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4340; loss: 11.778097; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4350; loss: 8.808122; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4360; loss: 9.291647; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4370; loss: 12.880272; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4380; loss: 8.917133; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4390; loss: 64.06109; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4400; loss: 12.207502; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4410; loss: 15.073626; examples/sec: 3.0; retinanet_lr: 0.0001; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 4420; loss: 27.404594; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4430; loss: 8.58303; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4440; loss: 11.655981; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4450; loss: 14.152287; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4460; loss: 8.887828; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4470; loss: 11.305538; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4480; loss: 25.806826; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4490; loss: 8.057903; examples/sec: 3.05; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4500; loss: 7.202816; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4510; loss: 9.274717; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4520; loss: 8.096905; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4530; loss: 14.798803; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4540; loss: 32.59485; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4550; loss: 8.667824; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4560; loss: 9.388587; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4570; loss: 9.918667; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4580; loss: 10.453765; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4590; loss: 6.807415; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4600; loss: 177.14072; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4610; loss: 12.515327; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4620; loss: 39.182114; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4630; loss: 9.492175; examples/sec: 3.07; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4640; loss: 53.710587; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4650; loss: 9.777803; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4660; loss: 13.095442; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4670; loss: 10.334923; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4680; loss: 12.099136; examples/sec: 2.98; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4690; loss: 106.44346; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4700; loss: 125.63737; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4710; loss: 9.080007; examples/sec: 2.97; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4720; loss: 6.154909; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4730; loss: 6.5231724; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4740; loss: 9.796009; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4750; loss: 8.047068; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4760; loss: 73.26223; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4770; loss: 9.268993; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4780; loss: 10.345024; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4790; loss: 22.03531; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4800; loss: 11.651434; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4810; loss: 11.907363; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4820; loss: 9.053142; examples/sec: 2.99; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4830; loss: 8.972277; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4840; loss: 11.119512; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4850; loss: 9.564171; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4860; loss: 11.128086; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4870; loss: 9.196759; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4880; loss: 9.182453; examples/sec: 3.1; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4890; loss: 8.633343; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4900; loss: 8.477563; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4910; loss: 7.492322; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4920; loss: 9.161808; examples/sec: 3.09; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4930; loss: 7.793801; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4940; loss: 7.5302944; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4950; loss: 12.074488; examples/sec: 3.0; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4960; loss: 8.615339; examples/sec: 3.01; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4970; loss: 8.806835; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4980; loss: 9.593116; examples/sec: 3.02; retinanet_lr: 0.0001; \n",
      "FastEstimator-Train: step: 4990; loss: 13.059241; examples/sec: 3.08; retinanet_lr: 0.0001; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-LRController: learning rate reduced by factor of 0.33\n",
      "FastEstimator-Eval: step: 5000; epoch: 3; loss: 14.993944; min_loss: 7.780156; since_best_loss: 3; \n",
      "FastEstimator-Train: step: 5000; loss: 9.09725; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5010; loss: 7.801058; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5020; loss: 7.8372955; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5030; loss: 6.769694; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5040; loss: 8.1077585; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5050; loss: 10.100203; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5060; loss: 11.045732; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5070; loss: 9.401358; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5080; loss: 7.0868483; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5090; loss: 87.77792; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5100; loss: 8.504486; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5110; loss: 9.413781; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5120; loss: 30.532673; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5130; loss: 7.4152975; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5140; loss: 9.786596; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5150; loss: 9.528213; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5160; loss: 12.61088; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5170; loss: 10.403009; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5180; loss: 9.313161; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5190; loss: 9.897931; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5200; loss: 7.0765805; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5210; loss: 8.453414; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5220; loss: 13.24448; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5230; loss: 11.526068; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5240; loss: 10.35651; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5250; loss: 8.052905; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5260; loss: 10.3545885; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5270; loss: 8.633476; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5280; loss: 7.488703; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 5290; loss: 6.786724; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5300; loss: 15.25146; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5310; loss: 99.22125; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5320; loss: 5.8942914; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5330; loss: 6.214903; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5340; loss: 7.440377; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5350; loss: 7.2416763; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5360; loss: 14.251676; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5370; loss: 26.403566; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5380; loss: 8.170165; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5390; loss: 6.9146895; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5400; loss: 10.41411; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5410; loss: 56.027287; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5420; loss: 6.1939178; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5430; loss: 10.78899; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5440; loss: 10.117554; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5450; loss: 9.642433; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5460; loss: 7.1859617; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5470; loss: 7.375968; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5480; loss: 8.214165; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5490; loss: 9.468407; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5500; loss: 5.158041; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5510; loss: 8.797181; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5520; loss: 10.381163; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5530; loss: 10.436033; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5540; loss: 5.083212; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5550; loss: 6.415188; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5560; loss: 6.0035963; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5570; loss: 11.086837; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5580; loss: 6.9629664; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5590; loss: 75.261055; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5600; loss: 7.8396964; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5610; loss: 5.034737; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5620; loss: 6.963686; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5630; loss: 6.3103194; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5640; loss: 7.7168937; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5650; loss: 6.908393; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5660; loss: 6.1076727; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5670; loss: 6.1154943; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5680; loss: 7.528928; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5690; loss: 9.4474; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5700; loss: 6.519453; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5710; loss: 6.851405; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5720; loss: 7.9763184; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5730; loss: 5.670167; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5740; loss: 6.177044; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5750; loss: 7.3966208; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5760; loss: 5.542474; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5770; loss: 5.8819547; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5780; loss: 5.7933707; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5790; loss: 5.6775527; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5800; loss: 6.0827208; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5810; loss: 8.051016; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5820; loss: 6.6846104; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5830; loss: 7.2794495; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5840; loss: 7.312598; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5850; loss: 8.77425; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5860; loss: 6.1787815; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5870; loss: 7.63757; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5880; loss: 6.745406; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5890; loss: 13.138279; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5900; loss: 5.051724; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5910; loss: 5.4567094; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5920; loss: 10.284246; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5930; loss: 12.562338; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5940; loss: 8.921577; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5950; loss: 6.1153374; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5960; loss: 14.471611; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5970; loss: 12.314896; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5980; loss: 56.842983; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 5990; loss: 5.8023996; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6000; loss: 6.1240387; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6010; loss: 6.639511; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6020; loss: 6.7598753; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6030; loss: 6.059932; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6040; loss: 6.913893; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6050; loss: 6.086022; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6060; loss: 6.686671; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6070; loss: 9.41787; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6080; loss: 9.46865; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6090; loss: 5.937372; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6100; loss: 8.379545; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6110; loss: 9.090161; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6120; loss: 6.120949; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6130; loss: 7.142452; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6140; loss: 41.000874; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6150; loss: 5.270953; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6160; loss: 14.546997; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 6170; loss: 6.6098213; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6180; loss: 6.3321724; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6190; loss: 15.899292; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6200; loss: 5.476915; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6210; loss: 5.408903; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6220; loss: 5.1377115; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6230; loss: 8.120037; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6240; loss: 4.7525063; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 6250; epoch: 4; loss: 6.7818384; min_loss: 6.7818384; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 6250; loss: 4.823556; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6260; loss: 23.752586; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6270; loss: 6.0268908; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6280; loss: 4.3954983; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6290; loss: 4.849203; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6300; loss: 6.876708; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6310; loss: 7.652993; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6320; loss: 6.673336; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6330; loss: 31.642006; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6340; loss: 4.5659065; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6350; loss: 5.2227445; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6360; loss: 3.947112; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6370; loss: 5.0766644; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6380; loss: 4.697577; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6390; loss: 5.0480156; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6400; loss: 5.23728; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6410; loss: 4.639671; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6420; loss: 4.357763; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6430; loss: 4.2830048; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6440; loss: 4.511443; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6450; loss: 6.4535174; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6460; loss: 4.4574647; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6470; loss: 4.6844387; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6480; loss: 4.0240464; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6490; loss: 4.223136; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6500; loss: 4.0032344; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6510; loss: 4.876033; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6520; loss: 4.296729; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6530; loss: 7.8976035; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6540; loss: 6.122776; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6550; loss: 11.284722; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6560; loss: 8.965364; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6570; loss: 4.426306; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6580; loss: 7.124231; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6590; loss: 14.332664; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6600; loss: 4.3999653; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6610; loss: 5.266406; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6620; loss: 11.169374; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6630; loss: 4.4536505; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6640; loss: 4.864359; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6650; loss: 4.7221375; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6660; loss: 7.7055182; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6670; loss: 4.139001; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6680; loss: 4.0707703; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6690; loss: 3.9385233; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6700; loss: 4.8595905; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6710; loss: 4.300667; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6720; loss: 4.1934013; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6730; loss: 3.9165916; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6740; loss: 4.3139853; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6750; loss: 4.2279315; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6760; loss: 4.0574903; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6770; loss: 5.37203; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6780; loss: 33.391956; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6790; loss: 4.92266; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6800; loss: 4.35272; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6810; loss: 4.630804; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6820; loss: 4.5343018; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6830; loss: 3.9857473; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6840; loss: 7.7983346; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6850; loss: 3.994893; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6860; loss: 4.128276; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6870; loss: 6.457594; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6880; loss: 4.068272; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6890; loss: 4.2249913; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6900; loss: 4.103503; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6910; loss: 4.4526587; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6920; loss: 4.9590425; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6930; loss: 36.759495; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6940; loss: 5.173424; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6950; loss: 4.578093; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6960; loss: 4.0325108; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6970; loss: 4.274109; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6980; loss: 4.290819; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 6990; loss: 6.538518; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7000; loss: 7.0375443; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7010; loss: 4.3607936; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7020; loss: 5.839424; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 7030; loss: 19.869099; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7040; loss: 4.7094197; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7050; loss: 4.1319723; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7060; loss: 4.64158; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7070; loss: 4.3586416; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7080; loss: 4.234207; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7090; loss: 5.0823216; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7100; loss: 3.8995798; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7110; loss: 4.2224836; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7120; loss: 16.489197; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7130; loss: 4.034567; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7140; loss: 4.506494; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7150; loss: 4.2952175; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7160; loss: 5.3628936; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7170; loss: 9.345867; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7180; loss: 4.1453567; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7190; loss: 4.5623527; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7200; loss: 3.6563902; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7210; loss: 4.257734; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7220; loss: 4.3356013; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7230; loss: 4.3101234; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7240; loss: 4.050048; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7250; loss: 4.7454786; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7260; loss: 4.161815; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7270; loss: 4.4691544; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7280; loss: 4.6218586; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7290; loss: 8.36454; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7300; loss: 3.7427602; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7310; loss: 5.1133094; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7320; loss: 4.4711804; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7330; loss: 6.7646217; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7340; loss: 10.323302; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7350; loss: 5.1106725; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7360; loss: 4.694139; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7370; loss: 5.2722526; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7380; loss: 4.3668375; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7390; loss: 4.429447; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7400; loss: 6.680761; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7410; loss: 4.366032; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7420; loss: 6.958623; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7430; loss: 6.9238267; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7440; loss: 4.329077; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7450; loss: 4.2536983; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7460; loss: 3.7050219; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7470; loss: 4.2752285; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7480; loss: 3.8269353; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7490; loss: 3.960405; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 7500; epoch: 5; loss: 6.506271; min_loss: 6.506271; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 7500; loss: 4.8667755; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7510; loss: 4.4192414; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7520; loss: 4.7494097; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7530; loss: 5.0218534; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7540; loss: 3.849506; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7550; loss: 3.910801; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7560; loss: 4.1996593; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7570; loss: 4.193886; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7580; loss: 3.4568732; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7590; loss: 3.533459; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7600; loss: 5.9623594; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7610; loss: 3.9368916; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7620; loss: 12.545021; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7630; loss: 3.7896361; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7640; loss: 4.1704535; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7650; loss: 4.240444; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7660; loss: 3.971414; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7670; loss: 3.9689808; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7680; loss: 3.870059; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7690; loss: 19.575394; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7700; loss: 4.084135; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7710; loss: 3.8830867; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7720; loss: 4.4711385; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7730; loss: 4.1489587; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7740; loss: 4.0608673; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7750; loss: 4.640149; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7760; loss: 4.0451245; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7770; loss: 4.5580397; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7780; loss: 4.1572165; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7790; loss: 4.1947937; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7800; loss: 7.2946124; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7810; loss: 10.63156; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7820; loss: 4.1287217; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7830; loss: 4.6979313; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7840; loss: 4.29312; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7850; loss: 4.7305655; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7860; loss: 3.9284468; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7870; loss: 3.7227678; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 7880; loss: 5.71714; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7890; loss: 4.874145; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7900; loss: 4.228168; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7910; loss: 4.119414; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7920; loss: 6.776742; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7930; loss: 4.0668125; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7940; loss: 4.0338173; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7950; loss: 8.024405; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7960; loss: 3.9472108; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7970; loss: 7.499281; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7980; loss: 4.0394526; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 7990; loss: 4.226777; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8000; loss: 3.7972841; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8010; loss: 4.294448; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8020; loss: 7.2614923; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8030; loss: 4.443863; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8040; loss: 4.3660173; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8050; loss: 4.496805; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8060; loss: 5.0027933; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8070; loss: 4.357567; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8080; loss: 4.658663; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8090; loss: 12.4777; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8100; loss: 4.8671327; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8110; loss: 5.3814363; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8120; loss: 11.347269; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8130; loss: 5.70143; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8140; loss: 5.771345; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8150; loss: 4.08885; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8160; loss: 3.8753505; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8170; loss: 4.4309344; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8180; loss: 4.1968455; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8190; loss: 4.2611175; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8200; loss: 4.852568; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8210; loss: 8.188143; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8220; loss: 3.4698293; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8230; loss: 11.017059; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8240; loss: 3.5456743; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8250; loss: 3.5512137; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8260; loss: 4.125448; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8270; loss: 4.3307695; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8280; loss: 4.0815053; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8290; loss: 5.3808165; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8300; loss: 4.039078; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8310; loss: 4.870534; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8320; loss: 4.3343287; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8330; loss: 4.262146; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8340; loss: 4.50121; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8350; loss: 16.410515; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8360; loss: 3.8152459; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8370; loss: 4.0491934; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8380; loss: 4.162381; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8390; loss: 4.44358; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8400; loss: 9.631051; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8410; loss: 4.289442; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8420; loss: 3.7000153; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8430; loss: 4.5095577; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8440; loss: 3.6699939; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8450; loss: 5.902808; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8460; loss: 4.5384293; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8470; loss: 4.9094744; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8480; loss: 4.5956607; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8490; loss: 4.207856; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8500; loss: 5.019245; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8510; loss: 3.8072062; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8520; loss: 3.760771; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8530; loss: 4.260337; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8540; loss: 4.051401; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8550; loss: 5.6415606; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8560; loss: 4.750884; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8570; loss: 4.287447; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8580; loss: 4.7811933; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8590; loss: 3.7020502; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8600; loss: 4.131276; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8610; loss: 4.40792; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8620; loss: 4.0475245; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8630; loss: 4.066141; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8640; loss: 4.344322; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8650; loss: 4.2023516; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8660; loss: 4.8195066; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8670; loss: 3.7166762; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8680; loss: 3.9866846; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8690; loss: 4.4712563; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8700; loss: 3.678012; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8710; loss: 4.288229; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8720; loss: 4.5278177; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8730; loss: 4.5576096; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8740; loss: 3.603249; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "No records found to evaluate\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 8750; epoch: 6; loss: 5.5725355; min_loss: 5.5725355; since_best_loss: 0; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 8750; loss: 3.504712; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8760; loss: 3.6363544; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8770; loss: 4.4150586; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8780; loss: 3.7550263; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8790; loss: 3.9652288; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8800; loss: 3.7426364; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8810; loss: 3.5989845; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8820; loss: 4.1176977; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8830; loss: 6.0479636; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8840; loss: 4.3034887; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8850; loss: 4.1569633; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8860; loss: 3.87623; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8870; loss: 3.7702856; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8880; loss: 3.6425142; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8890; loss: 4.1404138; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8900; loss: 3.811936; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8910; loss: 4.0504093; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8920; loss: 4.354335; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8930; loss: 4.085332; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8940; loss: 3.8794599; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8950; loss: 4.1926193; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8960; loss: 4.01517; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8970; loss: 4.2010975; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8980; loss: 3.4357648; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 8990; loss: 3.4995286; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9000; loss: 6.0533857; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9010; loss: 3.6995306; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9020; loss: 4.210864; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9030; loss: 8.288675; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9040; loss: 4.3288627; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9050; loss: 3.7763944; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9060; loss: 4.198917; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9070; loss: 4.099793; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9080; loss: 4.2626896; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9090; loss: 3.8138928; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9100; loss: 3.8584597; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9110; loss: 3.702192; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9120; loss: 4.0295644; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9130; loss: 3.3196356; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9140; loss: 4.375553; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9150; loss: 4.2268844; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9160; loss: 4.337384; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9170; loss: 9.753153; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9180; loss: 10.608162; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9190; loss: 4.0687613; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9200; loss: 4.4092703; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9210; loss: 8.165389; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9220; loss: 3.763024; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9230; loss: 9.046974; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9240; loss: 4.4201465; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9250; loss: 4.100376; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9260; loss: 4.4790573; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9270; loss: 8.294619; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9280; loss: 4.0199294; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9290; loss: 5.6997995; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9300; loss: 4.056278; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9310; loss: 4.355177; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9320; loss: 3.6906168; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9330; loss: 4.1841908; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9340; loss: 4.5142937; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9350; loss: 3.6130784; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9360; loss: 3.929614; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9370; loss: 4.3507376; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9380; loss: 3.9538417; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9390; loss: 4.2062907; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9400; loss: 5.5313125; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9410; loss: 7.5424995; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9420; loss: 4.045665; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9430; loss: 3.8996835; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9440; loss: 4.9284697; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9450; loss: 5.5564117; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9460; loss: 5.5381627; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9470; loss: 5.4091864; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9480; loss: 4.650817; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9490; loss: 3.8707345; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9500; loss: 9.371464; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9510; loss: 8.868832; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9520; loss: 6.140203; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9530; loss: 8.196699; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9540; loss: 5.372718; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9550; loss: 12.578087; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9560; loss: 11.848791; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9570; loss: 5.787035; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9580; loss: 4.43759; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9590; loss: 3.257895; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9600; loss: 3.7184796; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9610; loss: 4.969779; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9620; loss: 4.6437364; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 9630; loss: 7.2735863; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9640; loss: 11.864368; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9650; loss: 4.391987; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9660; loss: 4.045534; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9670; loss: 10.327583; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9680; loss: 4.4945765; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9690; loss: 4.449721; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9700; loss: 4.0093174; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9710; loss: 3.7922583; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9720; loss: 4.905232; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9730; loss: 3.715565; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9740; loss: 4.0540724; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9750; loss: 4.2505217; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9760; loss: 4.299756; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9770; loss: 4.506802; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9780; loss: 4.8752832; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9790; loss: 7.1946926; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9800; loss: 4.6012816; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9810; loss: 5.2198005; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9820; loss: 4.7405653; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9830; loss: 4.6424775; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9840; loss: 3.9817996; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9850; loss: 5.6421623; examples/sec: 2.95; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9860; loss: 5.744787; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9870; loss: 6.2323723; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9880; loss: 4.2183223; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9890; loss: 4.5513525; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9900; loss: 4.221303; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9910; loss: 7.186427; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9920; loss: 4.4649014; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9930; loss: 4.1982403; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9940; loss: 5.2033615; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9950; loss: 4.0849752; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9960; loss: 3.9427795; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9970; loss: 4.322892; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9980; loss: 6.398115; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 9990; loss: 3.8665495; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 10000; epoch: 7; loss: 6.119079; min_loss: 5.5725355; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 10000; loss: 5.281431; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10010; loss: 3.5630763; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10020; loss: 4.3655095; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10030; loss: 4.7353725; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10040; loss: 3.7764647; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10050; loss: 4.0163956; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10060; loss: 5.3857784; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10070; loss: 3.6894443; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10080; loss: 5.02434; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10090; loss: 4.3501406; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10100; loss: 4.789058; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10110; loss: 4.788203; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10120; loss: 3.5161479; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10130; loss: 3.7534554; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10140; loss: 5.8555865; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10150; loss: 10.117073; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10160; loss: 4.1713123; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10170; loss: 9.589525; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10180; loss: 4.204861; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10190; loss: 5.2464304; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10200; loss: 4.685484; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10210; loss: 4.394739; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10220; loss: 4.130211; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10230; loss: 5.189523; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10240; loss: 3.4656587; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10250; loss: 3.6506522; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10260; loss: 4.2921915; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10270; loss: 3.3066926; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10280; loss: 3.1415792; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10290; loss: 3.235487; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10300; loss: 3.8203015; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10310; loss: 3.5942101; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10320; loss: 4.093828; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10330; loss: 3.5240622; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10340; loss: 4.407384; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10350; loss: 3.8982866; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10360; loss: 4.2784176; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 10370; loss: 9.178055; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10380; loss: 4.0678973; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10390; loss: 3.386115; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10400; loss: 4.068206; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10410; loss: 3.6969118; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10420; loss: 3.6450078; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10430; loss: 3.612822; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10440; loss: 3.9576607; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10450; loss: 5.3058004; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10460; loss: 5.1870623; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10470; loss: 4.6992607; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10480; loss: 3.9620252; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10490; loss: 3.866191; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10500; loss: 3.993001; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10510; loss: 3.3146267; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10520; loss: 3.4553392; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10530; loss: 3.379143; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10540; loss: 4.011815; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10550; loss: 3.8118162; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10560; loss: 3.4514074; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10570; loss: 3.6379774; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10580; loss: 4.073352; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10590; loss: 4.0341063; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10600; loss: 3.7651396; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10610; loss: 3.4398036; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10620; loss: 3.5660446; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10630; loss: 3.5080347; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10640; loss: 4.4283886; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10650; loss: 3.6049566; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10660; loss: 4.643273; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10670; loss: 4.056873; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10680; loss: 3.863108; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10690; loss: 3.7243428; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10700; loss: 3.5505013; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10710; loss: 4.1260905; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10720; loss: 3.813932; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10730; loss: 3.7574615; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10740; loss: 3.503308; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10750; loss: 3.9558706; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10760; loss: 4.853129; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10770; loss: 3.8291807; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10780; loss: 3.6512046; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10790; loss: 3.9148996; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10800; loss: 3.7553246; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10810; loss: 3.343808; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10820; loss: 4.6785393; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10830; loss: 4.186079; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10840; loss: 3.9420786; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10850; loss: 8.664024; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10860; loss: 6.87158; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10870; loss: 19.670982; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10880; loss: 4.20932; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10890; loss: 4.620141; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10900; loss: 5.270362; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10910; loss: 6.1006503; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10920; loss: 3.7031927; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10930; loss: 3.4079685; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10940; loss: 7.432026; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10950; loss: 4.1874394; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10960; loss: 4.360752; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10970; loss: 3.7886229; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10980; loss: 4.066822; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 10990; loss: 4.1510344; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11000; loss: 3.6294827; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11010; loss: 3.7952926; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11020; loss: 4.285494; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11030; loss: 4.243084; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11040; loss: 4.353244; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11050; loss: 3.522349; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11060; loss: 3.8489964; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11070; loss: 6.4167137; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11080; loss: 3.7276223; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11090; loss: 4.1428785; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11100; loss: 4.200494; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11110; loss: 3.6274772; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11120; loss: 3.4090178; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11130; loss: 3.4451337; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11140; loss: 3.2650256; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11150; loss: 5.566275; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11160; loss: 3.8336775; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11170; loss: 4.4945784; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11180; loss: 3.8941753; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11190; loss: 4.9776106; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11200; loss: 4.7771893; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11210; loss: 4.067169; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11220; loss: 3.8453174; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11230; loss: 8.123651; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 11240; loss: 3.4559212; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 11250; epoch: 8; loss: 5.2728987; min_loss: 5.2728987; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 11250; loss: 3.3850236; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11260; loss: 3.781735; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11270; loss: 4.0545645; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11280; loss: 5.303915; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11290; loss: 4.6081915; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11300; loss: 14.104549; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11310; loss: 3.9936488; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11320; loss: 3.9791725; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11330; loss: 3.4450686; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11340; loss: 3.490665; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11350; loss: 3.2292676; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11360; loss: 3.6010337; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11370; loss: 3.0554018; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11380; loss: 3.5979927; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11390; loss: 5.176247; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11400; loss: 4.1294193; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11410; loss: 3.7633996; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11420; loss: 3.6855505; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11430; loss: 3.2956874; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11440; loss: 3.5092778; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11450; loss: 3.7555988; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11460; loss: 4.506484; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11470; loss: 4.2998896; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11480; loss: 3.5075846; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11490; loss: 6.432356; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11500; loss: 3.6283064; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11510; loss: 11.524941; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11520; loss: 3.3856328; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11530; loss: 3.790481; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11540; loss: 2.9596345; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11550; loss: 6.0368166; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11560; loss: 3.8837662; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11570; loss: 3.7875173; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11580; loss: 3.59607; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11590; loss: 3.660203; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11600; loss: 3.7165298; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11610; loss: 3.7960753; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11620; loss: 3.3341088; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11630; loss: 3.6337812; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11640; loss: 3.7794514; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11650; loss: 3.3325963; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11660; loss: 3.8212981; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11670; loss: 3.3194044; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11680; loss: 3.6420522; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11690; loss: 3.6773627; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11700; loss: 3.795374; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11710; loss: 3.4096155; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11720; loss: 3.3015203; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11730; loss: 3.3197315; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11740; loss: 3.31051; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11750; loss: 4.8249784; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11760; loss: 21.819878; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11770; loss: 4.8749294; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11780; loss: 5.602581; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11790; loss: 3.0649066; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11800; loss: 3.1506171; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11810; loss: 3.345653; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11820; loss: 6.0829506; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11830; loss: 3.3876152; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11840; loss: 3.1794987; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11850; loss: 3.6333838; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11860; loss: 7.4891744; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11870; loss: 6.255458; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11880; loss: 8.249885; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11890; loss: 4.0876317; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11900; loss: 3.7741554; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11910; loss: 6.9900894; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11920; loss: 4.450678; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11930; loss: 3.5600076; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11940; loss: 3.3988943; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11950; loss: 4.3656826; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11960; loss: 6.232272; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 11970; loss: 3.6196508; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11980; loss: 3.5203934; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 11990; loss: 4.2844334; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12000; loss: 3.565464; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12010; loss: 6.093401; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12020; loss: 3.3916504; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12030; loss: 5.051207; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12040; loss: 3.4910512; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12050; loss: 15.496996; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12060; loss: 4.1377187; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12070; loss: 195.9989; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12080; loss: 14.544671; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12090; loss: 46.779945; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12100; loss: 9.415791; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12110; loss: 4.3443656; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12120; loss: 3.8968863; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12130; loss: 6.0326686; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12140; loss: 4.5007057; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12150; loss: 6.824137; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12160; loss: 8.429498; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12170; loss: 4.0905476; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12180; loss: 3.5275369; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12190; loss: 4.6560354; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12200; loss: 6.3263855; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12210; loss: 3.8791952; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12220; loss: 4.1409135; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12230; loss: 5.3379045; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12240; loss: 3.5774643; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12250; loss: 4.2152424; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12260; loss: 3.5067983; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12270; loss: 3.4208841; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12280; loss: 3.7180445; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12290; loss: 6.7049575; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12300; loss: 3.670926; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12310; loss: 3.9901056; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12320; loss: 7.0380363; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12330; loss: 4.09715; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12340; loss: 3.775533; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12350; loss: 4.6353426; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12360; loss: 3.9802291; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12370; loss: 4.5396647; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12380; loss: 4.0281143; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12390; loss: 5.2871656; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12400; loss: 4.0802755; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12410; loss: 3.7941294; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12420; loss: 3.109902; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12430; loss: 3.1508389; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12440; loss: 3.7762978; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12450; loss: 4.298444; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12460; loss: 3.271153; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12470; loss: 3.3348422; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12480; loss: 3.549994; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12490; loss: 3.7947268; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 12500; epoch: 9; loss: 5.156212; min_loss: 5.156212; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 12500; loss: 5.180501; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12510; loss: 3.5092115; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12520; loss: 3.4274206; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12530; loss: 3.4464755; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12540; loss: 3.3992512; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12550; loss: 3.438972; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12560; loss: 3.6351314; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12570; loss: 3.4058175; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12580; loss: 3.2970757; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12590; loss: 3.612133; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12600; loss: 3.7360911; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12610; loss: 3.3052633; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12620; loss: 3.451549; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12630; loss: 3.9580839; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12640; loss: 3.3984325; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12650; loss: 3.1843848; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12660; loss: 3.4785123; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12670; loss: 10.205494; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12680; loss: 3.8350012; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12690; loss: 3.8401926; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 12700; loss: 3.4918547; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12710; loss: 4.337965; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12720; loss: 3.5387986; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12730; loss: 3.423657; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12740; loss: 3.4517224; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12750; loss: 3.4433274; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12760; loss: 3.3549237; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12770; loss: 3.3593955; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12780; loss: 5.0835085; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12790; loss: 3.7873082; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12800; loss: 4.238467; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12810; loss: 3.1521173; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12820; loss: 3.6081498; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12830; loss: 5.0782247; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12840; loss: 3.5244727; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12850; loss: 3.0865521; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12860; loss: 3.9593315; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12870; loss: 4.9128757; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12880; loss: 3.4426956; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12890; loss: 3.447893; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12900; loss: 3.8643775; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12910; loss: 2.973724; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12920; loss: 3.4347806; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12930; loss: 4.2764645; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12940; loss: 5.2570915; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12950; loss: 3.5706148; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12960; loss: 4.1728477; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12970; loss: 3.7741244; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12980; loss: 3.9060857; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 12990; loss: 3.1634889; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13000; loss: 3.885732; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13010; loss: 3.3610997; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13020; loss: 4.8411336; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13030; loss: 3.4554503; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13040; loss: 3.8189118; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13050; loss: 3.5727773; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13060; loss: 12.226376; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13070; loss: 3.8558598; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13080; loss: 3.8764782; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13090; loss: 3.6383443; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13100; loss: 3.3711782; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13110; loss: 3.650501; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13120; loss: 3.768937; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13130; loss: 4.8126125; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13140; loss: 4.4599733; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13150; loss: 4.440938; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13160; loss: 4.646481; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13170; loss: 3.9187427; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13180; loss: 3.8528733; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13190; loss: 3.4269238; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13200; loss: 3.5425959; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13210; loss: 3.3192635; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13220; loss: 3.5893474; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13230; loss: 3.3298306; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13240; loss: 4.960779; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13250; loss: 3.6171002; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13260; loss: 3.9285595; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13270; loss: 3.4853451; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13280; loss: 3.17231; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13290; loss: 4.5985126; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13300; loss: 4.9517927; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13310; loss: 4.5264325; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13320; loss: 5.3380985; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13330; loss: 3.799009; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13340; loss: 3.8122911; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13350; loss: 3.290042; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13360; loss: 5.107742; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13370; loss: 3.3907833; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13380; loss: 3.4506779; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13390; loss: 3.9690764; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13400; loss: 3.4800317; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13410; loss: 3.4508407; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13420; loss: 3.4088626; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13430; loss: 3.2853107; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13440; loss: 3.1238213; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13450; loss: 3.563058; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13460; loss: 3.715556; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13470; loss: 4.040104; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13480; loss: 3.295308; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13490; loss: 4.8237033; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13500; loss: 12.555336; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13510; loss: 3.430293; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13520; loss: 3.2802048; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13530; loss: 3.3760648; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13540; loss: 4.127116; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13550; loss: 10.476888; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13560; loss: 4.272342; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 13570; loss: 3.3822508; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13580; loss: 3.684188; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13590; loss: 3.5251446; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13600; loss: 3.9766006; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13610; loss: 4.1166086; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13620; loss: 4.115918; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13630; loss: 3.3385367; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13640; loss: 3.549407; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13650; loss: 3.364492; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13660; loss: 5.027657; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13670; loss: 3.3908818; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13680; loss: 3.1758866; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13690; loss: 3.6033745; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13700; loss: 3.2969244; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13710; loss: 16.685156; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13720; loss: 3.0623398; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13730; loss: 4.0212736; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13740; loss: 4.248871; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 13750; epoch: 10; loss: 5.2062707; min_loss: 5.156212; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 13750; loss: 4.3381853; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13760; loss: 3.9352612; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13770; loss: 3.8207; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13780; loss: 17.092987; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13790; loss: 3.4531589; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13800; loss: 4.9304085; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13810; loss: 3.6508703; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13820; loss: 3.609875; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13830; loss: 3.3670716; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13840; loss: 3.093062; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13850; loss: 3.7605796; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13860; loss: 3.0126529; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13870; loss: 8.428333; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13880; loss: 4.3454294; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13890; loss: 4.316452; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13900; loss: 4.0023766; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13910; loss: 3.4676704; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13920; loss: 3.2423615; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13930; loss: 3.294268; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13940; loss: 3.4782467; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13950; loss: 3.3755221; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13960; loss: 3.4890757; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13970; loss: 3.120964; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13980; loss: 4.4505033; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 13990; loss: 4.0219536; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14000; loss: 3.3810565; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14010; loss: 3.5358834; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14020; loss: 5.3186874; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14030; loss: 3.815578; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14040; loss: 4.768532; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14050; loss: 3.5687017; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14060; loss: 3.0857782; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14070; loss: 5.0220337; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14080; loss: 3.087229; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14090; loss: 3.6193662; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14100; loss: 3.0429478; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14110; loss: 3.802491; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14120; loss: 3.274381; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14130; loss: 4.9361315; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14140; loss: 4.1697826; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14150; loss: 3.5330524; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14160; loss: 3.9506793; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14170; loss: 4.0490756; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14180; loss: 3.4105365; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14190; loss: 4.627612; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14200; loss: 3.5010362; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14210; loss: 2.9169936; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14220; loss: 3.9165528; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14230; loss: 3.8945103; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14240; loss: 7.9613876; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14250; loss: 3.3609803; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14260; loss: 3.5002706; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14270; loss: 3.6414926; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14280; loss: 2.762291; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14290; loss: 3.7894566; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14300; loss: 4.2123446; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 14310; loss: 4.2332315; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14320; loss: 2.6827376; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14330; loss: 3.5465713; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14340; loss: 3.3142123; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14350; loss: 3.2558875; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14360; loss: 5.540868; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14370; loss: 4.0015793; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14380; loss: 3.730568; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14390; loss: 3.0727148; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14400; loss: 4.239009; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14410; loss: 3.2948809; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14420; loss: 4.365081; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14430; loss: 3.796707; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14440; loss: 3.1805828; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14450; loss: 3.122336; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14460; loss: 3.3734078; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14470; loss: 3.0691924; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14480; loss: 3.3462896; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14490; loss: 3.8485303; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14500; loss: 6.2699423; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14510; loss: 4.0976505; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14520; loss: 7.382787; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14530; loss: 3.6247253; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14540; loss: 3.6697702; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14550; loss: 3.2419808; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14560; loss: 5.2040534; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14570; loss: 4.0155883; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14580; loss: 2.7263024; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14590; loss: 3.2164044; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14600; loss: 3.0523756; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14610; loss: 2.9699173; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14620; loss: 2.963026; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14630; loss: 2.9164696; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14640; loss: 3.1846497; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14650; loss: 6.379015; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14660; loss: 3.4584012; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14670; loss: 3.3476737; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14680; loss: 3.889743; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14690; loss: 3.2394013; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14700; loss: 3.2302253; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14710; loss: 2.9236703; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14720; loss: 3.546742; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14730; loss: 3.0843515; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14740; loss: 4.9034157; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14750; loss: 3.7802238; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14760; loss: 3.7676854; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14770; loss: 4.8834496; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14780; loss: 3.2694893; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14790; loss: 3.1019936; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14800; loss: 3.528364; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14810; loss: 3.450259; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14820; loss: 3.3292298; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14830; loss: 3.2252479; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14840; loss: 3.1504626; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14850; loss: 3.608209; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14860; loss: 3.672841; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14870; loss: 3.3590102; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14880; loss: 3.5449169; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14890; loss: 7.343541; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14900; loss: 3.560481; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14910; loss: 3.175644; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14920; loss: 3.951262; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14930; loss: 5.4650583; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14940; loss: 3.4002576; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14950; loss: 3.5191987; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14960; loss: 2.9781685; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14970; loss: 3.2106595; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14980; loss: 2.7124438; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 14990; loss: 3.22673; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 15000; epoch: 11; loss: 4.867514; min_loss: 4.867514; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 15000; loss: 3.1728063; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15010; loss: 2.814066; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15020; loss: 3.220587; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15030; loss: 2.6678796; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 15040; loss: 2.8394794; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15050; loss: 2.8423853; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15060; loss: 2.6572113; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15070; loss: 3.0267496; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15080; loss: 3.0204625; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15090; loss: 3.1928234; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15100; loss: 2.6148627; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15110; loss: 3.864435; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15120; loss: 2.8766546; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15130; loss: 3.169454; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15140; loss: 2.9253697; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15150; loss: 3.2250047; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15160; loss: 3.8896987; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15170; loss: 3.1551237; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15180; loss: 3.0969296; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15190; loss: 3.4457512; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15200; loss: 3.156539; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15210; loss: 3.0510244; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15220; loss: 3.2565846; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15230; loss: 2.9820163; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15240; loss: 3.5970573; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15250; loss: 3.482285; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15260; loss: 3.6294987; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15270; loss: 3.4556012; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15280; loss: 3.418601; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15290; loss: 3.635519; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15300; loss: 2.8268986; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15310; loss: 4.9367023; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15320; loss: 3.3344004; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15330; loss: 3.4137292; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15340; loss: 4.2392516; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15350; loss: 3.154933; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15360; loss: 3.0653043; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15370; loss: 2.8541632; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15380; loss: 2.8290792; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15390; loss: 3.0856333; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15400; loss: 4.079816; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15410; loss: 4.800762; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15420; loss: 3.3822823; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15430; loss: 5.6355877; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15440; loss: 4.3952336; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15450; loss: 3.4876025; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15460; loss: 3.7365084; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15470; loss: 3.0741253; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15480; loss: 3.1286852; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15490; loss: 3.8500752; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15500; loss: 5.4657545; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15510; loss: 3.575884; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15520; loss: 3.0836043; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15530; loss: 3.1968148; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15540; loss: 3.0094094; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15550; loss: 3.4732964; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15560; loss: 4.7723246; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15570; loss: 3.290989; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15580; loss: 2.6461792; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15590; loss: 2.208725; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15600; loss: 3.4805794; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15610; loss: 10.119799; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15620; loss: 4.3497972; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15630; loss: 3.4128616; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15640; loss: 3.804022; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15650; loss: 3.5194955; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15660; loss: 4.334119; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15670; loss: 3.4304943; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15680; loss: 8.946453; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15690; loss: 3.4884076; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15700; loss: 3.180808; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15710; loss: 6.516265; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15720; loss: 3.1098342; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15730; loss: 3.2772458; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15740; loss: 4.1845055; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15750; loss: 4.0629845; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15760; loss: 4.0721297; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15770; loss: 3.5377252; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15780; loss: 3.2431593; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15790; loss: 3.477963; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15800; loss: 3.3117964; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15810; loss: 3.1555686; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15820; loss: 25.381283; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15830; loss: 4.232092; examples/sec: 2.96; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15840; loss: 3.463972; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15850; loss: 3.78968; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15860; loss: 4.0430484; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15870; loss: 3.2747934; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15880; loss: 11.3758745; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15890; loss: 4.154852; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15900; loss: 3.8083751; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 15910; loss: 3.5876126; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15920; loss: 4.023617; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15930; loss: 3.0051281; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15940; loss: 3.202749; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15950; loss: 3.4891908; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15960; loss: 3.1705256; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15970; loss: 2.938765; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15980; loss: 3.6063914; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 15990; loss: 3.424724; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16000; loss: 3.0600185; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16010; loss: 3.1090589; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16020; loss: 2.7537441; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16030; loss: 2.7209938; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16040; loss: 3.2972286; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16050; loss: 3.4185095; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16060; loss: 3.799205; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16070; loss: 3.396497; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16080; loss: 3.00781; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16090; loss: 3.7165675; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16100; loss: 2.7634547; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16110; loss: 6.2054768; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16120; loss: 2.9748793; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16130; loss: 3.4582646; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16140; loss: 5.93934; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16150; loss: 2.9820013; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16160; loss: 3.3546968; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16170; loss: 9.831283; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16180; loss: 2.4966037; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16190; loss: 2.3681211; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16200; loss: 3.0663834; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16210; loss: 3.2102334; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16220; loss: 2.6578264; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16230; loss: 3.0521004; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16240; loss: 2.5663645; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 16250; epoch: 12; loss: 5.093962; min_loss: 4.867514; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 16250; loss: 6.372811; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16260; loss: 4.162; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16270; loss: 3.3365254; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16280; loss: 2.9064972; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16290; loss: 3.1256287; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16300; loss: 4.099204; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16310; loss: 2.6706915; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16320; loss: 6.261116; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16330; loss: 3.517455; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16340; loss: 9.21803; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16350; loss: 3.6330807; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16360; loss: 4.038705; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16370; loss: 3.137752; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16380; loss: 2.9653587; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16390; loss: 2.9337838; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16400; loss: 3.1970043; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16410; loss: 4.302532; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16420; loss: 3.1692562; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16430; loss: 3.5177164; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16440; loss: 2.6697087; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16450; loss: 3.4676585; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16460; loss: 3.2561033; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16470; loss: 4.606166; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16480; loss: 3.3315718; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16490; loss: 2.7573967; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16500; loss: 3.3057013; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16510; loss: 3.216313; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16520; loss: 2.896698; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16530; loss: 2.588129; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16540; loss: 3.1089911; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16550; loss: 3.2427597; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16560; loss: 2.8179142; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16570; loss: 2.8094363; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16580; loss: 3.143636; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16590; loss: 2.7755723; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16600; loss: 5.653123; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16610; loss: 2.8900595; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16620; loss: 2.6973934; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16630; loss: 2.6480706; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16640; loss: 3.3287318; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 16650; loss: 2.8174675; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16660; loss: 8.576611; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16670; loss: 3.7698793; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16680; loss: 4.9349356; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16690; loss: 4.389183; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16700; loss: 2.898044; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16710; loss: 3.2768416; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16720; loss: 5.6377697; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16730; loss: 3.8937867; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16740; loss: 4.091819; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16750; loss: 2.546709; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16760; loss: 2.8572252; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16770; loss: 5.3487873; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16780; loss: 3.0078826; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16790; loss: 3.0634153; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16800; loss: 2.701494; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16810; loss: 3.6337504; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16820; loss: 3.4430046; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16830; loss: 2.9804418; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16840; loss: 3.0446644; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16850; loss: 2.6221623; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16860; loss: 3.111395; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16870; loss: 3.3823657; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16880; loss: 3.2561502; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16890; loss: 3.3171716; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16900; loss: 3.374137; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16910; loss: 4.2648005; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16920; loss: 2.8677406; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16930; loss: 2.4773295; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16940; loss: 3.5719657; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16950; loss: 3.3870203; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16960; loss: 3.01431; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16970; loss: 3.1970882; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16980; loss: 2.7024622; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 16990; loss: 2.7926414; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17000; loss: 3.1782992; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17010; loss: 3.0053823; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17020; loss: 2.5440667; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17030; loss: 3.403966; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17040; loss: 3.6697707; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17050; loss: 4.8124757; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17060; loss: 3.2558866; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17070; loss: 3.059036; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17080; loss: 2.908086; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17090; loss: 2.738709; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17100; loss: 2.765253; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17110; loss: 3.2044306; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17120; loss: 2.864314; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17130; loss: 4.369165; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17140; loss: 5.2202096; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17150; loss: 2.938623; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17160; loss: 2.9989626; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17170; loss: 2.4478018; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17180; loss: 3.1505818; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17190; loss: 2.9196713; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17200; loss: 3.2160137; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17210; loss: 3.9464312; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17220; loss: 2.9736521; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17230; loss: 4.193589; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17240; loss: 3.2247667; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17250; loss: 3.965536; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17260; loss: 3.0533135; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17270; loss: 4.0418034; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17280; loss: 2.6444092; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17290; loss: 7.9380007; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17300; loss: 3.417559; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17310; loss: 2.4391673; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17320; loss: 4.075017; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17330; loss: 4.567318; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17340; loss: 4.360416; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17350; loss: 3.2625954; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17360; loss: 3.32329; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17370; loss: 3.7688823; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17380; loss: 3.6335666; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17390; loss: 3.075307; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17400; loss: 2.9543307; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17410; loss: 4.903253; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17420; loss: 2.9091747; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17430; loss: 2.7904203; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17440; loss: 3.118797; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17450; loss: 2.7777705; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17460; loss: 3.001709; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17470; loss: 3.4775755; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17480; loss: 2.5122476; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17490; loss: 3.2514176; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 17500; epoch: 13; loss: 4.6330395; min_loss: 4.6330395; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 17500; loss: 2.5318127; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17510; loss: 3.0472598; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17520; loss: 3.3859332; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17530; loss: 2.9332964; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17540; loss: 3.0824804; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17550; loss: 2.9943569; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17560; loss: 2.5051966; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17570; loss: 3.6868916; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17580; loss: 3.5376487; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17590; loss: 2.8009753; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17600; loss: 3.7567346; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17610; loss: 4.8636684; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17620; loss: 3.0985563; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17630; loss: 4.209591; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17640; loss: 3.2134566; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17650; loss: 2.6088426; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17660; loss: 2.9575396; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17670; loss: 2.6083894; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17680; loss: 3.4061203; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17690; loss: 3.2931566; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17700; loss: 2.751562; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17710; loss: 2.4811194; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17720; loss: 3.2852426; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17730; loss: 2.7543232; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17740; loss: 2.530707; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17750; loss: 2.8836505; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17760; loss: 2.7464852; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17770; loss: 3.9977195; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17780; loss: 3.4920418; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17790; loss: 3.1289654; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17800; loss: 3.5749097; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17810; loss: 3.0206444; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17820; loss: 2.483929; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17830; loss: 2.8560605; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17840; loss: 2.4706569; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17850; loss: 2.8510954; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17860; loss: 2.935368; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17870; loss: 2.5302334; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17880; loss: 2.3669212; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17890; loss: 2.7700403; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17900; loss: 4.3595467; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17910; loss: 2.9837315; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17920; loss: 2.55461; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17930; loss: 2.754283; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17940; loss: 3.2482686; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17950; loss: 3.1863902; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17960; loss: 2.6593046; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17970; loss: 3.0089543; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17980; loss: 3.0563142; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 17990; loss: 2.6954625; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18000; loss: 3.0740225; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18010; loss: 3.8446589; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18020; loss: 2.9320984; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18030; loss: 2.8563278; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18040; loss: 2.6205559; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18050; loss: 3.9515977; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18060; loss: 3.1160052; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18070; loss: 2.567345; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18080; loss: 3.0908086; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18090; loss: 3.6409316; examples/sec: 2.97; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18100; loss: 3.1039963; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18110; loss: 2.7166722; examples/sec: 3.06; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18120; loss: 3.4365637; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18130; loss: 2.9030735; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18140; loss: 3.2633178; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18150; loss: 2.6740282; examples/sec: 3.07; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18160; loss: 2.597928; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18170; loss: 6.4077234; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18180; loss: 3.2104425; examples/sec: 2.98; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18190; loss: 2.8397286; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18200; loss: 2.9831586; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18210; loss: 4.0911007; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18220; loss: 3.7965322; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18230; loss: 3.1493187; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18240; loss: 3.5816576; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18250; loss: 3.047559; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18260; loss: 3.0626402; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18270; loss: 3.1271796; examples/sec: 3.05; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18280; loss: 3.303732; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18290; loss: 2.9358034; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18300; loss: 4.9654865; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18310; loss: 6.411124; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18320; loss: 2.8419342; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18330; loss: 3.0027752; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18340; loss: 3.0326576; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 18350; loss: 2.4362578; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18360; loss: 3.1047544; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18370; loss: 2.3897462; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18380; loss: 3.2942076; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18390; loss: 2.529871; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18400; loss: 2.9410307; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18410; loss: 3.044488; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18420; loss: 6.180418; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18430; loss: 3.666319; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18440; loss: 6.5540714; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18450; loss: 2.9929821; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18460; loss: 3.4517658; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18470; loss: 5.715453; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18480; loss: 3.58186; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18490; loss: 3.8074117; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18500; loss: 3.1930673; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18510; loss: 3.3459659; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18520; loss: 2.6826446; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18530; loss: 3.04215; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18540; loss: 2.4936786; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18550; loss: 2.7421045; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18560; loss: 2.9920187; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18570; loss: 2.9263783; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18580; loss: 3.0221052; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18590; loss: 2.5982525; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18600; loss: 4.242381; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18610; loss: 3.3120475; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18620; loss: 3.1323867; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18630; loss: 2.6359496; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18640; loss: 2.9784293; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18650; loss: 3.1072445; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18660; loss: 3.9304423; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18670; loss: 2.6101365; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18680; loss: 3.1639762; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18690; loss: 2.85982; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18700; loss: 2.8813066; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18710; loss: 3.1479294; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18720; loss: 3.2688532; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18730; loss: 3.4770608; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18740; loss: 3.655061; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 18750; epoch: 14; loss: 4.589236; min_loss: 4.589236; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 18750; loss: 2.5008063; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18760; loss: 2.667501; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18770; loss: 2.9626436; examples/sec: 3.13; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18780; loss: 3.336112; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18790; loss: 2.5108871; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18800; loss: 3.2001565; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18810; loss: 3.0168705; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18820; loss: 3.2233396; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18830; loss: 2.6848893; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18840; loss: 2.6922436; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18850; loss: 3.2686286; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18860; loss: 3.0297213; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18870; loss: 2.6870484; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18880; loss: 3.3509235; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18890; loss: 2.4536188; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18900; loss: 2.2617018; examples/sec: 3.13; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18910; loss: 6.072214; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18920; loss: 3.2560785; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18930; loss: 4.1345687; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18940; loss: 5.6904726; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18950; loss: 6.055462; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18960; loss: 3.8057444; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18970; loss: 3.0905805; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18980; loss: 3.859881; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 18990; loss: 3.4807208; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19000; loss: 3.298802; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19010; loss: 3.489956; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19020; loss: 2.9868436; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19030; loss: 2.7232866; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19040; loss: 3.2557425; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19050; loss: 3.3306499; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19060; loss: 2.7867608; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19070; loss: 2.628376; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 19080; loss: 2.8723264; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19090; loss: 2.710871; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19100; loss: 3.67432; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19110; loss: 1.9596446; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19120; loss: 3.3080463; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19130; loss: 4.6887617; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19140; loss: 2.3651826; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19150; loss: 2.844551; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19160; loss: 2.930491; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19170; loss: 2.7124572; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19180; loss: 4.347809; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19190; loss: 2.6738615; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19200; loss: 3.3063998; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19210; loss: 2.7509277; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19220; loss: 2.6281033; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19230; loss: 12.776306; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19240; loss: 3.0061707; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19250; loss: 3.0038524; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19260; loss: 3.1176114; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19270; loss: 2.2432413; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19280; loss: 2.6832006; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19290; loss: 2.7547607; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19300; loss: 2.998178; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19310; loss: 2.929493; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19320; loss: 2.7219877; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19330; loss: 2.813005; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19340; loss: 2.9499867; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19350; loss: 2.2925704; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19360; loss: 2.6867166; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19370; loss: 3.4465833; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19380; loss: 3.6115854; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19390; loss: 2.9256485; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19400; loss: 3.2777686; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19410; loss: 2.6690912; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19420; loss: 2.4927347; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19430; loss: 2.4374776; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19440; loss: 2.5443645; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19450; loss: 3.4423966; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19460; loss: 4.2338543; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19470; loss: 3.9806757; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19480; loss: 2.465478; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19490; loss: 2.8249757; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19500; loss: 3.139973; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19510; loss: 3.0124977; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19520; loss: 3.295144; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19530; loss: 3.0752947; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19540; loss: 3.244061; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19550; loss: 3.3830774; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19560; loss: 2.6244097; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19570; loss: 2.0844872; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19580; loss: 2.6214325; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19590; loss: 2.3911097; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19600; loss: 4.4198427; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19610; loss: 2.2935398; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19620; loss: 3.2030091; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19630; loss: 2.826797; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19640; loss: 2.8884544; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19650; loss: 2.2370608; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19660; loss: 3.2115188; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19670; loss: 2.889388; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19680; loss: 2.6142673; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19690; loss: 3.315329; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19700; loss: 3.6377249; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19710; loss: 2.606973; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19720; loss: 2.7472417; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19730; loss: 3.9179003; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19740; loss: 2.471363; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19750; loss: 3.3998148; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19760; loss: 3.1460202; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19770; loss: 2.6436808; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19780; loss: 3.0341592; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19790; loss: 2.2767682; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19800; loss: 2.7010958; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19810; loss: 2.8872125; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19820; loss: 2.9108512; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19830; loss: 4.354805; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19840; loss: 3.0517907; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19850; loss: 3.0042; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19860; loss: 4.4544106; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19870; loss: 4.456971; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19880; loss: 3.16882; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19890; loss: 4.483344; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19900; loss: 4.035453; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19910; loss: 4.7010264; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19920; loss: 2.736718; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19930; loss: 2.5027003; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19940; loss: 2.2707791; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 19950; loss: 4.235609; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19960; loss: 2.7870722; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19970; loss: 3.5563712; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19980; loss: 2.9212153; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 19990; loss: 6.705543; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 20000; epoch: 15; loss: 4.5733275; min_loss: 4.5733275; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 20000; loss: 2.6352558; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20010; loss: 3.2719607; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20020; loss: 2.729074; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20030; loss: 2.7733374; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20040; loss: 1.9504035; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20050; loss: 3.1869102; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20060; loss: 2.8341315; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20070; loss: 2.7133212; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20080; loss: 2.8481302; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20090; loss: 2.15103; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20100; loss: 2.615311; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20110; loss: 3.206326; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20120; loss: 3.6703584; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20130; loss: 2.3601434; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20140; loss: 2.579585; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20150; loss: 2.1775506; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20160; loss: 2.937104; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20170; loss: 2.740283; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20180; loss: 2.8854666; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20190; loss: 2.480248; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20200; loss: 2.288145; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20210; loss: 2.8397155; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20220; loss: 2.515975; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20230; loss: 4.0220103; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20240; loss: 2.4018946; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20250; loss: 3.9897115; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20260; loss: 2.2963836; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20270; loss: 2.58209; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20280; loss: 3.3661656; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20290; loss: 2.4184542; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20300; loss: 3.650627; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20310; loss: 2.516477; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20320; loss: 2.6404674; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20330; loss: 2.5988998; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20340; loss: 2.9458554; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20350; loss: 2.6369298; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20360; loss: 2.9817414; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20370; loss: 2.6203747; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20380; loss: 2.8900025; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20390; loss: 2.525977; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20400; loss: 2.783765; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20410; loss: 2.6484494; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20420; loss: 2.865923; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20430; loss: 2.58524; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20440; loss: 2.4454994; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20450; loss: 2.547204; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20460; loss: 2.9239757; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20470; loss: 2.3537216; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20480; loss: 2.9092603; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20490; loss: 3.0651884; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20500; loss: 3.0671763; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20510; loss: 2.4190211; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20520; loss: 2.3724234; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20530; loss: 2.658101; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20540; loss: 2.1980095; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20550; loss: 2.6034815; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20560; loss: 2.713496; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20570; loss: 3.2619946; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20580; loss: 3.09523; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20590; loss: 2.4578767; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20600; loss: 2.6794758; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20610; loss: 2.4423652; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20620; loss: 2.5002654; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20630; loss: 2.036192; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20640; loss: 2.3761308; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20650; loss: 3.615118; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20660; loss: 3.9746227; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20670; loss: 3.1915824; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 20680; loss: 3.3021092; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20690; loss: 2.9502387; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20700; loss: 3.1086838; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20710; loss: 3.0425467; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20720; loss: 2.9120693; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20730; loss: 3.1563067; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20740; loss: 3.0837412; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20750; loss: 2.4179916; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20760; loss: 3.218904; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20770; loss: 6.3008924; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20780; loss: 3.1023395; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20790; loss: 3.2559829; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20800; loss: 5.510998; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20810; loss: 2.1862137; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20820; loss: 2.9952796; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20830; loss: 2.419133; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20840; loss: 3.2138824; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20850; loss: 2.71495; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20860; loss: 2.8794818; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20870; loss: 2.800066; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20880; loss: 2.7077365; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20890; loss: 12.287725; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20900; loss: 3.1143336; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20910; loss: 3.3457398; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20920; loss: 3.0259821; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20930; loss: 2.4389715; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20940; loss: 3.917723; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20950; loss: 2.502157; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20960; loss: 2.9723573; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20970; loss: 2.918803; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20980; loss: 2.9806862; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 20990; loss: 2.6611412; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21000; loss: 2.7524195; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21010; loss: 6.2590666; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21020; loss: 3.0537984; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21030; loss: 2.9486325; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21040; loss: 3.2117515; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21050; loss: 2.2442114; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21060; loss: 3.915561; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21070; loss: 2.7420177; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21080; loss: 2.7270393; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21090; loss: 2.7987828; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21100; loss: 2.397663; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21110; loss: 2.3063645; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21120; loss: 2.90539; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21130; loss: 2.3200078; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21140; loss: 2.5907004; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21150; loss: 2.3022695; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21160; loss: 2.947751; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21170; loss: 2.9303012; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21180; loss: 2.5102959; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21190; loss: 2.121616; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21200; loss: 3.221728; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21210; loss: 2.8003016; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21220; loss: 4.6451387; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21230; loss: 3.2286916; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21240; loss: 3.524871; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 21250; epoch: 16; loss: 4.437698; min_loss: 4.437698; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 21250; loss: 2.5725355; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21260; loss: 2.269236; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21270; loss: 3.400178; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21280; loss: 2.5925593; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21290; loss: 2.5709715; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21300; loss: 2.239128; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21310; loss: 3.164122; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21320; loss: 2.8161454; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21330; loss: 2.3124552; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21340; loss: 2.6060097; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21350; loss: 2.9698236; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21360; loss: 2.6249194; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21370; loss: 2.6752365; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21380; loss: 2.273405; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21390; loss: 3.5895247; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21400; loss: 2.5729425; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 21410; loss: 2.6254277; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21420; loss: 2.0498815; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21430; loss: 2.7840228; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21440; loss: 3.59019; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21450; loss: 2.5606885; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21460; loss: 2.9224787; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21470; loss: 3.216058; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21480; loss: 2.6503417; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21490; loss: 2.3050199; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21500; loss: 2.3170247; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21510; loss: 2.033475; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21520; loss: 2.2899365; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21530; loss: 2.7047083; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21540; loss: 2.6202602; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21550; loss: 2.334043; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21560; loss: 2.8202586; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21570; loss: 2.5117815; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21580; loss: 2.085782; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21590; loss: 2.6012707; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21600; loss: 2.4181802; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21610; loss: 2.3922582; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21620; loss: 2.9127703; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21630; loss: 2.5471492; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21640; loss: 3.400951; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21650; loss: 2.589406; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21660; loss: 3.0318842; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21670; loss: 2.3583794; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21680; loss: 2.3015242; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21690; loss: 5.5033817; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21700; loss: 2.4060369; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21710; loss: 3.2507606; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21720; loss: 2.765577; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21730; loss: 2.6737742; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21740; loss: 4.5033317; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21750; loss: 2.136365; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21760; loss: 2.2721612; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21770; loss: 3.231647; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21780; loss: 2.6176004; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21790; loss: 2.0576618; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21800; loss: 2.6097627; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21810; loss: 2.4975784; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21820; loss: 2.2393265; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21830; loss: 2.6288123; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21840; loss: 2.4300208; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21850; loss: 2.9789882; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21860; loss: 2.36518; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21870; loss: 2.431269; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21880; loss: 3.064681; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21890; loss: 2.9276485; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21900; loss: 2.6314306; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21910; loss: 2.6758034; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21920; loss: 2.5070627; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21930; loss: 2.1341267; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21940; loss: 2.2511287; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21950; loss: 3.8466587; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21960; loss: 2.7242606; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21970; loss: 2.908376; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21980; loss: 2.6214027; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 21990; loss: 2.9753556; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22000; loss: 2.2210915; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22010; loss: 2.460435; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22020; loss: 2.4180732; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22030; loss: 2.5498576; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22040; loss: 2.1432602; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22050; loss: 2.5388036; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22060; loss: 2.2783096; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22070; loss: 2.3641095; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22080; loss: 2.439054; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22090; loss: 3.2339897; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22100; loss: 2.1156871; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22110; loss: 2.4713256; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22120; loss: 2.4375782; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22130; loss: 2.0552762; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22140; loss: 2.2692385; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22150; loss: 2.1801784; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22160; loss: 2.550808; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22170; loss: 2.5927224; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22180; loss: 2.593242; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22190; loss: 2.5835094; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22200; loss: 3.1452765; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22210; loss: 2.757165; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22220; loss: 2.5639002; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22230; loss: 2.9364243; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22240; loss: 2.6219704; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22250; loss: 2.5407794; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22260; loss: 3.1476738; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22270; loss: 2.4384246; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 22280; loss: 2.6345594; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22290; loss: 2.7154353; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22300; loss: 3.0411015; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22310; loss: 2.493675; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22320; loss: 2.604614; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22330; loss: 2.5701907; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22340; loss: 3.3823242; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22350; loss: 2.687483; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22360; loss: 2.2916837; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22370; loss: 2.5352082; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22380; loss: 2.370168; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22390; loss: 2.237191; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22400; loss: 2.417059; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22410; loss: 2.8988695; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22420; loss: 1.9000123; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22430; loss: 2.6132956; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22440; loss: 13.048988; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22450; loss: 3.5523152; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22460; loss: 2.7654243; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22470; loss: 2.9870627; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22480; loss: 2.2299662; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22490; loss: 2.5601287; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 22500; epoch: 17; loss: 4.5585933; min_loss: 4.437698; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 22500; loss: 2.2773025; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22510; loss: 2.855524; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22520; loss: 2.622961; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22530; loss: 2.4784021; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22540; loss: 2.4998913; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22550; loss: 2.6997843; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22560; loss: 4.7833395; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22570; loss: 2.953825; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22580; loss: 3.0422049; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22590; loss: 3.7763815; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22600; loss: 3.0504873; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22610; loss: 4.25299; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22620; loss: 2.6567397; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22630; loss: 3.6206856; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22640; loss: 2.9253426; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22650; loss: 2.9444072; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22660; loss: 2.765857; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22670; loss: 2.7104418; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22680; loss: 2.9280856; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22690; loss: 2.8934388; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22700; loss: 2.8935544; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22710; loss: 2.8645272; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22720; loss: 2.2564645; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22730; loss: 2.349148; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22740; loss: 2.0202167; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22750; loss: 2.9158292; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22760; loss: 2.7479312; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22770; loss: 2.3074222; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22780; loss: 2.815986; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22790; loss: 2.4732046; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22800; loss: 2.761732; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22810; loss: 2.1109793; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22820; loss: 2.5366874; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22830; loss: 2.3689227; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22840; loss: 2.577867; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22850; loss: 2.7398744; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22860; loss: 2.418201; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22870; loss: 2.441208; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22880; loss: 2.2023842; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22890; loss: 2.5283427; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22900; loss: 2.3088536; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22910; loss: 2.0600824; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22920; loss: 2.6932614; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22930; loss: 2.6481328; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22940; loss: 2.864271; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22950; loss: 2.4587004; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22960; loss: 2.112758; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22970; loss: 2.0910056; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22980; loss: 2.6205459; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 22990; loss: 2.3341334; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23000; loss: 2.476737; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23010; loss: 3.145309; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 23020; loss: 3.0546036; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23030; loss: 2.6074712; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23040; loss: 3.2362714; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23050; loss: 2.2482963; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23060; loss: 2.9003859; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23070; loss: 2.1247048; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23080; loss: 2.1402097; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23090; loss: 2.1860995; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23100; loss: 2.4396594; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23110; loss: 2.6251469; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23120; loss: 2.6038074; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23130; loss: 2.3077564; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23140; loss: 1.8754601; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23150; loss: 2.0612617; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23160; loss: 2.6389165; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23170; loss: 2.376606; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23180; loss: 2.4978359; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23190; loss: 2.2495568; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23200; loss: 2.4692981; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23210; loss: 2.8501506; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23220; loss: 2.4015765; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23230; loss: 2.7848654; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23240; loss: 2.3450906; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23250; loss: 2.6453097; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23260; loss: 2.1049995; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23270; loss: 2.2401974; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23280; loss: 2.1818175; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23290; loss: 2.4382634; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23300; loss: 2.4974527; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23310; loss: 2.905804; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23320; loss: 2.8808231; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23330; loss: 2.163295; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23340; loss: 2.820331; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23350; loss: 2.5788305; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23360; loss: 2.1630101; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23370; loss: 2.3998656; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23380; loss: 2.3678122; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23390; loss: 2.492898; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23400; loss: 2.4153147; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23410; loss: 2.69039; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23420; loss: 2.4818563; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23430; loss: 2.9744158; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23440; loss: 2.9615269; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23450; loss: 2.2999592; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23460; loss: 2.4245028; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23470; loss: 2.516481; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23480; loss: 2.2647066; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23490; loss: 2.6215305; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23500; loss: 2.9268742; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23510; loss: 2.7865725; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23520; loss: 2.7985992; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23530; loss: 2.311297; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23540; loss: 2.6027985; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23550; loss: 2.79322; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23560; loss: 2.5406826; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23570; loss: 2.8860874; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23580; loss: 2.6688588; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23590; loss: 2.1393008; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23600; loss: 2.408086; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23610; loss: 1.8607588; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23620; loss: 2.5867043; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23630; loss: 2.2992735; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23640; loss: 2.3242912; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23650; loss: 2.195888; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23660; loss: 2.6223853; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23670; loss: 2.9608567; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23680; loss: 2.168091; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23690; loss: 3.157864; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23700; loss: 2.510927; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23710; loss: 2.4762; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23720; loss: 2.7437613; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23730; loss: 2.5969858; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23740; loss: 2.5269654; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 23750; epoch: 18; loss: 4.4164143; min_loss: 4.4164143; since_best_loss: 0; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 23750; loss: 2.3234944; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23760; loss: 2.3474844; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23770; loss: 2.7569323; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23780; loss: 2.2640214; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23790; loss: 2.5207157; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23800; loss: 2.0948262; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23810; loss: 1.932148; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23820; loss: 2.3619666; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23830; loss: 2.2260458; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23840; loss: 2.4553223; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23850; loss: 2.422061; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23860; loss: 2.5171256; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23870; loss: 2.4973617; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23880; loss: 2.319086; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23890; loss: 2.105723; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23900; loss: 2.3847144; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23910; loss: 2.1326203; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23920; loss: 2.254643; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23930; loss: 2.430748; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23940; loss: 1.7338184; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23950; loss: 2.5176873; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23960; loss: 1.930283; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23970; loss: 2.3968797; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23980; loss: 2.5727963; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 23990; loss: 2.041145; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24000; loss: 2.4416203; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24010; loss: 2.4754653; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24020; loss: 2.6875699; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24030; loss: 2.5532045; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24040; loss: 3.0991602; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24050; loss: 2.7454858; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24060; loss: 1.8522756; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24070; loss: 2.115811; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24080; loss: 2.2649584; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24090; loss: 2.079988; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24100; loss: 2.0648005; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24110; loss: 2.3936381; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24120; loss: 2.1905582; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24130; loss: 3.0350413; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24140; loss: 2.5273395; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24150; loss: 2.5290127; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24160; loss: 2.2108579; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24170; loss: 1.4232436; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24180; loss: 2.6471424; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24190; loss: 2.2012184; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24200; loss: 2.548151; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24210; loss: 2.715283; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24220; loss: 1.7904829; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24230; loss: 2.0585816; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24240; loss: 1.9740489; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24250; loss: 2.3758678; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24260; loss: 2.2878995; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24270; loss: 2.002142; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24280; loss: 2.0057764; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24290; loss: 3.0574832; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24300; loss: 2.4443648; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24310; loss: 2.6568503; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24320; loss: 1.9903; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24330; loss: 1.843825; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24340; loss: 2.3251643; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24350; loss: 2.6222482; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24360; loss: 2.4776278; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24370; loss: 2.135158; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24380; loss: 2.0152292; examples/sec: 3.13; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24390; loss: 1.9530594; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24400; loss: 2.7025046; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24410; loss: 3.0682328; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24420; loss: 2.0286613; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24430; loss: 2.3083758; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24440; loss: 2.7612648; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24450; loss: 2.1919343; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24460; loss: 2.8320994; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24470; loss: 2.9437966; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24480; loss: 2.2121387; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24490; loss: 2.1943042; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24500; loss: 1.8898106; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24510; loss: 2.0810885; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24520; loss: 2.5296717; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24530; loss: 2.6930437; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24540; loss: 2.109165; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24550; loss: 1.840215; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24560; loss: 2.5449133; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24570; loss: 2.2297063; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24580; loss: 1.9238636; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24590; loss: 2.9199982; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24600; loss: 1.8177347; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24610; loss: 2.3236625; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 24620; loss: 2.659626; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24630; loss: 2.4571438; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24640; loss: 2.1559157; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24650; loss: 2.0832453; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24660; loss: 2.2218785; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24670; loss: 2.3871336; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24680; loss: 2.1940436; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24690; loss: 2.2659862; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24700; loss: 3.7157366; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24710; loss: 2.0696437; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24720; loss: 2.112032; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24730; loss: 2.4413152; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24740; loss: 2.1713593; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24750; loss: 2.7100606; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24760; loss: 2.9226592; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24770; loss: 2.480105; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24780; loss: 3.2475739; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24790; loss: 2.5470717; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24800; loss: 2.1726365; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24810; loss: 2.8273695; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24820; loss: 1.9531804; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24830; loss: 2.7182121; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24840; loss: 2.0364792; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24850; loss: 1.7338338; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24860; loss: 1.5873312; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24870; loss: 2.3095908; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24880; loss: 2.4191418; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24890; loss: 2.3034658; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24900; loss: 2.9631028; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24910; loss: 2.4482737; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24920; loss: 2.2340295; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24930; loss: 2.0316644; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24940; loss: 3.806651; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24950; loss: 2.4155858; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24960; loss: 1.9293358; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24970; loss: 2.5872374; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24980; loss: 3.3170745; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 24990; loss: 3.0649257; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 25000; epoch: 19; loss: 4.873438; min_loss: 4.4164143; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 25000; loss: 2.1374874; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25010; loss: 2.3594518; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25020; loss: 2.1017604; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25030; loss: 1.8815415; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25040; loss: 1.8248603; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25050; loss: 1.7673192; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25060; loss: 2.934273; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25070; loss: 2.1616716; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25080; loss: 2.7698321; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25090; loss: 1.8546181; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25100; loss: 2.3605843; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25110; loss: 1.8593962; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25120; loss: 1.9558685; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25130; loss: 2.106886; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25140; loss: 2.0658443; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25150; loss: 2.22197; examples/sec: 3.13; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25160; loss: 2.8002992; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25170; loss: 2.5625448; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25180; loss: 2.3517365; examples/sec: 3.13; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25190; loss: 1.748164; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25200; loss: 2.5846646; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25210; loss: 2.0915809; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25220; loss: 2.164318; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25230; loss: 2.4238837; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25240; loss: 2.1157947; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25250; loss: 2.1345108; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25260; loss: 2.3863595; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25270; loss: 2.167863; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25280; loss: 2.5385077; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25290; loss: 1.98367; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25300; loss: 2.6837401; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25310; loss: 2.5042503; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25320; loss: 3.5706627; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25330; loss: 2.554422; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25340; loss: 2.9338124; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25350; loss: 2.3615685; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 25360; loss: 2.089318; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25370; loss: 2.2493715; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25380; loss: 2.9169044; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25390; loss: 2.3602943; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25400; loss: 2.572256; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25410; loss: 2.2162228; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25420; loss: 4.9334364; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25430; loss: 2.2393644; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25440; loss: 2.021968; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25450; loss: 2.5770261; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25460; loss: 1.8334734; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25470; loss: 1.8909562; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25480; loss: 2.1260643; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25490; loss: 2.352261; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25500; loss: 2.4732857; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25510; loss: 1.8482249; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25520; loss: 1.9152799; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25530; loss: 2.3822498; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25540; loss: 2.5195794; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25550; loss: 1.8915824; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25560; loss: 3.0911055; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25570; loss: 2.1317797; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25580; loss: 2.157764; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25590; loss: 1.9006937; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25600; loss: 2.2804632; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25610; loss: 2.6147196; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25620; loss: 2.4984322; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25630; loss: 2.0792935; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25640; loss: 1.8426033; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25650; loss: 2.1956713; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25660; loss: 1.6061115; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25670; loss: 1.9617722; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25680; loss: 2.0338883; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25690; loss: 2.6917853; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25700; loss: 2.3968687; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25710; loss: 2.1275632; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25720; loss: 1.8571677; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25730; loss: 1.6215883; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25740; loss: 2.1307116; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25750; loss: 2.59259; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25760; loss: 1.9893212; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25770; loss: 2.2429302; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25780; loss: 2.2209923; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25790; loss: 1.958871; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25800; loss: 2.9765255; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25810; loss: 2.471684; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25820; loss: 2.9003673; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25830; loss: 2.573381; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25840; loss: 2.1728833; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25850; loss: 1.7572911; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25860; loss: 2.2605453; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25870; loss: 2.0037248; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25880; loss: 1.7721462; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25890; loss: 2.6140032; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25900; loss: 2.5022619; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25910; loss: 2.6654038; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25920; loss: 1.8401874; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25930; loss: 3.1193922; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25940; loss: 2.8151155; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25950; loss: 1.8678908; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25960; loss: 1.941262; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25970; loss: 1.9463933; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25980; loss: 1.9499149; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 25990; loss: 1.9285295; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26000; loss: 2.6755917; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26010; loss: 2.2070112; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26020; loss: 1.8950822; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26030; loss: 2.0466747; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26040; loss: 2.3408816; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26050; loss: 2.6367407; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26060; loss: 2.5066876; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26070; loss: 2.1283765; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26080; loss: 1.9552829; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26090; loss: 3.1145513; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26100; loss: 2.5285063; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26110; loss: 2.7474718; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26120; loss: 2.6194024; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26130; loss: 1.817656; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26140; loss: 2.4331062; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26150; loss: 2.1300519; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26160; loss: 1.9435493; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26170; loss: 1.9925733; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26180; loss: 2.0115843; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26190; loss: 1.5183121; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26200; loss: 2.750453; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26210; loss: 2.324757; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26220; loss: 3.3902917; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 26230; loss: 2.7999268; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26240; loss: 3.2420964; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 26250; epoch: 20; loss: 5.335272; min_loss: 4.4164143; since_best_loss: 2; \n",
      "FastEstimator-Train: step: 26250; loss: 2.4588397; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26260; loss: 2.8061528; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26270; loss: 1.8277609; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26280; loss: 1.6410892; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26290; loss: 2.1781063; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26300; loss: 1.7071242; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26310; loss: 1.9658833; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26320; loss: 2.0557284; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26330; loss: 2.181837; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26340; loss: 2.3487377; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26350; loss: 2.3416586; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26360; loss: 3.000907; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26370; loss: 1.8684256; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26380; loss: 2.126172; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26390; loss: 1.908232; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26400; loss: 1.7370704; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26410; loss: 2.376733; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26420; loss: 1.800601; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26430; loss: 2.7679856; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26440; loss: 2.284772; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26450; loss: 1.3740612; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26460; loss: 2.6731799; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26470; loss: 1.9034464; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26480; loss: 1.9674082; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26490; loss: 2.1340165; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26500; loss: 2.0009358; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26510; loss: 1.3154955; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26520; loss: 1.8182585; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26530; loss: 1.7655599; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26540; loss: 1.3139086; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26550; loss: 1.7736411; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26560; loss: 2.5297618; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26570; loss: 1.8647454; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26580; loss: 2.0801165; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26590; loss: 1.435104; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26600; loss: 2.1743374; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26610; loss: 2.6811092; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26620; loss: 2.0734148; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26630; loss: 1.8766503; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26640; loss: 1.7156756; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26650; loss: 2.2616098; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26660; loss: 2.4425602; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26670; loss: 1.9972425; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26680; loss: 2.4865494; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26690; loss: 1.6365201; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26700; loss: 2.1721368; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26710; loss: 2.2748508; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26720; loss: 1.7262187; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26730; loss: 1.6300228; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26740; loss: 2.1084723; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26750; loss: 1.8148475; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26760; loss: 2.5244024; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26770; loss: 1.4607686; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26780; loss: 2.1035604; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26790; loss: 1.9804883; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26800; loss: 2.4354653; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26810; loss: 1.3745314; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26820; loss: 2.2014446; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26830; loss: 1.8744186; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26840; loss: 2.1412237; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26850; loss: 1.4334714; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26860; loss: 1.8936484; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26870; loss: 2.3253405; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26880; loss: 2.7010949; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26890; loss: 2.1352284; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26900; loss: 1.5516741; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26910; loss: 1.8434653; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26920; loss: 2.2214384; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26930; loss: 1.9064304; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26940; loss: 2.301547; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26950; loss: 1.8076017; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26960; loss: 1.8025095; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 26970; loss: 2.2743087; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26980; loss: 2.0643635; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 26990; loss: 2.594649; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27000; loss: 7.0302324; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27010; loss: 2.7704935; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27020; loss: 2.114163; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27030; loss: 2.762745; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27040; loss: 2.0981746; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27050; loss: 2.185041; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27060; loss: 2.4012682; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27070; loss: 1.8873781; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27080; loss: 3.4996326; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27090; loss: 2.2433085; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27100; loss: 2.2748835; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27110; loss: 2.5858145; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27120; loss: 2.3549628; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27130; loss: 1.9875548; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27140; loss: 2.2002192; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27150; loss: 2.8326302; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27160; loss: 1.457452; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27170; loss: 2.5582633; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27180; loss: 1.7469072; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27190; loss: 1.8833168; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27200; loss: 1.5406477; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27210; loss: 1.6387179; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27220; loss: 1.7843015; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27230; loss: 1.8521054; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27240; loss: 2.0462475; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27250; loss: 2.2783825; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27260; loss: 11.692215; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27270; loss: 2.200993; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27280; loss: 2.102646; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27290; loss: 1.8049691; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27300; loss: 2.2645156; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27310; loss: 6.3830214; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27320; loss: 2.8836088; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27330; loss: 2.1645963; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27340; loss: 2.5397823; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27350; loss: 2.190699; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27360; loss: 2.4885917; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27370; loss: 3.24301; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27380; loss: 1.9956516; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27390; loss: 2.391702; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27400; loss: 1.9752946; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27410; loss: 2.149882; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27420; loss: 2.451548; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27430; loss: 2.0962903; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27440; loss: 2.7995334; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27450; loss: 2.2354748; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27460; loss: 2.082365; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27470; loss: 1.9520264; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27480; loss: 2.3994315; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27490; loss: 2.253333; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-ModelSaver: Saving model to /home/ubuntu/coco/bestmodel/retinanet_best_loss.h5\n",
      "FastEstimator-Eval: step: 27500; epoch: 21; loss: 4.409271; min_loss: 4.409271; since_best_loss: 0; \n",
      "FastEstimator-Train: step: 27500; loss: 2.3215194; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27510; loss: 2.1542969; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27520; loss: 1.8402067; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27530; loss: 2.018869; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27540; loss: 2.1333842; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27550; loss: 1.9834156; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27560; loss: 2.4019318; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27570; loss: 2.7697861; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27580; loss: 1.5378537; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27590; loss: 2.1556702; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27600; loss: 1.8962648; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27610; loss: 2.117389; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27620; loss: 2.3880973; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27630; loss: 2.1781082; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27640; loss: 2.1158085; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27650; loss: 2.228982; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27660; loss: 1.7783482; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27670; loss: 1.6736832; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27680; loss: 1.9268045; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27690; loss: 1.580302; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 27700; loss: 2.2447717; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27710; loss: 1.7510643; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27720; loss: 1.8259761; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27730; loss: 1.9297364; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27740; loss: 2.2787805; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27750; loss: 1.3277856; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27760; loss: 1.916412; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27770; loss: 2.0508456; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27780; loss: 2.5801857; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27790; loss: 2.096246; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27800; loss: 1.8255401; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27810; loss: 1.9690213; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27820; loss: 2.058434; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27830; loss: 1.8862299; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27840; loss: 1.7530215; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27850; loss: 1.7624876; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27860; loss: 2.1653275; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27870; loss: 2.1296859; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27880; loss: 2.0569718; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27890; loss: 1.7816501; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27900; loss: 2.5165405; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27910; loss: 2.2793121; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27920; loss: 3.6771057; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27930; loss: 1.6171615; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27940; loss: 1.6938107; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27950; loss: 1.8139665; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27960; loss: 1.8443108; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27970; loss: 1.9544667; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27980; loss: 1.5631933; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 27990; loss: 1.8367822; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28000; loss: 2.3087397; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28010; loss: 1.8960056; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28020; loss: 2.349722; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28030; loss: 2.367169; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28040; loss: 1.4775226; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28050; loss: 1.8317416; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28060; loss: 2.1992016; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28070; loss: 1.3864111; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28080; loss: 1.7898967; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28090; loss: 1.7401845; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28100; loss: 1.7742128; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28110; loss: 2.27176; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28120; loss: 2.1180727; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28130; loss: 1.8374708; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28140; loss: 1.7294501; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28150; loss: 2.2187843; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28160; loss: 1.9328669; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28170; loss: 1.8825746; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28180; loss: 1.59846; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28190; loss: 1.7766945; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28200; loss: 2.335973; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28210; loss: 2.8534563; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28220; loss: 2.3106918; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28230; loss: 2.1274533; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28240; loss: 2.0319958; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28250; loss: 2.2592533; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28260; loss: 1.6689079; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28270; loss: 2.1491055; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28280; loss: 2.2046688; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28290; loss: 1.8694091; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28300; loss: 1.9297585; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28310; loss: 1.6345377; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28320; loss: 1.9794528; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28330; loss: 1.3910753; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28340; loss: 2.2175155; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28350; loss: 2.1528468; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28360; loss: 1.8601048; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28370; loss: 2.0243032; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28380; loss: 1.68241; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28390; loss: 1.7597864; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28400; loss: 1.9069982; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28410; loss: 1.5467074; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28420; loss: 1.6761408; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28430; loss: 1.3966508; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28440; loss: 2.0725179; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28450; loss: 2.06676; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28460; loss: 2.1351674; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28470; loss: 2.1226583; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28480; loss: 2.3026752; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28490; loss: 1.8087494; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28500; loss: 1.9458454; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28510; loss: 2.6459622; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28520; loss: 2.3316288; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28530; loss: 2.332498; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28540; loss: 2.0676055; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28550; loss: 1.9733628; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28560; loss: 1.6375089; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 28570; loss: 1.4547153; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28580; loss: 1.6498669; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28590; loss: 1.762672; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28600; loss: 2.1515722; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28610; loss: 1.906933; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28620; loss: 1.367371; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28630; loss: 2.4165003; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28640; loss: 1.7701404; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28650; loss: 2.1019418; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28660; loss: 1.9726944; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28670; loss: 1.6003987; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28680; loss: 2.15865; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28690; loss: 1.9789293; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28700; loss: 1.9201843; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28710; loss: 1.9771906; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28720; loss: 1.6678134; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28730; loss: 1.7556016; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28740; loss: 1.8765521; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 28750; epoch: 22; loss: 4.7046547; min_loss: 4.409271; since_best_loss: 1; \n",
      "FastEstimator-Train: step: 28750; loss: 2.0394042; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28760; loss: 2.0023608; examples/sec: 3.08; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28770; loss: 1.881755; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28780; loss: 1.7409933; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28790; loss: 1.842286; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28800; loss: 1.9438174; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28810; loss: 2.036295; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28820; loss: 2.6473787; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28830; loss: 1.7164109; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28840; loss: 1.4103692; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28850; loss: 1.664365; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28860; loss: 2.0362642; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28870; loss: 1.9260569; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28880; loss: 2.5612097; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28890; loss: 1.2224274; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28900; loss: 2.003887; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28910; loss: 1.743093; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28920; loss: 2.1883411; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28930; loss: 1.9552569; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28940; loss: 2.0198576; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28950; loss: 2.2955403; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28960; loss: 1.8543077; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28970; loss: 1.9802479; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28980; loss: 1.4552587; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 28990; loss: 1.5846921; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29000; loss: 1.6219077; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29010; loss: 1.6683837; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29020; loss: 2.0190177; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29030; loss: 1.6861961; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29040; loss: 2.4105144; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29050; loss: 1.9241498; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29060; loss: 1.3558602; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29070; loss: 1.8778331; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29080; loss: 1.4522316; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29090; loss: 2.0502548; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29100; loss: 1.7111821; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29110; loss: 1.4644332; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29120; loss: 1.8435462; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29130; loss: 1.2820536; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29140; loss: 2.0329204; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29150; loss: 1.7120938; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29160; loss: 1.6364064; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29170; loss: 2.0587637; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29180; loss: 1.7725444; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29190; loss: 1.7860135; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29200; loss: 2.9260092; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29210; loss: 1.3874974; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29220; loss: 1.7537618; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29230; loss: 1.7058613; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29240; loss: 1.8754888; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29250; loss: 3.7751105; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29260; loss: 1.8564947; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29270; loss: 1.9115505; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29280; loss: 2.4400735; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29290; loss: 1.6466422; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29300; loss: 1.8837814; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 29310; loss: 1.5194501; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29320; loss: 1.7025024; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29330; loss: 1.8886857; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29340; loss: 1.7678055; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29350; loss: 2.1448488; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29360; loss: 2.0553904; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29370; loss: 2.0695014; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29380; loss: 1.003211; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29390; loss: 2.4036064; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29400; loss: 1.5457505; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29410; loss: 1.5086213; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29420; loss: 1.4926374; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29430; loss: 2.044988; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29440; loss: 1.3803344; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29450; loss: 1.7828434; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29460; loss: 2.028959; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29470; loss: 2.7568421; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29480; loss: 1.7706457; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29490; loss: 1.4104989; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29500; loss: 2.0093813; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29510; loss: 1.5351462; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29520; loss: 1.5912337; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29530; loss: 1.7079523; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29540; loss: 1.8293118; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29550; loss: 1.8669512; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29560; loss: 2.1212807; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29570; loss: 2.003078; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29580; loss: 2.0037408; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29590; loss: 2.1122804; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29600; loss: 1.829579; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29610; loss: 1.7833605; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29620; loss: 1.3376188; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29630; loss: 1.8314683; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29640; loss: 1.7234762; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29650; loss: 1.6146026; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29660; loss: 1.8034256; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29670; loss: 1.7809163; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29680; loss: 1.8138862; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29690; loss: 1.6580863; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29700; loss: 1.7465875; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29710; loss: 2.199944; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29720; loss: 1.934018; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29730; loss: 2.0916667; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29740; loss: 1.550841; examples/sec: 3.04; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29750; loss: 1.594748; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29760; loss: 2.0548863; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29770; loss: 1.6642877; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29780; loss: 2.2392597; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29790; loss: 1.532048; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29800; loss: 2.0472665; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29810; loss: 1.8019543; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29820; loss: 1.5165455; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29830; loss: 2.4987645; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29840; loss: 2.536385; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29850; loss: 2.2615416; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29860; loss: 1.4771364; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29870; loss: 2.191367; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29880; loss: 2.4436862; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29890; loss: 2.0850258; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29900; loss: 1.3511598; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29910; loss: 1.9379232; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29920; loss: 2.1029139; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29930; loss: 1.5588036; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29940; loss: 1.184695; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29950; loss: 2.0036306; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29960; loss: 1.7223748; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29970; loss: 1.3938949; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29980; loss: 2.1581056; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 29990; loss: 1.9078746; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 30000; epoch: 23; loss: 4.600623; min_loss: 4.409271; since_best_loss: 2; \n",
      "FastEstimator-Train: step: 30000; loss: 1.3133571; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30010; loss: 1.4421608; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30020; loss: 1.7695048; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30030; loss: 2.1655807; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30040; loss: 1.6682937; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 30050; loss: 1.9461346; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30060; loss: 2.1201348; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30070; loss: 1.875512; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30080; loss: 1.7174698; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30090; loss: 2.0261352; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30100; loss: 1.4303725; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30110; loss: 1.3216791; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30120; loss: 1.544493; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30130; loss: 1.4907886; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30140; loss: 1.6839392; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30150; loss: 1.9224486; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30160; loss: 1.9308228; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30170; loss: 1.9648955; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30180; loss: 1.2678338; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30190; loss: 1.38181; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30200; loss: 1.5793924; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30210; loss: 1.6367655; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30220; loss: 1.8774118; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30230; loss: 1.5134068; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30240; loss: 1.5530541; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30250; loss: 1.5392606; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30260; loss: 2.15113; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30270; loss: 1.448982; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30280; loss: 1.8108549; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30290; loss: 1.7857825; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30300; loss: 1.3199615; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30310; loss: 2.0636528; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30320; loss: 1.9603324; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30330; loss: 2.0378375; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30340; loss: 1.8557897; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30350; loss: 0.9721737; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30360; loss: 1.5866086; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30370; loss: 1.8480613; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30380; loss: 1.9940267; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30390; loss: 1.4763916; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30400; loss: 1.9746362; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30410; loss: 1.9018006; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30420; loss: 1.9125214; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30430; loss: 1.7667174; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30440; loss: 1.8720462; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30450; loss: 1.315871; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30460; loss: 1.7237227; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30470; loss: 1.8773144; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30480; loss: 1.5788181; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30490; loss: 2.2837033; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30500; loss: 1.8709003; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30510; loss: 1.5181224; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30520; loss: 1.5571213; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30530; loss: 1.6503736; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30540; loss: 1.3260721; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30550; loss: 1.9394546; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30560; loss: 1.4257908; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30570; loss: 1.5688115; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30580; loss: 1.6246144; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30590; loss: 2.1006854; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30600; loss: 1.5295249; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30610; loss: 1.762624; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30620; loss: 1.3866284; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30630; loss: 2.0536113; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30640; loss: 1.51758; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30650; loss: 1.7349309; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30660; loss: 1.7497449; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30670; loss: 1.4204915; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30680; loss: 1.4383299; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30690; loss: 1.2100422; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30700; loss: 2.0361974; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30710; loss: 4.8426666; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30720; loss: 1.7550781; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30730; loss: 2.4304183; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30740; loss: 1.6947494; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30750; loss: 1.5269372; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30760; loss: 1.7989525; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30770; loss: 1.6708221; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30780; loss: 1.4841151; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30790; loss: 1.5608486; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30800; loss: 1.865874; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30810; loss: 1.7151687; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30820; loss: 1.9672834; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30830; loss: 1.9129663; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30840; loss: 1.9035075; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30850; loss: 1.6161847; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30860; loss: 2.1546803; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30870; loss: 1.9598033; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30880; loss: 1.623541; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30890; loss: 1.8415835; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30900; loss: 1.3913372; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30910; loss: 1.402641; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 30920; loss: 1.4303677; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30930; loss: 1.6967032; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30940; loss: 1.7548656; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30950; loss: 1.791779; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30960; loss: 2.2665274; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30970; loss: 1.5788721; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30980; loss: 2.561169; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 30990; loss: 1.9319133; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31000; loss: 2.094872; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31010; loss: 1.7191523; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31020; loss: 1.3931489; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31030; loss: 1.792662; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31040; loss: 2.19638; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31050; loss: 2.18506; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31060; loss: 2.30787; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31070; loss: 1.2323208; examples/sec: 3.03; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31080; loss: 1.6561577; examples/sec: 3.12; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31090; loss: 1.8996412; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31100; loss: 1.1528044; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31110; loss: 1.8727889; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31120; loss: 2.186485; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31130; loss: 1.5974352; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31140; loss: 2.0217655; examples/sec: 2.99; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31150; loss: 1.7946258; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31160; loss: 1.4412816; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31170; loss: 2.0355668; examples/sec: 3.11; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31180; loss: 1.5535362; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31190; loss: 2.5843618; examples/sec: 3.0; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31200; loss: 2.0994594; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31210; loss: 1.8272444; examples/sec: 3.01; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31220; loss: 1.7128501; examples/sec: 3.1; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31230; loss: 1.3712828; examples/sec: 3.02; retinanet_lr: 3.3e-05; \n",
      "FastEstimator-Train: step: 31240; loss: 1.6871089; examples/sec: 3.09; retinanet_lr: 3.3e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-LRController: learning rate reduced by factor of 0.33\n",
      "FastEstimator-Eval: step: 31250; epoch: 24; loss: 4.7096915; min_loss: 4.409271; since_best_loss: 3; \n",
      "FastEstimator-Train: step: 31250; loss: 1.3122888; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31260; loss: 1.1994692; examples/sec: 2.99; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31270; loss: 1.1642437; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31280; loss: 1.4535297; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31290; loss: 1.8121297; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31300; loss: 1.2533576; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31310; loss: 1.1541262; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31320; loss: 1.2388653; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31330; loss: 1.6321217; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31340; loss: 1.7776762; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31350; loss: 2.194716; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31360; loss: 1.4166043; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31370; loss: 2.2349603; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31380; loss: 1.1671906; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31390; loss: 1.423478; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31400; loss: 1.8966188; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31410; loss: 1.558182; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31420; loss: 1.331206; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31430; loss: 1.581421; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31440; loss: 1.0663221; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31450; loss: 1.8326535; examples/sec: 3.08; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31460; loss: 1.5990992; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31470; loss: 1.5017629; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31480; loss: 1.5940565; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31490; loss: 1.7295245; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31500; loss: 1.8517469; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31510; loss: 1.8394338; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31520; loss: 1.2892932; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31530; loss: 1.8987944; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31540; loss: 1.2886227; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31550; loss: 2.131199; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31560; loss: 1.3116759; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31570; loss: 1.9105005; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31580; loss: 1.2445685; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31590; loss: 1.6977297; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31600; loss: 1.4818124; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31610; loss: 1.5753868; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31620; loss: 1.6176734; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31630; loss: 1.7251182; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31640; loss: 1.6953715; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 31650; loss: 1.3917437; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31660; loss: 2.0285387; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31670; loss: 1.6730199; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31680; loss: 1.7133439; examples/sec: 2.97; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31690; loss: 1.6145747; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31700; loss: 1.2435149; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31710; loss: 1.4621302; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31720; loss: 1.4636412; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31730; loss: 1.4388249; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31740; loss: 1.1239882; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31750; loss: 1.546109; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31760; loss: 1.3889356; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31770; loss: 1.6913466; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31780; loss: 1.2634788; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31790; loss: 1.7249659; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31800; loss: 1.6355612; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31810; loss: 1.3889161; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31820; loss: 1.343293; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31830; loss: 1.2767043; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31840; loss: 1.8983047; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31850; loss: 1.1462078; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31860; loss: 1.3269376; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31870; loss: 1.6537867; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31880; loss: 1.5146862; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31890; loss: 1.447362; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31900; loss: 1.5369219; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31910; loss: 1.498705; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31920; loss: 1.6506108; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31930; loss: 1.5937654; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31940; loss: 2.0171304; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31950; loss: 1.8261349; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31960; loss: 1.1269816; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31970; loss: 1.6819942; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31980; loss: 1.5025625; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 31990; loss: 2.1594656; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32000; loss: 1.2623869; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32010; loss: 1.4964321; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32020; loss: 1.8751035; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32030; loss: 1.5769454; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32040; loss: 1.6869665; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32050; loss: 1.4323058; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32060; loss: 1.5083886; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32070; loss: 1.6188169; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32080; loss: 1.6185921; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32090; loss: 1.9210169; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32100; loss: 1.4703879; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32110; loss: 1.3525543; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32120; loss: 1.123584; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32130; loss: 1.3235804; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32140; loss: 2.0832758; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32150; loss: 1.5427649; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32160; loss: 1.2793229; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32170; loss: 1.0892284; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32180; loss: 2.0544791; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32190; loss: 2.31566; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32200; loss: 1.5999289; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32210; loss: 2.1062987; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32220; loss: 1.8458824; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32230; loss: 1.5610094; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32240; loss: 1.5597483; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32250; loss: 1.3330834; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32260; loss: 1.870818; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32270; loss: 1.7955368; examples/sec: 2.99; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32280; loss: 1.6060616; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32290; loss: 1.93716; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32300; loss: 0.9522797; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32310; loss: 1.5352626; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32320; loss: 1.7701769; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32330; loss: 1.683179; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32340; loss: 0.9799758; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32350; loss: 1.5898893; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32360; loss: 1.3534033; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32370; loss: 1.626601; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32380; loss: 4.452428; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32390; loss: 1.8249084; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32400; loss: 1.1622715; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32410; loss: 1.3019783; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32420; loss: 0.8885224; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32430; loss: 1.2517807; examples/sec: 2.99; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32440; loss: 1.4553916; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32450; loss: 1.6573216; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32460; loss: 1.4525516; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32470; loss: 1.8037248; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32480; loss: 1.7245128; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32490; loss: 1.4166665; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 32500; epoch: 25; loss: 4.832403; min_loss: 4.409271; since_best_loss: 4; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 32500; loss: 0.83670795; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32510; loss: 1.7423813; examples/sec: 3.08; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32520; loss: 1.180064; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32530; loss: 0.8958508; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32540; loss: 1.4786344; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32550; loss: 1.8913016; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32560; loss: 2.2391827; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32570; loss: 1.7137954; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32580; loss: 1.3178387; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32590; loss: 1.152802; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32600; loss: 1.2676795; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32610; loss: 1.1826682; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32620; loss: 1.5809884; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32630; loss: 1.3029159; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32640; loss: 0.7744869; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32650; loss: 1.9184391; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32660; loss: 1.3888655; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32670; loss: 1.2482908; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32680; loss: 1.4772351; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32690; loss: 1.6801641; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32700; loss: 1.0352029; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32710; loss: 1.3344955; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32720; loss: 1.5272461; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32730; loss: 1.3171277; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32740; loss: 1.2852054; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32750; loss: 1.1275017; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32760; loss: 1.5028411; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32770; loss: 1.3326558; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32780; loss: 1.570637; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32790; loss: 1.2849848; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32800; loss: 1.733756; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32810; loss: 1.0716003; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32820; loss: 1.3837425; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32830; loss: 1.258862; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32840; loss: 1.7024279; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32850; loss: 1.3491813; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32860; loss: 1.8248345; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32870; loss: 1.5206962; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32880; loss: 1.5060371; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32890; loss: 1.8305243; examples/sec: 3.08; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32900; loss: 1.3125081; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32910; loss: 1.3875806; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32920; loss: 1.5507201; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32930; loss: 1.5967536; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32940; loss: 2.0113246; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32950; loss: 1.58767; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32960; loss: 1.1183302; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32970; loss: 1.737886; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32980; loss: 1.5843006; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 32990; loss: 1.8614368; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33000; loss: 1.6619711; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33010; loss: 1.8870087; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33020; loss: 1.1041709; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33030; loss: 1.7275126; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33040; loss: 1.3618643; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33050; loss: 1.3633202; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33060; loss: 1.3128376; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33070; loss: 1.4171739; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33080; loss: 1.2527608; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33090; loss: 1.4083424; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33100; loss: 1.5475479; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33110; loss: 1.3719506; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33120; loss: 1.411943; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33130; loss: 1.2545955; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33140; loss: 1.4737535; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33150; loss: 1.5236671; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33160; loss: 1.4961419; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33170; loss: 1.7119254; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33180; loss: 1.0596355; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33190; loss: 1.3405479; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33200; loss: 1.3059212; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33210; loss: 0.96279067; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33220; loss: 1.2749987; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33230; loss: 1.3228818; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33240; loss: 1.2964617; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33250; loss: 1.3040477; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33260; loss: 1.580622; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33270; loss: 0.9433688; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33280; loss: 1.5442083; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33290; loss: 1.2618284; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33300; loss: 1.7537713; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33310; loss: 1.2524168; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33320; loss: 1.8040375; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33330; loss: 1.2586532; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33340; loss: 1.9095447; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33350; loss: 0.85968256; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33360; loss: 1.5895596; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 33370; loss: 1.9929754; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33380; loss: 1.3937931; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33390; loss: 1.4191248; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33400; loss: 1.5471445; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33410; loss: 1.6462184; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33420; loss: 1.6286027; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33430; loss: 1.2600151; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33440; loss: 1.0013006; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33450; loss: 1.2581483; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33460; loss: 1.1808933; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33470; loss: 1.0990281; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33480; loss: 1.3183081; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33490; loss: 1.1530286; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33500; loss: 1.2939957; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33510; loss: 1.1846814; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33520; loss: 1.314589; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33530; loss: 1.294971; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33540; loss: 1.8176858; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33550; loss: 1.3406963; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33560; loss: 1.4340122; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33570; loss: 1.7714543; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33580; loss: 1.645035; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33590; loss: 1.3933606; examples/sec: 3.08; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33600; loss: 1.3002725; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33610; loss: 1.5534427; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33620; loss: 1.6959193; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33630; loss: 1.031899; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33640; loss: 1.0749564; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33650; loss: 1.3089143; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33660; loss: 1.2578199; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33670; loss: 1.3048658; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33680; loss: 2.0402606; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33690; loss: 1.3324; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33700; loss: 1.273507; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33710; loss: 1.6083395; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33720; loss: 1.3140442; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33730; loss: 1.0455191; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33740; loss: 1.2516327; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 33750; epoch: 26; loss: 4.862702; min_loss: 4.409271; since_best_loss: 5; \n",
      "FastEstimator-Train: step: 33750; loss: 1.6179774; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33760; loss: 1.1724272; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33770; loss: 1.6073432; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33780; loss: 1.4845049; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33790; loss: 1.424552; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33800; loss: 1.3698328; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33810; loss: 1.0055146; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33820; loss: 1.3399181; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33830; loss: 1.7526488; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33840; loss: 1.3452419; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33850; loss: 1.6802703; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33860; loss: 1.5280035; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33870; loss: 1.5951998; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33880; loss: 1.66926; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33890; loss: 1.469554; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33900; loss: 1.0663743; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33910; loss: 1.350066; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33920; loss: 1.3066559; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33930; loss: 1.4529716; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33940; loss: 1.5493778; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33950; loss: 1.2380481; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33960; loss: 1.0330343; examples/sec: 3.05; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33970; loss: 1.434221; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33980; loss: 1.397193; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 33990; loss: 1.6349983; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34000; loss: 1.6488304; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34010; loss: 1.9468191; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34020; loss: 1.3079209; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34030; loss: 1.3081746; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34040; loss: 1.3461828; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34050; loss: 1.3922626; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34060; loss: 1.168206; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34070; loss: 0.9364505; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34080; loss: 1.6944003; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34090; loss: 1.4517102; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34100; loss: 1.1096206; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 34110; loss: 0.96881336; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34120; loss: 1.0435728; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34130; loss: 1.7005424; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34140; loss: 1.4957037; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34150; loss: 0.92161405; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34160; loss: 1.2035855; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34170; loss: 1.5019499; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34180; loss: 1.4060764; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34190; loss: 1.3990707; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34200; loss: 1.4571738; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34210; loss: 1.3007824; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34220; loss: 1.542001; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34230; loss: 1.3157196; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34240; loss: 1.104665; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34250; loss: 2.0282092; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34260; loss: 1.2908647; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34270; loss: 0.87584007; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34280; loss: 1.0312808; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34290; loss: 1.589247; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34300; loss: 1.3260602; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34310; loss: 1.329865; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34320; loss: 0.9082699; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34330; loss: 1.1226509; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34340; loss: 1.3781741; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34350; loss: 1.4715027; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34360; loss: 1.4420905; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34370; loss: 1.1216396; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34380; loss: 1.0598428; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34390; loss: 1.6332476; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34400; loss: 1.8379472; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34410; loss: 1.7646838; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34420; loss: 1.2912139; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34430; loss: 1.4774195; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34440; loss: 1.3861568; examples/sec: 3.04; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34450; loss: 1.4738526; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34460; loss: 1.6641715; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34470; loss: 1.3459392; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34480; loss: 2.041471; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34490; loss: 1.3133025; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34500; loss: 1.5569458; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34510; loss: 1.6398246; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34520; loss: 1.1329482; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34530; loss: 1.1652974; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34540; loss: 1.3288863; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34550; loss: 1.8516436; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34560; loss: 1.0821829; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34570; loss: 1.8185039; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34580; loss: 0.8316971; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34590; loss: 1.4116521; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34600; loss: 1.5142473; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34610; loss: 1.7616371; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34620; loss: 1.0927294; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34630; loss: 1.1100476; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34640; loss: 0.91385174; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34650; loss: 0.95069563; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34660; loss: 1.7776144; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34670; loss: 0.8943591; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34680; loss: 1.884578; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34690; loss: 1.7561936; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34700; loss: 1.46769; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34710; loss: 1.2964284; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34720; loss: 1.3423307; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34730; loss: 1.0710464; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34740; loss: 0.7968301; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34750; loss: 1.2292838; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34760; loss: 1.3471621; examples/sec: 3.08; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34770; loss: 1.9047747; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34780; loss: 0.9577405; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34790; loss: 1.4094981; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34800; loss: 1.6460283; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34810; loss: 1.28835; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34820; loss: 1.952883; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34830; loss: 1.3378181; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34840; loss: 1.4831504; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34850; loss: 1.859695; examples/sec: 3.12; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34860; loss: 1.4860588; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34870; loss: 1.557878; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34880; loss: 1.6632719; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34890; loss: 1.8809098; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34900; loss: 1.4756396; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34910; loss: 1.5931618; examples/sec: 3.01; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34920; loss: 1.2970269; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34930; loss: 1.514046; examples/sec: 3.02; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34940; loss: 1.1263242; examples/sec: 3.09; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34950; loss: 0.99327505; examples/sec: 3.0; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34960; loss: 1.0886626; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34970; loss: 1.1579566; examples/sec: 3.11; retinanet_lr: 1.1e-05; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 34980; loss: 1.1144952; examples/sec: 3.03; retinanet_lr: 1.1e-05; \n",
      "FastEstimator-Train: step: 34990; loss: 1.3683505; examples/sec: 3.1; retinanet_lr: 1.1e-05; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-LRController: learning rate reduced by factor of 0.33\n",
      "FastEstimator-Eval: step: 35000; epoch: 27; loss: 4.878162; min_loss: 4.409271; since_best_loss: 6; \n",
      "FastEstimator-Train: step: 35000; loss: 1.484171; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35010; loss: 1.0709381; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35020; loss: 1.1908548; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35030; loss: 0.8030808; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35040; loss: 1.3094265; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35050; loss: 1.3494487; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35060; loss: 1.6230423; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35070; loss: 1.2153115; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35080; loss: 1.1482472; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35090; loss: 1.5528915; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35100; loss: 1.2007008; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35110; loss: 1.3701758; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35120; loss: 1.0133775; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35130; loss: 0.95770407; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35140; loss: 1.3956779; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35150; loss: 1.4944284; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35160; loss: 1.3727667; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35170; loss: 1.1293488; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35180; loss: 1.3272319; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35190; loss: 1.5853988; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35200; loss: 1.2785001; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35210; loss: 1.0476508; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35220; loss: 1.5183575; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35230; loss: 1.247314; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35240; loss: 1.3701843; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35250; loss: 1.5989424; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35260; loss: 1.424622; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35270; loss: 1.4308691; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35280; loss: 1.0964081; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35290; loss: 0.9444071; examples/sec: 3.12; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35300; loss: 1.1994674; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35310; loss: 0.8913724; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35320; loss: 1.4855294; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35330; loss: 0.9973051; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35340; loss: 1.1711836; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35350; loss: 1.2121038; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35360; loss: 0.950984; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35370; loss: 1.595762; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35380; loss: 0.9044533; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35390; loss: 1.1838769; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35400; loss: 1.0372552; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35410; loss: 0.92555374; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35420; loss: 1.4244287; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35430; loss: 0.9768032; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35440; loss: 1.0703796; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35450; loss: 1.4782217; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35460; loss: 1.5199789; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35470; loss: 1.4763136; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35480; loss: 1.1583035; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35490; loss: 1.710807; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35500; loss: 1.4168451; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35510; loss: 1.515617; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35520; loss: 1.8013655; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35530; loss: 1.0478368; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35540; loss: 0.9098676; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35550; loss: 1.698824; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35560; loss: 1.2664924; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35570; loss: 1.8025222; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35580; loss: 1.5866858; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35590; loss: 1.3395658; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35600; loss: 1.3957546; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35610; loss: 1.2521818; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35620; loss: 1.1373272; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35630; loss: 1.0215431; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35640; loss: 1.0644095; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35650; loss: 0.9911921; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35660; loss: 1.5716186; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35670; loss: 1.1988838; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35680; loss: 1.2685218; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35690; loss: 1.2553141; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35700; loss: 1.468751; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35710; loss: 1.3215975; examples/sec: 3.1; retinanet_lr: 4e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 35720; loss: 1.0276128; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35730; loss: 0.9486395; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35740; loss: 1.6804452; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35750; loss: 0.92194897; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35760; loss: 1.3089038; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35770; loss: 1.2653742; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35780; loss: 1.3056567; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35790; loss: 1.0930898; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35800; loss: 1.2177055; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35810; loss: 1.3074713; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35820; loss: 1.2236794; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35830; loss: 0.8744095; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35840; loss: 1.2688054; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35850; loss: 1.027179; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35860; loss: 1.5699065; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35870; loss: 1.0349329; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35880; loss: 0.9548416; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35890; loss: 1.5437353; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35900; loss: 0.9324366; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35910; loss: 1.4810231; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35920; loss: 1.1352195; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35930; loss: 1.7043564; examples/sec: 2.99; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35940; loss: 0.8118197; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35950; loss: 1.1810321; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35960; loss: 1.2725133; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35970; loss: 1.0734497; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35980; loss: 1.2268469; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 35990; loss: 0.79184973; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36000; loss: 1.8479363; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36010; loss: 1.5676813; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36020; loss: 0.7525042; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36030; loss: 1.1210576; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36040; loss: 1.1073352; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36050; loss: 1.1147035; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36060; loss: 1.2781794; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36070; loss: 0.7196803; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36080; loss: 1.1333054; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36090; loss: 1.3052214; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36100; loss: 0.9991505; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36110; loss: 1.0072386; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36120; loss: 1.4813673; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36130; loss: 1.2587488; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36140; loss: 1.2452545; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36150; loss: 1.3028427; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36160; loss: 1.2527273; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36170; loss: 1.2595472; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36180; loss: 1.5239358; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36190; loss: 1.353876; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36200; loss: 1.2237046; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36210; loss: 1.7733588; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36220; loss: 1.0238209; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36230; loss: 1.8501463; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36240; loss: 1.1318178; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 36250; epoch: 28; loss: 4.9772315; min_loss: 4.409271; since_best_loss: 7; \n",
      "FastEstimator-Train: step: 36250; loss: 1.1223233; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36260; loss: 1.2088197; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36270; loss: 1.2943208; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36280; loss: 0.8488227; examples/sec: 3.12; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36290; loss: 1.0061746; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36300; loss: 1.2008619; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36310; loss: 0.8207302; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36320; loss: 0.98481923; examples/sec: 3.12; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36330; loss: 1.3985; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36340; loss: 1.0475867; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36350; loss: 1.4741738; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36360; loss: 1.4718331; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36370; loss: 1.368095; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36380; loss: 1.040348; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36390; loss: 1.3040962; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36400; loss: 1.391417; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36410; loss: 1.3825223; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36420; loss: 1.165843; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36430; loss: 1.0941951; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36440; loss: 1.2367615; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36450; loss: 1.0259478; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36460; loss: 1.4017026; examples/sec: 3.09; retinanet_lr: 4e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 36470; loss: 0.9905775; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36480; loss: 0.9595574; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36490; loss: 0.7706555; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36500; loss: 0.78619576; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36510; loss: 1.3620584; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36520; loss: 1.1872282; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36530; loss: 1.6433558; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36540; loss: 1.5292695; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36550; loss: 0.9510946; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36560; loss: 1.2003111; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36570; loss: 1.0433812; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36580; loss: 1.4104557; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36590; loss: 1.4210243; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36600; loss: 0.9639858; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36610; loss: 1.2477152; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36620; loss: 1.3298534; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36630; loss: 1.674534; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36640; loss: 1.1145065; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36650; loss: 1.4875478; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36660; loss: 0.9321103; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36670; loss: 0.9841204; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36680; loss: 1.7241776; examples/sec: 3.12; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36690; loss: 0.97454685; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36700; loss: 1.1762555; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36710; loss: 1.2224835; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36720; loss: 1.6331103; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36730; loss: 1.446897; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36740; loss: 1.3918409; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36750; loss: 1.2229044; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36760; loss: 1.4777055; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36770; loss: 1.3054051; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36780; loss: 1.1142306; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36790; loss: 0.9250538; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36800; loss: 1.0679612; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36810; loss: 1.1833584; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36820; loss: 1.2463872; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36830; loss: 1.3855708; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36840; loss: 1.2834369; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36850; loss: 1.6463594; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36860; loss: 0.9280575; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36870; loss: 1.3570255; examples/sec: 2.98; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36880; loss: 1.3610075; examples/sec: 2.98; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36890; loss: 1.3452235; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36900; loss: 1.1534125; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36910; loss: 1.2655073; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36920; loss: 0.8723552; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36930; loss: 1.3991835; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36940; loss: 1.0262424; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36950; loss: 1.2593842; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36960; loss: 1.5694747; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36970; loss: 1.4945168; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36980; loss: 0.9766754; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 36990; loss: 1.278532; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37000; loss: 1.3865955; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37010; loss: 1.675541; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37020; loss: 1.3035314; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37030; loss: 1.3201015; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37040; loss: 1.1813946; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37050; loss: 0.97822785; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37060; loss: 1.1986973; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37070; loss: 1.0227401; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37080; loss: 1.1769606; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37090; loss: 1.5416584; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37100; loss: 1.2973398; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37110; loss: 1.3747462; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37120; loss: 1.7471976; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37130; loss: 0.9759923; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37140; loss: 0.98855543; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37150; loss: 1.2313957; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37160; loss: 1.0585916; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37170; loss: 0.91002065; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37180; loss: 1.4637915; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37190; loss: 1.0632111; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37200; loss: 1.5119841; examples/sec: 3.07; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37210; loss: 1.3267522; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37220; loss: 1.0291865; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37230; loss: 1.4582292; examples/sec: 2.99; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37240; loss: 1.0628605; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37250; loss: 2.0364006; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37260; loss: 1.6608889; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37270; loss: 0.89824647; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37280; loss: 1.1911414; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37290; loss: 0.9645213; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37300; loss: 1.2452993; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37310; loss: 1.5765451; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37320; loss: 0.9258493; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37330; loss: 1.2345375; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37340; loss: 1.4199132; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37350; loss: 1.2390244; examples/sec: 3.01; retinanet_lr: 4e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 37360; loss: 1.0964108; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37370; loss: 1.653831; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37380; loss: 1.0764067; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37390; loss: 1.021036; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37400; loss: 1.066168; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37410; loss: 1.4752054; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37420; loss: 1.0399773; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37430; loss: 1.0927119; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37440; loss: 1.3723814; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37450; loss: 1.2951107; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37460; loss: 1.0537498; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37470; loss: 1.2817365; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37480; loss: 1.047457; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37490; loss: 0.9888963; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 37500; epoch: 29; loss: 5.079204; min_loss: 4.409271; since_best_loss: 8; \n",
      "FastEstimator-Train: step: 37500; loss: 1.0246662; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37510; loss: 1.1048392; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37520; loss: 1.4631284; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37530; loss: 1.1290332; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37540; loss: 1.2842305; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37550; loss: 1.4059829; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37560; loss: 1.122029; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37570; loss: 0.760892; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37580; loss: 0.92006564; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37590; loss: 1.7353221; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37600; loss: 0.77183545; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37610; loss: 1.5446649; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37620; loss: 1.2794093; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37630; loss: 1.1778367; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37640; loss: 0.9538386; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37650; loss: 1.3479728; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37660; loss: 1.3376694; examples/sec: 3.04; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37670; loss: 1.0411077; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37680; loss: 1.1771706; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37690; loss: 0.98939455; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37700; loss: 1.1584466; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37710; loss: 1.3596545; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37720; loss: 1.0996969; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37730; loss: 1.8295928; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37740; loss: 1.3505588; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37750; loss: 1.3507202; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37760; loss: 1.1083148; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37770; loss: 1.1913323; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37780; loss: 1.2404829; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37790; loss: 1.4053667; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37800; loss: 1.1289535; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37810; loss: 1.1588528; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37820; loss: 1.5619705; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37830; loss: 1.0866206; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37840; loss: 1.4072759; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37850; loss: 1.5326043; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37860; loss: 1.6597898; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37870; loss: 1.547546; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37880; loss: 0.93410105; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37890; loss: 1.1732416; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37900; loss: 1.2693682; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37910; loss: 1.1503296; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37920; loss: 0.8202252; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37930; loss: 1.0306945; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37940; loss: 0.8342498; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37950; loss: 0.9241046; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37960; loss: 1.1854391; examples/sec: 2.99; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37970; loss: 0.9291033; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37980; loss: 1.3262663; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 37990; loss: 1.157996; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38000; loss: 1.3385246; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38010; loss: 1.1046555; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38020; loss: 1.2028059; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38030; loss: 1.1302134; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38040; loss: 1.5392083; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38050; loss: 1.0811954; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38060; loss: 1.2071383; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38070; loss: 1.3744719; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38080; loss: 1.1179007; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38090; loss: 1.1692984; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38100; loss: 1.3733509; examples/sec: 3.01; retinanet_lr: 4e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 38110; loss: 0.87766385; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38120; loss: 0.8659969; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38130; loss: 1.327124; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38140; loss: 1.858144; examples/sec: 2.99; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38150; loss: 1.3872186; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38160; loss: 0.7440926; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38170; loss: 0.89566964; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38180; loss: 1.2737253; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38190; loss: 1.3065321; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38200; loss: 0.8845347; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38210; loss: 1.2524655; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38220; loss: 1.9931396; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38230; loss: 1.2958946; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38240; loss: 1.0629976; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38250; loss: 1.0502588; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38260; loss: 0.9552171; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38270; loss: 1.1658154; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38280; loss: 0.8970939; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38290; loss: 1.6780788; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38300; loss: 1.1009436; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38310; loss: 1.1749005; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38320; loss: 1.1632934; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38330; loss: 1.1182704; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38340; loss: 1.4188871; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38350; loss: 1.2809836; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38360; loss: 1.0944227; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38370; loss: 1.2720405; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38380; loss: 1.1865565; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38390; loss: 1.4757638; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38400; loss: 1.2102933; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38410; loss: 1.7257452; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38420; loss: 1.0063181; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38430; loss: 1.2488223; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38440; loss: 1.2912519; examples/sec: 3.11; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38450; loss: 0.9148357; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38460; loss: 0.7897848; examples/sec: 3.03; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38470; loss: 1.3988719; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38480; loss: 1.1054285; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38490; loss: 1.2665; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38500; loss: 1.1756481; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38510; loss: 1.2164565; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38520; loss: 0.967718; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38530; loss: 1.1684983; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38540; loss: 0.8458932; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38550; loss: 1.2822249; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38560; loss: 1.2066245; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38570; loss: 1.1517314; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38580; loss: 1.3832201; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38590; loss: 1.1592395; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38600; loss: 1.124331; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38610; loss: 0.91333437; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38620; loss: 1.2065991; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38630; loss: 1.0923536; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38640; loss: 1.522729; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38650; loss: 1.6451333; examples/sec: 3.08; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38660; loss: 0.7999421; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38670; loss: 1.0026554; examples/sec: 3.09; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38680; loss: 1.2672668; examples/sec: 3.01; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38690; loss: 1.4911816; examples/sec: 3.12; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38700; loss: 1.3029653; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38710; loss: 1.1140565; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38720; loss: 0.8852378; examples/sec: 3.0; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38730; loss: 0.88668704; examples/sec: 3.02; retinanet_lr: 4e-06; \n",
      "FastEstimator-Train: step: 38740; loss: 1.4025702; examples/sec: 3.1; retinanet_lr: 4e-06; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-LRController: learning rate reduced by factor of 0.33\n",
      "FastEstimator-Eval: step: 38750; epoch: 30; loss: 5.078563; min_loss: 4.409271; since_best_loss: 9; \n",
      "FastEstimator-Train: step: 38750; loss: 1.4649554; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38760; loss: 1.3152132; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38770; loss: 1.2028182; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38780; loss: 0.7661294; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38790; loss: 1.1842666; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38800; loss: 1.3769789; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38810; loss: 1.0163356; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38820; loss: 1.0055192; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38830; loss: 1.2880901; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38840; loss: 1.2659361; examples/sec: 3.02; retinanet_lr: 1e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 38850; loss: 1.8633554; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38860; loss: 1.2405297; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38870; loss: 0.72647536; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38880; loss: 1.0407419; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38890; loss: 0.87800986; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38900; loss: 1.4847076; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38910; loss: 1.4356124; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38920; loss: 1.050643; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38930; loss: 1.0256723; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38940; loss: 1.4511096; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38950; loss: 1.1443617; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38960; loss: 0.82004905; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38970; loss: 1.0777972; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38980; loss: 1.3581336; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 38990; loss: 1.0935309; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39000; loss: 0.9056741; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39010; loss: 1.1050568; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39020; loss: 1.6458238; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39030; loss: 0.7224153; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39040; loss: 0.8828484; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39050; loss: 1.4375411; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39060; loss: 1.1584375; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39070; loss: 1.0557604; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39080; loss: 1.111177; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39090; loss: 0.84967715; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39100; loss: 1.2723358; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39110; loss: 1.089544; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39120; loss: 1.2106072; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39130; loss: 1.0435047; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39140; loss: 1.2002728; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39150; loss: 0.9207128; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39160; loss: 1.3479159; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39170; loss: 1.1198156; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39180; loss: 1.3266068; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39190; loss: 1.3569639; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39200; loss: 0.7077734; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39210; loss: 1.1232642; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39220; loss: 1.0489249; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39230; loss: 1.7254256; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39240; loss: 1.1209495; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39250; loss: 1.3868614; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39260; loss: 1.0053873; examples/sec: 3.08; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39270; loss: 1.2574148; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39280; loss: 1.1159108; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39290; loss: 1.261229; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39300; loss: 1.3019497; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39310; loss: 1.0367973; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39320; loss: 0.67889035; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39330; loss: 1.1776736; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39340; loss: 1.5010313; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39350; loss: 1.0068539; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39360; loss: 1.2841113; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39370; loss: 0.87432945; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39380; loss: 1.2058814; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39390; loss: 0.88645816; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39400; loss: 1.0809407; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39410; loss: 1.1846287; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39420; loss: 1.3629183; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39430; loss: 1.407812; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39440; loss: 1.1488017; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39450; loss: 0.985171; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39460; loss: 1.6599438; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39470; loss: 1.2118944; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39480; loss: 1.0015843; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39490; loss: 1.5226026; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39500; loss: 1.1342269; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39510; loss: 0.695385; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39520; loss: 1.2160819; examples/sec: 2.99; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39530; loss: 1.7315814; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39540; loss: 1.6255941; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39550; loss: 2.0375736; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39560; loss: 1.2641742; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39570; loss: 1.2143134; examples/sec: 3.08; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39580; loss: 1.6475601; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39590; loss: 1.7089412; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39600; loss: 1.301295; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39610; loss: 1.2357405; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39620; loss: 1.1761894; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39630; loss: 0.96149427; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39640; loss: 1.1960459; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39650; loss: 1.1387327; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39660; loss: 1.3647101; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39670; loss: 1.328492; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39680; loss: 0.87620366; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39690; loss: 0.96594703; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39700; loss: 0.6941741; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39710; loss: 1.1563824; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39720; loss: 1.0956196; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39730; loss: 1.4507688; examples/sec: 3.1; retinanet_lr: 1e-06; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 39740; loss: 0.9516573; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39750; loss: 0.88454086; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39760; loss: 1.2386603; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39770; loss: 0.72071123; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39780; loss: 1.3752626; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39790; loss: 1.049256; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39800; loss: 0.970901; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39810; loss: 1.1551927; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39820; loss: 1.2767997; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39830; loss: 1.0558124; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39840; loss: 1.0011817; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39850; loss: 1.1660259; examples/sec: 2.99; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39860; loss: 1.0452529; examples/sec: 3.08; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39870; loss: 1.2558932; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39880; loss: 1.1090035; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39890; loss: 1.2970996; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39900; loss: 1.7560222; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39910; loss: 1.5377989; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39920; loss: 1.470411; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39930; loss: 0.9696516; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39940; loss: 1.0761031; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39950; loss: 1.1380545; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39960; loss: 1.1057487; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39970; loss: 1.6123288; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39980; loss: 1.7968023; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 39990; loss: 1.2858013; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "FastEstimator-Eval: step: 40000; epoch: 31; loss: 5.097453; min_loss: 4.409271; since_best_loss: 10; \n",
      "FastEstimator-Train: step: 40000; loss: 0.90045404; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40010; loss: 1.0392821; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40020; loss: 1.0723151; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40030; loss: 1.0841019; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40040; loss: 1.2249343; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40050; loss: 1.3254814; examples/sec: 3.12; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40060; loss: 1.5780478; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40070; loss: 1.4964957; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40080; loss: 1.2133025; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40090; loss: 1.0579994; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40100; loss: 1.0937543; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40110; loss: 1.4316304; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40120; loss: 0.8515769; examples/sec: 3.09; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40130; loss: 1.0877441; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40140; loss: 0.8793031; examples/sec: 3.12; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40150; loss: 1.4108703; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40160; loss: 0.8832594; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40170; loss: 1.1852701; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40180; loss: 1.1711079; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40190; loss: 1.2479361; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40200; loss: 0.92661214; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40210; loss: 0.7525955; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40220; loss: 1.1451472; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40230; loss: 1.2637141; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40240; loss: 1.116173; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40250; loss: 1.0398127; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40260; loss: 0.96569407; examples/sec: 3.03; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40270; loss: 0.9460491; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40280; loss: 0.8934981; examples/sec: 3.0; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40290; loss: 1.0131316; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40300; loss: 1.0585957; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40310; loss: 0.92069983; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40320; loss: 0.9776937; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40330; loss: 1.146873; examples/sec: 3.01; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40340; loss: 1.3819242; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40350; loss: 0.5698727; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40360; loss: 1.0193989; examples/sec: 3.11; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40370; loss: 1.1052299; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40380; loss: 0.9052853; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40390; loss: 0.8098894; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40400; loss: 1.5006487; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40410; loss: 1.6517662; examples/sec: 3.12; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40420; loss: 1.1058835; examples/sec: 3.02; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40430; loss: 1.1209366; examples/sec: 3.1; retinanet_lr: 1e-06; \n",
      "FastEstimator-Train: step: 40440; loss: 0.7785761; examples/sec: 3.01; retinanet_lr: 1e-06; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastesti2",
   "language": "python",
   "name": "fastesti2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
