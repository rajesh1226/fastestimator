{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.architecture.retinanet import RetinaNet, get_fpn_anchor_box, get_target\n",
    "from fastestimator.dataset.mscoco import load_data\n",
    "from fastestimator.op import NumpyOp, TensorOp\n",
    "from fastestimator.op.numpyop import ImageReader, ResizeImageAndBbox, TypeConverter\n",
    "from fastestimator.op.tensorop import Loss, ModelOp, Pad, Rescale\n",
    "from fastestimator.trace import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv, val_csv, path = load_data(path='/data/hsiming/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class String2List(NumpyOp):\n",
    "    # this thing converts '[1, 2, 3]' into np.array([1, 2, 3])\n",
    "    def forward(self, data, state):\n",
    "        data = map(literal_eval, data)\n",
    "        return data\n",
    "    \n",
    "\n",
    "class GenerateTarget(NumpyOp):\n",
    "    def __init__(self, inputs=None, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.anchorbox, _ = get_fpn_anchor_box(input_shape=(512, 512, 3))\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        obj_label, x1, y1, width, height = data\n",
    "        cls_gt, x1_gt, y1_gt, w_gt, h_gt = get_target(self.anchorbox, obj_label, x1, y1, width, height)\n",
    "        return cls_gt, x1_gt, y1_gt, w_gt, h_gt\n",
    "\n",
    "\n",
    "class RetinaLoss(Loss):\n",
    "    def focal_loss(self, cls_gt_example, cls_pred_example, alpha=0.25, gamma=2.0):\n",
    "        # cls_gt_example shape: [A], cls_pred_example shape: [A, K]\n",
    "        num_classes = cls_pred_example.shape[-1]\n",
    "        # gather the objects and background, discard the rest\n",
    "        anchor_obj_idx = tf.where(tf.greater_equal(cls_gt_example, 0))\n",
    "        anchor_obj_bg_idx = tf.where(tf.greater_equal(cls_gt_example, -1))\n",
    "        anchor_obj_count = tf.cast(tf.shape(anchor_obj_idx)[0], tf.float32)\n",
    "        cls_gt_example = tf.one_hot(cls_gt_example, num_classes)\n",
    "        cls_gt_example = tf.gather_nd(cls_gt_example, anchor_obj_bg_idx)\n",
    "        cls_pred_example = tf.gather_nd(cls_pred_example, anchor_obj_bg_idx)\n",
    "        cls_gt_example = tf.reshape(cls_gt_example, (-1, 1))\n",
    "        cls_pred_example = tf.reshape(cls_pred_example, (-1, 1))\n",
    "        # compute the focal weight on each selected anchor box\n",
    "        alpha_factor = tf.ones_like(cls_gt_example) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(cls_gt_example, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = tf.where(tf.equal(cls_gt_example, 1), 1 - cls_pred_example, cls_pred_example)\n",
    "        focal_weight = alpha_factor * focal_weight**gamma / anchor_obj_count\n",
    "        cls_loss = tf.losses.BinaryCrossentropy(reduction='sum')(cls_gt_example,\n",
    "                                                                 cls_pred_example,\n",
    "                                                                 sample_weight=focal_weight)\n",
    "        return cls_loss, anchor_obj_idx\n",
    "\n",
    "    def smooth_l1(self, loc_gt_example, loc_pred_example, anchor_obj_idx, beta=0.1):\n",
    "        \"\"\"Return smooth l1 loss for box regesssion.\n",
    "\n",
    "        Args:\n",
    "            loc_gt_example (Tensor): Tensor of shape (padded=252, 4).\n",
    "            loc_pred_example (Tensor): Tensor of shape (num_anchors, 4).\n",
    "            anchor_obj_idx (Tensor): Indices of selected anchor box.\n",
    "\n",
    "        Returns:\n",
    "            float: Smooth l1 loss.\n",
    "        \"\"\"\n",
    "        loc_pred = tf.gather_nd(loc_pred_example, anchor_obj_idx)  #anchor_obj_count x 4\n",
    "        anchor_obj_count = tf.shape(loc_pred)[0]\n",
    "        loc_gt = loc_gt_example[:anchor_obj_count]  #anchor_obj_count x 4\n",
    "        loc_gt = tf.reshape(loc_gt, (-1, 1))\n",
    "        loc_pred = tf.reshape(loc_pred, (-1, 1))\n",
    "        loc_diff = tf.abs(loc_gt - loc_pred)\n",
    "        cond = tf.less(loc_diff, beta)\n",
    "        smooth_l1_loss = tf.where(cond, 0.5 * loc_diff**2 / beta, loc_diff - 0.5 * beta)\n",
    "        smooth_l1_loss = tf.reduce_sum(smooth_l1_loss) / tf.cast(anchor_obj_count, tf.float32)\n",
    "        return smooth_l1_loss\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        cls_gt, x1_gt, y1_gt, w_gt, h_gt, cls_pred, loc_pred = data\n",
    "        local_batch_size = state[\"local_batch_size\"]\n",
    "        focal_loss = []\n",
    "        l1_loss = []\n",
    "        total_loss = []\n",
    "        for idx in range(local_batch_size):\n",
    "            cls_gt_example = cls_gt[idx]\n",
    "            x1_gt_example = x1_gt[idx]\n",
    "            y1_gt_example = y1_gt[idx]\n",
    "            w_gt_example = w_gt[idx]\n",
    "            h_gt_example = h_gt[idx]\n",
    "            loc_gt_example = tf.transpose(tf.stack([x1_gt_example, y1_gt_example, w_gt_example, h_gt_example]))\n",
    "            cls_pred_example = cls_pred[idx]\n",
    "            loc_pred_example = loc_pred[idx]\n",
    "            focal_loss_example, anchor_obj_idx = self.focal_loss(cls_gt_example, cls_pred_example)\n",
    "            smooth_l1_loss_example = self.smooth_l1(loc_gt_example, loc_pred_example, anchor_obj_idx)\n",
    "            focal_loss.append(focal_loss_example)\n",
    "            l1_loss.append(smooth_l1_loss_example)\n",
    "        focal_loss = tf.stack(focal_loss)\n",
    "        l1_loss = tf.stack(l1_loss)\n",
    "        total_loss = focal_loss + l1_loss\n",
    "\n",
    "        return total_loss, focal_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictBox(TensorOp):\n",
    "    def __init__(self,\n",
    "                 inputs=None,\n",
    "                 outputs=None,\n",
    "                 mode=None,\n",
    "                 input_shape=(512, 512, 3),\n",
    "                 select_top_k=1000,\n",
    "                 nms_max_outputs=100):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.input_shape = input_shape\n",
    "        self.select_top_k = tf.cast(select_top_k, dtype=tf.int32)\n",
    "        self.nms_max_outputs = nms_max_outputs\n",
    "\n",
    "        all_anchors, num_anchors_per_level = get_fpn_anchor_box(input_shape=input_shape)\n",
    "        self.all_anchors = tf.convert_to_tensor(all_anchors)\n",
    "        self.num_anchors_per_level = tf.convert_to_tensor(num_anchors_per_level, dtype=tf.int32)\n",
    "\n",
    "    def index_to_bool(self, indices, length):\n",
    "        updates = tf.ones_like(indices, dtype=tf.bool)\n",
    "        shape = tf.expand_dims(length, 0)\n",
    "        is_selected = tf.scatter_nd(tf.cast(tf.expand_dims(indices, axis=-1), dtype=tf.int32), updates, shape)\n",
    "        return is_selected\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        pred = []\n",
    "        gt = []\n",
    "\n",
    "        # extract max score and its class label\n",
    "        cls_pred, deltas, label_gt, x1_gt, y1_gt, w_gt, h_gt = data\n",
    "        labels = tf.cast(tf.argmax(cls_pred, axis=2), dtype=tf.int32)\n",
    "        scores = tf.reduce_max(cls_pred, axis=2)\n",
    "\n",
    "        # iterate over image\n",
    "        for i in range(state['local_batch_size']):\n",
    "            labels_per_image = labels[i]\n",
    "            scores_per_image = scores[i]\n",
    "            deltas_per_image = deltas[i]\n",
    "            \n",
    "            keep_gt = label_gt[i] > 0\n",
    "            label_gt_per_image = label_gt[i][keep_gt]\n",
    "            x1_gt_per_image = x1_gt[i][keep_gt]\n",
    "            y1_gt_per_image = y1_gt[i][keep_gt]\n",
    "            w_gt_per_image = w_gt[i][keep_gt]\n",
    "            h_gt_per_image = h_gt[i][keep_gt]\n",
    "\n",
    "            selected_deltas_per_image = tf.constant([], shape=(0, 4))\n",
    "            selected_labels_per_image = tf.constant([], dtype=tf.int32)\n",
    "            selected_scores_per_image = tf.constant([])\n",
    "            selected_anchor_indices_per_image = tf.constant([], dtype=tf.int32)\n",
    "\n",
    "            end_index = 0\n",
    "            # iterate over each pyramid level\n",
    "            for j in range(self.num_anchors_per_level.shape[0]):\n",
    "                start_index = end_index\n",
    "                end_index += self.num_anchors_per_level[j]\n",
    "                anchor_indices = tf.range(start_index, end_index, dtype=tf.int32)\n",
    "\n",
    "                level_scores = scores_per_image[start_index:end_index]\n",
    "                level_deltas = deltas_per_image[start_index:end_index]\n",
    "                level_labels = labels_per_image[start_index:end_index]\n",
    "\n",
    "                # select top k\n",
    "                if self.num_anchors_per_level[j] >= self.select_top_k:\n",
    "                    # won't work without the tf.minimum\n",
    "                    top_k = tf.math.top_k(level_scores, tf.minimum(self.num_anchors_per_level[j], self.select_top_k))\n",
    "                    top_k_scores = top_k.values\n",
    "                    top_k_indices = tf.add(top_k.indices, [start_index])\n",
    "                else:\n",
    "                    top_k_scores = level_scores\n",
    "                    top_k_indices = anchor_indices\n",
    "\n",
    "                # filter out low score\n",
    "                is_high_score = tf.greater(top_k_scores, 0.05)\n",
    "                selected_indices = tf.boolean_mask(top_k_indices, is_high_score)\n",
    "                is_selected = self.index_to_bool(tf.subtract(selected_indices, [start_index]),\n",
    "                                                 self.num_anchors_per_level[j])\n",
    "\n",
    "                # combine all pyramid levels\n",
    "                selected_deltas_per_image = tf.concat(\n",
    "                    [selected_deltas_per_image, tf.boolean_mask(level_deltas, is_selected)], axis=0)\n",
    "                selected_scores_per_image = tf.concat(\n",
    "                    [selected_scores_per_image, tf.boolean_mask(level_scores, is_selected)], axis=0)\n",
    "                selected_labels_per_image = tf.concat(\n",
    "                    [selected_labels_per_image, tf.boolean_mask(level_labels, is_selected)], axis=0)\n",
    "                selected_anchor_indices_per_image = tf.concat(\n",
    "                    [selected_anchor_indices_per_image, tf.boolean_mask(anchor_indices, is_selected)], axis=0)\n",
    "\n",
    "            # delta -> (x1, y1, w, h)\n",
    "            anchor_mask = self.index_to_bool(selected_anchor_indices_per_image, self.all_anchors.shape[0])\n",
    "            x1 = (selected_deltas_per_image[:, 0] * tf.boolean_mask(\n",
    "                self.all_anchors, anchor_mask)[:, 2]) + tf.boolean_mask(self.all_anchors, anchor_mask)[:, 0]\n",
    "            y1 = (selected_deltas_per_image[:, 1] * tf.boolean_mask(\n",
    "                self.all_anchors, anchor_mask)[:, 3]) + tf.boolean_mask(self.all_anchors, anchor_mask)[:, 1]\n",
    "            w = tf.math.exp(selected_deltas_per_image[:, 2]) * tf.boolean_mask(self.all_anchors, anchor_mask)[:, 2]\n",
    "            h = tf.math.exp(selected_deltas_per_image[:, 3]) * tf.boolean_mask(self.all_anchors, anchor_mask)[:, 3]\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "\n",
    "            # nms\n",
    "            boxes_per_image = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "            nms_indices = tf.image.non_max_suppression(boxes_per_image, selected_scores_per_image, self.nms_max_outputs)\n",
    "\n",
    "            nms_boxes = tf.gather(boxes_per_image, nms_indices)\n",
    "            final_scores = tf.gather(selected_scores_per_image, nms_indices)\n",
    "            final_labels = tf.gather(selected_labels_per_image, nms_indices)\n",
    "\n",
    "            x1 = tf.clip_by_value(nms_boxes[:, 1], clip_value_min=0, clip_value_max=self.input_shape[1])\n",
    "            y1 = tf.clip_by_value(nms_boxes[:, 0], clip_value_min=0, clip_value_max=self.input_shape[0])\n",
    "            w = tf.clip_by_value(nms_boxes[:, 3], clip_value_min=0, clip_value_max=self.input_shape[1]) - x1\n",
    "            h = tf.clip_by_value(nms_boxes[:, 2], clip_value_min=0, clip_value_max=self.input_shape[0]) - y1\n",
    "\n",
    "            final_boxes = tf.stack([x1, y1, w, h], axis=1)\n",
    "\n",
    "            # combine image results into batch\n",
    "            image_results = tf.concat([\n",
    "                tf.pad(final_boxes, [[0, 0], [1, 0]], constant_values=i),\n",
    "                tf.cast(tf.expand_dims(final_labels, axis=1), dtype=tf.float32),\n",
    "                tf.expand_dims(final_scores, axis=1)\n",
    "            ],\n",
    "                                      axis=1)\n",
    "\n",
    "            image_gt = tf.transpose(\n",
    "               tf.concat([\n",
    "                   tf.stack([i * tf.ones_like(x1_gt_per_image), x1_gt_per_image]),\n",
    "                   tf.expand_dims(y1_gt_per_image, axis=0),\n",
    "                   tf.expand_dims(w_gt_per_image, axis=0),\n",
    "                   tf.expand_dims(h_gt_per_image, axis=0),\n",
    "                   tf.expand_dims(label_gt_per_image, axis=0)\n",
    "               ],\n",
    "                         axis=0))\n",
    "            pred.append(image_results)\n",
    "            gt.append(image_gt)\n",
    "            \n",
    "            #tf.print('image_gt', image_gt)\n",
    "            #tf.print('final_boxes', final_boxes)\n",
    "            \n",
    "        return tf.concat(pred, axis=0), tf.concat(gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/data/hsiming/mscoco_model/'\n",
    "writer = fe.RecordWriter(\n",
    "    save_dir=os.path.join(path, \"retinanet_coco_all\"),\n",
    "    train_data='/data/hsiming/dataset/MSCOCO2017/train_object.csv',\n",
    "    validation_data='/data/hsiming/dataset/MSCOCO2017/val_object.csv',\n",
    "    ops=[\n",
    "        ImageReader(inputs=\"image\", parent_path=path, outputs=\"image\"),\n",
    "        String2List(inputs=[\"x1\", \"y1\", \"width\", \"height\", \"obj_label\"],\n",
    "                    outputs=[\"x1\", \"y1\", \"width\", \"height\", \"obj_label\"]),\n",
    "        ResizeImageAndBbox(target_size=(512, 512),\n",
    "                           keep_ratio=True,\n",
    "                           inputs=[\"image\", \"x1\", \"y1\", \"width\", \"height\"],\n",
    "                           outputs=[\"image\", \"x1\", \"y1\", \"width\", \"height\"]),\n",
    "        GenerateTarget(inputs=(\"obj_label\", \"x1\", \"y1\", \"width\", \"height\"),\n",
    "                       outputs=(\"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\")),\n",
    "        TypeConverter(target_type='int32', inputs=[\"id\", \"cls_gt\"], outputs=[\"id\", \"cls_gt\"]),\n",
    "        TypeConverter(target_type='float32',\n",
    "                      inputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"],\n",
    "                      outputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"])\n",
    "    ],\n",
    "    compression=\"GZIP\",\n",
    "    write_feature=[\n",
    "        \"image\", \"id\", \"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\", \"obj_label\", \"x1\", \"y1\", \"width\", \"height\"\n",
    "    ])\n",
    "\n",
    "# prepare pipeline\n",
    "pipeline = fe.Pipeline(\n",
    "    batch_size=8,\n",
    "    data=writer,\n",
    "    ops=[\n",
    "        Rescale(inputs=\"image\", outputs=\"image\"),\n",
    "        Pad(padded_shape=[190],\n",
    "            inputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\", \"obj_label\", \"x1\", \"y1\", \"width\", \"height\"],\n",
    "            outputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\", \"obj_label\", \"x1\", \"y1\", \"width\", \"height\"])\n",
    "    ])\n",
    "\n",
    "# prepare network\n",
    "model = fe.build(model_def=lambda: RetinaNet(input_shape=(512, 512, 3), num_classes=90),\n",
    "                 model_name=\"retinanet\",\n",
    "                 optimizer=tf.optimizers.Adam(learning_rate=0.0002),\n",
    "                 loss_name=\"total_loss\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=\"image\", model=model, outputs=[\"cls_pred\", \"loc_pred\"]),\n",
    "    PredictBox(inputs=[\"cls_pred\", \"loc_pred\", \"obj_label\", \"x1\", \"y1\", \"width\", \"height\"],\n",
    "               outputs=(\"pred\", \"gt\"),\n",
    "               mode=\"eval\"),\n",
    "    RetinaLoss(inputs=(\"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\", \"cls_pred\", \"loc_pred\"),\n",
    "               outputs=(\"total_loss\", \"focal_loss\", \"l1_loss\"))\n",
    "])\n",
    "\n",
    "# prepare estimator\n",
    "estimator = fe.Estimator(\n",
    "    network=network,\n",
    "    pipeline=pipeline,\n",
    "    epochs=80,\n",
    "    #steps_per_epoch=2,\n",
    "    #log_steps=1,\n",
    "    #validation_steps=2,\n",
    "    traces=ModelSaver(model_name=\"retinanet\", save_dir=model_dir, save_best=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator: Reading non-empty directory: /data/hsiming/dataset/MSCOCO2017/retinanet_coco_all\n",
      "FastEstimator: Found 117266 examples for train in /data/hsiming/dataset/MSCOCO2017/retinanet_coco_all/train_summary0.json\n",
      "FastEstimator: Found 4952 examples for eval in /data/hsiming/dataset/MSCOCO2017/retinanet_coco_all/eval_summary0.json\n",
      "FastEstimator-Start: step: 0; total_train_steps: 1172640; retinanet_lr: 0.0002; \n",
      "FastEstimator-Train: step: 0; focal_loss: 1.5600891; l1_loss: 0.703277; total_loss: 2.2633662; \n",
      "FastEstimator-Train: step: 100; focal_loss: 1.1645204; l1_loss: 0.7520683; total_loss: 1.9165885; examples/sec: 33.5; progress: 0.0%; \n",
      "FastEstimator-Train: step: 200; focal_loss: 0.9954345; l1_loss: 0.66015; total_loss: 1.6555846; examples/sec: 33.4; progress: 0.0%; \n",
      "FastEstimator-Train: step: 300; focal_loss: 1.0938352; l1_loss: 0.6976941; total_loss: 1.7915292; examples/sec: 33.3; progress: 0.0%; \n",
      "FastEstimator-Train: step: 400; focal_loss: 0.8942057; l1_loss: 0.7040013; total_loss: 1.598207; examples/sec: 33.3; progress: 0.0%; \n",
      "FastEstimator-Train: step: 500; focal_loss: 0.9683896; l1_loss: 0.825398; total_loss: 1.7937878; examples/sec: 33.4; progress: 0.0%; \n",
      "FastEstimator-Train: step: 600; focal_loss: 0.9766657; l1_loss: 0.6272684; total_loss: 1.603934; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 700; focal_loss: 0.9592865; l1_loss: 0.6959818; total_loss: 1.6552683; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 800; focal_loss: 0.9589478; l1_loss: 0.6429254; total_loss: 1.6018732; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 900; focal_loss: 0.8926387; l1_loss: 0.611475; total_loss: 1.5041138; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1000; focal_loss: 1.0766885; l1_loss: 0.6021826; total_loss: 1.6788712; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1100; focal_loss: 0.9101833; l1_loss: 0.5608944; total_loss: 1.4710778; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1200; focal_loss: 0.9306473; l1_loss: 0.6843033; total_loss: 1.6149505; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1300; focal_loss: 0.872883; l1_loss: 0.5870844; total_loss: 1.4599674; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1400; focal_loss: 0.7468872; l1_loss: 0.5359474; total_loss: 1.2828345; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1500; focal_loss: 0.8645629; l1_loss: 0.5878126; total_loss: 1.4523754; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1600; focal_loss: 0.9692807; l1_loss: 0.5178747; total_loss: 1.4871554; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1700; focal_loss: 0.8547168; l1_loss: 0.519079; total_loss: 1.3737957; examples/sec: 33.3; progress: 0.1%; \n",
      "FastEstimator-Train: step: 1800; focal_loss: 0.9332561; l1_loss: 0.4792136; total_loss: 1.4124696; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 1900; focal_loss: 0.991772; l1_loss: 0.5303307; total_loss: 1.5221027; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2000; focal_loss: 0.8925483; l1_loss: 0.4663756; total_loss: 1.3589239; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2100; focal_loss: 0.818798; l1_loss: 0.6199551; total_loss: 1.438753; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2200; focal_loss: 0.866976; l1_loss: 0.4878136; total_loss: 1.3547895; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2300; focal_loss: 0.861272; l1_loss: 0.5471449; total_loss: 1.408417; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2400; focal_loss: 0.9196922; l1_loss: 0.5431018; total_loss: 1.4627941; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2500; focal_loss: 0.8844761; l1_loss: 0.5236497; total_loss: 1.4081259; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2600; focal_loss: 0.896515; l1_loss: 0.5242631; total_loss: 1.420778; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2700; focal_loss: 0.8446241; l1_loss: 0.2972146; total_loss: 1.1418388; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2800; focal_loss: 0.8153272; l1_loss: 0.5382368; total_loss: 1.3535639; examples/sec: 33.3; progress: 0.2%; \n",
      "FastEstimator-Train: step: 2900; focal_loss: 0.8953471; l1_loss: 0.5182754; total_loss: 1.4136225; examples/sec: 33.4; progress: 0.2%; \n",
      "FastEstimator-Train: step: 3000; focal_loss: 0.7563828; l1_loss: 0.4904204; total_loss: 1.2468033; examples/sec: 33.3; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3100; focal_loss: 0.8492045; l1_loss: 0.6283157; total_loss: 1.4775201; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3200; focal_loss: 0.8344554; l1_loss: 0.5197488; total_loss: 1.3542042; examples/sec: 33.3; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3300; focal_loss: 0.7648406; l1_loss: 0.5115078; total_loss: 1.2763486; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3400; focal_loss: 0.7901629; l1_loss: 0.5784176; total_loss: 1.3685806; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3500; focal_loss: 0.6994814; l1_loss: 0.6240678; total_loss: 1.3235493; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3600; focal_loss: 0.9855859; l1_loss: 0.5164659; total_loss: 1.5020518; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3700; focal_loss: 0.8991108; l1_loss: 0.4928141; total_loss: 1.3919249; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3800; focal_loss: 0.7369293; l1_loss: 0.3840218; total_loss: 1.1209512; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 3900; focal_loss: 0.8471105; l1_loss: 0.5173671; total_loss: 1.3644775; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 4000; focal_loss: 0.8553324; l1_loss: 0.5688671; total_loss: 1.4241996; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 4100; focal_loss: 0.7744812; l1_loss: 0.4830869; total_loss: 1.2575681; examples/sec: 33.4; progress: 0.3%; \n",
      "FastEstimator-Train: step: 4200; focal_loss: 0.6682031; l1_loss: 0.3721771; total_loss: 1.0403801; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4300; focal_loss: 0.8058448; l1_loss: 0.5114952; total_loss: 1.3173401; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4400; focal_loss: 0.7196988; l1_loss: 0.4509892; total_loss: 1.1706879; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4500; focal_loss: 0.6640113; l1_loss: 0.5017304; total_loss: 1.1657417; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4600; focal_loss: 0.8295735; l1_loss: 0.4826658; total_loss: 1.3122393; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4700; focal_loss: 0.7107644; l1_loss: 0.4863132; total_loss: 1.1970776; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4800; focal_loss: 0.7881105; l1_loss: 0.5267756; total_loss: 1.3148861; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 4900; focal_loss: 0.6469324; l1_loss: 0.4933523; total_loss: 1.1402847; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 5000; focal_loss: 0.7593168; l1_loss: 0.4530554; total_loss: 1.2123723; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 5100; focal_loss: 0.7831074; l1_loss: 0.5128833; total_loss: 1.2959907; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 5200; focal_loss: 0.7386783; l1_loss: 0.5714699; total_loss: 1.3101482; examples/sec: 33.4; progress: 0.4%; \n",
      "FastEstimator-Train: step: 5300; focal_loss: 0.7756113; l1_loss: 0.5347674; total_loss: 1.3103788; examples/sec: 33.3; progress: 0.5%; \n",
      "FastEstimator-Train: step: 5400; focal_loss: 0.6961636; l1_loss: 0.3086419; total_loss: 1.0048054; examples/sec: 33.4; progress: 0.5%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 5500; focal_loss: 0.7637422; l1_loss: 0.5298596; total_loss: 1.293602; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 5600; focal_loss: 0.7404329; l1_loss: 0.4863608; total_loss: 1.2267938; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 5700; focal_loss: 0.6726234; l1_loss: 0.4808474; total_loss: 1.1534708; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 5800; focal_loss: 0.7431409; l1_loss: 0.53739; total_loss: 1.2805309; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 5900; focal_loss: 0.839144; l1_loss: 0.4973605; total_loss: 1.3365045; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6000; focal_loss: 0.7792312; l1_loss: 0.4192572; total_loss: 1.1984885; examples/sec: 33.3; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6100; focal_loss: 0.6893817; l1_loss: 0.4184314; total_loss: 1.1078131; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6200; focal_loss: 0.7585382; l1_loss: 0.6234294; total_loss: 1.3819675; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6300; focal_loss: 0.6679248; l1_loss: 0.4748406; total_loss: 1.1427653; examples/sec: 33.3; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6400; focal_loss: 0.6444134; l1_loss: 0.4461644; total_loss: 1.0905778; examples/sec: 33.4; progress: 0.5%; \n",
      "FastEstimator-Train: step: 6500; focal_loss: 0.5990648; l1_loss: 0.4942765; total_loss: 1.0933414; examples/sec: 33.3; progress: 0.6%; \n",
      "FastEstimator-Train: step: 6600; focal_loss: 0.8494283; l1_loss: 0.4272564; total_loss: 1.2766848; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 6700; focal_loss: 0.6454868; l1_loss: 0.4566614; total_loss: 1.1021483; examples/sec: 33.3; progress: 0.6%; \n",
      "FastEstimator-Train: step: 6800; focal_loss: 0.889274; l1_loss: 0.5256814; total_loss: 1.4149554; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 6900; focal_loss: 0.6772699; l1_loss: 0.4365094; total_loss: 1.1137793; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7000; focal_loss: 0.7510675; l1_loss: 0.5302468; total_loss: 1.2813143; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7100; focal_loss: 0.723198; l1_loss: 0.4370404; total_loss: 1.1602385; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7200; focal_loss: 0.6300983; l1_loss: 0.4294488; total_loss: 1.0595471; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7300; focal_loss: 0.682606; l1_loss: 0.4110184; total_loss: 1.0936245; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7400; focal_loss: 0.7158972; l1_loss: 0.3418988; total_loss: 1.0577959; examples/sec: 33.3; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7500; focal_loss: 0.7317343; l1_loss: 0.4463029; total_loss: 1.1780372; examples/sec: 33.3; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7600; focal_loss: 0.6375473; l1_loss: 0.3803576; total_loss: 1.0179049; examples/sec: 33.4; progress: 0.6%; \n",
      "FastEstimator-Train: step: 7700; focal_loss: 0.7423788; l1_loss: 0.480683; total_loss: 1.2230618; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 7800; focal_loss: 0.801089; l1_loss: 0.4500792; total_loss: 1.2511683; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 7900; focal_loss: 0.6362018; l1_loss: 0.4034501; total_loss: 1.0396519; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8000; focal_loss: 0.6948571; l1_loss: 0.4397072; total_loss: 1.1345643; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8100; focal_loss: 0.7101708; l1_loss: 0.5043482; total_loss: 1.214519; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8200; focal_loss: 0.6267745; l1_loss: 0.4170526; total_loss: 1.043827; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8300; focal_loss: 0.7742524; l1_loss: 0.478372; total_loss: 1.2526245; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8400; focal_loss: 0.7106306; l1_loss: 0.565468; total_loss: 1.2760985; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8500; focal_loss: 0.6854724; l1_loss: 0.3920538; total_loss: 1.0775263; examples/sec: 33.3; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8600; focal_loss: 0.6946202; l1_loss: 0.4414608; total_loss: 1.1360811; examples/sec: 33.4; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8700; focal_loss: 0.5787782; l1_loss: 0.422303; total_loss: 1.0010812; examples/sec: 33.3; progress: 0.7%; \n",
      "FastEstimator-Train: step: 8800; focal_loss: 0.7371462; l1_loss: 0.4856152; total_loss: 1.2227614; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 8900; focal_loss: 0.790939; l1_loss: 0.539289; total_loss: 1.3302281; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9000; focal_loss: 0.6676956; l1_loss: 0.3771277; total_loss: 1.0448234; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9100; focal_loss: 0.5844236; l1_loss: 0.4178014; total_loss: 1.0022249; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9200; focal_loss: 0.5979622; l1_loss: 0.4939888; total_loss: 1.0919511; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9300; focal_loss: 0.5695188; l1_loss: 0.4465935; total_loss: 1.0161123; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9400; focal_loss: 0.7967686; l1_loss: 0.5294231; total_loss: 1.3261918; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9500; focal_loss: 0.629874; l1_loss: 0.4549088; total_loss: 1.0847827; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9600; focal_loss: 0.6170447; l1_loss: 0.4515478; total_loss: 1.0685924; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9700; focal_loss: 0.7450123; l1_loss: 0.5676887; total_loss: 1.312701; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9800; focal_loss: 0.7055044; l1_loss: 0.529016; total_loss: 1.2345203; examples/sec: 33.3; progress: 0.8%; \n",
      "FastEstimator-Train: step: 9900; focal_loss: 0.6770374; l1_loss: 0.4931672; total_loss: 1.1702046; examples/sec: 33.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 10000; focal_loss: 0.7592821; l1_loss: 0.5435887; total_loss: 1.3028708; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10100; focal_loss: 0.5686044; l1_loss: 0.5184398; total_loss: 1.0870441; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10200; focal_loss: 0.6772804; l1_loss: 0.4688916; total_loss: 1.146172; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10300; focal_loss: 0.7502347; l1_loss: 0.4399272; total_loss: 1.1901618; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10400; focal_loss: 0.771468; l1_loss: 0.4845856; total_loss: 1.2560536; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10500; focal_loss: 0.5753488; l1_loss: 0.2795511; total_loss: 0.8548998; examples/sec: 33.3; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10600; focal_loss: 0.6294955; l1_loss: 0.4914297; total_loss: 1.1209252; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10700; focal_loss: 0.6755072; l1_loss: 0.5728923; total_loss: 1.2483995; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10800; focal_loss: 0.7050778; l1_loss: 0.3605244; total_loss: 1.0656022; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 10900; focal_loss: 0.733937; l1_loss: 0.4126136; total_loss: 1.1465507; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 11000; focal_loss: 0.708431; l1_loss: 0.565024; total_loss: 1.273455; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 11100; focal_loss: 0.6308675; l1_loss: 0.4420526; total_loss: 1.0729201; examples/sec: 33.4; progress: 0.9%; \n",
      "FastEstimator-Train: step: 11200; focal_loss: 0.6834868; l1_loss: 0.4636832; total_loss: 1.1471698; examples/sec: 33.3; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11300; focal_loss: 0.7053942; l1_loss: 0.491034; total_loss: 1.1964282; examples/sec: 33.3; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11400; focal_loss: 0.7337716; l1_loss: 0.3747464; total_loss: 1.108518; examples/sec: 33.3; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11500; focal_loss: 0.6734939; l1_loss: 0.4754576; total_loss: 1.1489515; examples/sec: 33.3; progress: 1.0%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 11600; focal_loss: 0.6499062; l1_loss: 0.4524004; total_loss: 1.1023066; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11700; focal_loss: 0.6320558; l1_loss: 0.5093858; total_loss: 1.1414416; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11800; focal_loss: 0.6557302; l1_loss: 0.4566703; total_loss: 1.1124005; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 11900; focal_loss: 0.665969; l1_loss: 0.3976321; total_loss: 1.0636011; examples/sec: 33.3; progress: 1.0%; \n",
      "FastEstimator-Train: step: 12000; focal_loss: 0.8009624; l1_loss: 0.527833; total_loss: 1.3287953; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 12100; focal_loss: 0.5591606; l1_loss: 0.4449278; total_loss: 1.0040884; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 12200; focal_loss: 0.6896286; l1_loss: 0.4546295; total_loss: 1.144258; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 12300; focal_loss: 0.5917549; l1_loss: 0.370744; total_loss: 0.9624989; examples/sec: 33.4; progress: 1.0%; \n",
      "FastEstimator-Train: step: 12400; focal_loss: 0.790298; l1_loss: 0.5375412; total_loss: 1.3278393; examples/sec: 33.3; progress: 1.1%; \n",
      "FastEstimator-Train: step: 12500; focal_loss: 0.6302266; l1_loss: 0.3656296; total_loss: 0.9958562; examples/sec: 33.3; progress: 1.1%; \n",
      "FastEstimator-Train: step: 12600; focal_loss: 0.6107111; l1_loss: 0.3647392; total_loss: 0.9754503; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 12700; focal_loss: 0.7436687; l1_loss: 0.6212399; total_loss: 1.3649085; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 12800; focal_loss: 0.7033888; l1_loss: 0.4023372; total_loss: 1.105726; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 12900; focal_loss: 0.658326; l1_loss: 0.4501139; total_loss: 1.1084399; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13000; focal_loss: 0.5842028; l1_loss: 0.2888972; total_loss: 0.8730999; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13100; focal_loss: 0.594238; l1_loss: 0.5543908; total_loss: 1.148629; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13200; focal_loss: 0.5573364; l1_loss: 0.3563897; total_loss: 0.9137261; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13300; focal_loss: 0.765186; l1_loss: 0.5261513; total_loss: 1.2913375; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13400; focal_loss: 0.7954639; l1_loss: 0.4280378; total_loss: 1.2235017; examples/sec: 33.4; progress: 1.1%; \n",
      "FastEstimator-Train: step: 13500; focal_loss: 0.6837212; l1_loss: 0.3190208; total_loss: 1.0027419; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 13600; focal_loss: 0.6106645; l1_loss: 0.3266128; total_loss: 0.9372773; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 13700; focal_loss: 0.5885542; l1_loss: 0.5260347; total_loss: 1.114589; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 13800; focal_loss: 0.8763725; l1_loss: 0.6048874; total_loss: 1.4812598; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 13900; focal_loss: 0.7601135; l1_loss: 0.45222; total_loss: 1.2123334; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14000; focal_loss: 0.6604804; l1_loss: 0.4545485; total_loss: 1.115029; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14100; focal_loss: 0.6427827; l1_loss: 0.4914738; total_loss: 1.1342564; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14200; focal_loss: 0.6622904; l1_loss: 0.5097608; total_loss: 1.1720512; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14300; focal_loss: 0.5516338; l1_loss: 0.3674525; total_loss: 0.9190862; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14400; focal_loss: 0.7016908; l1_loss: 0.3311666; total_loss: 1.0328574; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14500; focal_loss: 0.6698486; l1_loss: 0.3471205; total_loss: 1.016969; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-Train: step: 14600; focal_loss: 0.8059242; l1_loss: 0.4274494; total_loss: 1.2333736; examples/sec: 33.4; progress: 1.2%; \n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 14658; epoch: 0; focal_loss: 0.6325516; l1_loss: 0.4237996; total_loss: 1.0563512; \n",
      "FastEstimator-Train: step: 14700; focal_loss: 0.5183214; l1_loss: 0.3167762; total_loss: 0.8350975; examples/sec: 19.7; progress: 1.3%; \n",
      "FastEstimator-Train: step: 14800; focal_loss: 0.5898566; l1_loss: 0.3881306; total_loss: 0.9779872; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 14900; focal_loss: 0.66822; l1_loss: 0.3671733; total_loss: 1.0353934; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15000; focal_loss: 0.5790319; l1_loss: 0.2285214; total_loss: 0.8075532; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15100; focal_loss: 0.5186376; l1_loss: 0.3070398; total_loss: 0.8256774; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15200; focal_loss: 0.4623586; l1_loss: 0.3229874; total_loss: 0.7853461; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15300; focal_loss: 0.63195; l1_loss: 0.3518586; total_loss: 0.9838087; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15400; focal_loss: 0.5333464; l1_loss: 0.4444157; total_loss: 0.977762; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15500; focal_loss: 0.467604; l1_loss: 0.3654083; total_loss: 0.8330123; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15600; focal_loss: 0.5764045; l1_loss: 0.3645213; total_loss: 0.9409258; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15700; focal_loss: 0.7006304; l1_loss: 0.4772428; total_loss: 1.1778733; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15800; focal_loss: 0.661376; l1_loss: 0.3054476; total_loss: 0.9668235; examples/sec: 33.4; progress: 1.3%; \n",
      "FastEstimator-Train: step: 15900; focal_loss: 0.6138598; l1_loss: 0.3407418; total_loss: 0.9546016; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16000; focal_loss: 0.6863358; l1_loss: 0.3681993; total_loss: 1.054535; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16100; focal_loss: 0.5117421; l1_loss: 0.3171508; total_loss: 0.828893; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16200; focal_loss: 0.7351638; l1_loss: 0.402719; total_loss: 1.1378828; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16300; focal_loss: 0.6010786; l1_loss: 0.4030796; total_loss: 1.0041583; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16400; focal_loss: 0.6803943; l1_loss: 0.5112472; total_loss: 1.1916416; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16500; focal_loss: 0.6354761; l1_loss: 0.3172532; total_loss: 0.9527292; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16600; focal_loss: 0.5868502; l1_loss: 0.4162407; total_loss: 1.0030909; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16700; focal_loss: 0.5884964; l1_loss: 0.3678573; total_loss: 0.9563537; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16800; focal_loss: 0.7065392; l1_loss: 0.3704463; total_loss: 1.0769855; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 16900; focal_loss: 0.6641932; l1_loss: 0.4965757; total_loss: 1.160769; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 17000; focal_loss: 0.6622614; l1_loss: 0.3986722; total_loss: 1.0609336; examples/sec: 33.4; progress: 1.4%; \n",
      "FastEstimator-Train: step: 17100; focal_loss: 0.4917616; l1_loss: 0.3984731; total_loss: 0.8902346; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17200; focal_loss: 0.6847117; l1_loss: 0.4142246; total_loss: 1.0989363; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17300; focal_loss: 0.6139898; l1_loss: 0.4113764; total_loss: 1.0253663; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17400; focal_loss: 0.5514152; l1_loss: 0.4502084; total_loss: 1.0016236; examples/sec: 33.4; progress: 1.5%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 17500; focal_loss: 0.7006044; l1_loss: 0.4018294; total_loss: 1.1024339; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17600; focal_loss: 0.6982337; l1_loss: 0.504255; total_loss: 1.2024888; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17700; focal_loss: 0.5847476; l1_loss: 0.3894202; total_loss: 0.9741678; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17800; focal_loss: 0.5707952; l1_loss: 0.3387395; total_loss: 0.9095347; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 17900; focal_loss: 0.6011859; l1_loss: 0.3815624; total_loss: 0.9827484; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 18000; focal_loss: 0.6768208; l1_loss: 0.4311139; total_loss: 1.1079347; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 18100; focal_loss: 0.543067; l1_loss: 0.3362033; total_loss: 0.8792703; examples/sec: 33.4; progress: 1.5%; \n",
      "FastEstimator-Train: step: 18200; focal_loss: 0.7049836; l1_loss: 0.4576137; total_loss: 1.1625973; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18300; focal_loss: 0.6884312; l1_loss: 0.3575182; total_loss: 1.0459493; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18400; focal_loss: 0.688774; l1_loss: 0.4412461; total_loss: 1.13002; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18500; focal_loss: 0.7771182; l1_loss: 0.3756631; total_loss: 1.1527812; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18600; focal_loss: 0.7357207; l1_loss: 0.3457193; total_loss: 1.08144; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18700; focal_loss: 0.6961718; l1_loss: 0.4197906; total_loss: 1.1159623; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18800; focal_loss: 0.5112006; l1_loss: 0.4131572; total_loss: 0.9243579; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 18900; focal_loss: 0.6064772; l1_loss: 0.4517124; total_loss: 1.0581896; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 19000; focal_loss: 0.5846777; l1_loss: 0.4454868; total_loss: 1.0301645; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 19100; focal_loss: 0.729032; l1_loss: 0.4901961; total_loss: 1.2192281; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 19200; focal_loss: 0.4945302; l1_loss: 0.2967706; total_loss: 0.7913008; examples/sec: 33.4; progress: 1.6%; \n",
      "FastEstimator-Train: step: 19300; focal_loss: 0.5372694; l1_loss: 0.3673085; total_loss: 0.9045779; examples/sec: 33.3; progress: 1.6%; \n",
      "FastEstimator-Train: step: 19400; focal_loss: 0.5269984; l1_loss: 0.388485; total_loss: 0.9154834; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 19500; focal_loss: 0.6745684; l1_loss: 0.3924752; total_loss: 1.0670435; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 19600; focal_loss: 0.4810419; l1_loss: 0.3114978; total_loss: 0.7925396; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 19700; focal_loss: 0.5703574; l1_loss: 0.3841634; total_loss: 0.9545208; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 19800; focal_loss: 0.5517725; l1_loss: 0.449026; total_loss: 1.0007985; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 19900; focal_loss: 0.5829474; l1_loss: 0.4597302; total_loss: 1.0426774; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20000; focal_loss: 0.6418168; l1_loss: 0.4165456; total_loss: 1.0583624; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20100; focal_loss: 0.5714546; l1_loss: 0.3560786; total_loss: 0.9275333; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20200; focal_loss: 0.7874979; l1_loss: 0.3729614; total_loss: 1.1604592; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20300; focal_loss: 0.7682086; l1_loss: 0.4279258; total_loss: 1.1961344; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20400; focal_loss: 0.6101646; l1_loss: 0.4504638; total_loss: 1.0606284; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20500; focal_loss: 0.5515458; l1_loss: 0.349694; total_loss: 0.9012398; examples/sec: 33.4; progress: 1.7%; \n",
      "FastEstimator-Train: step: 20600; focal_loss: 0.633304; l1_loss: 0.3889291; total_loss: 1.022233; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 20700; focal_loss: 0.6460765; l1_loss: 0.408126; total_loss: 1.0542026; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 20800; focal_loss: 0.6165586; l1_loss: 0.3615801; total_loss: 0.9781387; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 20900; focal_loss: 0.5133718; l1_loss: 0.3493803; total_loss: 0.8627521; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21000; focal_loss: 0.6186242; l1_loss: 0.4648824; total_loss: 1.0835067; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21100; focal_loss: 0.619079; l1_loss: 0.4197572; total_loss: 1.0388362; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21200; focal_loss: 0.6193846; l1_loss: 0.4043631; total_loss: 1.0237476; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21300; focal_loss: 0.6672678; l1_loss: 0.3683418; total_loss: 1.0356096; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21400; focal_loss: 0.5475334; l1_loss: 0.3938372; total_loss: 0.9413705; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21500; focal_loss: 0.5765865; l1_loss: 0.3882679; total_loss: 0.9648544; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21600; focal_loss: 0.4936456; l1_loss: 0.3208897; total_loss: 0.8145354; examples/sec: 33.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 21700; focal_loss: 0.516109; l1_loss: 0.2990946; total_loss: 0.8152036; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 21800; focal_loss: 0.6796046; l1_loss: 0.4412578; total_loss: 1.1208625; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 21900; focal_loss: 0.5438176; l1_loss: 0.3985096; total_loss: 0.9423273; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22000; focal_loss: 0.6138895; l1_loss: 0.4432782; total_loss: 1.0571678; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22100; focal_loss: 0.6409814; l1_loss: 0.4105781; total_loss: 1.0515594; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22200; focal_loss: 0.7009936; l1_loss: 0.374889; total_loss: 1.0758827; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22300; focal_loss: 0.6798402; l1_loss: 0.5557311; total_loss: 1.2355714; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22400; focal_loss: 0.4373001; l1_loss: 0.3290123; total_loss: 0.7663124; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22500; focal_loss: 0.5036482; l1_loss: 0.4099865; total_loss: 0.9136346; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22600; focal_loss: 0.6464802; l1_loss: 0.4696644; total_loss: 1.1161447; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22700; focal_loss: 0.4805978; l1_loss: 0.3640036; total_loss: 0.8446014; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22800; focal_loss: 0.729855; l1_loss: 0.391474; total_loss: 1.1213288; examples/sec: 33.4; progress: 1.9%; \n",
      "FastEstimator-Train: step: 22900; focal_loss: 0.6035253; l1_loss: 0.5345316; total_loss: 1.1380569; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23000; focal_loss: 0.5693164; l1_loss: 0.4927248; total_loss: 1.0620413; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23100; focal_loss: 0.5124126; l1_loss: 0.3597646; total_loss: 0.8721772; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23200; focal_loss: 0.6183504; l1_loss: 0.4452606; total_loss: 1.063611; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23300; focal_loss: 0.6163854; l1_loss: 0.3540749; total_loss: 0.9704602; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23400; focal_loss: 0.7726836; l1_loss: 0.4563847; total_loss: 1.2290684; examples/sec: 33.4; progress: 2.0%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 23500; focal_loss: 0.7295968; l1_loss: 0.4555186; total_loss: 1.1851153; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23600; focal_loss: 0.624904; l1_loss: 0.3597507; total_loss: 0.9846547; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23700; focal_loss: 0.4301724; l1_loss: 0.3233625; total_loss: 0.7535349; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23800; focal_loss: 0.5936264; l1_loss: 0.3632671; total_loss: 0.9568935; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 23900; focal_loss: 0.5004794; l1_loss: 0.2948154; total_loss: 0.7952948; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 24000; focal_loss: 0.5357234; l1_loss: 0.487462; total_loss: 1.0231855; examples/sec: 33.4; progress: 2.0%; \n",
      "FastEstimator-Train: step: 24100; focal_loss: 0.5940969; l1_loss: 0.3605058; total_loss: 0.9546026; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24200; focal_loss: 0.4632706; l1_loss: 0.3800408; total_loss: 0.8433114; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24300; focal_loss: 0.4866997; l1_loss: 0.3511155; total_loss: 0.8378152; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24400; focal_loss: 0.616899; l1_loss: 0.3592457; total_loss: 0.9761448; examples/sec: 33.3; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24500; focal_loss: 0.6072051; l1_loss: 0.4838; total_loss: 1.0910051; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24600; focal_loss: 0.5450109; l1_loss: 0.3067848; total_loss: 0.8517958; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24700; focal_loss: 0.5441798; l1_loss: 0.3570717; total_loss: 0.9012514; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24800; focal_loss: 0.5128392; l1_loss: 0.3662958; total_loss: 0.879135; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 24900; focal_loss: 0.6746788; l1_loss: 0.3710511; total_loss: 1.0457299; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 25000; focal_loss: 0.5732298; l1_loss: 0.3912218; total_loss: 0.9644515; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 25100; focal_loss: 0.6444498; l1_loss: 0.563231; total_loss: 1.2076808; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 25200; focal_loss: 0.5956002; l1_loss: 0.5014118; total_loss: 1.097012; examples/sec: 33.4; progress: 2.1%; \n",
      "FastEstimator-Train: step: 25300; focal_loss: 0.5095988; l1_loss: 0.312797; total_loss: 0.8223958; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25400; focal_loss: 0.5475602; l1_loss: 0.3389374; total_loss: 0.8864976; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25500; focal_loss: 0.557056; l1_loss: 0.3614349; total_loss: 0.9184909; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25600; focal_loss: 0.3933857; l1_loss: 0.2785758; total_loss: 0.6719616; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25700; focal_loss: 0.6268978; l1_loss: 0.3233769; total_loss: 0.9502748; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25800; focal_loss: 0.6845511; l1_loss: 0.4974998; total_loss: 1.1820511; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 25900; focal_loss: 0.5142029; l1_loss: 0.3921916; total_loss: 0.9063945; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 26000; focal_loss: 0.5778398; l1_loss: 0.3697007; total_loss: 0.9475404; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 26100; focal_loss: 0.4796374; l1_loss: 0.4242413; total_loss: 0.9038787; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 26200; focal_loss: 0.5642108; l1_loss: 0.340666; total_loss: 0.9048768; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 26300; focal_loss: 0.6954012; l1_loss: 0.2977565; total_loss: 0.9931576; examples/sec: 33.4; progress: 2.2%; \n",
      "FastEstimator-Train: step: 26400; focal_loss: 0.5066002; l1_loss: 0.3732812; total_loss: 0.8798815; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 26500; focal_loss: 0.5507308; l1_loss: 0.3969774; total_loss: 0.9477082; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 26600; focal_loss: 0.5092642; l1_loss: 0.437773; total_loss: 0.9470371; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 26700; focal_loss: 0.5605876; l1_loss: 0.437173; total_loss: 0.9977606; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 26800; focal_loss: 0.520923; l1_loss: 0.4461667; total_loss: 0.9670897; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 26900; focal_loss: 0.6056967; l1_loss: 0.3856783; total_loss: 0.9913749; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27000; focal_loss: 0.5985366; l1_loss: 0.3336562; total_loss: 0.9321928; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27100; focal_loss: 0.6287982; l1_loss: 0.3147147; total_loss: 0.9435129; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27200; focal_loss: 0.5554296; l1_loss: 0.3854266; total_loss: 0.9408562; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27300; focal_loss: 0.5304552; l1_loss: 0.2971958; total_loss: 0.827651; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27400; focal_loss: 0.8571101; l1_loss: 0.4125225; total_loss: 1.2696326; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27500; focal_loss: 0.5862628; l1_loss: 0.3969957; total_loss: 0.9832585; examples/sec: 33.4; progress: 2.3%; \n",
      "FastEstimator-Train: step: 27600; focal_loss: 0.6066052; l1_loss: 0.3688856; total_loss: 0.9754907; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 27700; focal_loss: 0.7331738; l1_loss: 0.303359; total_loss: 1.0365329; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 27800; focal_loss: 0.4952946; l1_loss: 0.285602; total_loss: 0.7808966; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 27900; focal_loss: 0.5697208; l1_loss: 0.3174153; total_loss: 0.8871362; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28000; focal_loss: 0.5591365; l1_loss: 0.2989793; total_loss: 0.8581159; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28100; focal_loss: 0.6719379; l1_loss: 0.4641814; total_loss: 1.1361194; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28200; focal_loss: 0.6262052; l1_loss: 0.2901166; total_loss: 0.9163218; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28300; focal_loss: 0.6569506; l1_loss: 0.5045646; total_loss: 1.1615152; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28400; focal_loss: 0.761326; l1_loss: 0.3742663; total_loss: 1.1355923; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28500; focal_loss: 0.6843965; l1_loss: 0.3766567; total_loss: 1.0610533; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28600; focal_loss: 0.5922479; l1_loss: 0.4165964; total_loss: 1.0088444; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28700; focal_loss: 0.5378424; l1_loss: 0.3192402; total_loss: 0.8570826; examples/sec: 33.4; progress: 2.4%; \n",
      "FastEstimator-Train: step: 28800; focal_loss: 0.4737054; l1_loss: 0.2451119; total_loss: 0.7188172; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 28900; focal_loss: 0.6916202; l1_loss: 0.3679761; total_loss: 1.0595963; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29000; focal_loss: 0.5589208; l1_loss: 0.4453838; total_loss: 1.0043045; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29100; focal_loss: 0.4536152; l1_loss: 0.3072255; total_loss: 0.7608406; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29200; focal_loss: 0.4905897; l1_loss: 0.335946; total_loss: 0.8265356; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29300; focal_loss: 0.565271; l1_loss: 0.3658942; total_loss: 0.9311652; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 29316; epoch: 1; focal_loss: 0.5988857; l1_loss: 0.3962; total_loss: 0.9950857; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 29400; focal_loss: 0.535392; l1_loss: 0.4920212; total_loss: 1.0274134; examples/sec: 19.3; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29500; focal_loss: 0.5803125; l1_loss: 0.3135663; total_loss: 0.8938788; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29600; focal_loss: 0.6264062; l1_loss: 0.3724274; total_loss: 0.9988335; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29700; focal_loss: 0.5009958; l1_loss: 0.3788614; total_loss: 0.8798573; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29800; focal_loss: 0.5386863; l1_loss: 0.316874; total_loss: 0.8555602; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 29900; focal_loss: 0.669926; l1_loss: 0.4311368; total_loss: 1.1010628; examples/sec: 33.4; progress: 2.5%; \n",
      "FastEstimator-Train: step: 30000; focal_loss: 0.6603713; l1_loss: 0.4262386; total_loss: 1.0866098; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30100; focal_loss: 0.5274316; l1_loss: 0.3746116; total_loss: 0.9020432; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30200; focal_loss: 0.6384299; l1_loss: 0.4942854; total_loss: 1.1327152; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30300; focal_loss: 0.4823536; l1_loss: 0.2994088; total_loss: 0.7817624; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30400; focal_loss: 0.5995309; l1_loss: 0.2506744; total_loss: 0.8502052; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30500; focal_loss: 0.6030313; l1_loss: 0.334383; total_loss: 0.9374142; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30600; focal_loss: 0.6428708; l1_loss: 0.4849132; total_loss: 1.127784; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30700; focal_loss: 0.5275438; l1_loss: 0.2414922; total_loss: 0.769036; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30800; focal_loss: 0.4871522; l1_loss: 0.3397893; total_loss: 0.8269414; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 30900; focal_loss: 0.672707; l1_loss: 0.5071784; total_loss: 1.1798854; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 31000; focal_loss: 0.3672278; l1_loss: 0.3652347; total_loss: 0.7324626; examples/sec: 33.4; progress: 2.6%; \n",
      "FastEstimator-Train: step: 31100; focal_loss: 0.6384058; l1_loss: 0.424118; total_loss: 1.0625238; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31200; focal_loss: 0.5259568; l1_loss: 0.3796787; total_loss: 0.9056355; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31300; focal_loss: 0.6176101; l1_loss: 0.3100842; total_loss: 0.9276943; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31400; focal_loss: 0.5356304; l1_loss: 0.3196601; total_loss: 0.8552905; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31500; focal_loss: 0.5654845; l1_loss: 0.3561425; total_loss: 0.921627; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31600; focal_loss: 0.5587452; l1_loss: 0.3932186; total_loss: 0.9519639; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31700; focal_loss: 0.429717; l1_loss: 0.3601772; total_loss: 0.7898944; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31800; focal_loss: 0.6090318; l1_loss: 0.3583592; total_loss: 0.9673911; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 31900; focal_loss: 0.5667293; l1_loss: 0.3694136; total_loss: 0.936143; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 32000; focal_loss: 0.6871082; l1_loss: 0.4054889; total_loss: 1.0925971; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 32100; focal_loss: 0.6336344; l1_loss: 0.3372904; total_loss: 0.9709249; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 32200; focal_loss: 0.5186338; l1_loss: 0.4360506; total_loss: 0.9546844; examples/sec: 33.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 32300; focal_loss: 0.5387913; l1_loss: 0.4237774; total_loss: 0.9625687; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32400; focal_loss: 0.4390014; l1_loss: 0.2773052; total_loss: 0.7163066; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32500; focal_loss: 0.622258; l1_loss: 0.3126381; total_loss: 0.9348961; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32600; focal_loss: 0.5147496; l1_loss: 0.324617; total_loss: 0.8393667; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32700; focal_loss: 0.6680926; l1_loss: 0.4107244; total_loss: 1.0788169; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32800; focal_loss: 0.4880923; l1_loss: 0.2333796; total_loss: 0.721472; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 32900; focal_loss: 0.5235057; l1_loss: 0.3577082; total_loss: 0.8812138; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33000; focal_loss: 0.5977168; l1_loss: 0.4592042; total_loss: 1.056921; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33100; focal_loss: 0.6619172; l1_loss: 0.2974653; total_loss: 0.9593825; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33200; focal_loss: 0.3843576; l1_loss: 0.2552844; total_loss: 0.6396421; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33300; focal_loss: 0.6337332; l1_loss: 0.4423049; total_loss: 1.0760381; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33400; focal_loss: 0.6014763; l1_loss: 0.3386224; total_loss: 0.9400988; examples/sec: 33.4; progress: 2.8%; \n",
      "FastEstimator-Train: step: 33500; focal_loss: 0.345035; l1_loss: 0.2615478; total_loss: 0.6065829; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 33600; focal_loss: 0.45911; l1_loss: 0.470321; total_loss: 0.929431; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 33700; focal_loss: 0.6305328; l1_loss: 0.3513266; total_loss: 0.9818594; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 33800; focal_loss: 0.5759937; l1_loss: 0.2354688; total_loss: 0.8114624; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 33900; focal_loss: 0.597719; l1_loss: 0.3188408; total_loss: 0.9165598; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34000; focal_loss: 0.7369728; l1_loss: 0.4052936; total_loss: 1.1422664; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34100; focal_loss: 0.4483996; l1_loss: 0.4180189; total_loss: 0.8664186; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34200; focal_loss: 0.5066832; l1_loss: 0.3875805; total_loss: 0.8942636; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34300; focal_loss: 0.4981712; l1_loss: 0.3215375; total_loss: 0.8197087; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34400; focal_loss: 0.5357272; l1_loss: 0.316189; total_loss: 0.8519164; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34500; focal_loss: 0.4823584; l1_loss: 0.2790534; total_loss: 0.7614118; examples/sec: 33.4; progress: 2.9%; \n",
      "FastEstimator-Train: step: 34600; focal_loss: 0.5537172; l1_loss: 0.3412149; total_loss: 0.8949321; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 34700; focal_loss: 0.6026061; l1_loss: 0.388703; total_loss: 0.991309; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 34800; focal_loss: 0.6251685; l1_loss: 0.3639334; total_loss: 0.9891019; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 34900; focal_loss: 0.4734076; l1_loss: 0.4539474; total_loss: 0.927355; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35000; focal_loss: 0.608138; l1_loss: 0.495255; total_loss: 1.1033931; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35100; focal_loss: 0.6028093; l1_loss: 0.371937; total_loss: 0.9747463; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35200; focal_loss: 0.4269396; l1_loss: 0.2286884; total_loss: 0.655628; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35300; focal_loss: 0.5094863; l1_loss: 0.3430308; total_loss: 0.8525172; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35400; focal_loss: 0.500431; l1_loss: 0.3451227; total_loss: 0.8455538; examples/sec: 33.4; progress: 3.0%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 35500; focal_loss: 0.5259742; l1_loss: 0.4346815; total_loss: 0.9606557; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35600; focal_loss: 0.4974788; l1_loss: 0.3555345; total_loss: 0.8530132; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35700; focal_loss: 0.494554; l1_loss: 0.339315; total_loss: 0.8338691; examples/sec: 33.4; progress: 3.0%; \n",
      "FastEstimator-Train: step: 35800; focal_loss: 0.6034432; l1_loss: 0.3417949; total_loss: 0.9452382; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 35900; focal_loss: 0.5680786; l1_loss: 0.3711158; total_loss: 0.9391944; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36000; focal_loss: 0.544618; l1_loss: 0.4394548; total_loss: 0.9840728; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36100; focal_loss: 0.552405; l1_loss: 0.3617129; total_loss: 0.9141179; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36200; focal_loss: 0.6476027; l1_loss: 0.4162284; total_loss: 1.0638311; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36300; focal_loss: 0.6478132; l1_loss: 0.5145322; total_loss: 1.1623454; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36400; focal_loss: 0.5148418; l1_loss: 0.2929654; total_loss: 0.8078072; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36500; focal_loss: 0.5113124; l1_loss: 0.3707042; total_loss: 0.8820165; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36600; focal_loss: 0.5493588; l1_loss: 0.4616949; total_loss: 1.0110537; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36700; focal_loss: 0.4261; l1_loss: 0.2942882; total_loss: 0.7203882; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36800; focal_loss: 0.542346; l1_loss: 0.400023; total_loss: 0.9423691; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 36900; focal_loss: 0.4547382; l1_loss: 0.4393282; total_loss: 0.8940664; examples/sec: 33.4; progress: 3.1%; \n",
      "FastEstimator-Train: step: 37000; focal_loss: 0.7214566; l1_loss: 0.5089546; total_loss: 1.2304113; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37100; focal_loss: 0.4959903; l1_loss: 0.3652928; total_loss: 0.8612831; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37200; focal_loss: 0.6113302; l1_loss: 0.3363344; total_loss: 0.9476646; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37300; focal_loss: 0.5873935; l1_loss: 0.4182068; total_loss: 1.0056003; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37400; focal_loss: 0.4103398; l1_loss: 0.2751734; total_loss: 0.6855132; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37500; focal_loss: 0.5849034; l1_loss: 0.4333718; total_loss: 1.0182753; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37600; focal_loss: 0.5267556; l1_loss: 0.502745; total_loss: 1.0295006; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37700; focal_loss: 0.640515; l1_loss: 0.4723582; total_loss: 1.1128732; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37800; focal_loss: 0.6062728; l1_loss: 0.4953994; total_loss: 1.1016722; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 37900; focal_loss: 0.5908829; l1_loss: 0.3162729; total_loss: 0.9071558; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 38000; focal_loss: 0.4906144; l1_loss: 0.3432364; total_loss: 0.8338509; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 38100; focal_loss: 0.5576846; l1_loss: 0.3936766; total_loss: 0.9513612; examples/sec: 33.4; progress: 3.2%; \n",
      "FastEstimator-Train: step: 38200; focal_loss: 0.4564233; l1_loss: 0.1731482; total_loss: 0.6295714; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38300; focal_loss: 0.5961232; l1_loss: 0.41407; total_loss: 1.0101931; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38400; focal_loss: 0.495762; l1_loss: 0.3833856; total_loss: 0.8791476; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38500; focal_loss: 0.4846958; l1_loss: 0.3705496; total_loss: 0.8552454; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38600; focal_loss: 0.6431079; l1_loss: 0.4063894; total_loss: 1.0494974; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38700; focal_loss: 0.5532462; l1_loss: 0.2727898; total_loss: 0.826036; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38800; focal_loss: 0.538423; l1_loss: 0.3696209; total_loss: 0.908044; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 38900; focal_loss: 0.5910609; l1_loss: 0.4024571; total_loss: 0.993518; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 39000; focal_loss: 0.5700168; l1_loss: 0.3480242; total_loss: 0.9180411; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 39100; focal_loss: 0.6247127; l1_loss: 0.4470871; total_loss: 1.0717998; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 39200; focal_loss: 0.5634734; l1_loss: 0.3941687; total_loss: 0.9576421; examples/sec: 33.4; progress: 3.3%; \n",
      "FastEstimator-Train: step: 39300; focal_loss: 0.5148856; l1_loss: 0.3644836; total_loss: 0.8793693; examples/sec: 33.4; progress: 3.4%; \n",
      "FastEstimator-Train: step: 39400; focal_loss: 0.4608411; l1_loss: 0.39963; total_loss: 0.8604711; examples/sec: 33.4; progress: 3.4%; \n",
      "FastEstimator-Train: step: 39500; focal_loss: 0.4273213; l1_loss: 0.3075881; total_loss: 0.7349094; examples/sec: 33.4; progress: 3.4%; \n",
      "FastEstimator-Train: step: 39600; focal_loss: 0.5002085; l1_loss: 0.4350285; total_loss: 0.935237; examples/sec: 33.4; progress: 3.4%; \n",
      "FastEstimator-Train: step: 39700; focal_loss: 0.358792; l1_loss: 0.2118322; total_loss: 0.5706242; examples/sec: 33.4; progress: 3.4%; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
