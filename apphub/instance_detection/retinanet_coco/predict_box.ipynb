{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from ast import literal_eval\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import fastestimator as fe\n",
    "from fastestimator.architecture.retinanet import RetinaNet, get_fpn_anchor_box, get_target\n",
    "from fastestimator.dataset.mscoco import load_data\n",
    "from fastestimator.op import NumpyOp, TensorOp\n",
    "from fastestimator.op.numpyop import ImageReader, ResizeImageAndBbox, TypeConverter\n",
    "from fastestimator.op.tensorop import Loss, ModelOp, Pad, Rescale\n",
    "from fastestimator.trace import ModelSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv, val_csv, path = load_data(path='/data/hsiming/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class String2List(NumpyOp):\n",
    "    # this thing converts '[1, 2, 3]' into np.array([1, 2, 3])\n",
    "    def forward(self, data, state):\n",
    "        data = map(literal_eval, data)\n",
    "        return data\n",
    "\n",
    "\n",
    "class GenerateTarget(NumpyOp):\n",
    "    def __init__(self, inputs=None, outputs=None, mode=None):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.anchorbox, _ = get_fpn_anchor_box(input_shape=(512, 512, 3))\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        obj_label, x1, y1, width, height = data\n",
    "        cls_gt, x1_gt, y1_gt, w_gt, h_gt = get_target(self.anchorbox, obj_label, x1, y1, width, height)\n",
    "        return cls_gt, x1_gt, y1_gt, w_gt, h_gt\n",
    "\n",
    "\n",
    "class RetinaLoss(Loss):\n",
    "    def focal_loss(self, cls_gt_example, cls_pred_example, alpha=0.25, gamma=2.0):\n",
    "        # cls_gt_example shape: [A], cls_pred_example shape: [A, K]\n",
    "        num_classes = cls_pred_example.shape[-1]\n",
    "        # gather the objects and background, discard the rest\n",
    "        anchor_obj_idx = tf.where(tf.greater_equal(cls_gt_example, 0))\n",
    "        anchor_obj_bg_idx = tf.where(tf.greater_equal(cls_gt_example, -1))\n",
    "        anchor_obj_count = tf.cast(tf.shape(anchor_obj_idx)[0], tf.float32)\n",
    "        cls_gt_example = tf.one_hot(cls_gt_example, num_classes)\n",
    "        cls_gt_example = tf.gather_nd(cls_gt_example, anchor_obj_bg_idx)\n",
    "        cls_pred_example = tf.gather_nd(cls_pred_example, anchor_obj_bg_idx)\n",
    "        cls_gt_example = tf.reshape(cls_gt_example, (-1, 1))\n",
    "        cls_pred_example = tf.reshape(cls_pred_example, (-1, 1))\n",
    "        # compute the focal weight on each selected anchor box\n",
    "        alpha_factor = tf.ones_like(cls_gt_example) * alpha\n",
    "        alpha_factor = tf.where(tf.equal(cls_gt_example, 1), alpha_factor, 1 - alpha_factor)\n",
    "        focal_weight = tf.where(tf.equal(cls_gt_example, 1), 1 - cls_pred_example, cls_pred_example)\n",
    "        focal_weight = alpha_factor * focal_weight**gamma / anchor_obj_count\n",
    "        cls_loss = tf.losses.BinaryCrossentropy(reduction='sum')(cls_gt_example,\n",
    "                                                                 cls_pred_example,\n",
    "                                                                 sample_weight=focal_weight)\n",
    "        return cls_loss, anchor_obj_idx\n",
    "\n",
    "    def smooth_l1(self, loc_gt_example, loc_pred_example, anchor_obj_idx, beta=0.1):\n",
    "        \"\"\"Return smooth l1 loss for box regesssion.\n",
    "\n",
    "        Args:\n",
    "            loc_gt_example (Tensor): Tensor of shape (padded=252, 4).\n",
    "            loc_pred_example (Tensor): Tensor of shape (num_anchors, 4).\n",
    "            anchor_obj_idx (Tensor): Indices of selected anchor box.\n",
    "\n",
    "        Returns:\n",
    "            float: Smooth l1 loss.\n",
    "        \"\"\"\n",
    "        loc_pred = tf.gather_nd(loc_pred_example, anchor_obj_idx)  #anchor_obj_count x 4\n",
    "        anchor_obj_count = tf.shape(loc_pred)[0]\n",
    "        loc_gt = loc_gt_example[:anchor_obj_count]  #anchor_obj_count x 4\n",
    "        loc_gt = tf.reshape(loc_gt, (-1, 1))\n",
    "        loc_pred = tf.reshape(loc_pred, (-1, 1))\n",
    "        loc_diff = tf.abs(loc_gt - loc_pred)\n",
    "        cond = tf.less(loc_diff, beta)\n",
    "        smooth_l1_loss = tf.where(cond, 0.5 * loc_diff**2 / beta, loc_diff - 0.5 * beta)\n",
    "        smooth_l1_loss = tf.reduce_sum(smooth_l1_loss) / tf.cast(anchor_obj_count, tf.float32)\n",
    "        return smooth_l1_loss\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        cls_gt, x1_gt, y1_gt, w_gt, h_gt, cls_pred, loc_pred = data\n",
    "        local_batch_size = state[\"local_batch_size\"]\n",
    "        focal_loss = []\n",
    "        l1_loss = []\n",
    "        total_loss = []\n",
    "        for idx in range(local_batch_size):\n",
    "            cls_gt_example = cls_gt[idx]\n",
    "            x1_gt_example = x1_gt[idx]\n",
    "            y1_gt_example = y1_gt[idx]\n",
    "            w_gt_example = w_gt[idx]\n",
    "            h_gt_example = h_gt[idx]\n",
    "            loc_gt_example = tf.transpose(tf.stack([x1_gt_example, y1_gt_example, w_gt_example, h_gt_example]))\n",
    "            cls_pred_example = cls_pred[idx]\n",
    "            loc_pred_example = loc_pred[idx]\n",
    "            focal_loss_example, anchor_obj_idx = self.focal_loss(cls_gt_example, cls_pred_example)\n",
    "            smooth_l1_loss_example = self.smooth_l1(loc_gt_example, loc_pred_example, anchor_obj_idx)\n",
    "            focal_loss.append(focal_loss_example)\n",
    "            l1_loss.append(smooth_l1_loss_example)\n",
    "        focal_loss = tf.stack(focal_loss)\n",
    "        l1_loss = tf.stack(l1_loss)\n",
    "        total_loss = focal_loss + l1_loss\n",
    "\n",
    "        return total_loss, focal_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictBox(TensorOp):\n",
    "    def __init__(self,\n",
    "                 inputs=None,\n",
    "                 outputs=None,\n",
    "                 mode=None,\n",
    "                 input_shape=(512, 512, 3),\n",
    "                 select_top_k=1000,\n",
    "                 nms_max_outputs=100):\n",
    "        super().__init__(inputs=inputs, outputs=outputs, mode=mode)\n",
    "        self.input_shape = input_shape\n",
    "        self.select_top_k = tf.cast(select_top_k, dtype=tf.int32)\n",
    "        self.nms_max_outputs = nms_max_outputs\n",
    "\n",
    "        all_anchors, num_anchors_per_level = get_fpn_anchor_box(input_shape=input_shape)\n",
    "        self.all_anchors = tf.convert_to_tensor(all_anchors)\n",
    "        self.num_anchors_per_level = tf.convert_to_tensor(num_anchors_per_level, dtype=tf.int32)\n",
    "\n",
    "    def index_to_bool(self, indices, length):\n",
    "        updates = tf.ones_like(indices, dtype=tf.bool)\n",
    "        shape = tf.expand_dims(length, 0)\n",
    "        is_selected = tf.scatter_nd(tf.cast(tf.expand_dims(indices, axis=-1), dtype=tf.int32), updates, shape)\n",
    "        return is_selected\n",
    "\n",
    "    def forward(self, data, state):\n",
    "        \"\"\"\n",
    "        # state['local_batch_size']\n",
    "        # cls_pred.shape = (8, 49104, 90)\n",
    "        \"\"\"\n",
    "\n",
    "        pred = []\n",
    "        gt = []\n",
    "\n",
    "        # extract max score and its class label\n",
    "        #cls_pred, deltas, label_gt, x1_gt, y1_gt, w_gt, h_gt = data\n",
    "        cls_pred, deltas = data\n",
    "        #label_gt = tf.convert_to_tensor(label_gt)\n",
    "        #x1_gt = tf.convert_to_tensor(x1_gt)\n",
    "        #y1_gt = tf.convert_to_tensor(y1_gt)\n",
    "        #w_gt = tf.convert_to_tensor(w_gt)\n",
    "        #h_gt = tf.convert_to_tensor(h_gt)\n",
    "\n",
    "        labels = tf.cast(tf.argmax(cls_pred, axis=2), dtype=tf.int32)\n",
    "        scores = tf.reduce_max(cls_pred, axis=2)\n",
    "\n",
    "        # iterate over image\n",
    "        for i in range(state['local_batch_size']):\n",
    "            labels_per_image = labels[i]\n",
    "            scores_per_image = scores[i]\n",
    "            deltas_per_image = deltas[i]\n",
    "            \n",
    "            #keep_gt = tf.greater(label_gt[i], 0)\n",
    "            #label_gt_per_image = label_gt[i][keep_gt]\n",
    "            #x1_gt_per_image = x1_gt[i][keep_gt]\n",
    "            #y1_gt_per_image = y1_gt[i][keep_gt]\n",
    "            #w_gt_per_image = w_gt[i][keep_gt]\n",
    "            #h_gt_per_image = h_gt[i][keep_gt]\n",
    "\n",
    "            selected_deltas_per_image = tf.constant([], shape=(0, 4))\n",
    "            selected_labels_per_image = tf.constant([], dtype=tf.int32)\n",
    "            selected_scores_per_image = tf.constant([])\n",
    "            selected_anchor_indices_per_image = tf.constant([], dtype=tf.int32)\n",
    "\n",
    "            end_index = 0\n",
    "            # iterate over each pyramid level\n",
    "            for j in range(self.num_anchors_per_level.shape[0]):\n",
    "                start_index = end_index\n",
    "                end_index += self.num_anchors_per_level[j]\n",
    "                anchor_indices = tf.range(start_index, end_index, dtype=tf.int32)\n",
    "\n",
    "                level_scores = scores_per_image[start_index:end_index]\n",
    "                level_deltas = deltas_per_image[start_index:end_index]\n",
    "                level_labels = labels_per_image[start_index:end_index]\n",
    "\n",
    "                # select top k\n",
    "                if self.num_anchors_per_level[j] >= self.select_top_k:\n",
    "                    # won't work without the tf.minimum\n",
    "                    top_k = tf.math.top_k(level_scores, tf.minimum(self.num_anchors_per_level[j], self.select_top_k))\n",
    "                    top_k_scores = top_k.values\n",
    "                    top_k_indices = tf.add(top_k.indices, [start_index])\n",
    "                else:\n",
    "                    top_k_scores = level_scores\n",
    "                    top_k_indices = anchor_indices\n",
    "\n",
    "                # filter out low score\n",
    "                is_high_score = tf.greater(top_k_scores, 0.05)\n",
    "                selected_indices = tf.boolean_mask(top_k_indices, is_high_score)\n",
    "                is_selected = self.index_to_bool(tf.subtract(selected_indices, [start_index]),\n",
    "                                                 self.num_anchors_per_level[j])\n",
    "\n",
    "                # combine all pyramid levels\n",
    "                selected_deltas_per_image = tf.concat(\n",
    "                    [selected_deltas_per_image, tf.boolean_mask(level_deltas, is_selected)], axis=0)\n",
    "                selected_scores_per_image = tf.concat(\n",
    "                    [selected_scores_per_image, tf.boolean_mask(level_scores, is_selected)], axis=0)\n",
    "                selected_labels_per_image = tf.concat(\n",
    "                    [selected_labels_per_image, tf.boolean_mask(level_labels, is_selected)], axis=0)\n",
    "                selected_anchor_indices_per_image = tf.concat(\n",
    "                    [selected_anchor_indices_per_image, tf.boolean_mask(anchor_indices, is_selected)], axis=0)\n",
    "\n",
    "            # delta -> (x1, y1, w, h)\n",
    "            anchor_mask = self.index_to_bool(selected_anchor_indices_per_image, self.all_anchors.shape[0])\n",
    "            x1 = (selected_deltas_per_image[:, 0] * tf.boolean_mask(\n",
    "                self.all_anchors, anchor_mask)[:, 2]) + tf.boolean_mask(self.all_anchors, anchor_mask)[:, 0]\n",
    "            y1 = (selected_deltas_per_image[:, 1] * tf.boolean_mask(\n",
    "                self.all_anchors, anchor_mask)[:, 3]) + tf.boolean_mask(self.all_anchors, anchor_mask)[:, 1]\n",
    "            w = tf.math.exp(selected_deltas_per_image[:, 2]) * tf.boolean_mask(self.all_anchors, anchor_mask)[:, 2]\n",
    "            h = tf.math.exp(selected_deltas_per_image[:, 3]) * tf.boolean_mask(self.all_anchors, anchor_mask)[:, 3]\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "\n",
    "            # nms\n",
    "            boxes_per_image = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "            nms_indices = tf.image.non_max_suppression(boxes_per_image, selected_scores_per_image, self.nms_max_outputs)\n",
    "\n",
    "            nms_boxes = tf.gather(boxes_per_image, nms_indices)\n",
    "            final_scores = tf.gather(selected_scores_per_image, nms_indices)\n",
    "            final_labels = tf.gather(selected_labels_per_image, nms_indices)\n",
    "\n",
    "            x1 = tf.clip_by_value(nms_boxes[:, 1], clip_value_min=0, clip_value_max=self.input_shape[1])\n",
    "            y1 = tf.clip_by_value(nms_boxes[:, 0], clip_value_min=0, clip_value_max=self.input_shape[0])\n",
    "            w = tf.clip_by_value(nms_boxes[:, 3], clip_value_min=0, clip_value_max=self.input_shape[1]) - x1\n",
    "            h = tf.clip_by_value(nms_boxes[:, 2], clip_value_min=0, clip_value_max=self.input_shape[0]) - y1\n",
    "\n",
    "            final_boxes = tf.stack([x1, y1, w, h], axis=1)\n",
    "\n",
    "            # combine image results into batch\n",
    "            image_results = tf.concat([\n",
    "                tf.pad(final_boxes, [[0, 0], [1, 0]], constant_values=i),\n",
    "                tf.cast(tf.expand_dims(final_labels, axis=1), dtype=tf.float32),\n",
    "                tf.expand_dims(final_scores, axis=1)\n",
    "            ],\n",
    "                                      axis=1)\n",
    "\n",
    "            #image_gt = tf.transpose(\n",
    "            #    tf.concat([\n",
    "            #        tf.stack([i * tf.ones_like(x1_gt_per_image), x1_gt_per_image]),\n",
    "            #        tf.expand_dims(y1_gt_per_image, axis=0),\n",
    "            #        tf.expand_dims(w_gt_per_image, axis=0),\n",
    "            #        tf.expand_dims(h_gt_per_image, axis=0),\n",
    "            #        tf.expand_dims(label_gt_per_image, axis=0)\n",
    "            #    ],\n",
    "            #              axis=0))\n",
    "            pred.append(image_results)\n",
    "            #gt.append(image_gt)\n",
    "            tf.print(final_scores)\n",
    "        return tf.concat(pred, axis=0)  #, tf.concat(gt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/data/hsiming/mscoco_model/'\n",
    "writer = fe.RecordWriter(\n",
    "    save_dir=os.path.join(path, \"retinanet_coco_small\"),\n",
    "    train_data='/data/hsiming/dataset/MSCOCO2017/train_object_small.csv',\n",
    "    validation_data='/data/hsiming/dataset/MSCOCO2017/train_object_small.csv',\n",
    "    ops=[\n",
    "        ImageReader(inputs=\"image\", parent_path=path, outputs=\"image\"),\n",
    "        String2List(inputs=[\"x1\", \"y1\", \"width\", \"height\", \"obj_label\"],\n",
    "                    outputs=[\"x1\", \"y1\", \"width\", \"height\", \"obj_label\"]),\n",
    "        ResizeImageAndBbox(target_size=(512, 512),\n",
    "                           keep_ratio=True,\n",
    "                           inputs=[\"image\", \"x1\", \"y1\", \"width\", \"height\"],\n",
    "                           outputs=[\"image\", \"x1\", \"y1\", \"width\", \"height\"]),\n",
    "        GenerateTarget(inputs=(\"obj_label\", \"x1\", \"y1\", \"width\", \"height\"),\n",
    "                       outputs=(\"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\")),\n",
    "        TypeConverter(target_type='int32', inputs=[\"id\", \"cls_gt\"], outputs=[\"id\", \"cls_gt\"]),\n",
    "        TypeConverter(target_type='float32',\n",
    "                      inputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"],\n",
    "                      outputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"])\n",
    "    ],\n",
    "    compression=\"GZIP\",\n",
    "    write_feature=[\"image\", \"id\", \"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"])\n",
    "\n",
    "# prepare pipeline\n",
    "pipeline = fe.Pipeline(\n",
    "    batch_size=8,\n",
    "    padded_batch=True,\n",
    "    data=writer,\n",
    "    ops=[\n",
    "        Rescale(inputs=\"image\", outputs=\"image\"),\n",
    "        Pad(padded_shape=[190], inputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"], outputs=[\"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\"])\n",
    "    ])\n",
    "\n",
    "# prepare network\n",
    "model = fe.build(model_def=lambda: RetinaNet(input_shape=(512, 512, 3), num_classes=90),\n",
    "                 model_name=\"retinanet\",\n",
    "                 optimizer=tf.optimizers.Adam(learning_rate=0.0002),\n",
    "                 loss_name=\"total_loss\")\n",
    "network = fe.Network(ops=[\n",
    "    ModelOp(inputs=\"image\", model=model, outputs=[\"cls_pred\", \"loc_pred\"]),\n",
    "    PredictBox(inputs=[\"cls_pred\", \"loc_pred\"],\n",
    "               outputs=(\"pred\"),\n",
    "               mode=\"eval\"),\n",
    "    RetinaLoss(inputs=(\"cls_gt\", \"x1_gt\", \"y1_gt\", \"w_gt\", \"h_gt\", \"cls_pred\", \"loc_pred\"),\n",
    "               outputs=(\"total_loss\", \"focal_loss\", \"l1_loss\"))\n",
    "])\n",
    "\n",
    "# prepare estimator\n",
    "estimator = fe.Estimator(\n",
    "    network=network,\n",
    "    pipeline=pipeline,\n",
    "    epochs=200,\n",
    "    #steps_per_epoch=2,\n",
    "    log_steps=1,\n",
    "    #validation_steps=2,\n",
    "    traces=ModelSaver(model_name=\"retinanet\", save_dir=model_dir, save_best=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ______           __  ______     __  _                 __            \n",
      "   / ____/___ ______/ /_/ ____/____/ /_(_)___ ___  ____ _/ /_____  _____\n",
      "  / /_  / __ `/ ___/ __/ __/ / ___/ __/ / __ `__ \\/ __ `/ __/ __ \\/ ___/\n",
      " / __/ / /_/ (__  ) /_/ /___(__  ) /_/ / / / / / / /_/ / /_/ /_/ / /    \n",
      "/_/    \\__,_/____/\\__/_____/____/\\__/_/_/ /_/ /_/\\__,_/\\__/\\____/_/     \n",
      "                                                                        \n",
      "\n",
      "FastEstimator: Reading non-empty directory: /data/hsiming/dataset/MSCOCO2017/retinanet_coco_small\n",
      "FastEstimator: Found 50 examples for train in /data/hsiming/dataset/MSCOCO2017/retinanet_coco_small/train_summary0.json\n",
      "FastEstimator: Found 50 examples for eval in /data/hsiming/dataset/MSCOCO2017/retinanet_coco_small/eval_summary0.json\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Start: step: 0; total_train_steps: 1200; retinanet_lr: 0.0002; \n",
      "FastEstimator-Train: step: 0; focal_loss: 2.1004574; l1_loss: 0.9493042; total_loss: 3.0497618; \n",
      "FastEstimator-Train: step: 1; focal_loss: 1.5857413; l1_loss: 0.7389255; total_loss: 2.324667; examples/sec: 41.6; progress: 0.1%; \n",
      "FastEstimator-Train: step: 2; focal_loss: 1.3985401; l1_loss: 0.6798483; total_loss: 2.0783885; examples/sec: 31.5; progress: 0.2%; \n",
      "FastEstimator-Train: step: 3; focal_loss: 1.7327094; l1_loss: 0.8502496; total_loss: 2.5829592; examples/sec: 32.2; progress: 0.2%; \n",
      "FastEstimator-Train: step: 4; focal_loss: 1.3219792; l1_loss: 0.6102425; total_loss: 1.9322217; examples/sec: 32.6; progress: 0.3%; \n",
      "FastEstimator-Train: step: 5; focal_loss: 1.315549; l1_loss: 0.6427998; total_loss: 1.9583488; examples/sec: 32.2; progress: 0.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 6; epoch: 0; focal_loss: 1.2837057; l1_loss: 0.674478; total_loss: 1.9581838; \n",
      "FastEstimator-Train: step: 6; focal_loss: 1.2654704; l1_loss: 0.7027554; total_loss: 1.9682258; examples/sec: 31.9; progress: 0.5%; \n",
      "FastEstimator-Train: step: 7; focal_loss: 1.2238009; l1_loss: 0.5797948; total_loss: 1.8035958; examples/sec: 32.2; progress: 0.6%; \n",
      "FastEstimator-Train: step: 8; focal_loss: 1.2653501; l1_loss: 0.6942194; total_loss: 1.9595695; examples/sec: 31.7; progress: 0.7%; \n",
      "FastEstimator-Train: step: 9; focal_loss: 1.2542269; l1_loss: 0.6758152; total_loss: 1.9300421; examples/sec: 32.3; progress: 0.8%; \n",
      "FastEstimator-Train: step: 10; focal_loss: 1.2850989; l1_loss: 0.5968801; total_loss: 1.8819788; examples/sec: 32.4; progress: 0.8%; \n",
      "FastEstimator-Train: step: 11; focal_loss: 1.198189; l1_loss: 0.7621252; total_loss: 1.9603142; examples/sec: 32.0; progress: 0.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 12; epoch: 1; focal_loss: 1.2602435; l1_loss: 0.7221784; total_loss: 1.982422; \n",
      "FastEstimator-Train: step: 12; focal_loss: 1.1956761; l1_loss: 0.633791; total_loss: 1.829467; examples/sec: 31.9; progress: 1.0%; \n",
      "FastEstimator-Train: step: 13; focal_loss: 1.1879764; l1_loss: 0.723869; total_loss: 1.9118454; examples/sec: 31.9; progress: 1.1%; \n",
      "FastEstimator-Train: step: 14; focal_loss: 1.2242767; l1_loss: 0.6186546; total_loss: 1.8429312; examples/sec: 31.9; progress: 1.2%; \n",
      "FastEstimator-Train: step: 15; focal_loss: 1.1759655; l1_loss: 0.5850733; total_loss: 1.761039; examples/sec: 31.8; progress: 1.2%; \n",
      "FastEstimator-Train: step: 16; focal_loss: 1.1813316; l1_loss: 0.8405983; total_loss: 2.02193; examples/sec: 32.5; progress: 1.3%; \n",
      "FastEstimator-Train: step: 17; focal_loss: 1.1756825; l1_loss: 0.5837886; total_loss: 1.7594712; examples/sec: 32.3; progress: 1.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 18; epoch: 2; focal_loss: 1.2955736; l1_loss: 0.7007528; total_loss: 1.9963264; \n",
      "FastEstimator-Train: step: 18; focal_loss: 1.1675333; l1_loss: 0.6306444; total_loss: 1.7981778; examples/sec: 32.0; progress: 1.5%; \n",
      "FastEstimator-Train: step: 19; focal_loss: 1.1553093; l1_loss: 0.5634593; total_loss: 1.7187686; examples/sec: 31.7; progress: 1.6%; \n",
      "FastEstimator-Train: step: 20; focal_loss: 1.1502556; l1_loss: 0.6685938; total_loss: 1.8188496; examples/sec: 32.1; progress: 1.7%; \n",
      "FastEstimator-Train: step: 21; focal_loss: 1.1861876; l1_loss: 0.5945686; total_loss: 1.7807562; examples/sec: 31.8; progress: 1.8%; \n",
      "FastEstimator-Train: step: 22; focal_loss: 1.1548593; l1_loss: 0.499162; total_loss: 1.6540213; examples/sec: 32.4; progress: 1.8%; \n",
      "FastEstimator-Train: step: 23; focal_loss: 1.1497136; l1_loss: 0.6154455; total_loss: 1.7651592; examples/sec: 32.6; progress: 1.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 24; epoch: 3; focal_loss: 1.4520102; l1_loss: 0.7388262; total_loss: 2.1908362; \n",
      "FastEstimator-Train: step: 24; focal_loss: 1.1456336; l1_loss: 0.7488996; total_loss: 1.8945332; examples/sec: 32.0; progress: 2.0%; \n",
      "FastEstimator-Train: step: 25; focal_loss: 1.1471918; l1_loss: 0.6281029; total_loss: 1.7752945; examples/sec: 31.7; progress: 2.1%; \n",
      "FastEstimator-Train: step: 26; focal_loss: 1.1433496; l1_loss: 0.6121855; total_loss: 1.7555352; examples/sec: 31.9; progress: 2.2%; \n",
      "FastEstimator-Train: step: 27; focal_loss: 1.1343337; l1_loss: 0.5868466; total_loss: 1.7211804; examples/sec: 32.0; progress: 2.2%; \n",
      "FastEstimator-Train: step: 28; focal_loss: 1.1558728; l1_loss: 0.6062356; total_loss: 1.7621086; examples/sec: 32.3; progress: 2.3%; \n",
      "FastEstimator-Train: step: 29; focal_loss: 1.1261379; l1_loss: 0.5944844; total_loss: 1.7206224; examples/sec: 32.2; progress: 2.4%; \n",
      "[0.0518689454 0.0515335798 0.0512547493 0.0506761074]\n",
      "[0.0500326455]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0546835065 0.0542956591 0.0540081859 0.0535241961]\n",
      "[]\n",
      "[0.0643113852 0.0639410913 0.0624687374 ... 0.053291589 0.0525572 0.0524494052]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0515896678 0.0510865748]\n",
      "[]\n",
      "[0.0529096127 0.0506296158]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0504063368]\n",
      "[0.0544760525 0.0544099808 0.053563416 0.0534321368]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0608489811 0.0607346892 0.0585332215 0.0575953424 0.0522241 0.0515828431]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0535287559 0.0534718037 0.0529037118 0.0527918041]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0512647331]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0512051284]\n",
      "FastEstimator-Eval: step: 30; epoch: 4; focal_loss: 1.5026544; l1_loss: 0.7102929; total_loss: 2.2129471; \n",
      "FastEstimator-Train: step: 30; focal_loss: 1.1198848; l1_loss: 0.6970074; total_loss: 1.8168921; examples/sec: 32.2; progress: 2.5%; \n",
      "FastEstimator-Train: step: 31; focal_loss: 1.4433455; l1_loss: 0.6210527; total_loss: 2.0643983; examples/sec: 31.5; progress: 2.6%; \n",
      "FastEstimator-Train: step: 32; focal_loss: 1.1117504; l1_loss: 0.6044574; total_loss: 1.7162077; examples/sec: 31.4; progress: 2.7%; \n",
      "FastEstimator-Train: step: 33; focal_loss: 1.1075543; l1_loss: 0.6573862; total_loss: 1.7649406; examples/sec: 32.2; progress: 2.8%; \n",
      "FastEstimator-Train: step: 34; focal_loss: 1.1352267; l1_loss: 0.6175565; total_loss: 1.7527832; examples/sec: 32.1; progress: 2.8%; \n",
      "FastEstimator-Train: step: 35; focal_loss: 1.0661261; l1_loss: 0.7837034; total_loss: 1.8498294; examples/sec: 32.2; progress: 2.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 36; epoch: 5; focal_loss: 1.5659542; l1_loss: 0.7014889; total_loss: 2.2674434; \n",
      "FastEstimator-Train: step: 36; focal_loss: 1.1608716; l1_loss: 0.6458678; total_loss: 1.8067394; examples/sec: 32.2; progress: 3.0%; \n",
      "FastEstimator-Train: step: 37; focal_loss: 1.1279905; l1_loss: 0.5213232; total_loss: 1.6493136; examples/sec: 31.6; progress: 3.1%; \n",
      "FastEstimator-Train: step: 38; focal_loss: 1.0335499; l1_loss: 0.6136642; total_loss: 1.6472142; examples/sec: 32.1; progress: 3.2%; \n",
      "FastEstimator-Train: step: 39; focal_loss: 1.067869; l1_loss: 0.655349; total_loss: 1.723218; examples/sec: 32.3; progress: 3.2%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 40; focal_loss: 1.0125945; l1_loss: 0.6951562; total_loss: 1.7077508; examples/sec: 31.8; progress: 3.3%; \n",
      "FastEstimator-Train: step: 41; focal_loss: 1.6896902; l1_loss: 0.5435516; total_loss: 2.2332416; examples/sec: 32.4; progress: 3.4%; \n",
      "[0.999990344 0.999976516 0.999874592 ... 0.0867998898 0.0821536779 0.074852705]\n",
      "[0.999946356 0.999582052 0.998945355 ... 0.0637586117 0.0589213073 0.0526533127]\n",
      "[0.998245716 0.997383 0.99127388 ... 0.0639478 0.0566522777 0.0512379706]\n",
      "[0.999984 0.999952912 0.999782085 ... 0.0840135217 0.0801663399 0.0724467933]\n",
      "[0.999999762 0.999999285 0.999997079 ... 0.239436626 0.236735612 0.173248261]\n",
      "[0.99999 0.999966145 0.999850214 ... 0.10776028 0.0966772139 0.0939851105]\n",
      "[0.998591065 0.994471669 0.987825155 ... 0.0586817861 0.0541267693 0.0511571467]\n",
      "[0.998968244 0.997483611 0.992986321 ... 0.0565140843 0.0527821779 0.051310569]\n",
      "[0.999959648 0.999933124 0.999650717 ... 0.087109983 0.0790414512 0.0789936781]\n",
      "[0.998859763 0.996772289 0.99088335 ... 0.0644387603 0.0592905581 0.0521211922]\n",
      "[0.897414565 0.873845696 0.767886162 ... 0.0541750193 0.0522845387 0.0516944826]\n",
      "[0.999372602 0.998972952 0.996156037 ... 0.0665093064 0.0532763898 0.0529204905]\n",
      "[0.999998 0.999991238 0.999957323 ... 0.0971548855 0.0920275748 0.0822804272]\n",
      "[0.765824795 0.65460521 0.534280539 ... 0.0630866 0.0536930263 0.0525853634]\n",
      "[0.993074894 0.989008665 0.970102906 ... 0.0604871213 0.0597537756 0.0532085299]\n",
      "[0.999978065 0.999922633 0.9997015 ... 0.0844603479 0.0795790851 0.0780836046]\n",
      "[0.909716 0.882663786 0.780981421 ... 0.0534778237 0.0534678698 0.0533255041]\n",
      "[0.999486923 0.999022365 0.996591449 ... 0.0581438243 0.0563983917 0.0523388684]\n",
      "[0.992963433 0.97831279 0.957471132 ... 0.0586933494 0.0583772361 0.055311054]\n",
      "[0.999614835 0.999249458 0.997332811 ... 0.0626449 0.0577471256 0.0567580163]\n",
      "[0.999917269 0.999726415 0.999037147 ... 0.059271574 0.0539964736 0.052860111]\n",
      "[0.999995112 0.999969 0.999888599 ... 0.142461032 0.129168928 0.117486179]\n",
      "[0.999971271 0.999953 0.999742389 ... 0.100361407 0.100177348 0.0924843252]\n",
      "[0.999774694 0.99936229 0.997874796 ... 0.0609331429 0.0583650768 0.0524825454]\n",
      "[0.999999523 0.999997377 0.999985933 ... 0.20674023 0.155862 0.148684978]\n",
      "[0.999597132 0.998123348 0.995496 ... 0.0578927696 0.0572300255 0.0541087091]\n",
      "[0.995781839 0.991793036 0.979033113 ... 0.0622513592 0.0591371655 0.0530118048]\n",
      "[0.999999106 0.999995947 0.999985337 ... 0.216977715 0.160506606 0.126292616]\n",
      "[0.999995351 0.999983191 0.999918699 ... 0.082556814 0.0742955208 0.0722833872]\n",
      "[0.999974847 0.999950767 0.999752402 ... 0.0889839232 0.0771588683 0.074659735]\n",
      "[0.976726174 0.965997458 0.920807123 ... 0.0536101758 0.0517771244 0.0504238307]\n",
      "[0.999982476 0.999927223 0.999723315 ... 0.0816316 0.0742350519 0.0682195425]\n",
      "[0.963855088 0.954977512 0.897191644 ... 0.0520817935 0.0507552028 0.0504851937]\n",
      "[0.999192357 0.997776747 0.993868113 ... 0.0582606494 0.0549140871 0.0536059737]\n",
      "[0.999889731 0.999719858 0.998955727 ... 0.0585309565 0.0517456532 0.050234139]\n",
      "[0.999861 0.999727607 0.998874903 ... 0.0631134212 0.0546736121 0.0520135164]\n",
      "[0.999988794 0.999953747 0.999815822 ... 0.102846116 0.0922917426 0.0919902325]\n",
      "[0.999915361 0.999840677 0.999281347 ... 0.0603752732 0.0581467748 0.0555324554]\n",
      "[0.999916792 0.999649763 0.998942912 ... 0.0626139045 0.0557553172 0.0537871718]\n",
      "[0.995777786 0.991068 0.977659345 ... 0.0582479537 0.0530027449 0.0504066348]\n",
      "[0.999898493 0.999813318 0.999208093 ... 0.0561071336 0.0515599251 0.0507378]\n",
      "[0.99833 0.997889221 0.992421508 ... 0.0567076504 0.0564132333 0.052598536]\n",
      "[0.992770135 0.99250865 0.975972056 ... 0.0614238381 0.0570128858 0.0515013039]\n",
      "[0.999604821 0.999426246 0.997713745 ... 0.0591110587 0.0573158264 0.0550152957]\n",
      "[0.999918938 0.999762475 0.999135375 ... 0.0567705035 0.05249843 0.0518246293]\n",
      "[0.999999046 0.999996662 0.99998939 ... 0.191747427 0.143249571 0.134752125]\n",
      "[0.998771429 0.99715054 0.992188632 ... 0.0601205528 0.0541867316 0.0527564287]\n",
      "[0.968619406 0.964362383 0.910554111 ... 0.0533106029 0.0504193306 0.0502365232]\n",
      "FastEstimator-Eval: step: 42; epoch: 6; focal_loss: 32.277172; l1_loss: 1.0946909; total_loss: 33.37186; \n",
      "FastEstimator-Train: step: 42; focal_loss: 1.1167581; l1_loss: 0.6006763; total_loss: 1.7174344; examples/sec: 32.1; progress: 3.5%; \n",
      "FastEstimator-Train: step: 43; focal_loss: 1.0483905; l1_loss: 0.6962055; total_loss: 1.744596; examples/sec: 32.2; progress: 3.6%; \n",
      "FastEstimator-Train: step: 44; focal_loss: 1.0302429; l1_loss: 0.5008914; total_loss: 1.5311341; examples/sec: 31.6; progress: 3.7%; \n",
      "FastEstimator-Train: step: 45; focal_loss: 1.0818169; l1_loss: 0.5892572; total_loss: 1.6710742; examples/sec: 32.3; progress: 3.8%; \n",
      "FastEstimator-Train: step: 46; focal_loss: 1.1024895; l1_loss: 0.6532884; total_loss: 1.755778; examples/sec: 32.0; progress: 3.8%; \n",
      "FastEstimator-Train: step: 47; focal_loss: 1.1145883; l1_loss: 0.6049666; total_loss: 1.719555; examples/sec: 32.2; progress: 3.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 48; epoch: 7; focal_loss: 1.3286062; l1_loss: 0.6792912; total_loss: 2.0078974; \n",
      "FastEstimator-Train: step: 48; focal_loss: 1.1186116; l1_loss: 0.5320416; total_loss: 1.6506531; examples/sec: 32.1; progress: 4.0%; \n",
      "FastEstimator-Train: step: 49; focal_loss: 1.1012042; l1_loss: 0.6119446; total_loss: 1.7131488; examples/sec: 32.1; progress: 4.1%; \n",
      "FastEstimator-Train: step: 50; focal_loss: 1.0953486; l1_loss: 0.5489487; total_loss: 1.6442974; examples/sec: 32.2; progress: 4.2%; \n",
      "FastEstimator-Train: step: 51; focal_loss: 1.1107202; l1_loss: 0.5262198; total_loss: 1.63694; examples/sec: 31.9; progress: 4.2%; \n",
      "FastEstimator-Train: step: 52; focal_loss: 1.1197026; l1_loss: 0.5623502; total_loss: 1.6820529; examples/sec: 32.1; progress: 4.3%; \n",
      "FastEstimator-Train: step: 53; focal_loss: 1.0904331; l1_loss: 0.5757182; total_loss: 1.6661513; examples/sec: 32.5; progress: 4.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 54; epoch: 8; focal_loss: 1.5929409; l1_loss: 0.686038; total_loss: 2.278979; \n",
      "FastEstimator-Train: step: 54; focal_loss: 1.0895435; l1_loss: 0.6127078; total_loss: 1.7022512; examples/sec: 31.9; progress: 4.5%; \n",
      "FastEstimator-Train: step: 55; focal_loss: 1.0699685; l1_loss: 0.4630586; total_loss: 1.5330269; examples/sec: 31.9; progress: 4.6%; \n",
      "FastEstimator-Train: step: 56; focal_loss: 1.0635605; l1_loss: 0.5039484; total_loss: 1.5675089; examples/sec: 32.2; progress: 4.7%; \n",
      "FastEstimator-Train: step: 57; focal_loss: 1.05359; l1_loss: 0.5098831; total_loss: 1.5634731; examples/sec: 32.2; progress: 4.8%; \n",
      "FastEstimator-Train: step: 58; focal_loss: 1.0554236; l1_loss: 0.5676075; total_loss: 1.6230311; examples/sec: 32.2; progress: 4.8%; \n",
      "FastEstimator-Train: step: 59; focal_loss: 1.0000976; l1_loss: 0.5400576; total_loss: 1.5401552; examples/sec: 31.5; progress: 4.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 60; epoch: 9; focal_loss: 1.692767; l1_loss: 0.7255662; total_loss: 2.4183333; \n",
      "FastEstimator-Train: step: 60; focal_loss: 1.0709677; l1_loss: 0.6427902; total_loss: 1.7137578; examples/sec: 31.6; progress: 5.0%; \n",
      "FastEstimator-Train: step: 61; focal_loss: 1.0159011; l1_loss: 0.4215359; total_loss: 1.437437; examples/sec: 31.6; progress: 5.1%; \n",
      "FastEstimator-Train: step: 62; focal_loss: 0.9518722; l1_loss: 0.5262106; total_loss: 1.4780829; examples/sec: 32.2; progress: 5.2%; \n",
      "FastEstimator-Train: step: 63; focal_loss: 0.9717777; l1_loss: 0.5358156; total_loss: 1.5075932; examples/sec: 32.1; progress: 5.2%; \n",
      "FastEstimator-Train: step: 64; focal_loss: 0.9428526; l1_loss: 0.4482371; total_loss: 1.3910898; examples/sec: 32.2; progress: 5.3%; \n",
      "FastEstimator-Train: step: 65; focal_loss: 1.0250127; l1_loss: 0.4780683; total_loss: 1.5030811; examples/sec: 32.3; progress: 5.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 66; epoch: 10; focal_loss: 1.7068847; l1_loss: 0.7050376; total_loss: 2.4119222; \n",
      "FastEstimator-Train: step: 66; focal_loss: 0.9251978; l1_loss: 0.4014777; total_loss: 1.3266757; examples/sec: 32.2; progress: 5.5%; \n",
      "FastEstimator-Train: step: 67; focal_loss: 0.901158; l1_loss: 0.4899395; total_loss: 1.3910975; examples/sec: 32.3; progress: 5.6%; \n",
      "FastEstimator-Train: step: 68; focal_loss: 0.9769981; l1_loss: 0.5195095; total_loss: 1.4965076; examples/sec: 32.0; progress: 5.7%; \n",
      "FastEstimator-Train: step: 69; focal_loss: 0.951048; l1_loss: 0.5391904; total_loss: 1.4902385; examples/sec: 31.9; progress: 5.8%; \n",
      "FastEstimator-Train: step: 70; focal_loss: 1.1865665; l1_loss: 0.4966197; total_loss: 1.6831862; examples/sec: 31.5; progress: 5.8%; \n",
      "FastEstimator-Train: step: 71; focal_loss: 0.855185; l1_loss: 0.3893334; total_loss: 1.2445185; examples/sec: 31.9; progress: 5.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 72; epoch: 11; focal_loss: 1.626212; l1_loss: 0.7247276; total_loss: 2.3509395; \n",
      "FastEstimator-Train: step: 72; focal_loss: 0.9280174; l1_loss: 0.4653316; total_loss: 1.393349; examples/sec: 32.6; progress: 6.0%; \n",
      "FastEstimator-Train: step: 73; focal_loss: 0.9246808; l1_loss: 0.471082; total_loss: 1.3957629; examples/sec: 32.5; progress: 6.1%; \n",
      "FastEstimator-Train: step: 74; focal_loss: 0.9575851; l1_loss: 0.4206141; total_loss: 1.3781992; examples/sec: 31.5; progress: 6.2%; \n",
      "FastEstimator-Train: step: 75; focal_loss: 1.0150843; l1_loss: 0.5179262; total_loss: 1.5330105; examples/sec: 32.2; progress: 6.2%; \n",
      "FastEstimator-Train: step: 76; focal_loss: 0.9705608; l1_loss: 0.5642926; total_loss: 1.5348532; examples/sec: 32.2; progress: 6.3%; \n",
      "FastEstimator-Train: step: 77; focal_loss: 0.9695777; l1_loss: 0.532496; total_loss: 1.5020735; examples/sec: 31.6; progress: 6.4%; \n",
      "[0.0615277886]\n",
      "[0.0613262653]\n",
      "[0.0623108447]\n",
      "[0.0656018555]\n",
      "[0.0632059872]\n",
      "[0.0610700846]\n",
      "[0.0624171495]\n",
      "[0.0616354346]\n",
      "[0.0589095652]\n",
      "[0.0652558208]\n",
      "[0.0618877411]\n",
      "[0.0621213317]\n",
      "[0.0651881695]\n",
      "[0.0625994205]\n",
      "[0.0598157644]\n",
      "[0.0646571219]\n",
      "[0.0644677877]\n",
      "[0.0648810565]\n",
      "[0.0615303218]\n",
      "[0.0623425543]\n",
      "[0.0583852828]\n",
      "[0.0626522303]\n",
      "[0.0617949963]\n",
      "[0.0607915223]\n",
      "[0.0624471605]\n",
      "[0.0622344315]\n",
      "[0.0646745861]\n",
      "[0.064535439]\n",
      "[0.0616649687]\n",
      "[0.0626729131]\n",
      "[0.0632065833]\n",
      "[0.0639728606]\n",
      "[0.0647425056]\n",
      "[0.0777682364]\n",
      "[0.0648068786]\n",
      "[0.0608502626]\n",
      "[0.06327039]\n",
      "[0.0658112466]\n",
      "[0.0618491173]\n",
      "[0.0627482533]\n",
      "[0.0635571182]\n",
      "[0.0522424281]\n",
      "[0.061650455]\n",
      "[0.0674731135]\n",
      "[0.0618689954]\n",
      "[0.0625710189]\n",
      "[0.0601501763]\n",
      "[0.0616614819]\n",
      "FastEstimator-Eval: step: 78; epoch: 12; focal_loss: 1.8579298; l1_loss: 0.665358; total_loss: 2.5232878; \n",
      "FastEstimator-Train: step: 78; focal_loss: 0.883631; l1_loss: 0.518529; total_loss: 1.4021599; examples/sec: 31.7; progress: 6.5%; \n",
      "FastEstimator-Train: step: 79; focal_loss: 0.9222619; l1_loss: 0.4350322; total_loss: 1.3572941; examples/sec: 32.4; progress: 6.6%; \n",
      "FastEstimator-Train: step: 80; focal_loss: 0.9482347; l1_loss: 0.3910122; total_loss: 1.339247; examples/sec: 32.1; progress: 6.7%; \n",
      "FastEstimator-Train: step: 81; focal_loss: 0.9369032; l1_loss: 0.4744848; total_loss: 1.4113882; examples/sec: 32.3; progress: 6.8%; \n",
      "FastEstimator-Train: step: 82; focal_loss: 0.9369082; l1_loss: 0.5519708; total_loss: 1.488879; examples/sec: 32.4; progress: 6.8%; \n",
      "FastEstimator-Train: step: 83; focal_loss: 0.8898535; l1_loss: 0.4357106; total_loss: 1.3255643; examples/sec: 32.0; progress: 6.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 84; epoch: 13; focal_loss: 1.9655092; l1_loss: 0.651849; total_loss: 2.6173584; \n",
      "FastEstimator-Train: step: 84; focal_loss: 0.8923516; l1_loss: 0.4492692; total_loss: 1.3416209; examples/sec: 31.6; progress: 7.0%; \n",
      "FastEstimator-Train: step: 85; focal_loss: 0.9071188; l1_loss: 0.476517; total_loss: 1.3836358; examples/sec: 32.6; progress: 7.1%; \n",
      "FastEstimator-Train: step: 86; focal_loss: 0.8285947; l1_loss: 0.4111194; total_loss: 1.2397141; examples/sec: 32.1; progress: 7.2%; \n",
      "FastEstimator-Train: step: 87; focal_loss: 0.8759906; l1_loss: 0.5046776; total_loss: 1.3806682; examples/sec: 32.4; progress: 7.2%; \n",
      "FastEstimator-Train: step: 88; focal_loss: 0.8601632; l1_loss: 0.3562247; total_loss: 1.2163879; examples/sec: 32.2; progress: 7.3%; \n",
      "FastEstimator-Train: step: 89; focal_loss: 0.8830938; l1_loss: 0.3185451; total_loss: 1.2016389; examples/sec: 32.2; progress: 7.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 90; epoch: 14; focal_loss: 1.9323006; l1_loss: 0.7050558; total_loss: 2.6373568; \n",
      "FastEstimator-Train: step: 90; focal_loss: 0.8703563; l1_loss: 0.421805; total_loss: 1.2921613; examples/sec: 32.1; progress: 7.5%; \n",
      "FastEstimator-Train: step: 91; focal_loss: 1.0916951; l1_loss: 0.4206698; total_loss: 1.5123649; examples/sec: 32.6; progress: 7.6%; \n",
      "FastEstimator-Train: step: 92; focal_loss: 0.7954085; l1_loss: 0.542482; total_loss: 1.3378904; examples/sec: 31.8; progress: 7.7%; \n",
      "FastEstimator-Train: step: 93; focal_loss: 1.0541005; l1_loss: 0.4754467; total_loss: 1.5295472; examples/sec: 31.7; progress: 7.8%; \n",
      "FastEstimator-Train: step: 94; focal_loss: 0.9295785; l1_loss: 0.3250079; total_loss: 1.2545863; examples/sec: 32.1; progress: 7.8%; \n",
      "FastEstimator-Train: step: 95; focal_loss: 0.9213319; l1_loss: 0.4276283; total_loss: 1.3489603; examples/sec: 32.0; progress: 7.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 96; epoch: 15; focal_loss: 1.5211817; l1_loss: 0.7047243; total_loss: 2.2259061; \n",
      "FastEstimator-Train: step: 96; focal_loss: 0.7725634; l1_loss: 0.4048978; total_loss: 1.1774613; examples/sec: 31.8; progress: 8.0%; \n",
      "FastEstimator-Train: step: 97; focal_loss: 0.9359563; l1_loss: 0.4210869; total_loss: 1.3570431; examples/sec: 32.0; progress: 8.1%; \n",
      "FastEstimator-Train: step: 98; focal_loss: 0.9226596; l1_loss: 0.4947882; total_loss: 1.4174478; examples/sec: 32.6; progress: 8.2%; \n",
      "FastEstimator-Train: step: 99; focal_loss: 0.8661531; l1_loss: 0.3398896; total_loss: 1.2060428; examples/sec: 32.3; progress: 8.2%; \n",
      "FastEstimator-Train: step: 100; focal_loss: 0.6958872; l1_loss: 0.4301097; total_loss: 1.1259968; examples/sec: 32.1; progress: 8.3%; \n",
      "FastEstimator-Train: step: 101; focal_loss: 0.8867674; l1_loss: 0.3820884; total_loss: 1.2688558; examples/sec: 32.1; progress: 8.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 102; epoch: 16; focal_loss: 1.5040888; l1_loss: 0.6599341; total_loss: 2.1640232; \n",
      "FastEstimator-Train: step: 102; focal_loss: 0.8638513; l1_loss: 0.4297886; total_loss: 1.2936399; examples/sec: 32.2; progress: 8.5%; \n",
      "FastEstimator-Train: step: 103; focal_loss: 0.7812599; l1_loss: 0.3751533; total_loss: 1.1564132; examples/sec: 31.6; progress: 8.6%; \n",
      "FastEstimator-Train: step: 104; focal_loss: 0.9216006; l1_loss: 0.4565546; total_loss: 1.3781554; examples/sec: 32.3; progress: 8.7%; \n",
      "FastEstimator-Train: step: 105; focal_loss: 0.765786; l1_loss: 0.447266; total_loss: 1.213052; examples/sec: 31.9; progress: 8.8%; \n",
      "FastEstimator-Train: step: 106; focal_loss: 0.8515927; l1_loss: 0.4690336; total_loss: 1.3206264; examples/sec: 32.1; progress: 8.8%; \n",
      "FastEstimator-Train: step: 107; focal_loss: 0.8569363; l1_loss: 0.5432957; total_loss: 1.400232; examples/sec: 32.1; progress: 8.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 108; epoch: 17; focal_loss: 1.7049865; l1_loss: 0.7303948; total_loss: 2.4353812; \n",
      "FastEstimator-Train: step: 108; focal_loss: 0.8381426; l1_loss: 0.4327022; total_loss: 1.2708449; examples/sec: 31.7; progress: 9.0%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 109; focal_loss: 0.8596258; l1_loss: 0.505895; total_loss: 1.3655207; examples/sec: 32.1; progress: 9.1%; \n",
      "FastEstimator-Train: step: 110; focal_loss: 0.8301064; l1_loss: 0.3836161; total_loss: 1.2137225; examples/sec: 32.3; progress: 9.2%; \n",
      "FastEstimator-Train: step: 111; focal_loss: 0.712482; l1_loss: 0.3897237; total_loss: 1.1022058; examples/sec: 32.2; progress: 9.2%; \n",
      "FastEstimator-Train: step: 112; focal_loss: 0.6941641; l1_loss: 0.3090229; total_loss: 1.003187; examples/sec: 31.6; progress: 9.3%; \n",
      "FastEstimator-Train: step: 113; focal_loss: 0.8082272; l1_loss: 0.3516878; total_loss: 1.1599151; examples/sec: 32.0; progress: 9.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 114; epoch: 18; focal_loss: 1.8645892; l1_loss: 0.6885447; total_loss: 2.5531337; \n",
      "FastEstimator-Train: step: 114; focal_loss: 0.7150674; l1_loss: 0.4032079; total_loss: 1.1182753; examples/sec: 31.7; progress: 9.5%; \n",
      "FastEstimator-Train: step: 115; focal_loss: 0.6690888; l1_loss: 0.3691512; total_loss: 1.03824; examples/sec: 31.9; progress: 9.6%; \n",
      "FastEstimator-Train: step: 116; focal_loss: 0.7706828; l1_loss: 0.4604068; total_loss: 1.2310895; examples/sec: 32.5; progress: 9.7%; \n",
      "FastEstimator-Train: step: 117; focal_loss: 0.7519832; l1_loss: 0.4667272; total_loss: 1.2187104; examples/sec: 31.9; progress: 9.8%; \n",
      "FastEstimator-Train: step: 118; focal_loss: 0.6350114; l1_loss: 0.426684; total_loss: 1.0616955; examples/sec: 32.1; progress: 9.8%; \n",
      "FastEstimator-Train: step: 119; focal_loss: 0.7312378; l1_loss: 0.3454878; total_loss: 1.0767255; examples/sec: 31.9; progress: 9.9%; \n",
      "[0.0671315491 0.0642085671 0.0505411625]\n",
      "[0.0643279552 0.0579710305 0.0509443879]\n",
      "[0.0666164458 0.0638539493 0.0513211191]\n",
      "[0.0674235523 0.0635297894 0.0512678027]\n",
      "[0.0657210052 0.0568954051 0.0551670492]\n",
      "[0.0624656379 0.0572594106]\n",
      "[0.0666765571 0.059633106]\n",
      "[0.0676238239 0.0557882488 0.0524800718]\n",
      "[0.0673950911 0.0638043582 0.0500551164]\n",
      "[0.0673448741 0.0608951151]\n",
      "[0.065559566 0.0646373928 0.052254647]\n",
      "[0.0669670403 0.0605482757 0.0506797731]\n",
      "[0.0696754754 0.0602154136 0.0503297746]\n",
      "[0.0657402277 0.062141]\n",
      "[0.0661705732 0.0622048378]\n",
      "[0.0666715205 0.059679985 0.0510590971]\n",
      "[0.0674670041 0.0611245334 0.0508648157]\n",
      "[0.0648317039 0.0623652935]\n",
      "[0.0674157739 0.0629020333 0.0506541133]\n",
      "[0.0667607784 0.0629980862 0.0502106547]\n",
      "[0.0675526261 0.0606599748]\n",
      "[0.0663987398 0.0618537962 0.0506902039]\n",
      "[0.0666133761 0.0636671185 0.0502780676]\n",
      "[0.0669251084 0.0560004413 0.055698961]\n",
      "[0.0671239793 0.0641483068 0.0513132215]\n",
      "[0.0667612255 0.0603925288]\n",
      "[0.0650546849 0.0586416423]\n",
      "[0.0674285 0.0636922419 0.0508699417]\n",
      "[0.0658829212 0.0597433746]\n",
      "[0.0622088313 0.0589919686]\n",
      "[0.06525895 0.0634925067]\n",
      "[0.0670824945 0.06159693]\n",
      "[0.0675805211 0.0629403591 0.0510257781]\n",
      "[0.0674332082 0.0644094646 0.0510876775]\n",
      "[0.0644137 0.0627555549 0.0507067442]\n",
      "[0.0672474205 0.0644006133 0.0512684584]\n",
      "[0.0666457713 0.059460938 0.0503691137]\n",
      "[0.0659807 0.0587495863 0.0514061749]\n",
      "[0.0674292147 0.0624699 0.0507004559]\n",
      "[0.0671296418 0.0599312484]\n",
      "[0.0665327609 0.0610093474]\n",
      "[0.0669415593 0.0609696805 0.0508663356]\n",
      "[0.0665695071 0.0599932969 0.0506751835]\n",
      "[0.0668759346 0.0583371222 0.0525719523]\n",
      "[0.0674422085 0.064565748 0.050903827]\n",
      "[0.0627957284 0.0556075871]\n",
      "[0.0669209063 0.0593144894 0.0518489182]\n",
      "[0.0679141283 0.059273839]\n",
      "FastEstimator-Eval: step: 120; epoch: 19; focal_loss: 1.7207423; l1_loss: 0.693703; total_loss: 2.4144452; \n",
      "FastEstimator-Train: step: 120; focal_loss: 0.7868085; l1_loss: 0.373332; total_loss: 1.1601405; examples/sec: 32.1; progress: 10.0%; \n",
      "FastEstimator-Train: step: 121; focal_loss: 0.7015003; l1_loss: 0.3727538; total_loss: 1.0742542; examples/sec: 31.9; progress: 10.1%; \n",
      "FastEstimator-Train: step: 122; focal_loss: 0.6656114; l1_loss: 0.3479098; total_loss: 1.0135212; examples/sec: 32.4; progress: 10.2%; \n",
      "FastEstimator-Train: step: 123; focal_loss: 0.843328; l1_loss: 0.383057; total_loss: 1.226385; examples/sec: 32.3; progress: 10.2%; \n",
      "FastEstimator-Train: step: 124; focal_loss: 0.663175; l1_loss: 0.2392522; total_loss: 0.9024271; examples/sec: 31.6; progress: 10.3%; \n",
      "FastEstimator-Train: step: 125; focal_loss: 0.6929252; l1_loss: 0.3489072; total_loss: 1.0418326; examples/sec: 31.6; progress: 10.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 126; epoch: 20; focal_loss: 1.7581275; l1_loss: 0.7008498; total_loss: 2.4589775; \n",
      "FastEstimator-Train: step: 126; focal_loss: 0.6166455; l1_loss: 0.4791186; total_loss: 1.0957642; examples/sec: 32.3; progress: 10.5%; \n",
      "FastEstimator-Train: step: 127; focal_loss: 0.6673728; l1_loss: 0.3365307; total_loss: 1.0039035; examples/sec: 32.1; progress: 10.6%; \n",
      "FastEstimator-Train: step: 128; focal_loss: 0.6516719; l1_loss: 0.3340807; total_loss: 0.9857526; examples/sec: 31.9; progress: 10.7%; \n",
      "FastEstimator-Train: step: 129; focal_loss: 0.7019916; l1_loss: 0.4075543; total_loss: 1.109546; examples/sec: 32.6; progress: 10.8%; \n",
      "FastEstimator-Train: step: 130; focal_loss: 0.7889263; l1_loss: 0.3613224; total_loss: 1.1502488; examples/sec: 32.0; progress: 10.8%; \n",
      "FastEstimator-Train: step: 131; focal_loss: 0.5777152; l1_loss: 0.4425822; total_loss: 1.0202973; examples/sec: 31.7; progress: 10.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 132; epoch: 21; focal_loss: 1.557907; l1_loss: 0.7173136; total_loss: 2.2752206; \n",
      "FastEstimator-Train: step: 132; focal_loss: 0.6155746; l1_loss: 0.3029888; total_loss: 0.9185633; examples/sec: 32.1; progress: 11.0%; \n",
      "FastEstimator-Train: step: 133; focal_loss: 0.7064151; l1_loss: 0.3577322; total_loss: 1.0641474; examples/sec: 32.0; progress: 11.1%; \n",
      "FastEstimator-Train: step: 134; focal_loss: 0.7892103; l1_loss: 0.2839249; total_loss: 1.0731354; examples/sec: 32.5; progress: 11.2%; \n",
      "FastEstimator-Train: step: 135; focal_loss: 0.6652026; l1_loss: 0.4082695; total_loss: 1.073472; examples/sec: 32.3; progress: 11.2%; \n",
      "FastEstimator-Train: step: 136; focal_loss: 0.650778; l1_loss: 0.4086557; total_loss: 1.0594337; examples/sec: 31.7; progress: 11.3%; \n",
      "FastEstimator-Train: step: 137; focal_loss: 0.6796963; l1_loss: 0.2819254; total_loss: 0.9616218; examples/sec: 32.1; progress: 11.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 138; epoch: 22; focal_loss: 1.4537364; l1_loss: 0.7192272; total_loss: 2.1729639; \n",
      "FastEstimator-Train: step: 138; focal_loss: 0.6773042; l1_loss: 0.2816909; total_loss: 0.9589952; examples/sec: 32.0; progress: 11.5%; \n",
      "FastEstimator-Train: step: 139; focal_loss: 0.6062084; l1_loss: 0.3414855; total_loss: 0.9476939; examples/sec: 32.1; progress: 11.6%; \n",
      "FastEstimator-Train: step: 140; focal_loss: 0.5995518; l1_loss: 0.2088319; total_loss: 0.8083837; examples/sec: 32.1; progress: 11.7%; \n",
      "FastEstimator-Train: step: 141; focal_loss: 0.5717122; l1_loss: 0.317624; total_loss: 0.8893363; examples/sec: 32.5; progress: 11.8%; \n",
      "FastEstimator-Train: step: 142; focal_loss: 0.7556414; l1_loss: 0.364404; total_loss: 1.1200454; examples/sec: 32.2; progress: 11.8%; \n",
      "FastEstimator-Train: step: 143; focal_loss: 0.6076674; l1_loss: 0.3027969; total_loss: 0.9104642; examples/sec: 32.1; progress: 11.9%; \n",
      "[0.0702429116 0.0642449856]\n",
      "[0.0736453235 0.0667679608]\n",
      "[0.071947366 0.0655907691]\n",
      "[0.0735095739 0.0676913261]\n",
      "[0.0726106465 0.0660113096]\n",
      "[0.0787250698 0.0711535513]\n",
      "[0.0744967759 0.0672405362]\n",
      "[0.0721174479 0.0658293366]\n",
      "[0.0709883869 0.0647880733]\n",
      "[0.0608079731]\n",
      "[0.0700449646 0.0640793741]\n",
      "[0.0713807642 0.0651378334]\n",
      "[0.0683570504 0.0625410378]\n",
      "[0.0745826662 0.0671533346]\n",
      "[0.0742024779 0.067461729]\n",
      "[0.0724476278 0.0655931234]\n",
      "[0.0733835697 0.0667675138]\n",
      "[0.0707615316 0.0646346509]\n",
      "[0.0733172297 0.0665636659]\n",
      "[0.0710090399 0.0650381744]\n",
      "[0.0803527236 0.0720341206]\n",
      "[0.0729875565 0.0662094057]\n",
      "[0.0698139369 0.0639561415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0732933879 0.0667878091]\n",
      "[0.0693983734 0.0635132492]\n",
      "[0.0794959664 0.0718862116]\n",
      "[0.0725059509 0.0661008954]\n",
      "[0.0731957257 0.0666798949]\n",
      "[0.0712218881 0.0649889708]\n",
      "[0.0702788234 0.0643031299]\n",
      "[0.0750010908 0.068380028]\n",
      "[0.0754281878 0.0680479705]\n",
      "[0.0702354908 0.0642284155]\n",
      "[0.0698229074 0.063891083]\n",
      "[0.0718272 0.0653479099]\n",
      "[0.0712842941 0.0650559068]\n",
      "[0.0756658316 0.0684907138]\n",
      "[0.0703611374 0.0643287]\n",
      "[0.0704133511 0.0643597245]\n",
      "[0.0729327202 0.066041559]\n",
      "[0.0759119093 0.0685941]\n",
      "[0.0714818239 0.0651920736]\n",
      "[0.0743719637 0.066973865]\n",
      "[0.0703962147 0.064342171]\n",
      "[0.0713973641 0.0652080178]\n",
      "[0.0752164721 0.0685777068]\n",
      "[0.0708459616 0.0647032]\n",
      "[0.0751808584 0.0681744814]\n",
      "FastEstimator-Eval: step: 144; epoch: 23; focal_loss: 1.6281838; l1_loss: 0.7138706; total_loss: 2.3420544; \n",
      "FastEstimator-Train: step: 144; focal_loss: 0.6102322; l1_loss: 0.2369818; total_loss: 0.847214; examples/sec: 32.2; progress: 12.0%; \n",
      "FastEstimator-Train: step: 145; focal_loss: 0.7052793; l1_loss: 0.2983068; total_loss: 1.003586; examples/sec: 32.2; progress: 12.1%; \n",
      "FastEstimator-Train: step: 146; focal_loss: 0.5034788; l1_loss: 0.3360648; total_loss: 0.8395436; examples/sec: 32.2; progress: 12.2%; \n",
      "FastEstimator-Train: step: 147; focal_loss: 0.6058552; l1_loss: 0.2351782; total_loss: 0.8410335; examples/sec: 32.2; progress: 12.2%; \n",
      "FastEstimator-Train: step: 148; focal_loss: 0.6129458; l1_loss: 0.2914516; total_loss: 0.9043974; examples/sec: 32.4; progress: 12.3%; \n",
      "FastEstimator-Train: step: 149; focal_loss: 0.6158342; l1_loss: 0.2611244; total_loss: 0.8769586; examples/sec: 32.2; progress: 12.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 150; epoch: 24; focal_loss: 1.713614; l1_loss: 0.7213596; total_loss: 2.4349737; \n",
      "FastEstimator-Train: step: 150; focal_loss: 0.5458269; l1_loss: 0.2742404; total_loss: 0.8200673; examples/sec: 32.2; progress: 12.5%; \n",
      "FastEstimator-Train: step: 151; focal_loss: 0.5400834; l1_loss: 0.2504201; total_loss: 0.7905035; examples/sec: 32.0; progress: 12.6%; \n",
      "FastEstimator-Train: step: 152; focal_loss: 0.6700841; l1_loss: 0.2596215; total_loss: 0.9297057; examples/sec: 32.4; progress: 12.7%; \n",
      "FastEstimator-Train: step: 153; focal_loss: 0.6699082; l1_loss: 0.2550496; total_loss: 0.9249579; examples/sec: 32.2; progress: 12.8%; \n",
      "FastEstimator-Train: step: 154; focal_loss: 0.6224956; l1_loss: 0.2808912; total_loss: 0.9033869; examples/sec: 32.4; progress: 12.8%; \n",
      "FastEstimator-Train: step: 155; focal_loss: 0.6723848; l1_loss: 0.3092591; total_loss: 0.9816439; examples/sec: 32.2; progress: 12.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 156; epoch: 25; focal_loss: 1.5887223; l1_loss: 0.7047897; total_loss: 2.293512; \n",
      "FastEstimator-Train: step: 156; focal_loss: 0.5232177; l1_loss: 0.2374003; total_loss: 0.760618; examples/sec: 32.0; progress: 13.0%; \n",
      "FastEstimator-Train: step: 157; focal_loss: 0.5130126; l1_loss: 0.2251399; total_loss: 0.7381526; examples/sec: 32.0; progress: 13.1%; \n",
      "FastEstimator-Train: step: 158; focal_loss: 0.5978372; l1_loss: 0.2647921; total_loss: 0.8626293; examples/sec: 32.0; progress: 13.2%; \n",
      "FastEstimator-Train: step: 159; focal_loss: 0.5857746; l1_loss: 0.278186; total_loss: 0.8639606; examples/sec: 32.3; progress: 13.2%; \n",
      "FastEstimator-Train: step: 160; focal_loss: 0.5902844; l1_loss: 0.26126; total_loss: 0.8515444; examples/sec: 32.6; progress: 13.3%; \n",
      "FastEstimator-Train: step: 161; focal_loss: 0.556991; l1_loss: 0.1965757; total_loss: 0.7535668; examples/sec: 32.2; progress: 13.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 162; epoch: 26; focal_loss: 1.4386007; l1_loss: 0.700406; total_loss: 2.1390069; \n",
      "FastEstimator-Train: step: 162; focal_loss: 0.4835278; l1_loss: 0.1945485; total_loss: 0.6780762; examples/sec: 32.1; progress: 13.5%; \n",
      "FastEstimator-Train: step: 163; focal_loss: 0.5205046; l1_loss: 0.3144555; total_loss: 0.83496; examples/sec: 31.9; progress: 13.6%; \n",
      "FastEstimator-Train: step: 164; focal_loss: 0.5811842; l1_loss: 0.2665422; total_loss: 0.8477263; examples/sec: 31.8; progress: 13.7%; \n",
      "FastEstimator-Train: step: 165; focal_loss: 0.5572878; l1_loss: 0.2056841; total_loss: 0.7629719; examples/sec: 32.1; progress: 13.8%; \n",
      "FastEstimator-Train: step: 166; focal_loss: 0.5609331; l1_loss: 0.25892; total_loss: 0.819853; examples/sec: 32.5; progress: 13.8%; \n",
      "FastEstimator-Train: step: 167; focal_loss: 0.4803012; l1_loss: 0.21847; total_loss: 0.6987712; examples/sec: 31.9; progress: 13.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 168; epoch: 27; focal_loss: 1.492054; l1_loss: 0.7132688; total_loss: 2.205323; \n",
      "FastEstimator-Train: step: 168; focal_loss: 0.6151436; l1_loss: 0.2254876; total_loss: 0.8406311; examples/sec: 32.1; progress: 14.0%; \n",
      "FastEstimator-Train: step: 169; focal_loss: 0.431787; l1_loss: 0.1911834; total_loss: 0.6229704; examples/sec: 32.1; progress: 14.1%; \n",
      "FastEstimator-Train: step: 170; focal_loss: 0.4955604; l1_loss: 0.2253391; total_loss: 0.7208995; examples/sec: 32.0; progress: 14.2%; \n",
      "FastEstimator-Train: step: 171; focal_loss: 0.5409674; l1_loss: 0.231793; total_loss: 0.7727604; examples/sec: 32.0; progress: 14.2%; \n",
      "FastEstimator-Train: step: 172; focal_loss: 0.6478499; l1_loss: 0.2216448; total_loss: 0.8694947; examples/sec: 32.6; progress: 14.3%; \n",
      "FastEstimator-Train: step: 173; focal_loss: 0.5733961; l1_loss: 0.2309975; total_loss: 0.8043936; examples/sec: 32.6; progress: 14.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 174; epoch: 28; focal_loss: 1.3264333; l1_loss: 0.685976; total_loss: 2.0124094; \n",
      "FastEstimator-Train: step: 174; focal_loss: 0.5109117; l1_loss: 0.1936938; total_loss: 0.7046056; examples/sec: 31.8; progress: 14.5%; \n",
      "FastEstimator-Train: step: 175; focal_loss: 0.4975381; l1_loss: 0.1941061; total_loss: 0.6916442; examples/sec: 32.1; progress: 14.6%; \n",
      "FastEstimator-Train: step: 176; focal_loss: 0.4991108; l1_loss: 0.1837495; total_loss: 0.6828602; examples/sec: 32.1; progress: 14.7%; \n",
      "FastEstimator-Train: step: 177; focal_loss: 0.5361471; l1_loss: 0.239385; total_loss: 0.7755322; examples/sec: 32.2; progress: 14.8%; \n",
      "FastEstimator-Train: step: 178; focal_loss: 0.5140753; l1_loss: 0.2127347; total_loss: 0.72681; examples/sec: 32.2; progress: 14.8%; \n",
      "FastEstimator-Train: step: 179; focal_loss: 0.609098; l1_loss: 0.266048; total_loss: 0.8751459; examples/sec: 32.5; progress: 14.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 180; epoch: 29; focal_loss: 1.4794192; l1_loss: 0.7147776; total_loss: 2.1941965; \n",
      "FastEstimator-Train: step: 180; focal_loss: 0.6002327; l1_loss: 0.1647196; total_loss: 0.7649523; examples/sec: 31.6; progress: 15.0%; \n",
      "FastEstimator-Train: step: 181; focal_loss: 0.4029649; l1_loss: 0.1506334; total_loss: 0.5535983; examples/sec: 32.2; progress: 15.1%; \n",
      "FastEstimator-Train: step: 182; focal_loss: 0.5154684; l1_loss: 0.1596305; total_loss: 0.6750988; examples/sec: 32.1; progress: 15.2%; \n",
      "FastEstimator-Train: step: 183; focal_loss: 0.508671; l1_loss: 0.1709744; total_loss: 0.6796454; examples/sec: 32.3; progress: 15.2%; \n",
      "FastEstimator-Train: step: 184; focal_loss: 0.524784; l1_loss: 0.2425086; total_loss: 0.7672926; examples/sec: 32.5; progress: 15.3%; \n",
      "FastEstimator-Train: step: 185; focal_loss: 0.6120308; l1_loss: 0.1418083; total_loss: 0.753839; examples/sec: 32.6; progress: 15.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 186; epoch: 30; focal_loss: 1.4727545; l1_loss: 0.7181861; total_loss: 2.1909406; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 186; focal_loss: 0.5320952; l1_loss: 0.194546; total_loss: 0.726641; examples/sec: 32.3; progress: 15.5%; \n",
      "FastEstimator-Train: step: 187; focal_loss: 0.506256; l1_loss: 0.2154603; total_loss: 0.7217163; examples/sec: 31.9; progress: 15.6%; \n",
      "FastEstimator-Train: step: 188; focal_loss: 0.5634352; l1_loss: 0.1990896; total_loss: 0.7625247; examples/sec: 32.1; progress: 15.7%; \n",
      "FastEstimator-Train: step: 189; focal_loss: 0.6093622; l1_loss: 0.1759262; total_loss: 0.7852884; examples/sec: 32.0; progress: 15.8%; \n",
      "FastEstimator-Train: step: 190; focal_loss: 0.5703912; l1_loss: 0.1662356; total_loss: 0.7366268; examples/sec: 31.6; progress: 15.8%; \n",
      "FastEstimator-Train: step: 191; focal_loss: 0.5932364; l1_loss: 0.2074812; total_loss: 0.8007176; examples/sec: 32.5; progress: 15.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 192; epoch: 31; focal_loss: 1.4363178; l1_loss: 0.7109926; total_loss: 2.1473103; \n",
      "FastEstimator-Train: step: 192; focal_loss: 0.5569207; l1_loss: 0.1913593; total_loss: 0.74828; examples/sec: 31.6; progress: 16.0%; \n",
      "FastEstimator-Train: step: 193; focal_loss: 0.5177676; l1_loss: 0.16624; total_loss: 0.6840076; examples/sec: 31.9; progress: 16.1%; \n",
      "FastEstimator-Train: step: 194; focal_loss: 0.6311871; l1_loss: 0.1650136; total_loss: 0.7962008; examples/sec: 32.1; progress: 16.2%; \n",
      "FastEstimator-Train: step: 195; focal_loss: 0.5972017; l1_loss: 0.1821122; total_loss: 0.7793139; examples/sec: 31.8; progress: 16.2%; \n",
      "FastEstimator-Train: step: 196; focal_loss: 0.5379011; l1_loss: 0.1416794; total_loss: 0.6795804; examples/sec: 32.0; progress: 16.3%; \n",
      "FastEstimator-Train: step: 197; focal_loss: 0.60622; l1_loss: 0.2036613; total_loss: 0.8098812; examples/sec: 32.0; progress: 16.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 198; epoch: 32; focal_loss: 1.3525991; l1_loss: 0.715277; total_loss: 2.067876; \n",
      "FastEstimator-Train: step: 198; focal_loss: 0.5091614; l1_loss: 0.1773658; total_loss: 0.6865272; examples/sec: 32.2; progress: 16.5%; \n",
      "FastEstimator-Train: step: 199; focal_loss: 0.5202471; l1_loss: 0.1302383; total_loss: 0.6504854; examples/sec: 31.6; progress: 16.6%; \n",
      "FastEstimator-Train: step: 200; focal_loss: 0.5335124; l1_loss: 0.2060672; total_loss: 0.7395798; examples/sec: 31.7; progress: 16.7%; \n",
      "FastEstimator-Train: step: 201; focal_loss: 0.4813452; l1_loss: 0.1793804; total_loss: 0.6607257; examples/sec: 31.6; progress: 16.8%; \n",
      "FastEstimator-Train: step: 202; focal_loss: 0.4856994; l1_loss: 0.1060366; total_loss: 0.5917361; examples/sec: 32.2; progress: 16.8%; \n",
      "FastEstimator-Train: step: 203; focal_loss: 0.4754154; l1_loss: 0.1557531; total_loss: 0.6311686; examples/sec: 32.2; progress: 16.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 204; epoch: 33; focal_loss: 1.5275413; l1_loss: 0.7111468; total_loss: 2.238688; \n",
      "FastEstimator-Train: step: 204; focal_loss: 0.5561316; l1_loss: 0.1967294; total_loss: 0.752861; examples/sec: 32.2; progress: 17.0%; \n",
      "FastEstimator-Train: step: 205; focal_loss: 0.5736814; l1_loss: 0.1774635; total_loss: 0.7511448; examples/sec: 32.1; progress: 17.1%; \n",
      "FastEstimator-Train: step: 206; focal_loss: 0.4539261; l1_loss: 0.183443; total_loss: 0.6373692; examples/sec: 32.1; progress: 17.2%; \n",
      "FastEstimator-Train: step: 207; focal_loss: 0.5266912; l1_loss: 0.1457063; total_loss: 0.6723975; examples/sec: 32.3; progress: 17.2%; \n",
      "FastEstimator-Train: step: 208; focal_loss: 0.4485012; l1_loss: 0.1554795; total_loss: 0.6039806; examples/sec: 31.9; progress: 17.3%; \n",
      "FastEstimator-Train: step: 209; focal_loss: 0.4392727; l1_loss: 0.1751806; total_loss: 0.6144532; examples/sec: 31.7; progress: 17.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 210; epoch: 34; focal_loss: 1.52681; l1_loss: 0.6976964; total_loss: 2.2245064; \n",
      "FastEstimator-Train: step: 210; focal_loss: 0.4379955; l1_loss: 0.1438864; total_loss: 0.5818819; examples/sec: 32.2; progress: 17.5%; \n",
      "FastEstimator-Train: step: 211; focal_loss: 0.4012056; l1_loss: 0.1350713; total_loss: 0.5362768; examples/sec: 32.0; progress: 17.6%; \n",
      "FastEstimator-Train: step: 212; focal_loss: 0.3958473; l1_loss: 0.0907891; total_loss: 0.4866364; examples/sec: 32.3; progress: 17.7%; \n",
      "FastEstimator-Train: step: 213; focal_loss: 0.4438172; l1_loss: 0.1254325; total_loss: 0.5692497; examples/sec: 32.1; progress: 17.8%; \n",
      "FastEstimator-Train: step: 214; focal_loss: 0.4868327; l1_loss: 0.2129856; total_loss: 0.6998182; examples/sec: 32.3; progress: 17.8%; \n",
      "FastEstimator-Train: step: 215; focal_loss: 0.4096253; l1_loss: 0.1712878; total_loss: 0.580913; examples/sec: 32.2; progress: 17.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 216; epoch: 35; focal_loss: 1.6167564; l1_loss: 0.695708; total_loss: 2.3124645; \n",
      "FastEstimator-Train: step: 216; focal_loss: 0.5592486; l1_loss: 0.1344915; total_loss: 0.6937402; examples/sec: 32.3; progress: 18.0%; \n",
      "FastEstimator-Train: step: 217; focal_loss: 0.4624509; l1_loss: 0.1524246; total_loss: 0.6148756; examples/sec: 31.9; progress: 18.1%; \n",
      "FastEstimator-Train: step: 218; focal_loss: 0.4259534; l1_loss: 0.1482936; total_loss: 0.574247; examples/sec: 32.0; progress: 18.2%; \n",
      "FastEstimator-Train: step: 219; focal_loss: 0.3811132; l1_loss: 0.1466952; total_loss: 0.5278083; examples/sec: 31.5; progress: 18.2%; \n",
      "FastEstimator-Train: step: 220; focal_loss: 0.4518706; l1_loss: 0.0883822; total_loss: 0.5402528; examples/sec: 32.1; progress: 18.3%; \n",
      "FastEstimator-Train: step: 221; focal_loss: 0.4806061; l1_loss: 0.1480893; total_loss: 0.6286954; examples/sec: 31.8; progress: 18.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 222; epoch: 36; focal_loss: 1.7813123; l1_loss: 0.6988364; total_loss: 2.4801486; \n",
      "FastEstimator-Train: step: 222; focal_loss: 0.4067773; l1_loss: 0.1720568; total_loss: 0.5788341; examples/sec: 32.4; progress: 18.5%; \n",
      "FastEstimator-Train: step: 223; focal_loss: 0.4013008; l1_loss: 0.108127; total_loss: 0.5094278; examples/sec: 32.5; progress: 18.6%; \n",
      "FastEstimator-Train: step: 224; focal_loss: 0.505647; l1_loss: 0.2216196; total_loss: 0.7272666; examples/sec: 31.7; progress: 18.7%; \n",
      "FastEstimator-Train: step: 225; focal_loss: 0.3511221; l1_loss: 0.0835587; total_loss: 0.4346808; examples/sec: 31.9; progress: 18.8%; \n",
      "FastEstimator-Train: step: 226; focal_loss: 0.4293778; l1_loss: 0.1061857; total_loss: 0.5355636; examples/sec: 31.7; progress: 18.8%; \n",
      "FastEstimator-Train: step: 227; focal_loss: 0.5398416; l1_loss: 0.1460621; total_loss: 0.6859036; examples/sec: 31.7; progress: 18.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 228; epoch: 37; focal_loss: 1.7614288; l1_loss: 0.7031417; total_loss: 2.4645705; \n",
      "FastEstimator-Train: step: 228; focal_loss: 0.5687518; l1_loss: 0.1238055; total_loss: 0.6925574; examples/sec: 32.3; progress: 19.0%; \n",
      "FastEstimator-Train: step: 229; focal_loss: 0.460973; l1_loss: 0.1594289; total_loss: 0.6204018; examples/sec: 32.6; progress: 19.1%; \n",
      "FastEstimator-Train: step: 230; focal_loss: 0.383314; l1_loss: 0.1636237; total_loss: 0.5469377; examples/sec: 31.6; progress: 19.2%; \n",
      "FastEstimator-Train: step: 231; focal_loss: 0.5074468; l1_loss: 0.1912093; total_loss: 0.698656; examples/sec: 32.0; progress: 19.2%; \n",
      "FastEstimator-Train: step: 232; focal_loss: 0.3534385; l1_loss: 0.1580735; total_loss: 0.511512; examples/sec: 31.9; progress: 19.3%; \n",
      "FastEstimator-Train: step: 233; focal_loss: 0.4610366; l1_loss: 0.1179362; total_loss: 0.5789728; examples/sec: 32.2; progress: 19.4%; \n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 234; epoch: 38; focal_loss: 1.658595; l1_loss: 0.7092954; total_loss: 2.3678906; \n",
      "FastEstimator-Train: step: 234; focal_loss: 0.3408537; l1_loss: 0.1396355; total_loss: 0.4804892; examples/sec: 32.2; progress: 19.5%; \n",
      "FastEstimator-Train: step: 235; focal_loss: 0.5093234; l1_loss: 0.1835295; total_loss: 0.6928529; examples/sec: 32.5; progress: 19.6%; \n",
      "FastEstimator-Train: step: 236; focal_loss: 0.3864958; l1_loss: 0.0830109; total_loss: 0.4695068; examples/sec: 32.2; progress: 19.7%; \n",
      "FastEstimator-Train: step: 237; focal_loss: 0.497008; l1_loss: 0.1694269; total_loss: 0.6664349; examples/sec: 31.9; progress: 19.8%; \n",
      "FastEstimator-Train: step: 238; focal_loss: 0.4924298; l1_loss: 0.1985443; total_loss: 0.690974; examples/sec: 32.2; progress: 19.8%; \n",
      "FastEstimator-Train: step: 239; focal_loss: 0.428805; l1_loss: 0.1880541; total_loss: 0.6168591; examples/sec: 32.0; progress: 19.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 240; epoch: 39; focal_loss: 1.4807769; l1_loss: 0.703567; total_loss: 2.184344; \n",
      "FastEstimator-Train: step: 240; focal_loss: 0.5051062; l1_loss: 0.154627; total_loss: 0.6597332; examples/sec: 32.3; progress: 20.0%; \n",
      "FastEstimator-Train: step: 241; focal_loss: 0.3623635; l1_loss: 0.1383196; total_loss: 0.500683; examples/sec: 32.5; progress: 20.1%; \n",
      "FastEstimator-Train: step: 242; focal_loss: 0.4581388; l1_loss: 0.1434551; total_loss: 0.6015938; examples/sec: 31.9; progress: 20.2%; \n",
      "FastEstimator-Train: step: 243; focal_loss: 0.388974; l1_loss: 0.106804; total_loss: 0.495778; examples/sec: 32.1; progress: 20.2%; \n",
      "FastEstimator-Train: step: 244; focal_loss: 0.355357; l1_loss: 0.1130054; total_loss: 0.4683625; examples/sec: 32.0; progress: 20.3%; \n",
      "FastEstimator-Train: step: 245; focal_loss: 0.3469132; l1_loss: 0.1300342; total_loss: 0.4769474; examples/sec: 32.1; progress: 20.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 246; epoch: 40; focal_loss: 1.6471859; l1_loss: 0.7050246; total_loss: 2.3522108; \n",
      "FastEstimator-Train: step: 246; focal_loss: 0.373272; l1_loss: 0.2136419; total_loss: 0.5869138; examples/sec: 31.9; progress: 20.5%; \n",
      "FastEstimator-Train: step: 247; focal_loss: 0.4099665; l1_loss: 0.1395066; total_loss: 0.5494732; examples/sec: 32.3; progress: 20.6%; \n",
      "FastEstimator-Train: step: 248; focal_loss: 0.4504442; l1_loss: 0.1767; total_loss: 0.6271442; examples/sec: 32.3; progress: 20.7%; \n",
      "FastEstimator-Train: step: 249; focal_loss: 0.2877522; l1_loss: 0.1075421; total_loss: 0.3952943; examples/sec: 32.2; progress: 20.8%; \n",
      "FastEstimator-Train: step: 250; focal_loss: 0.2478004; l1_loss: 0.0808951; total_loss: 0.3286955; examples/sec: 32.2; progress: 20.8%; \n",
      "FastEstimator-Train: step: 251; focal_loss: 0.3465107; l1_loss: 0.1990743; total_loss: 0.545585; examples/sec: 32.1; progress: 20.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 252; epoch: 41; focal_loss: 1.6681515; l1_loss: 0.6978662; total_loss: 2.3660176; \n",
      "FastEstimator-Train: step: 252; focal_loss: 0.3600555; l1_loss: 0.21212; total_loss: 0.5721755; examples/sec: 32.1; progress: 21.0%; \n",
      "FastEstimator-Train: step: 253; focal_loss: 0.4409838; l1_loss: 0.1731928; total_loss: 0.6141766; examples/sec: 32.3; progress: 21.1%; \n",
      "FastEstimator-Train: step: 254; focal_loss: 0.4742; l1_loss: 0.1632679; total_loss: 0.637468; examples/sec: 32.5; progress: 21.2%; \n",
      "FastEstimator-Train: step: 255; focal_loss: 0.347866; l1_loss: 0.1748891; total_loss: 0.5227551; examples/sec: 32.3; progress: 21.2%; \n",
      "FastEstimator-Train: step: 256; focal_loss: 0.4044726; l1_loss: 0.1909232; total_loss: 0.5953958; examples/sec: 32.2; progress: 21.3%; \n",
      "FastEstimator-Train: step: 257; focal_loss: 0.2838849; l1_loss: 0.1669906; total_loss: 0.4508754; examples/sec: 31.7; progress: 21.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 258; epoch: 42; focal_loss: 1.7213446; l1_loss: 0.7099056; total_loss: 2.4312503; \n",
      "FastEstimator-Train: step: 258; focal_loss: 0.3959084; l1_loss: 0.2177156; total_loss: 0.613624; examples/sec: 32.1; progress: 21.5%; \n",
      "FastEstimator-Train: step: 259; focal_loss: 0.3460252; l1_loss: 0.1150172; total_loss: 0.4610424; examples/sec: 32.0; progress: 21.6%; \n",
      "FastEstimator-Train: step: 260; focal_loss: 0.3339898; l1_loss: 0.1233326; total_loss: 0.4573225; examples/sec: 32.2; progress: 21.7%; \n",
      "FastEstimator-Train: step: 261; focal_loss: 0.3216117; l1_loss: 0.1353954; total_loss: 0.4570072; examples/sec: 32.0; progress: 21.8%; \n",
      "FastEstimator-Train: step: 262; focal_loss: 0.3269277; l1_loss: 0.1607595; total_loss: 0.4876873; examples/sec: 32.2; progress: 21.8%; \n",
      "FastEstimator-Train: step: 263; focal_loss: 0.220561; l1_loss: 0.1225209; total_loss: 0.3430818; examples/sec: 32.1; progress: 21.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 264; epoch: 43; focal_loss: 1.7264585; l1_loss: 0.6864344; total_loss: 2.4128933; \n",
      "FastEstimator-Train: step: 264; focal_loss: 0.290288; l1_loss: 0.1680278; total_loss: 0.4583158; examples/sec: 32.3; progress: 22.0%; \n",
      "FastEstimator-Train: step: 265; focal_loss: 0.3919981; l1_loss: 0.1914892; total_loss: 0.5834872; examples/sec: 32.2; progress: 22.1%; \n",
      "FastEstimator-Train: step: 266; focal_loss: 0.3415652; l1_loss: 0.3178184; total_loss: 0.6593836; examples/sec: 32.4; progress: 22.2%; \n",
      "FastEstimator-Train: step: 267; focal_loss: 0.3161718; l1_loss: 0.1805857; total_loss: 0.4967575; examples/sec: 32.2; progress: 22.2%; \n",
      "FastEstimator-Train: step: 268; focal_loss: 0.2936143; l1_loss: 0.158652; total_loss: 0.4522663; examples/sec: 32.1; progress: 22.3%; \n",
      "FastEstimator-Train: step: 269; focal_loss: 0.275572; l1_loss: 0.1563903; total_loss: 0.4319624; examples/sec: 31.8; progress: 22.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 270; epoch: 44; focal_loss: 1.788683; l1_loss: 0.7142278; total_loss: 2.5029109; \n",
      "FastEstimator-Train: step: 270; focal_loss: 0.2500082; l1_loss: 0.1533101; total_loss: 0.4033182; examples/sec: 31.9; progress: 22.5%; \n",
      "FastEstimator-Train: step: 271; focal_loss: 0.2501863; l1_loss: 0.1949179; total_loss: 0.4451043; examples/sec: 31.8; progress: 22.6%; \n",
      "FastEstimator-Train: step: 272; focal_loss: 0.3588376; l1_loss: 0.1561099; total_loss: 0.5149474; examples/sec: 32.4; progress: 22.7%; \n",
      "FastEstimator-Train: step: 273; focal_loss: 0.2692983; l1_loss: 0.1943491; total_loss: 0.4636474; examples/sec: 32.5; progress: 22.8%; \n",
      "FastEstimator-Train: step: 274; focal_loss: 0.2224885; l1_loss: 0.1361079; total_loss: 0.3585964; examples/sec: 32.2; progress: 22.8%; \n",
      "FastEstimator-Train: step: 275; focal_loss: 0.1883584; l1_loss: 0.1038676; total_loss: 0.292226; examples/sec: 32.2; progress: 22.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 276; epoch: 45; focal_loss: 1.9250122; l1_loss: 0.6920808; total_loss: 2.617093; \n",
      "FastEstimator-Train: step: 276; focal_loss: 0.244685; l1_loss: 0.1434505; total_loss: 0.3881355; examples/sec: 31.9; progress: 23.0%; \n",
      "FastEstimator-Train: step: 277; focal_loss: 0.3207685; l1_loss: 0.1706419; total_loss: 0.4914104; examples/sec: 32.3; progress: 23.1%; \n",
      "FastEstimator-Train: step: 278; focal_loss: 0.2813454; l1_loss: 0.1252448; total_loss: 0.4065902; examples/sec: 32.3; progress: 23.2%; \n",
      "FastEstimator-Train: step: 279; focal_loss: 0.2889575; l1_loss: 0.136566; total_loss: 0.4255234; examples/sec: 32.4; progress: 23.2%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 280; focal_loss: 0.2793612; l1_loss: 0.1575928; total_loss: 0.436954; examples/sec: 31.5; progress: 23.3%; \n",
      "FastEstimator-Train: step: 281; focal_loss: 0.2382887; l1_loss: 0.1458648; total_loss: 0.3841535; examples/sec: 32.2; progress: 23.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 282; epoch: 46; focal_loss: 1.9785182; l1_loss: 0.6995486; total_loss: 2.6780665; \n",
      "FastEstimator-Train: step: 282; focal_loss: 0.2050052; l1_loss: 0.1146727; total_loss: 0.319678; examples/sec: 32.1; progress: 23.5%; \n",
      "FastEstimator-Train: step: 283; focal_loss: 0.1906573; l1_loss: 0.0971853; total_loss: 0.2878426; examples/sec: 32.1; progress: 23.6%; \n",
      "FastEstimator-Train: step: 284; focal_loss: 0.2046748; l1_loss: 0.1197355; total_loss: 0.3244104; examples/sec: 32.4; progress: 23.7%; \n",
      "FastEstimator-Train: step: 285; focal_loss: 0.1842426; l1_loss: 0.1334932; total_loss: 0.3177358; examples/sec: 32.6; progress: 23.8%; \n",
      "FastEstimator-Train: step: 286; focal_loss: 0.2795113; l1_loss: 0.137893; total_loss: 0.4174044; examples/sec: 32.0; progress: 23.8%; \n",
      "FastEstimator-Train: step: 287; focal_loss: 0.2213039; l1_loss: 0.1063045; total_loss: 0.3276084; examples/sec: 31.9; progress: 23.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 288; epoch: 47; focal_loss: 1.9737748; l1_loss: 0.6942034; total_loss: 2.6679783; \n",
      "FastEstimator-Train: step: 288; focal_loss: 0.1890954; l1_loss: 0.1199605; total_loss: 0.3090558; examples/sec: 32.1; progress: 24.0%; \n",
      "FastEstimator-Train: step: 289; focal_loss: 0.2522861; l1_loss: 0.1565566; total_loss: 0.4088427; examples/sec: 32.1; progress: 24.1%; \n",
      "FastEstimator-Train: step: 290; focal_loss: 0.2159723; l1_loss: 0.1384842; total_loss: 0.3544565; examples/sec: 31.9; progress: 24.2%; \n",
      "FastEstimator-Train: step: 291; focal_loss: 0.191332; l1_loss: 0.1631501; total_loss: 0.3544821; examples/sec: 32.3; progress: 24.2%; \n",
      "FastEstimator-Train: step: 292; focal_loss: 0.266181; l1_loss: 0.1073634; total_loss: 0.3735444; examples/sec: 32.0; progress: 24.3%; \n",
      "FastEstimator-Train: step: 293; focal_loss: 0.2955151; l1_loss: 0.1245654; total_loss: 0.4200806; examples/sec: 32.2; progress: 24.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 294; epoch: 48; focal_loss: 1.9871132; l1_loss: 0.6890676; total_loss: 2.6761808; \n",
      "FastEstimator-Train: step: 294; focal_loss: 0.22745; l1_loss: 0.1012316; total_loss: 0.3286817; examples/sec: 32.3; progress: 24.5%; \n",
      "FastEstimator-Train: step: 295; focal_loss: 0.1523275; l1_loss: 0.0755672; total_loss: 0.2278946; examples/sec: 32.1; progress: 24.6%; \n",
      "FastEstimator-Train: step: 296; focal_loss: 0.2729612; l1_loss: 0.0983248; total_loss: 0.371286; examples/sec: 32.3; progress: 24.7%; \n",
      "FastEstimator-Train: step: 297; focal_loss: 0.1548011; l1_loss: 0.100585; total_loss: 0.255386; examples/sec: 31.9; progress: 24.8%; \n",
      "FastEstimator-Train: step: 298; focal_loss: 0.2568419; l1_loss: 0.1198476; total_loss: 0.3766895; examples/sec: 32.6; progress: 24.8%; \n",
      "FastEstimator-Train: step: 299; focal_loss: 0.1900609; l1_loss: 0.1074596; total_loss: 0.2975205; examples/sec: 32.0; progress: 24.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 300; epoch: 49; focal_loss: 1.9944488; l1_loss: 0.6879394; total_loss: 2.6823883; \n",
      "FastEstimator-Train: step: 300; focal_loss: 0.2187732; l1_loss: 0.1301901; total_loss: 0.3489632; examples/sec: 32.4; progress: 25.0%; \n",
      "FastEstimator-Train: step: 301; focal_loss: 0.1739289; l1_loss: 0.0991199; total_loss: 0.2730487; examples/sec: 32.1; progress: 25.1%; \n",
      "FastEstimator-Train: step: 302; focal_loss: 0.2311445; l1_loss: 0.18108; total_loss: 0.4122244; examples/sec: 32.1; progress: 25.2%; \n",
      "FastEstimator-Train: step: 303; focal_loss: 0.2284716; l1_loss: 0.1293314; total_loss: 0.3578029; examples/sec: 32.3; progress: 25.2%; \n",
      "FastEstimator-Train: step: 304; focal_loss: 0.3863697; l1_loss: 0.1345179; total_loss: 0.5208876; examples/sec: 32.4; progress: 25.3%; \n",
      "FastEstimator-Train: step: 305; focal_loss: 0.2067826; l1_loss: 0.0883172; total_loss: 0.2950998; examples/sec: 32.2; progress: 25.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 306; epoch: 50; focal_loss: 1.9748368; l1_loss: 0.6938364; total_loss: 2.6686733; \n",
      "FastEstimator-Train: step: 306; focal_loss: 0.1727589; l1_loss: 0.0959494; total_loss: 0.2687083; examples/sec: 31.8; progress: 25.5%; \n",
      "FastEstimator-Train: step: 307; focal_loss: 0.2327759; l1_loss: 0.1054072; total_loss: 0.3381831; examples/sec: 31.9; progress: 25.6%; \n",
      "FastEstimator-Train: step: 308; focal_loss: 0.1881236; l1_loss: 0.1011775; total_loss: 0.2893011; examples/sec: 32.2; progress: 25.7%; \n",
      "FastEstimator-Train: step: 309; focal_loss: 0.1410266; l1_loss: 0.0769527; total_loss: 0.2179792; examples/sec: 32.1; progress: 25.8%; \n",
      "FastEstimator-Train: step: 310; focal_loss: 0.2578063; l1_loss: 0.0778767; total_loss: 0.335683; examples/sec: 32.5; progress: 25.8%; \n",
      "FastEstimator-Train: step: 311; focal_loss: 0.1851884; l1_loss: 0.131043; total_loss: 0.3162314; examples/sec: 32.1; progress: 25.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 312; epoch: 51; focal_loss: 1.9267918; l1_loss: 0.682402; total_loss: 2.6091938; \n",
      "FastEstimator-Train: step: 312; focal_loss: 0.1600874; l1_loss: 0.0414378; total_loss: 0.2015252; examples/sec: 31.7; progress: 26.0%; \n",
      "FastEstimator-Train: step: 313; focal_loss: 0.1522713; l1_loss: 0.1445218; total_loss: 0.2967931; examples/sec: 32.1; progress: 26.1%; \n",
      "FastEstimator-Train: step: 314; focal_loss: 0.2214433; l1_loss: 0.0801994; total_loss: 0.3016427; examples/sec: 31.8; progress: 26.2%; \n",
      "FastEstimator-Train: step: 315; focal_loss: 0.2702628; l1_loss: 0.1261754; total_loss: 0.3964382; examples/sec: 32.1; progress: 26.2%; \n",
      "FastEstimator-Train: step: 316; focal_loss: 0.205314; l1_loss: 0.0975302; total_loss: 0.3028442; examples/sec: 32.5; progress: 26.3%; \n",
      "FastEstimator-Train: step: 317; focal_loss: 0.1766896; l1_loss: 0.1024801; total_loss: 0.2791697; examples/sec: 32.1; progress: 26.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 318; epoch: 52; focal_loss: 1.9588976; l1_loss: 0.68013; total_loss: 2.6390276; \n",
      "FastEstimator-Train: step: 318; focal_loss: 0.165662; l1_loss: 0.0948717; total_loss: 0.2605337; examples/sec: 32.2; progress: 26.5%; \n",
      "FastEstimator-Train: step: 319; focal_loss: 0.1268115; l1_loss: 0.0563072; total_loss: 0.1831187; examples/sec: 32.0; progress: 26.6%; \n",
      "FastEstimator-Train: step: 320; focal_loss: 0.1847084; l1_loss: 0.095011; total_loss: 0.2797194; examples/sec: 32.1; progress: 26.7%; \n",
      "FastEstimator-Train: step: 321; focal_loss: 0.1723463; l1_loss: 0.0562736; total_loss: 0.2286199; examples/sec: 31.6; progress: 26.8%; \n",
      "FastEstimator-Train: step: 322; focal_loss: 0.1460293; l1_loss: 0.0641578; total_loss: 0.2101871; examples/sec: 32.6; progress: 26.8%; \n",
      "FastEstimator-Train: step: 323; focal_loss: 0.2438235; l1_loss: 0.1019761; total_loss: 0.3457997; examples/sec: 32.6; progress: 26.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 324; epoch: 53; focal_loss: 1.9396915; l1_loss: 0.6687145; total_loss: 2.6084063; \n",
      "FastEstimator-Train: step: 324; focal_loss: 0.1196966; l1_loss: 0.0716889; total_loss: 0.1913854; examples/sec: 32.0; progress: 27.0%; \n",
      "FastEstimator-Train: step: 325; focal_loss: 0.1801388; l1_loss: 0.1087269; total_loss: 0.2888657; examples/sec: 32.0; progress: 27.1%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 326; focal_loss: 0.1958224; l1_loss: 0.1085356; total_loss: 0.304358; examples/sec: 32.1; progress: 27.2%; \n",
      "FastEstimator-Train: step: 327; focal_loss: 0.1546651; l1_loss: 0.0749369; total_loss: 0.229602; examples/sec: 32.2; progress: 27.3%; \n",
      "FastEstimator-Train: step: 328; focal_loss: 0.1554606; l1_loss: 0.0643299; total_loss: 0.2197905; examples/sec: 32.2; progress: 27.3%; \n",
      "FastEstimator-Train: step: 329; focal_loss: 0.1940213; l1_loss: 0.0631352; total_loss: 0.2571565; examples/sec: 32.6; progress: 27.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 330; epoch: 54; focal_loss: 1.918313; l1_loss: 0.6741193; total_loss: 2.5924327; \n",
      "FastEstimator-Train: step: 330; focal_loss: 0.1406052; l1_loss: 0.0813263; total_loss: 0.2219315; examples/sec: 32.4; progress: 27.5%; \n",
      "FastEstimator-Train: step: 331; focal_loss: 0.167948; l1_loss: 0.127603; total_loss: 0.295551; examples/sec: 32.1; progress: 27.6%; \n",
      "FastEstimator-Train: step: 332; focal_loss: 0.1629351; l1_loss: 0.0435171; total_loss: 0.2064522; examples/sec: 32.2; progress: 27.7%; \n",
      "FastEstimator-Train: step: 333; focal_loss: 0.1228253; l1_loss: 0.0587612; total_loss: 0.1815865; examples/sec: 32.0; progress: 27.8%; \n",
      "FastEstimator-Train: step: 334; focal_loss: 0.1643568; l1_loss: 0.0694892; total_loss: 0.233846; examples/sec: 31.6; progress: 27.8%; \n",
      "FastEstimator-Train: step: 335; focal_loss: 0.1458394; l1_loss: 0.0674613; total_loss: 0.2133008; examples/sec: 32.6; progress: 27.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 336; epoch: 55; focal_loss: 2.0651028; l1_loss: 0.666985; total_loss: 2.732088; \n",
      "FastEstimator-Train: step: 336; focal_loss: 0.1304678; l1_loss: 0.1140926; total_loss: 0.2445604; examples/sec: 32.1; progress: 28.0%; \n",
      "FastEstimator-Train: step: 337; focal_loss: 0.1345279; l1_loss: 0.0516453; total_loss: 0.1861732; examples/sec: 32.4; progress: 28.1%; \n",
      "FastEstimator-Train: step: 338; focal_loss: 0.0792267; l1_loss: 0.0306643; total_loss: 0.109891; examples/sec: 32.1; progress: 28.2%; \n",
      "FastEstimator-Train: step: 339; focal_loss: 0.1493728; l1_loss: 0.0804123; total_loss: 0.2297851; examples/sec: 32.1; progress: 28.2%; \n",
      "FastEstimator-Train: step: 340; focal_loss: 0.184316; l1_loss: 0.0636502; total_loss: 0.2479661; examples/sec: 32.1; progress: 28.3%; \n",
      "FastEstimator-Train: step: 341; focal_loss: 0.1649936; l1_loss: 0.0722498; total_loss: 0.2372434; examples/sec: 32.4; progress: 28.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 342; epoch: 56; focal_loss: 2.087825; l1_loss: 0.6613646; total_loss: 2.7491896; \n",
      "FastEstimator-Train: step: 342; focal_loss: 0.1913292; l1_loss: 0.0650702; total_loss: 0.2563994; examples/sec: 31.8; progress: 28.5%; \n",
      "FastEstimator-Train: step: 343; focal_loss: 0.1021075; l1_loss: 0.0826647; total_loss: 0.1847721; examples/sec: 32.2; progress: 28.6%; \n",
      "FastEstimator-Train: step: 344; focal_loss: 0.1302357; l1_loss: 0.0777712; total_loss: 0.2080068; examples/sec: 31.7; progress: 28.7%; \n",
      "FastEstimator-Train: step: 345; focal_loss: 0.0874914; l1_loss: 0.0433461; total_loss: 0.1308374; examples/sec: 31.7; progress: 28.7%; \n",
      "FastEstimator-Train: step: 346; focal_loss: 0.1323466; l1_loss: 0.0745058; total_loss: 0.2068524; examples/sec: 32.1; progress: 28.8%; \n",
      "FastEstimator-Train: step: 347; focal_loss: 0.1738339; l1_loss: 0.0768585; total_loss: 0.2506924; examples/sec: 32.6; progress: 28.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 348; epoch: 57; focal_loss: 2.1180441; l1_loss: 0.6663156; total_loss: 2.7843597; \n",
      "FastEstimator-Train: step: 348; focal_loss: 0.1793035; l1_loss: 0.0654383; total_loss: 0.2447418; examples/sec: 31.7; progress: 29.0%; \n",
      "FastEstimator-Train: step: 349; focal_loss: 0.0837432; l1_loss: 0.0526484; total_loss: 0.1363915; examples/sec: 32.1; progress: 29.1%; \n",
      "FastEstimator-Train: step: 350; focal_loss: 0.1395534; l1_loss: 0.0678044; total_loss: 0.2073578; examples/sec: 32.1; progress: 29.2%; \n",
      "FastEstimator-Train: step: 351; focal_loss: 0.0909734; l1_loss: 0.0583187; total_loss: 0.1492921; examples/sec: 32.1; progress: 29.2%; \n",
      "FastEstimator-Train: step: 352; focal_loss: 0.1463107; l1_loss: 0.0785527; total_loss: 0.2248634; examples/sec: 32.0; progress: 29.3%; \n",
      "FastEstimator-Train: step: 353; focal_loss: 0.1387147; l1_loss: 0.0676669; total_loss: 0.2063816; examples/sec: 32.1; progress: 29.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 354; epoch: 58; focal_loss: 2.2573514; l1_loss: 0.6434385; total_loss: 2.90079; \n",
      "FastEstimator-Train: step: 354; focal_loss: 0.1403399; l1_loss: 0.0369635; total_loss: 0.1773034; examples/sec: 32.3; progress: 29.5%; \n",
      "FastEstimator-Train: step: 355; focal_loss: 0.2027125; l1_loss: 0.0350161; total_loss: 0.2377286; examples/sec: 31.8; progress: 29.6%; \n",
      "FastEstimator-Train: step: 356; focal_loss: 0.1085335; l1_loss: 0.04132; total_loss: 0.1498535; examples/sec: 32.1; progress: 29.7%; \n",
      "FastEstimator-Train: step: 357; focal_loss: 0.273472; l1_loss: 0.0737768; total_loss: 0.3472488; examples/sec: 32.2; progress: 29.8%; \n",
      "FastEstimator-Train: step: 358; focal_loss: 0.1434571; l1_loss: 0.0662638; total_loss: 0.2097208; examples/sec: 32.1; progress: 29.8%; \n",
      "FastEstimator-Train: step: 359; focal_loss: 0.1048602; l1_loss: 0.0485433; total_loss: 0.1534036; examples/sec: 31.8; progress: 29.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 360; epoch: 59; focal_loss: 2.1738937; l1_loss: 0.6429412; total_loss: 2.8168347; \n",
      "FastEstimator-Train: step: 360; focal_loss: 0.1315095; l1_loss: 0.0690195; total_loss: 0.200529; examples/sec: 32.1; progress: 30.0%; \n",
      "FastEstimator-Train: step: 361; focal_loss: 0.0901173; l1_loss: 0.0424871; total_loss: 0.1326044; examples/sec: 32.1; progress: 30.1%; \n",
      "FastEstimator-Train: step: 362; focal_loss: 0.0682459; l1_loss: 0.0405599; total_loss: 0.1088057; examples/sec: 32.0; progress: 30.2%; \n",
      "FastEstimator-Train: step: 363; focal_loss: 0.1402566; l1_loss: 0.0646654; total_loss: 0.204922; examples/sec: 32.1; progress: 30.2%; \n",
      "FastEstimator-Train: step: 364; focal_loss: 0.1242389; l1_loss: 0.0742776; total_loss: 0.1985165; examples/sec: 32.0; progress: 30.3%; \n",
      "FastEstimator-Train: step: 365; focal_loss: 0.2666782; l1_loss: 0.0911206; total_loss: 0.3577988; examples/sec: 31.9; progress: 30.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 366; epoch: 60; focal_loss: 2.187936; l1_loss: 0.6505124; total_loss: 2.8384483; \n",
      "FastEstimator-Train: step: 366; focal_loss: 0.1067548; l1_loss: 0.0699514; total_loss: 0.1767062; examples/sec: 32.2; progress: 30.5%; \n",
      "FastEstimator-Train: step: 367; focal_loss: 0.0991152; l1_loss: 0.0518098; total_loss: 0.150925; examples/sec: 32.0; progress: 30.6%; \n",
      "FastEstimator-Train: step: 368; focal_loss: 0.1963932; l1_loss: 0.0477555; total_loss: 0.2441487; examples/sec: 32.2; progress: 30.7%; \n",
      "FastEstimator-Train: step: 369; focal_loss: 0.0630782; l1_loss: 0.0355184; total_loss: 0.0985966; examples/sec: 32.0; progress: 30.8%; \n",
      "FastEstimator-Train: step: 370; focal_loss: 0.1212316; l1_loss: 0.0540465; total_loss: 0.1752781; examples/sec: 32.2; progress: 30.8%; \n",
      "FastEstimator-Train: step: 371; focal_loss: 0.1262356; l1_loss: 0.0605154; total_loss: 0.186751; examples/sec: 32.2; progress: 30.9%; \n",
      "[]\n",
      "[]\n",
      "[0.059301883]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0537632108]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 372; epoch: 61; focal_loss: 2.1718113; l1_loss: 0.6380784; total_loss: 2.80989; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 372; focal_loss: 0.2624774; l1_loss: 0.0821001; total_loss: 0.3445775; examples/sec: 32.2; progress: 31.0%; \n",
      "FastEstimator-Train: step: 373; focal_loss: 0.0770511; l1_loss: 0.0415404; total_loss: 0.1185915; examples/sec: 32.6; progress: 31.1%; \n",
      "FastEstimator-Train: step: 374; focal_loss: 0.0823488; l1_loss: 0.0488975; total_loss: 0.1312462; examples/sec: 31.6; progress: 31.2%; \n",
      "FastEstimator-Train: step: 375; focal_loss: 0.0758244; l1_loss: 0.0365799; total_loss: 0.1124042; examples/sec: 32.2; progress: 31.2%; \n",
      "FastEstimator-Train: step: 376; focal_loss: 0.1020073; l1_loss: 0.0606005; total_loss: 0.1626078; examples/sec: 32.2; progress: 31.3%; \n",
      "FastEstimator-Train: step: 377; focal_loss: 0.1155452; l1_loss: 0.0744528; total_loss: 0.189998; examples/sec: 32.1; progress: 31.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.273067147 0.0624409914 0.0622786 0.0587450862]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 378; epoch: 62; focal_loss: 1.9910842; l1_loss: 0.6306722; total_loss: 2.6217566; \n",
      "FastEstimator-Train: step: 378; focal_loss: 0.1283013; l1_loss: 0.0488557; total_loss: 0.177157; examples/sec: 32.2; progress: 31.5%; \n",
      "FastEstimator-Train: step: 379; focal_loss: 0.1296477; l1_loss: 0.0461664; total_loss: 0.1758141; examples/sec: 32.7; progress: 31.6%; \n",
      "FastEstimator-Train: step: 380; focal_loss: 0.1900205; l1_loss: 0.0329376; total_loss: 0.2229581; examples/sec: 32.1; progress: 31.7%; \n",
      "FastEstimator-Train: step: 381; focal_loss: 0.1318522; l1_loss: 0.060911; total_loss: 0.1927632; examples/sec: 32.1; progress: 31.8%; \n",
      "FastEstimator-Train: step: 382; focal_loss: 0.087703; l1_loss: 0.0368108; total_loss: 0.1245138; examples/sec: 32.1; progress: 31.8%; \n",
      "FastEstimator-Train: step: 383; focal_loss: 0.0845362; l1_loss: 0.03538; total_loss: 0.1199162; examples/sec: 32.3; progress: 31.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0722783804]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 384; epoch: 63; focal_loss: 2.071298; l1_loss: 0.6380871; total_loss: 2.709385; \n",
      "FastEstimator-Train: step: 384; focal_loss: 0.1302453; l1_loss: 0.0867999; total_loss: 0.2170452; examples/sec: 31.8; progress: 32.0%; \n",
      "FastEstimator-Train: step: 385; focal_loss: 0.0391755; l1_loss: 0.0210319; total_loss: 0.0602073; examples/sec: 32.4; progress: 32.1%; \n",
      "FastEstimator-Train: step: 386; focal_loss: 0.1982742; l1_loss: 0.0555693; total_loss: 0.2538436; examples/sec: 32.3; progress: 32.2%; \n",
      "FastEstimator-Train: step: 387; focal_loss: 0.0749014; l1_loss: 0.0439877; total_loss: 0.1188891; examples/sec: 32.0; progress: 32.2%; \n",
      "FastEstimator-Train: step: 388; focal_loss: 0.1736112; l1_loss: 0.0279663; total_loss: 0.2015776; examples/sec: 31.6; progress: 32.3%; \n",
      "FastEstimator-Train: step: 389; focal_loss: 0.0891049; l1_loss: 0.0503516; total_loss: 0.1394565; examples/sec: 32.0; progress: 32.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.077110678 0.0693218708]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 390; epoch: 64; focal_loss: 2.0278776; l1_loss: 0.6447881; total_loss: 2.6726656; \n",
      "FastEstimator-Train: step: 390; focal_loss: 0.1465288; l1_loss: 0.0816914; total_loss: 0.2282202; examples/sec: 32.4; progress: 32.5%; \n",
      "FastEstimator-Train: step: 391; focal_loss: 0.0748064; l1_loss: 0.0315908; total_loss: 0.1063972; examples/sec: 32.5; progress: 32.6%; \n",
      "FastEstimator-Train: step: 392; focal_loss: 0.1337894; l1_loss: 0.0539821; total_loss: 0.1877716; examples/sec: 32.2; progress: 32.7%; \n",
      "FastEstimator-Train: step: 393; focal_loss: 0.0769859; l1_loss: 0.0652855; total_loss: 0.1422714; examples/sec: 32.1; progress: 32.8%; \n",
      "FastEstimator-Train: step: 394; focal_loss: 0.1834302; l1_loss: 0.0370007; total_loss: 0.2204309; examples/sec: 32.1; progress: 32.8%; \n",
      "FastEstimator-Train: step: 395; focal_loss: 0.1599191; l1_loss: 0.0674921; total_loss: 0.2274112; examples/sec: 32.2; progress: 32.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0896823704 0.0642223954 0.0632117689 0.0598112047 0.0540620387 0.0522891283]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 396; epoch: 65; focal_loss: 1.961868; l1_loss: 0.6372147; total_loss: 2.5990827; \n",
      "FastEstimator-Train: step: 396; focal_loss: 0.064324; l1_loss: 0.0372677; total_loss: 0.1015918; examples/sec: 32.1; progress: 33.0%; \n",
      "FastEstimator-Train: step: 397; focal_loss: 0.0987866; l1_loss: 0.0642784; total_loss: 0.163065; examples/sec: 31.8; progress: 33.1%; \n",
      "FastEstimator-Train: step: 398; focal_loss: 0.0563066; l1_loss: 0.0514066; total_loss: 0.1077132; examples/sec: 32.4; progress: 33.2%; \n",
      "FastEstimator-Train: step: 399; focal_loss: 0.0637109; l1_loss: 0.1260535; total_loss: 0.1897644; examples/sec: 32.1; progress: 33.2%; \n",
      "FastEstimator-Train: step: 400; focal_loss: 0.1204087; l1_loss: 0.0527334; total_loss: 0.173142; examples/sec: 32.1; progress: 33.3%; \n",
      "FastEstimator-Train: step: 401; focal_loss: 0.0889775; l1_loss: 0.0488567; total_loss: 0.1378342; examples/sec: 32.2; progress: 33.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.070895344 0.0708497763]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 402; epoch: 66; focal_loss: 2.02508; l1_loss: 0.6409086; total_loss: 2.6659884; \n",
      "FastEstimator-Train: step: 402; focal_loss: 0.2704881; l1_loss: 0.0508109; total_loss: 0.321299; examples/sec: 32.1; progress: 33.5%; \n",
      "FastEstimator-Train: step: 403; focal_loss: 0.0699541; l1_loss: 0.062194; total_loss: 0.1321481; examples/sec: 32.2; progress: 33.6%; \n",
      "FastEstimator-Train: step: 404; focal_loss: 0.0415198; l1_loss: 0.0818973; total_loss: 0.1234172; examples/sec: 32.4; progress: 33.7%; \n",
      "FastEstimator-Train: step: 405; focal_loss: 0.0849341; l1_loss: 0.0989146; total_loss: 0.1838487; examples/sec: 32.0; progress: 33.8%; \n",
      "FastEstimator-Train: step: 406; focal_loss: 0.1071511; l1_loss: 0.0626764; total_loss: 0.1698276; examples/sec: 32.2; progress: 33.8%; \n",
      "FastEstimator-Train: step: 407; focal_loss: 0.2026074; l1_loss: 0.1304913; total_loss: 0.3330988; examples/sec: 32.2; progress: 33.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0918293297]\n",
      "[0.0513812304]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0650647283]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0640550256]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0583645105]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0584302545 0.0548392832 0.054718703 0.0513189137]\n",
      "[]\n",
      "[0.0551597178 0.0522028208]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 408; epoch: 67; focal_loss: 2.020034; l1_loss: 0.6038034; total_loss: 2.6238375; \n",
      "FastEstimator-Train: step: 408; focal_loss: 0.0415112; l1_loss: 0.0555164; total_loss: 0.0970276; examples/sec: 32.3; progress: 34.0%; \n",
      "FastEstimator-Train: step: 409; focal_loss: 0.0663922; l1_loss: 0.0581938; total_loss: 0.124586; examples/sec: 32.2; progress: 34.1%; \n",
      "FastEstimator-Train: step: 410; focal_loss: 0.0574838; l1_loss: 0.0599849; total_loss: 0.1174688; examples/sec: 32.4; progress: 34.2%; \n",
      "FastEstimator-Train: step: 411; focal_loss: 0.0619049; l1_loss: 0.1567761; total_loss: 0.218681; examples/sec: 32.0; progress: 34.2%; \n",
      "FastEstimator-Train: step: 412; focal_loss: 0.1788126; l1_loss: 0.1202473; total_loss: 0.2990599; examples/sec: 32.4; progress: 34.3%; \n",
      "FastEstimator-Train: step: 413; focal_loss: 0.0562998; l1_loss: 0.0909738; total_loss: 0.1472736; examples/sec: 32.2; progress: 34.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0518692732]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0752045214 0.0651417077 0.0602283776 0.0574784875 0.057082206 0.0557416975]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 414; epoch: 68; focal_loss: 2.027404; l1_loss: 0.6224743; total_loss: 2.6498783; \n",
      "FastEstimator-Train: step: 414; focal_loss: 0.0655215; l1_loss: 0.0702786; total_loss: 0.1358001; examples/sec: 31.9; progress: 34.5%; \n",
      "FastEstimator-Train: step: 415; focal_loss: 0.191777; l1_loss: 0.1198086; total_loss: 0.3115856; examples/sec: 32.0; progress: 34.6%; \n",
      "FastEstimator-Train: step: 416; focal_loss: 0.0507412; l1_loss: 0.0767332; total_loss: 0.1274743; examples/sec: 32.6; progress: 34.7%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 417; focal_loss: 0.1838224; l1_loss: 0.1356826; total_loss: 0.319505; examples/sec: 31.9; progress: 34.8%; \n",
      "FastEstimator-Train: step: 418; focal_loss: 0.0610779; l1_loss: 0.0949396; total_loss: 0.1560175; examples/sec: 32.2; progress: 34.8%; \n",
      "FastEstimator-Train: step: 419; focal_loss: 0.1267405; l1_loss: 0.084968; total_loss: 0.2117085; examples/sec: 31.7; progress: 34.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0519040823]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0727717578 0.0578161776]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0685766935 0.0683392286 0.0600283742]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0971180201 0.0767020881]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 420; epoch: 69; focal_loss: 1.9964268; l1_loss: 0.6021744; total_loss: 2.598601; \n",
      "FastEstimator-Train: step: 420; focal_loss: 0.1910856; l1_loss: 0.1239132; total_loss: 0.3149989; examples/sec: 31.8; progress: 35.0%; \n",
      "FastEstimator-Train: step: 421; focal_loss: 0.0549175; l1_loss: 0.0882239; total_loss: 0.1431414; examples/sec: 31.7; progress: 35.1%; \n",
      "FastEstimator-Train: step: 422; focal_loss: 0.1065134; l1_loss: 0.0773422; total_loss: 0.1838556; examples/sec: 32.5; progress: 35.2%; \n",
      "FastEstimator-Train: step: 423; focal_loss: 0.0813735; l1_loss: 0.0906664; total_loss: 0.1720399; examples/sec: 32.4; progress: 35.2%; \n",
      "FastEstimator-Train: step: 424; focal_loss: 0.10144; l1_loss: 0.1094674; total_loss: 0.2109074; examples/sec: 32.4; progress: 35.3%; \n",
      "FastEstimator-Train: step: 425; focal_loss: 0.1260234; l1_loss: 0.0574007; total_loss: 0.1834242; examples/sec: 32.0; progress: 35.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0518042445 0.0513821244]\n",
      "[]\n",
      "[]\n",
      "[0.0662165 0.0630840361]\n",
      "[0.0647051]\n",
      "[0.0504826307]\n",
      "[]\n",
      "[]\n",
      "[0.148000777 0.083016187]\n",
      "[0.0595918298]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0553254187]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0549529195]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0536666512 0.0513171256]\n",
      "[]\n",
      "[]\n",
      "[0.056061089]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0654932559]\n",
      "[0.0590959787]\n",
      "[0.0713550746 0.0692148209 0.0669024587 0.0654530823 0.0599841475 0.0517467856]\n",
      "[0.0642168522]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 426; epoch: 70; focal_loss: 1.9501938; l1_loss: 0.5947754; total_loss: 2.544969; \n",
      "FastEstimator-Train: step: 426; focal_loss: 0.1785702; l1_loss: 0.062494; total_loss: 0.2410642; examples/sec: 31.9; progress: 35.5%; \n",
      "FastEstimator-Train: step: 427; focal_loss: 0.0848499; l1_loss: 0.0748256; total_loss: 0.1596754; examples/sec: 31.9; progress: 35.6%; \n",
      "FastEstimator-Train: step: 428; focal_loss: 0.0680028; l1_loss: 0.0997208; total_loss: 0.1677236; examples/sec: 32.3; progress: 35.7%; \n",
      "FastEstimator-Train: step: 429; focal_loss: 0.1210453; l1_loss: 0.0963436; total_loss: 0.217389; examples/sec: 32.4; progress: 35.8%; \n",
      "FastEstimator-Train: step: 430; focal_loss: 0.0887831; l1_loss: 0.0658464; total_loss: 0.1546295; examples/sec: 32.2; progress: 35.8%; \n",
      "FastEstimator-Train: step: 431; focal_loss: 0.0925909; l1_loss: 0.0502067; total_loss: 0.1427976; examples/sec: 32.0; progress: 35.9%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0532245338]\n",
      "[]\n",
      "[]\n",
      "[0.0933868]\n",
      "[0.0552105]\n",
      "[0.0702085197]\n",
      "[]\n",
      "[]\n",
      "[0.198511183 0.102574259 0.0541934371]\n",
      "[0.0565310717]\n",
      "[0.0593490899]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0593444109]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0598641336]\n",
      "[0.0511539]\n",
      "[0.0541404486]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.076901406]\n",
      "[0.0524661541]\n",
      "[0.096113205 0.0816718638 0.0740021467 ... 0.0567395091 0.0558918417 0.0508817136]\n",
      "[]\n",
      "FastEstimator-Eval: step: 432; epoch: 71; focal_loss: 2.0237062; l1_loss: 0.5871313; total_loss: 2.6108372; \n",
      "FastEstimator-Train: step: 432; focal_loss: 0.1437787; l1_loss: 0.0536262; total_loss: 0.1974048; examples/sec: 32.1; progress: 36.0%; \n",
      "FastEstimator-Train: step: 433; focal_loss: 0.054477; l1_loss: 0.053192; total_loss: 0.107669; examples/sec: 32.1; progress: 36.1%; \n",
      "FastEstimator-Train: step: 434; focal_loss: 0.0534969; l1_loss: 0.050171; total_loss: 0.103668; examples/sec: 32.3; progress: 36.2%; \n",
      "FastEstimator-Train: step: 435; focal_loss: 0.124178; l1_loss: 0.072774; total_loss: 0.1969519; examples/sec: 32.6; progress: 36.2%; \n",
      "FastEstimator-Train: step: 436; focal_loss: 0.060311; l1_loss: 0.0342161; total_loss: 0.0945271; examples/sec: 32.2; progress: 36.3%; \n",
      "FastEstimator-Train: step: 437; focal_loss: 0.0468397; l1_loss: 0.0428395; total_loss: 0.0896792; examples/sec: 32.2; progress: 36.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.052988261]\n",
      "[]\n",
      "[0.0638044477 0.056548655]\n",
      "[]\n",
      "[]\n",
      "[0.0654709637]\n",
      "[0.0505384803]\n",
      "[0.0608823597]\n",
      "[]\n",
      "[]\n",
      "[0.120143622 0.0849423409]\n",
      "[0.0734469891]\n",
      "[0.0721409]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0621552765]\n",
      "[]\n",
      "[0.0595682859]\n",
      "[]\n",
      "[]\n",
      "[0.0536103547 0.0534618497]\n",
      "[]\n",
      "[0.0763900876 0.0606457889]\n",
      "[0.0744735 0.0653342307 0.0562388 0.0538120568 0.0513182878]\n",
      "[0.0685599744]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0519115925 0.0510482788]\n",
      "[0.0576440394 0.051655829]\n",
      "FastEstimator-Eval: step: 438; epoch: 72; focal_loss: 1.9544464; l1_loss: 0.5779962; total_loss: 2.5324426; \n",
      "FastEstimator-Train: step: 438; focal_loss: 0.0145702; l1_loss: 0.0296014; total_loss: 0.0441716; examples/sec: 31.8; progress: 36.5%; \n",
      "FastEstimator-Train: step: 439; focal_loss: 0.0644344; l1_loss: 0.0317968; total_loss: 0.0962312; examples/sec: 32.2; progress: 36.6%; \n",
      "FastEstimator-Train: step: 440; focal_loss: 0.0524605; l1_loss: 0.0491671; total_loss: 0.1016276; examples/sec: 32.1; progress: 36.7%; \n",
      "FastEstimator-Train: step: 441; focal_loss: 0.0725807; l1_loss: 0.0712438; total_loss: 0.1438244; examples/sec: 32.5; progress: 36.8%; \n",
      "FastEstimator-Train: step: 442; focal_loss: 0.1840971; l1_loss: 0.0450692; total_loss: 0.2291663; examples/sec: 32.1; progress: 36.8%; \n",
      "FastEstimator-Train: step: 443; focal_loss: 0.0152518; l1_loss: 0.0396989; total_loss: 0.0549507; examples/sec: 32.3; progress: 36.9%; \n",
      "[0.116098613 0.087649256 0.0762114823 ... 0.0556980968 0.0527890623 0.0523655117]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0647879541]\n",
      "[]\n",
      "[0.0674444735 0.0590248704]\n",
      "[]\n",
      "[]\n",
      "[0.104921401]\n",
      "[0.0659747422 0.0540970862]\n",
      "[0.0512297451 0.0509308279]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0803067088]\n",
      "[0.0955462754]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0545712113]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.060693115 0.0502527952]\n",
      "[]\n",
      "[0.0800332725]\n",
      "[]\n",
      "[]\n",
      "[0.0552763343 0.0543487668]\n",
      "[]\n",
      "[0.0833727121]\n",
      "[0.142241299 0.0644420683 0.0643650889 ... 0.0547250211 0.0522548556 0.0511676073]\n",
      "[0.0761463046]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 444; epoch: 73; focal_loss: 2.019647; l1_loss: 0.5773804; total_loss: 2.5970273; \n",
      "FastEstimator-Train: step: 444; focal_loss: 0.0391526; l1_loss: 0.0447371; total_loss: 0.0838897; examples/sec: 32.2; progress: 37.0%; \n",
      "FastEstimator-Train: step: 445; focal_loss: 0.029901; l1_loss: 0.0239947; total_loss: 0.0538956; examples/sec: 32.1; progress: 37.1%; \n",
      "FastEstimator-Train: step: 446; focal_loss: 0.1685926; l1_loss: 0.0319169; total_loss: 0.2005096; examples/sec: 31.9; progress: 37.2%; \n",
      "FastEstimator-Train: step: 447; focal_loss: 0.0778238; l1_loss: 0.0422726; total_loss: 0.1200964; examples/sec: 32.5; progress: 37.2%; \n",
      "FastEstimator-Train: step: 448; focal_loss: 0.045001; l1_loss: 0.0426824; total_loss: 0.0876834; examples/sec: 32.6; progress: 37.3%; \n",
      "FastEstimator-Train: step: 449; focal_loss: 0.0389693; l1_loss: 0.0520561; total_loss: 0.0910255; examples/sec: 31.7; progress: 37.4%; \n",
      "[]\n",
      "[0.0591205359 0.0515192151]\n",
      "[0.109910131 0.104651183 0.0800936818 ... 0.0521645248 0.050845176 0.0505077839]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0560432971]\n",
      "[]\n",
      "[0.0622208118 0.0579072833]\n",
      "[]\n",
      "[]\n",
      "[0.0826714635 0.0592146516]\n",
      "[0.064884007 0.0515336096]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0620362163]\n",
      "[0.0760788321]\n",
      "[0.0818332434]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0557944477]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0563257933]\n",
      "[]\n",
      "[0.0631889105]\n",
      "[]\n",
      "[]\n",
      "[0.0550656319 0.0543581247]\n",
      "[]\n",
      "[0.0693976283]\n",
      "[0.167605549 0.10579294 0.0693277419 ... 0.0615280569 0.0600390434 0.0542881787]\n",
      "[0.0611448586]\n",
      "[]\n",
      "FastEstimator-Eval: step: 450; epoch: 74; focal_loss: 1.9897484; l1_loss: 0.5852716; total_loss: 2.5750198; \n",
      "FastEstimator-Train: step: 450; focal_loss: 0.0381196; l1_loss: 0.0348376; total_loss: 0.0729572; examples/sec: 32.2; progress: 37.5%; \n",
      "FastEstimator-Train: step: 451; focal_loss: 0.0215203; l1_loss: 0.0410619; total_loss: 0.0625822; examples/sec: 32.2; progress: 37.6%; \n",
      "FastEstimator-Train: step: 452; focal_loss: 0.0431241; l1_loss: 0.0364094; total_loss: 0.0795335; examples/sec: 32.1; progress: 37.7%; \n",
      "FastEstimator-Train: step: 453; focal_loss: 0.1401871; l1_loss: 0.0271385; total_loss: 0.1673256; examples/sec: 32.2; progress: 37.8%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 454; focal_loss: 0.0371829; l1_loss: 0.0309856; total_loss: 0.0681686; examples/sec: 32.4; progress: 37.8%; \n",
      "FastEstimator-Train: step: 455; focal_loss: 0.0184703; l1_loss: 0.0299705; total_loss: 0.0484408; examples/sec: 31.8; progress: 37.9%; \n",
      "[]\n",
      "[]\n",
      "[0.0542688072]\n",
      "[0.0616673231 0.0508593619]\n",
      "[0.0968754292 0.0875514746 0.0735142529 ... 0.0584772229 0.0562558174 0.0541520715]\n",
      "[0.0517039895]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0713874102 0.0600259304]\n",
      "[0.0552588701]\n",
      "[]\n",
      "[0.0669730902 0.0652269125]\n",
      "[0.0706136227 0.0528715849]\n",
      "[0.0534080267]\n",
      "[]\n",
      "[]\n",
      "[0.117527932 0.103952348]\n",
      "[0.0708145797]\n",
      "[0.0684148669]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.061343044]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0576118529 0.0524584353]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0541405082]\n",
      "[]\n",
      "[0.0569839478]\n",
      "[0.105550557 0.0988538265 0.0679168105 0.0632809401 0.0602642596 0.0591736138]\n",
      "FastEstimator-Eval: step: 456; epoch: 75; focal_loss: 1.978965; l1_loss: 0.5640296; total_loss: 2.5429945; \n",
      "FastEstimator-Train: step: 456; focal_loss: 0.053988; l1_loss: 0.0527958; total_loss: 0.1067838; examples/sec: 32.5; progress: 38.0%; \n",
      "FastEstimator-Train: step: 457; focal_loss: 0.0283516; l1_loss: 0.0282229; total_loss: 0.0565745; examples/sec: 31.8; progress: 38.1%; \n",
      "FastEstimator-Train: step: 458; focal_loss: 0.0438681; l1_loss: 0.0418369; total_loss: 0.0857051; examples/sec: 32.2; progress: 38.2%; \n",
      "FastEstimator-Train: step: 459; focal_loss: 0.0123844; l1_loss: 0.0317926; total_loss: 0.044177; examples/sec: 32.1; progress: 38.2%; \n",
      "FastEstimator-Train: step: 460; focal_loss: 0.1335187; l1_loss: 0.0372865; total_loss: 0.1708052; examples/sec: 32.6; progress: 38.3%; \n",
      "FastEstimator-Train: step: 461; focal_loss: 0.0247164; l1_loss: 0.0216678; total_loss: 0.0463842; examples/sec: 32.2; progress: 38.4%; \n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0886190832 0.0702493787 0.0595560372 0.0563956797 0.050693363]\n",
      "[0.0813314319 0.0560359657]\n",
      "[0.152000636 0.106179446 0.0991050303 ... 0.0576482713 0.0523662269 0.0515367389]\n",
      "[0.07008937]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0506273508]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.073346585 0.0589203537]\n",
      "[0.0543912649]\n",
      "[]\n",
      "[0.078373611 0.0643215477 0.059040159]\n",
      "[0.100559831 0.0607623756]\n",
      "[0.0646925]\n",
      "[]\n",
      "[]\n",
      "[0.157391101 0.120536387]\n",
      "[0.0637576282]\n",
      "[0.0709616244 0.0520804524 0.0505526066]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0821094811]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0653767 0.0634258091]\n",
      "[]\n",
      "[0.0534028113]\n",
      "[]\n",
      "[]\n",
      "[0.0569833815]\n",
      "[]\n",
      "FastEstimator-Eval: step: 462; epoch: 76; focal_loss: 2.0034769; l1_loss: 0.5684443; total_loss: 2.571921; \n",
      "FastEstimator-Train: step: 462; focal_loss: 0.015455; l1_loss: 0.0224503; total_loss: 0.0379053; examples/sec: 32.2; progress: 38.5%; \n",
      "FastEstimator-Train: step: 463; focal_loss: 0.0291141; l1_loss: 0.0323968; total_loss: 0.0615109; examples/sec: 32.2; progress: 38.6%; \n",
      "FastEstimator-Train: step: 464; focal_loss: 0.1285305; l1_loss: 0.0327468; total_loss: 0.1612774; examples/sec: 31.8; progress: 38.7%; \n",
      "FastEstimator-Train: step: 465; focal_loss: 0.019444; l1_loss: 0.0443934; total_loss: 0.0638374; examples/sec: 32.2; progress: 38.8%; \n",
      "FastEstimator-Train: step: 466; focal_loss: 0.0416098; l1_loss: 0.0466053; total_loss: 0.088215; examples/sec: 32.5; progress: 38.8%; \n",
      "FastEstimator-Train: step: 467; focal_loss: 0.0330143; l1_loss: 0.0182079; total_loss: 0.0512222; examples/sec: 32.0; progress: 38.9%; \n",
      "[0.0813063681 0.0646575689]\n",
      "[0.238956 0.217306256 0.150119245 ... 0.0616764426 0.0611825 0.0544883311]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.115169138 0.0724635422 0.0702179372 0.0567263067 0.0506982505]\n",
      "[0.0893114209 0.0586550832]\n",
      "[0.136657506 0.114597082 0.103462636 ... 0.0519786775 0.0504757762 0.0500313342]\n",
      "[0.064267695]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0532361567]\n",
      "[]\n",
      "[0.0500066876]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0506123304]\n",
      "[]\n",
      "[0.0687530041 0.0649075806]\n",
      "[]\n",
      "[]\n",
      "[0.0730739236 0.0725804 0.0593288541]\n",
      "[0.116524279 0.0639466643]\n",
      "[0.0711131394 0.0602654517 0.0556812584]\n",
      "[]\n",
      "[]\n",
      "[0.226004571 0.143793136]\n",
      "[0.0611329079]\n",
      "[0.102653235 0.0788313746]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0840123892]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0616579354 0.0599395931]\n",
      "[]\n",
      "[0.0540231466]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 468; epoch: 77; focal_loss: 2.0512266; l1_loss: 0.547813; total_loss: 2.5990398; \n",
      "FastEstimator-Train: step: 468; focal_loss: 0.0292858; l1_loss: 0.0458042; total_loss: 0.0750901; examples/sec: 32.3; progress: 39.0%; \n",
      "FastEstimator-Train: step: 469; focal_loss: 0.0305471; l1_loss: 0.0380156; total_loss: 0.0685627; examples/sec: 32.5; progress: 39.1%; \n",
      "FastEstimator-Train: step: 470; focal_loss: 0.0114536; l1_loss: 0.0182803; total_loss: 0.0297338; examples/sec: 32.0; progress: 39.2%; \n",
      "FastEstimator-Train: step: 471; focal_loss: 0.031647; l1_loss: 0.0317931; total_loss: 0.0634401; examples/sec: 32.1; progress: 39.2%; \n",
      "FastEstimator-Train: step: 472; focal_loss: 0.1424887; l1_loss: 0.0515773; total_loss: 0.194066; examples/sec: 32.3; progress: 39.3%; \n",
      "FastEstimator-Train: step: 473; focal_loss: 0.0243073; l1_loss: 0.024222; total_loss: 0.0485292; examples/sec: 32.4; progress: 39.4%; \n",
      "[]\n",
      "[]\n",
      "[0.060521841 0.0582647622]\n",
      "[0.199861854 0.154233396 0.146875173 ... 0.056599021 0.0538619757 0.0536212027]\n",
      "[0.0501587689]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.100828499 0.0719839633 0.0581825078 0.05717206]\n",
      "[0.0663197637 0.0603655577]\n",
      "[0.183117867 0.0950789452 0.0786963403 ... 0.0515972674 0.0514896512 0.0510399342]\n",
      "[0.0542484522]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0506018698]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0826109648 0.0544779]\n",
      "[]\n",
      "[]\n",
      "[0.0753774643 0.0550614893]\n",
      "[0.0961728394 0.0705759823]\n",
      "[0.093383044 0.0683390498 0.0595324934 0.0576823652 0.0532509387]\n",
      "[]\n",
      "[]\n",
      "[0.221304178 0.0799465775]\n",
      "[0.0698550344]\n",
      "[0.0838803351 0.0691139698 0.0635505319 0.0626165867]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0707879364]\n",
      "[]\n",
      "[]\n",
      "[0.0507183075]\n",
      "[]\n",
      "[0.0615112484 0.0507660806]\n",
      "[]\n",
      "[0.0511539578]\n",
      "FastEstimator-Eval: step: 474; epoch: 78; focal_loss: 1.9124953; l1_loss: 0.5661354; total_loss: 2.4786303; \n",
      "FastEstimator-Train: step: 474; focal_loss: 0.1285605; l1_loss: 0.0296929; total_loss: 0.1582534; examples/sec: 32.0; progress: 39.5%; \n",
      "FastEstimator-Train: step: 475; focal_loss: 0.0365126; l1_loss: 0.0638432; total_loss: 0.1003559; examples/sec: 32.1; progress: 39.6%; \n",
      "FastEstimator-Train: step: 476; focal_loss: 0.0280653; l1_loss: 0.0250473; total_loss: 0.0531126; examples/sec: 32.0; progress: 39.7%; \n",
      "FastEstimator-Train: step: 477; focal_loss: 0.0302012; l1_loss: 0.0333285; total_loss: 0.0635297; examples/sec: 31.9; progress: 39.8%; \n",
      "FastEstimator-Train: step: 478; focal_loss: 0.014912; l1_loss: 0.0579746; total_loss: 0.0728866; examples/sec: 32.4; progress: 39.8%; \n",
      "FastEstimator-Train: step: 479; focal_loss: 0.0275509; l1_loss: 0.0716873; total_loss: 0.0992381; examples/sec: 32.5; progress: 39.9%; \n",
      "[]\n",
      "[]\n",
      "[0.0535564721]\n",
      "[]\n",
      "[0.0887928307 0.0689211488 0.0683337152 0.0557228327 0.0515396595]\n",
      "[0.24837631 0.2209512 0.214631587 ... 0.0590853095 0.0563989878 0.0551541448]\n",
      "[0.0538480282]\n",
      "[]\n",
      "[]\n",
      "[0.0677071214]\n",
      "[0.145601451 0.0772490799 0.064381 ... 0.0524912179 0.050522387 0.0504787266]\n",
      "[0.0704539418 0.0668303668]\n",
      "[0.191039413 0.145158142 0.121338308 ... 0.0763171315 0.0662663281 0.0524941385]\n",
      "[0.0596106648]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0644143224 0.0586687624]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0679608881]\n",
      "[]\n",
      "[0.0930876136 0.0649048686 0.0534245372]\n",
      "[0.0538308918]\n",
      "[]\n",
      "[0.0926736295 0.0742232203]\n",
      "[0.106536418 0.082719177]\n",
      "[0.106467932 0.095330745 0.0712088048 0.0652825534 0.0641653836 0.0584321022]\n",
      "[]\n",
      "[]\n",
      "[0.132392049 0.0580690503]\n",
      "[0.095368892]\n",
      "[0.112109005 0.101979077 0.0953971148 0.0727930665]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0787008107 0.0560937226]\n",
      "[]\n",
      "[]\n",
      "[0.059404403]\n",
      "[]\n",
      "[0.0820971429 0.0576829314]\n",
      "FastEstimator-Eval: step: 480; epoch: 79; focal_loss: 1.8834321; l1_loss: 0.5290148; total_loss: 2.412447; \n",
      "FastEstimator-Train: step: 480; focal_loss: 0.0103894; l1_loss: 0.0391275; total_loss: 0.0495169; examples/sec: 31.8; progress: 40.0%; \n",
      "FastEstimator-Train: step: 481; focal_loss: 0.0247673; l1_loss: 0.0421787; total_loss: 0.066946; examples/sec: 31.6; progress: 40.1%; \n",
      "FastEstimator-Train: step: 482; focal_loss: 0.0115528; l1_loss: 0.0966756; total_loss: 0.1082284; examples/sec: 31.9; progress: 40.2%; \n",
      "FastEstimator-Train: step: 483; focal_loss: 0.032139; l1_loss: 0.0743117; total_loss: 0.1064507; examples/sec: 31.9; progress: 40.2%; \n",
      "FastEstimator-Train: step: 484; focal_loss: 0.038779; l1_loss: 0.0562288; total_loss: 0.0950078; examples/sec: 32.1; progress: 40.3%; \n",
      "FastEstimator-Train: step: 485; focal_loss: 0.1317891; l1_loss: 0.0604001; total_loss: 0.1921891; examples/sec: 32.4; progress: 40.4%; \n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0596452653]\n",
      "[]\n",
      "[]\n",
      "[0.0561652184]\n",
      "[]\n",
      "[0.0757437944 0.0587329865 0.0572862923 0.0569879711]\n",
      "[0.284744531 0.262488484 0.232917726 ... 0.0594818 0.0570719242 0.0565716624]\n",
      "[0.0517336428]\n",
      "[]\n",
      "[]\n",
      "[0.0554404557]\n",
      "[0.123104692 0.0794409513 0.0681119859 0.0522255898]\n",
      "[0.0867781043 0.0752869546]\n",
      "[0.200320035 0.163270116 0.152150631 ... 0.0621328354 0.0527431667 0.0504055619]\n",
      "[0.0596161485]\n",
      "[]\n",
      "[]\n",
      "[0.0525304377]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0570390522]\n",
      "[]\n",
      "[0.0640508831 0.0637672544]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0573661625]\n",
      "[]\n",
      "[0.0837484 0.0592174232 0.0558230579]\n",
      "[]\n",
      "[]\n",
      "[0.106918246 0.0773898661 0.0560688674]\n",
      "[0.125879049 0.0823273957]\n",
      "[0.106348842 0.105233282 0.0672774 0.0599677861 0.0567598641]\n",
      "[]\n",
      "[]\n",
      "[0.0866716504]\n",
      "[0.0932399929]\n",
      "[0.0970404148 0.0767920613 0.0709037483]\n",
      "[0.0536907911]\n",
      "[]\n",
      "[]\n",
      "[0.0806602836 0.0543613434]\n",
      "[]\n",
      "[]\n",
      "[0.0568386912]\n",
      "FastEstimator-Eval: step: 486; epoch: 80; focal_loss: 2.0083268; l1_loss: 0.5371264; total_loss: 2.5454533; \n",
      "FastEstimator-Train: step: 486; focal_loss: 0.0179025; l1_loss: 0.0425141; total_loss: 0.0604166; examples/sec: 32.1; progress: 40.5%; \n",
      "FastEstimator-Train: step: 487; focal_loss: 0.0227595; l1_loss: 0.0566975; total_loss: 0.079457; examples/sec: 32.0; progress: 40.6%; \n",
      "FastEstimator-Train: step: 488; focal_loss: 0.1427099; l1_loss: 0.0535348; total_loss: 0.1962448; examples/sec: 32.1; progress: 40.7%; \n",
      "FastEstimator-Train: step: 489; focal_loss: 0.0160074; l1_loss: 0.0179357; total_loss: 0.0339431; examples/sec: 31.9; progress: 40.8%; \n",
      "FastEstimator-Train: step: 490; focal_loss: 0.005166; l1_loss: 0.0202129; total_loss: 0.0253789; examples/sec: 32.2; progress: 40.8%; \n",
      "FastEstimator-Train: step: 491; focal_loss: 0.019049; l1_loss: 0.0346729; total_loss: 0.0537219; examples/sec: 32.5; progress: 40.9%; \n",
      "[]\n",
      "[0.065579325 0.0542875826]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0519229472]\n",
      "[]\n",
      "[0.0732940137 0.0530450344]\n",
      "[0.180830151 0.17892471 0.157696366 0.0771911442 0.0647163093 0.0518388152]\n",
      "[0.0509842038]\n",
      "[]\n",
      "[]\n",
      "[0.057443589]\n",
      "[0.106553078 0.0812333524 0.0708225071 ... 0.0592838526 0.0514039099 0.0512212217]\n",
      "[0.0769264698 0.0712972581]\n",
      "[0.27390337 0.141671658 0.109632462 ... 0.0604408979 0.0571574569 0.0570487678]\n",
      "[0.0606877506]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0574319959]\n",
      "[]\n",
      "[0.0766658485 0.0636743605]\n",
      "[]\n",
      "[]\n",
      "[0.0519904494 0.0518194735]\n",
      "[0.0510551333]\n",
      "[]\n",
      "[0.0856458843 0.0687460899 0.0509156 0.0504382253]\n",
      "[]\n",
      "[]\n",
      "[0.080680877 0.0745278299 0.0531690419]\n",
      "[0.111218601 0.0693877935 0.0517175198]\n",
      "[0.117435843 0.0806798637 0.0688921809 0.0569880605 0.0555835962]\n",
      "[]\n",
      "[]\n",
      "[0.115843266]\n",
      "[0.0999409556]\n",
      "[0.132512182 0.0957235098 0.0877460539 0.0800976157]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0796449482 0.0527240336]\n",
      "[]\n",
      "FastEstimator-Eval: step: 492; epoch: 81; focal_loss: 1.9707626; l1_loss: 0.5483396; total_loss: 2.5191023; \n",
      "FastEstimator-Train: step: 492; focal_loss: 0.0289274; l1_loss: 0.0561317; total_loss: 0.0850591; examples/sec: 31.7; progress: 41.0%; \n",
      "FastEstimator-Train: step: 493; focal_loss: 0.0256633; l1_loss: 0.0869523; total_loss: 0.1126156; examples/sec: 32.4; progress: 41.1%; \n",
      "FastEstimator-Train: step: 494; focal_loss: 0.0174238; l1_loss: 0.0309558; total_loss: 0.0483796; examples/sec: 32.1; progress: 41.2%; \n",
      "FastEstimator-Train: step: 495; focal_loss: 0.0317378; l1_loss: 0.0670463; total_loss: 0.098784; examples/sec: 31.9; progress: 41.2%; \n",
      "FastEstimator-Train: step: 496; focal_loss: 0.0187538; l1_loss: 0.0382143; total_loss: 0.0569681; examples/sec: 32.0; progress: 41.3%; \n",
      "FastEstimator-Train: step: 497; focal_loss: 0.1288919; l1_loss: 0.057751; total_loss: 0.186643; examples/sec: 32.3; progress: 41.4%; \n",
      "[]\n",
      "[0.0763357282 0.0558505356]\n",
      "[]\n",
      "[0.0939075053 0.0823119]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0735797286 0.0577646792 0.0537916422]\n",
      "[]\n",
      "[0.0827410221 0.0746097 0.0512958765]\n",
      "[0.30846411 0.287380815 0.268517673 ... 0.0698547959 0.0677364171 0.0513450503]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0680737793 0.0573547482 0.0522340834]\n",
      "[0.207005352 0.174009204 0.071696341 0.0608917177 0.0542621911]\n",
      "[0.0902112722 0.0728170872]\n",
      "[0.134298384 0.132554233 0.129900366 ... 0.0527609 0.0519340336 0.0512748957]\n",
      "[0.104422778 0.0739768445 0.0613597929]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0763638616]\n",
      "[]\n",
      "[0.151761264 0.0711375773 0.062153697 0.0556986332]\n",
      "[]\n",
      "[]\n",
      "[0.0684689]\n",
      "[0.0895771086]\n",
      "[]\n",
      "[0.0873864591 0.0778722167 0.0703642368]\n",
      "[0.0672779083]\n",
      "[0.0522696078]\n",
      "[0.113560617 0.0808141828 0.0762087107 0.0589684248 0.0578389168 0.0567979515]\n",
      "[0.131350458 0.072503984]\n",
      "[0.0857075751 0.0763421059 0.0669039488 ... 0.0522781312 0.0522040725 0.0502661467]\n",
      "[]\n",
      "[]\n",
      "[0.124292016 0.0721880794]\n",
      "[0.120812237]\n",
      "[0.145806521 0.102433741 0.0819714665 0.0697639883 0.0614155531]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 498; epoch: 82; focal_loss: 1.8671145; l1_loss: 0.522856; total_loss: 2.3899708; \n",
      "FastEstimator-Train: step: 498; focal_loss: 0.0085225; l1_loss: 0.0304202; total_loss: 0.0389427; examples/sec: 32.1; progress: 41.5%; \n",
      "FastEstimator-Train: step: 499; focal_loss: 0.0103977; l1_loss: 0.0259172; total_loss: 0.0363149; examples/sec: 32.1; progress: 41.6%; \n",
      "FastEstimator-Train: step: 500; focal_loss: 0.0174897; l1_loss: 0.039514; total_loss: 0.0570037; examples/sec: 32.3; progress: 41.7%; \n",
      "FastEstimator-Train: step: 501; focal_loss: 0.1445761; l1_loss: 0.0448762; total_loss: 0.1894523; examples/sec: 32.2; progress: 41.8%; \n",
      "FastEstimator-Train: step: 502; focal_loss: 0.0393236; l1_loss: 0.047835; total_loss: 0.0871586; examples/sec: 32.1; progress: 41.8%; \n",
      "FastEstimator-Train: step: 503; focal_loss: 0.0388889; l1_loss: 0.0310982; total_loss: 0.0699872; examples/sec: 32.1; progress: 41.9%; \n",
      "[0.0892000496 0.0867472]\n",
      "[0.0675726533 0.0630206168 0.0623161793 0.0591069162 0.0554658473 0.0512289703]\n",
      "[]\n",
      "[0.0773164332 0.0591162443]\n",
      "[]\n",
      "[0.116948843 0.0593363643]\n",
      "[]\n",
      "[0.0523491502]\n",
      "[]\n",
      "[]\n",
      "[0.0603532791 0.0561921 0.0538721681]\n",
      "[]\n",
      "[0.0964168608 0.0872816741]\n",
      "[0.343946159 0.322800487 0.307427377 ... 0.0534160137 0.0531083047 0.0508987904]\n",
      "[0.0635531545]\n",
      "[]\n",
      "[]\n",
      "[0.0964603424 0.0679083467 0.061409235 0.0526828766]\n",
      "[0.236523032 0.213559 0.0720121562 ... 0.0567600727 0.0563960373 0.0529299378]\n",
      "[0.11463362 0.0890854299]\n",
      "[0.18585071 0.184136122 0.125143945 ... 0.0546776056 0.051879257 0.0510525107]\n",
      "[0.0903215408 0.0788776278]\n",
      "[]\n",
      "[]\n",
      "[0.0626999736]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0668254197 0.0639591515]\n",
      "[]\n",
      "[0.086137712 0.0632797182 0.0574527979 0.0555505753 0.0535457134]\n",
      "[]\n",
      "[]\n",
      "[0.0703903735]\n",
      "[0.0746536553 0.0706292689 0.0632815957]\n",
      "[]\n",
      "[0.122004777 0.0882092416 0.0645087063 ... 0.0571236312 0.0506708622 0.0500035]\n",
      "[0.0585492849]\n",
      "[0.0707511]\n",
      "[0.181512833 0.102165759 0.0518264771]\n",
      "[0.133695424 0.12903747 0.0664376]\n",
      "[0.150190383 0.116430044 0.112416476 ... 0.0821705759 0.0737596452 0.0595942736]\n",
      "[]\n",
      "[]\n",
      "[0.255632192 0.131248146]\n",
      "[0.127899408]\n",
      "[0.12973544 0.12393114 0.0721764 ... 0.0615949631 0.0534106493 0.053304255]\n",
      "[0.0565040708]\n",
      "FastEstimator-Eval: step: 504; epoch: 83; focal_loss: 1.9072129; l1_loss: 0.5090451; total_loss: 2.416258; \n",
      "FastEstimator-Train: step: 504; focal_loss: 0.0310964; l1_loss: 0.0580243; total_loss: 0.0891206; examples/sec: 32.1; progress: 42.0%; \n",
      "FastEstimator-Train: step: 505; focal_loss: 0.0157456; l1_loss: 0.0280667; total_loss: 0.0438123; examples/sec: 32.0; progress: 42.1%; \n",
      "FastEstimator-Train: step: 506; focal_loss: 0.0162283; l1_loss: 0.0427046; total_loss: 0.058933; examples/sec: 32.1; progress: 42.2%; \n",
      "FastEstimator-Train: step: 507; focal_loss: 0.1402708; l1_loss: 0.0827568; total_loss: 0.2230276; examples/sec: 31.7; progress: 42.2%; \n",
      "FastEstimator-Train: step: 508; focal_loss: 0.0151661; l1_loss: 0.0672785; total_loss: 0.0824446; examples/sec: 32.2; progress: 42.3%; \n",
      "FastEstimator-Train: step: 509; focal_loss: 0.0243697; l1_loss: 0.0266959; total_loss: 0.0510656; examples/sec: 32.0; progress: 42.4%; \n",
      "[]\n",
      "[]\n",
      "[0.084407419 0.0588697195]\n",
      "[0.0897283554]\n",
      "[]\n",
      "[0.0780406892 0.0568272471]\n",
      "[]\n",
      "[0.0878146]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0949726105 0.0621043444]\n",
      "[0.241804957 0.238587648 0.229504138 ... 0.0634432733 0.0582584441 0.0546589494]\n",
      "[0.0515748858]\n",
      "[]\n",
      "[]\n",
      "[0.130866647 0.0820132196 0.0808366835 0.070279628 0.0595425963 0.0547734499]\n",
      "[0.189816415 0.0820072889 0.0676654279 0.0602091551 0.057212323 0.0523802638]\n",
      "[0.088562429 0.0538434684]\n",
      "[0.275716305 0.12854594 0.0941100419 ... 0.0564987957 0.0563593805 0.0520782769]\n",
      "[0.0786036551]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0606582463]\n",
      "[]\n",
      "[0.0688041747 0.0587940812 0.0523910522 0.0521691442]\n",
      "[0.0583941638]\n",
      "[]\n",
      "[0.083879143 0.0514401793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0576451123 0.0515286326]\n",
      "[]\n",
      "[0.0800851882 0.0708044767 0.0691252947 0.0519917607]\n",
      "[]\n",
      "[0.0921362042 0.0577069223]\n",
      "[0.143055767 0.0615266562]\n",
      "[0.13686806 0.0922294259]\n",
      "[0.151354015 0.133118957 0.0930716395 0.0861772 0.0813877 0.0725294948]\n",
      "[]\n",
      "[]\n",
      "[0.222499073 0.0958429873]\n",
      "[0.123989791]\n",
      "FastEstimator-Eval: step: 510; epoch: 84; focal_loss: 1.9213766; l1_loss: 0.4879954; total_loss: 2.409372; \n",
      "FastEstimator-Train: step: 510; focal_loss: 0.0311881; l1_loss: 0.0467989; total_loss: 0.0779869; examples/sec: 32.4; progress: 42.5%; \n",
      "FastEstimator-Train: step: 511; focal_loss: 0.0261787; l1_loss: 0.0563311; total_loss: 0.0825098; examples/sec: 32.1; progress: 42.6%; \n",
      "FastEstimator-Train: step: 512; focal_loss: 0.0099472; l1_loss: 0.0539702; total_loss: 0.0639174; examples/sec: 32.1; progress: 42.7%; \n",
      "FastEstimator-Train: step: 513; focal_loss: 0.0137863; l1_loss: 0.0438854; total_loss: 0.0576717; examples/sec: 32.3; progress: 42.8%; \n",
      "FastEstimator-Train: step: 514; focal_loss: 0.0149047; l1_loss: 0.0255193; total_loss: 0.0404241; examples/sec: 32.6; progress: 42.8%; \n",
      "FastEstimator-Train: step: 515; focal_loss: 0.0297779; l1_loss: 0.0347606; total_loss: 0.0645386; examples/sec: 32.2; progress: 42.9%; \n",
      "[0.12142545 0.0906382203 0.0879270434 ... 0.0636379719 0.0573114157 0.0541477203]\n",
      "[0.05046314]\n",
      "[]\n",
      "[]\n",
      "[0.104795218 0.0631263852]\n",
      "[0.0591626763 0.0517700613]\n",
      "[]\n",
      "[0.0802147686 0.0570851564]\n",
      "[]\n",
      "[0.0921511352 0.0732150674]\n",
      "[]\n",
      "[0.0893497467 0.0569476485]\n",
      "[]\n",
      "[]\n",
      "[0.0606710613]\n",
      "[]\n",
      "[0.130340219 0.053624481]\n",
      "[0.289082944 0.279875845 0.257831544 ... 0.0740831792 0.0618609786 0.0532436669]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.194803268 0.13202396 0.131290555 0.0973326266 0.073405534 0.0562487841]\n",
      "[0.1694462 0.0916953683 0.0775043368 ... 0.065757513 0.0580013692 0.0551528633]\n",
      "[0.0682790875 0.0595124662]\n",
      "[0.325258106 0.16253674 0.136658788 ... 0.0556121171 0.0517885685 0.050991863]\n",
      "[0.0915932953 0.059105128]\n",
      "[]\n",
      "[]\n",
      "[0.0522185564]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0802600384]\n",
      "[]\n",
      "[0.115613818 0.0853763521 0.0848390758 0.0565440059 0.0535021722]\n",
      "[0.0507362485]\n",
      "[]\n",
      "[0.12669152 0.0790662467 0.0548149049]\n",
      "[0.103764564 0.0788981318 0.0626368523 0.0540536344 0.0530913174 0.0512066782]\n",
      "[]\n",
      "[0.0820766687 0.0734474063 0.0610837936 0.0523825 0.0516576171]\n",
      "[0.0889709 0.0549477041]\n",
      "[0.0805119276 0.0756804049]\n",
      "[0.0946961939 0.0601406097 0.0544052422]\n",
      "[0.146729678 0.086221844 0.0538047552]\n",
      "[0.221131563 0.125930458 0.107905626 ... 0.0776719153 0.0758285522 0.0573296249]\n",
      "[0.0541172624]\n",
      "[0.0658119]\n",
      "FastEstimator-Eval: step: 516; epoch: 85; focal_loss: 1.846984; l1_loss: 0.5157744; total_loss: 2.3627582; \n",
      "FastEstimator-Train: step: 516; focal_loss: 0.1398836; l1_loss: 0.0429053; total_loss: 0.182789; examples/sec: 32.1; progress: 43.0%; \n",
      "FastEstimator-Train: step: 517; focal_loss: 0.0715465; l1_loss: 0.0332176; total_loss: 0.1047641; examples/sec: 32.1; progress: 43.1%; \n",
      "FastEstimator-Train: step: 518; focal_loss: 0.0107936; l1_loss: 0.0384652; total_loss: 0.0492589; examples/sec: 31.9; progress: 43.2%; \n",
      "FastEstimator-Train: step: 519; focal_loss: 0.0074512; l1_loss: 0.0398462; total_loss: 0.0472974; examples/sec: 32.2; progress: 43.2%; \n",
      "FastEstimator-Train: step: 520; focal_loss: 0.0252719; l1_loss: 0.0616728; total_loss: 0.0869447; examples/sec: 32.0; progress: 43.3%; \n",
      "FastEstimator-Train: step: 521; focal_loss: 0.1775842; l1_loss: 0.0279621; total_loss: 0.2055463; examples/sec: 31.6; progress: 43.4%; \n",
      "[0.311827064 0.121709734]\n",
      "[0.117254764]\n",
      "[0.260548294 0.162648946 0.119519085 ... 0.0566493869 0.0538423061 0.0522809923]\n",
      "[0.0924448371 0.0791755915]\n",
      "[]\n",
      "[]\n",
      "[0.111046731 0.0824587345 0.07224226 0.0607871711]\n",
      "[0.119958073 0.119495153 0.0768493116 ... 0.0550630093 0.0507360101 0.0502287447]\n",
      "[]\n",
      "[0.106709778 0.0818614662]\n",
      "[]\n",
      "[0.120986164 0.0796744227]\n",
      "[]\n",
      "[0.124636352 0.0975832045 0.0731357336]\n",
      "[]\n",
      "[0.0529740751]\n",
      "[0.0621836483 0.0590317547]\n",
      "[]\n",
      "[0.14087382 0.0754784048 0.0702221692 0.0581169128 0.0535073578]\n",
      "[0.440850168 0.431455523 0.361333847 ... 0.0510213077 0.0505518317 0.0502819419]\n",
      "[0.0616906583 0.0607371032]\n",
      "[]\n",
      "[]\n",
      "[0.228423387 0.127527 0.114005208 ... 0.0610958636 0.0592968464 0.0563020706]\n",
      "[0.318590522 0.208473593 0.107262224 ... 0.0592066944 0.0544732511 0.0501962602]\n",
      "[0.0882147551 0.0837849379]\n",
      "[0.344113737 0.267670751 0.240610242 ... 0.0608287752 0.0553791821 0.0545402169]\n",
      "[0.0935701728 0.0816788077]\n",
      "[]\n",
      "[]\n",
      "[0.0507935286]\n",
      "[0.0573835075]\n",
      "[]\n",
      "[0.0791660547 0.0636203587]\n",
      "[0.0889425576]\n",
      "[]\n",
      "[0.125381917 0.100767821 0.0886320174 ... 0.0533376336 0.0523928106 0.0505789518]\n",
      "[0.0718252361]\n",
      "[]\n",
      "[0.16367057 0.0740733743 0.0567132831 0.0547532737]\n",
      "[0.110983849 0.109360307 0.0955712497 ... 0.0876077414 0.0770888627 0.0564818978]\n",
      "[]\n",
      "[0.130727261 0.107172996 0.0994354784 ... 0.0541750193 0.0531547368 0.0500881672]\n",
      "[0.0983683169 0.0754081607]\n",
      "[0.170710266 0.0788998306 0.0548144877 0.0538080335]\n",
      "[0.15504384 0.135476291 0.0565677881 0.0550051928]\n",
      "[0.206046045 0.139386058 0.0784779787]\n",
      "[0.366846234 0.283048898 0.249058545 ... 0.0774905682 0.0745874643 0.0619483888]\n",
      "FastEstimator-Eval: step: 522; epoch: 86; focal_loss: 1.7997674; l1_loss: 0.4873934; total_loss: 2.2871606; \n",
      "FastEstimator-Train: step: 522; focal_loss: 0.013119; l1_loss: 0.0432715; total_loss: 0.0563905; examples/sec: 31.7; progress: 43.5%; \n",
      "FastEstimator-Train: step: 523; focal_loss: 0.0265059; l1_loss: 0.055447; total_loss: 0.0819529; examples/sec: 32.7; progress: 43.6%; \n",
      "FastEstimator-Train: step: 524; focal_loss: 0.0046379; l1_loss: 0.0456834; total_loss: 0.0503213; examples/sec: 31.9; progress: 43.7%; \n",
      "FastEstimator-Train: step: 525; focal_loss: 0.0126794; l1_loss: 0.0532928; total_loss: 0.0659722; examples/sec: 32.2; progress: 43.8%; \n",
      "FastEstimator-Train: step: 526; focal_loss: 0.0203968; l1_loss: 0.072859; total_loss: 0.0932558; examples/sec: 32.3; progress: 43.8%; \n",
      "FastEstimator-Train: step: 527; focal_loss: 0.0101949; l1_loss: 0.0413651; total_loss: 0.0515599; examples/sec: 31.9; progress: 43.9%; \n",
      "[0.0528496802]\n",
      "[0.0527232]\n",
      "[0.482880384 0.158079445]\n",
      "[0.126694471]\n",
      "[0.206577569 0.142742544 0.076664567 ... 0.0568355024 0.0525745451 0.0516048968]\n",
      "[0.0649612844 0.0615076721]\n",
      "[]\n",
      "[]\n",
      "[0.0789099038 0.0648666918]\n",
      "[0.107592076 0.0878876448 0.076567024 0.0605019331]\n",
      "[]\n",
      "[0.0856324136 0.072196573]\n",
      "[]\n",
      "[0.0994545519 0.0538192391]\n",
      "[]\n",
      "[0.0976263583 0.0840067267 0.075184077]\n",
      "[]\n",
      "[]\n",
      "[0.0527614653]\n",
      "[]\n",
      "[0.123863578 0.0570173264]\n",
      "[0.363912 0.324425966 0.303390801 ... 0.0649993718 0.063795 0.0505306423]\n",
      "[0.0564593971]\n",
      "[]\n",
      "[]\n",
      "[0.136034459 0.0848150849 0.0752643645 0.0641738176 0.0550832152]\n",
      "[0.217345059 0.13474524 0.0885491669 0.0797560215 0.065556556 0.0533340573]\n",
      "[0.0742073953 0.059604615]\n",
      "[0.361631036 0.199523628 0.162994236 ... 0.0570092797 0.0553764403 0.0520518422]\n",
      "[0.0686906576 0.0629231632]\n",
      "[]\n",
      "[]\n",
      "[0.058401227]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0634734333]\n",
      "[]\n",
      "[0.0990593135 0.0826852 0.0732067823 ... 0.0542881489 0.0542571247 0.0514280796]\n",
      "[0.0832499 0.0510109067]\n",
      "[]\n",
      "[0.153002709 0.0635014176]\n",
      "[0.0828689933 0.0577786267]\n",
      "[]\n",
      "[0.143785089 0.142388344 0.0828169286 ... 0.0670737922 0.0630783141 0.0580251813]\n",
      "[0.0676126182 0.0567652]\n",
      "[0.157285511 0.0766792297]\n",
      "[0.135818303 0.090254873]\n",
      "FastEstimator-Eval: step: 528; epoch: 87; focal_loss: 1.8489528; l1_loss: 0.5029697; total_loss: 2.3519223; \n",
      "FastEstimator-Train: step: 528; focal_loss: 0.0155053; l1_loss: 0.0669182; total_loss: 0.0824235; examples/sec: 32.3; progress: 44.0%; \n",
      "FastEstimator-Train: step: 529; focal_loss: 0.1557193; l1_loss: 0.0354547; total_loss: 0.191174; examples/sec: 32.3; progress: 44.1%; \n",
      "FastEstimator-Train: step: 530; focal_loss: 0.0119343; l1_loss: 0.06769; total_loss: 0.0796243; examples/sec: 32.2; progress: 44.2%; \n",
      "FastEstimator-Train: step: 531; focal_loss: 0.0031409; l1_loss: 0.0324922; total_loss: 0.0356331; examples/sec: 31.8; progress: 44.2%; \n",
      "FastEstimator-Train: step: 532; focal_loss: 0.0198195; l1_loss: 0.0681008; total_loss: 0.0879203; examples/sec: 32.2; progress: 44.3%; \n",
      "FastEstimator-Train: step: 533; focal_loss: 0.0086454; l1_loss: 0.0755521; total_loss: 0.0841975; examples/sec: 32.1; progress: 44.4%; \n",
      "[0.120293349 0.0789576173 0.0644862652]\n",
      "[0.202144295 0.171888858 0.112705112 ... 0.0932314396 0.0914063156 0.0767092407]\n",
      "[]\n",
      "[]\n",
      "[0.596476734 0.50402981 0.0581834]\n",
      "[0.144043624]\n",
      "[0.158878356 0.150351882 0.0847763121 ... 0.0570709705 0.0536359251 0.051186502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0749069452 0.0698005557 0.0675132871]\n",
      "[]\n",
      "[]\n",
      "[0.109802783 0.068810761 0.0638430715 0.0622308552 0.0607531369]\n",
      "[0.125419945 0.061770469 0.0596316457 0.0584091246 0.0512347817 0.050157249]\n",
      "[0.0521358848]\n",
      "[0.126890957 0.0771668255]\n",
      "[]\n",
      "[0.118693143 0.0802769959]\n",
      "[]\n",
      "[0.0956392586 0.0683182478 0.0629867911]\n",
      "[]\n",
      "[0.0505784154]\n",
      "[0.069717139]\n",
      "[]\n",
      "[0.143980294 0.0994289815 0.0642589 0.0562269688 0.0530661941]\n",
      "[0.405483127 0.382745206 0.287802041 ... 0.0594323277 0.0548437238 0.0535919964]\n",
      "[0.0693743825 0.0515284538]\n",
      "[]\n",
      "[]\n",
      "[0.111126006 0.101614684 0.0933566689 ... 0.056484431 0.0531408489 0.052233994]\n",
      "[0.314218044 0.240303338 0.212854952 ... 0.0519712567 0.0506134927 0.0504033864]\n",
      "[0.0846454203 0.0753679872]\n",
      "[0.287835121 0.198907763 0.17116183 ... 0.0581835508 0.0564599335 0.0555751622]\n",
      "[0.0961715 0.0806106925]\n",
      "[]\n",
      "[]\n",
      "[0.0704305172]\n",
      "[]\n",
      "[]\n",
      "[0.156478614 0.113008708]\n",
      "[0.0964805782]\n",
      "[]\n",
      "[0.123099953 0.112387896 0.0688959956 ... 0.0560008287 0.0527002811 0.0504721105]\n",
      "[0.0679951906]\n",
      "[]\n",
      "[0.161593765 0.0738736689 0.0640091598]\n",
      "[0.108554512 0.0901636183 0.0858456194 0.0689925253 0.0571980774]\n",
      "[]\n",
      "[0.172074348 0.143903077 0.0736404657 0.062384367 0.0611069798 0.0569097102]\n",
      "[0.0650396645 0.0534262955]\n",
      "FastEstimator-Eval: step: 534; epoch: 88; focal_loss: 1.8278526; l1_loss: 0.4852442; total_loss: 2.313097; \n",
      "FastEstimator-Train: step: 534; focal_loss: 0.0283386; l1_loss: 0.0385188; total_loss: 0.0668574; examples/sec: 32.2; progress: 44.5%; \n",
      "FastEstimator-Train: step: 535; focal_loss: 0.0169409; l1_loss: 0.0291458; total_loss: 0.0460866; examples/sec: 32.6; progress: 44.6%; \n",
      "FastEstimator-Train: step: 536; focal_loss: 0.1224915; l1_loss: 0.0551836; total_loss: 0.1776751; examples/sec: 32.2; progress: 44.7%; \n",
      "FastEstimator-Train: step: 537; focal_loss: 0.1287526; l1_loss: 0.0846779; total_loss: 0.2134306; examples/sec: 32.1; progress: 44.8%; \n",
      "FastEstimator-Train: step: 538; focal_loss: 0.0092817; l1_loss: 0.07186; total_loss: 0.0811416; examples/sec: 31.8; progress: 44.8%; \n",
      "FastEstimator-Train: step: 539; focal_loss: 0.0109483; l1_loss: 0.0550166; total_loss: 0.0659649; examples/sec: 32.2; progress: 44.9%; \n",
      "[0.151607186 0.071628809]\n",
      "[0.388649881 0.0685060918 0.0590789318]\n",
      "[0.33004576 0.191568553 0.0791935325 0.0701360106 0.0528403223]\n",
      "[0.144084662 0.132820547 0.101830542 ... 0.0695477426 0.0619660616 0.0516535044]\n",
      "[0.0507463515]\n",
      "[]\n",
      "[0.397083402 0.392130196]\n",
      "[0.1330733]\n",
      "[0.160736412 0.101966649 0.0885138214 ... 0.067558825 0.0589199364 0.0548583865]\n",
      "[0.105913132 0.105240732 0.0785452127]\n",
      "[]\n",
      "[0.0929226577 0.0581488311]\n",
      "[0.187904984 0.127168089 0.120977074 ... 0.0638681054 0.0611356497 0.0603878796]\n",
      "[0.106528193 0.0948929191 0.0841055512 ... 0.0633682907 0.0630064905 0.0518477559]\n",
      "[0.0849213302 0.0686013699]\n",
      "[0.135772616 0.0636151433]\n",
      "[]\n",
      "[0.182805836 0.143869102]\n",
      "[]\n",
      "[0.0810206831 0.0610869825 0.0535359979]\n",
      "[]\n",
      "[0.0788319111 0.0582748055]\n",
      "[0.0972016454 0.0600204766]\n",
      "[]\n",
      "[0.12789616 0.112816125 0.0834742188]\n",
      "[0.48098731 0.434009939 0.365984201 ... 0.0538011491 0.0529765487 0.0516113639]\n",
      "[0.0886485875 0.0831427 0.0506810248]\n",
      "[]\n",
      "[]\n",
      "[0.111226082 0.09593153 0.0780428648 ... 0.0628207326 0.0565987229 0.0558324456]\n",
      "[0.451449543 0.318653524 0.164708197 ... 0.0633587539 0.0564412177 0.0553865433]\n",
      "[0.168742329 0.129039586]\n",
      "[0.179617614 0.170199692 0.159854 ... 0.0572458804 0.0568452477 0.0550522506]\n",
      "[0.193886966 0.155992538]\n",
      "[0.059081167]\n",
      "[]\n",
      "[0.0903999209 0.0531069934 0.0504318178]\n",
      "[0.0837394595 0.0513674617]\n",
      "[0.0566171706]\n",
      "[0.22307393 0.141518444 0.0999766]\n",
      "[0.204719037 0.0927287638]\n",
      "[]\n",
      "[0.0865174532 0.0859900713 0.0664598942 ... 0.0552909672 0.0551516116 0.0523899198]\n",
      "[0.0638670623]\n",
      "[]\n",
      "[0.176029563 0.0899279416 0.078342855 0.0544513166]\n",
      "[0.175796181 0.161777377 0.0834444165 0.0782000721 0.0681993067]\n",
      "[0.0533735156]\n",
      "FastEstimator-Eval: step: 540; epoch: 89; focal_loss: 1.8447996; l1_loss: 0.45579; total_loss: 2.3005896; \n",
      "FastEstimator-Train: step: 540; focal_loss: 0.0038543; l1_loss: 0.152588; total_loss: 0.1564423; examples/sec: 31.8; progress: 45.0%; \n",
      "FastEstimator-Train: step: 541; focal_loss: 0.057587; l1_loss: 0.0601623; total_loss: 0.1177493; examples/sec: 32.6; progress: 45.1%; \n",
      "FastEstimator-Train: step: 542; focal_loss: 0.0113375; l1_loss: 0.0677553; total_loss: 0.0790928; examples/sec: 32.1; progress: 45.2%; \n",
      "FastEstimator-Train: step: 543; focal_loss: 0.0033572; l1_loss: 0.0657705; total_loss: 0.0691277; examples/sec: 32.2; progress: 45.2%; \n",
      "FastEstimator-Train: step: 544; focal_loss: 0.0226668; l1_loss: 0.0928946; total_loss: 0.1155613; examples/sec: 32.0; progress: 45.3%; \n",
      "FastEstimator-Train: step: 545; focal_loss: 0.0183005; l1_loss: 0.0747101; total_loss: 0.0930106; examples/sec: 32.1; progress: 45.4%; \n",
      "[0.156736493 0.140139371 0.0854983 ... 0.0556092262 0.0529386103 0.0516614318]\n",
      "[0.054610163]\n",
      "[0.124445736 0.0886069834 0.0566307902]\n",
      "[0.0776453614 0.0755654871 0.0605747402 0.0583166778 0.0563784242]\n",
      "[0.167718232 0.0819765329 0.0724002719 0.0518145561]\n",
      "[0.223131269 0.15296936 0.129304618 ... 0.0730668604 0.0658839941 0.065731734]\n",
      "[0.0578758717]\n",
      "[0.050154537]\n",
      "[0.219177514 0.196262807]\n",
      "[0.151278168]\n",
      "[0.158077717 0.096152395 0.0815573335 ... 0.061930418 0.0558926463 0.055198431]\n",
      "[0.0751286745 0.0672318339 0.0594542325]\n",
      "[]\n",
      "[]\n",
      "[0.194116294 0.157765687 0.127334446 ... 0.0660227239 0.0583353639 0.0507826209]\n",
      "[0.108641624 0.0729461 0.0726865828 0.061586231 0.0562769175 0.0530687869]\n",
      "[0.0500645936]\n",
      "[0.0899137259 0.0582003891]\n",
      "[]\n",
      "[0.0968847573 0.0827687681]\n",
      "[]\n",
      "[0.0811212063]\n",
      "[]\n",
      "[0.0545220077]\n",
      "[]\n",
      "[]\n",
      "[0.121726692 0.0570603311]\n",
      "[0.472310185 0.369358063 0.367287815 ... 0.0648139119 0.0576440692 0.0571063161]\n",
      "[0.0591159463]\n",
      "[]\n",
      "[]\n",
      "[0.0990393162 0.0893133879 0.088450253 0.085026294 0.0841319263 0.0771167278]\n",
      "[0.256627738 0.242947668 0.224730074 ... 0.0515056849 0.0511662364 0.0506958961]\n",
      "[0.0885131359 0.0540468395]\n",
      "[0.525974333 0.240884602 0.163609743 ... 0.0515169501 0.0502392054 0.0501089692]\n",
      "[0.107731014 0.078556]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.0591358244]\n",
      "[]\n",
      "[0.0515378118]\n",
      "[0.141152978]\n",
      "[]\n",
      "[0.15957123 0.0790694356 0.074161917 ... 0.0528326929 0.0515438914 0.0501368046]\n",
      "[0.0681905746]\n",
      "[]\n",
      "[0.220083058 0.116515487 0.102709234 0.0512750745]\n",
      "FastEstimator-Eval: step: 546; epoch: 90; focal_loss: 1.7503546; l1_loss: 0.465541; total_loss: 2.2158954; \n",
      "FastEstimator-Train: step: 546; focal_loss: 0.0126535; l1_loss: 0.0662134; total_loss: 0.0788669; examples/sec: 32.2; progress: 45.5%; \n",
      "FastEstimator-Train: step: 547; focal_loss: 0.1273581; l1_loss: 0.0471049; total_loss: 0.174463; examples/sec: 32.2; progress: 45.6%; \n",
      "FastEstimator-Train: step: 548; focal_loss: 0.009398; l1_loss: 0.0628932; total_loss: 0.0722912; examples/sec: 32.5; progress: 45.7%; \n",
      "FastEstimator-Train: step: 549; focal_loss: 0.0050972; l1_loss: 0.0584261; total_loss: 0.0635233; examples/sec: 32.3; progress: 45.8%; \n",
      "FastEstimator-Train: step: 550; focal_loss: 0.0185841; l1_loss: 0.0545594; total_loss: 0.0731435; examples/sec: 32.3; progress: 45.8%; \n",
      "FastEstimator-Train: step: 551; focal_loss: 0.1244098; l1_loss: 0.1228414; total_loss: 0.2472512; examples/sec: 32.0; progress: 45.9%; \n",
      "[0.168812156 0.116276294 0.0730571449 ... 0.0641809106 0.0565977395 0.0538810194]\n",
      "[]\n",
      "[0.144206345 0.133375913 0.0731365085 ... 0.059766829 0.0594843924 0.0577095449]\n",
      "[0.0710733831 0.0625274777]\n",
      "[0.146071076 0.0992022753 0.0619409978]\n",
      "[0.305688441 0.135938406 0.0761702955 0.0694846511]\n",
      "[0.317300886 0.134616107 0.10700202 0.0643696487]\n",
      "[0.220826477 0.137184322 0.134426117 ... 0.0615750849 0.056963414 0.0562818944]\n",
      "[0.0718917847]\n",
      "[]\n",
      "[0.359184891 0.308790863]\n",
      "[0.234882146]\n",
      "[0.195798904 0.172732979 0.0959889 ... 0.0576250851 0.0568110347 0.0539257824]\n",
      "[0.0828403831 0.0812104046 0.0524345934]\n",
      "[]\n",
      "[0.0718748569]\n",
      "[0.233348489 0.214240402 0.186344832 ... 0.0577656627 0.0557563603 0.0531314313]\n",
      "[0.128724158 0.0989849865 0.082369715 ... 0.0553216338 0.0538683832 0.0527201593]\n",
      "[0.0843471 0.0550555587]\n",
      "[0.139067382 0.0944694579 0.0510365665]\n",
      "[]\n",
      "[0.163590431 0.128678262]\n",
      "[]\n",
      "[0.104924887 0.0678900778 0.0501355231]\n",
      "[]\n",
      "[0.076610595 0.0511656106]\n",
      "[0.0551766157]\n",
      "[]\n",
      "[0.148561656 0.0800278783]\n",
      "[0.506291628 0.432774961 0.383406341 ... 0.0590190589 0.0559512675 0.0557635128]\n",
      "[0.0660321414]\n",
      "[]\n",
      "[]\n",
      "[0.131456792 0.119184017 0.115332246 ... 0.0585529208 0.0557363033 0.0551334918]\n",
      "[0.442930758 0.328411937 0.279930145 ... 0.0571773648 0.0554812551 0.0503087938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.161205351 0.114719689]\n",
      "[0.406248093 0.311497331 0.186728179 ... 0.0540984869 0.0530863106 0.0527803898]\n",
      "[0.165196449 0.129729152 0.0601016283]\n",
      "[]\n",
      "[]\n",
      "[0.0774965 0.0528152287]\n",
      "[0.0874711275]\n",
      "[0.0559204221]\n",
      "[0.112556279]\n",
      "[0.23849833 0.0596384406]\n",
      "[]\n",
      "[0.124181628 0.0846076906 0.0810028613 ... 0.0505721867 0.0504721701 0.0503532]\n",
      "[0.0915232 0.053431958]\n",
      "FastEstimator-Eval: step: 552; epoch: 91; focal_loss: 1.7283524; l1_loss: 0.4319094; total_loss: 2.1602619; \n",
      "FastEstimator-Train: step: 552; focal_loss: 0.0049156; l1_loss: 0.0328113; total_loss: 0.0377269; examples/sec: 31.9; progress: 46.0%; \n",
      "FastEstimator-Train: step: 553; focal_loss: 0.0098253; l1_loss: 0.0364231; total_loss: 0.0462483; examples/sec: 32.3; progress: 46.1%; \n",
      "FastEstimator-Train: step: 554; focal_loss: 0.0470584; l1_loss: 0.064352; total_loss: 0.1114104; examples/sec: 32.5; progress: 46.2%; \n",
      "FastEstimator-Train: step: 555; focal_loss: 0.008797; l1_loss: 0.0752941; total_loss: 0.0840911; examples/sec: 32.2; progress: 46.2%; \n",
      "FastEstimator-Train: step: 556; focal_loss: 0.0128528; l1_loss: 0.0469443; total_loss: 0.0597971; examples/sec: 32.2; progress: 46.3%; \n",
      "FastEstimator-Train: step: 557; focal_loss: 0.1264559; l1_loss: 0.0460418; total_loss: 0.1724977; examples/sec: 31.9; progress: 46.4%; \n",
      "[]\n",
      "[0.294028 0.151021808 0.0930742621 0.0554752648]\n",
      "[0.140243113 0.133966029 0.120075107 ... 0.112977684 0.0920839906 0.0754450262]\n",
      "[]\n",
      "[0.135163575 0.127501577 0.0839756429 0.0786212683 0.0646895766]\n",
      "[0.0998113751 0.0804802775]\n",
      "[0.123001009 0.117454857 0.0738112926]\n",
      "[0.250985652 0.0991559 0.0569603443]\n",
      "[0.115564376 0.111512601 0.0872368515 0.0517852]\n",
      "[0.235062629 0.173628926 0.138711929 ... 0.0675466359 0.0615089536 0.0558140576]\n",
      "[0.0748237371]\n",
      "[]\n",
      "[0.468910456 0.339515775]\n",
      "[0.253328294]\n",
      "[0.234877378 0.147814035 0.0812739134 ... 0.0568139255 0.0566825569 0.0554834]\n",
      "[0.0834921598 0.0596883297]\n",
      "[]\n",
      "[]\n",
      "[0.232794374 0.223894 0.128242344 ... 0.0639669597 0.0588651 0.0518577099]\n",
      "[0.230018079 0.0934180617 0.0550562739 0.0533261597]\n",
      "[]\n",
      "[0.172085941 0.130611986]\n",
      "[0.0505096614]\n",
      "[0.17598027 0.0643361509]\n",
      "[]\n",
      "[0.0998072 0.0624240041 0.057605 0.0571575761]\n",
      "[]\n",
      "[0.0532301962]\n",
      "[0.0627952218 0.0555875]\n",
      "[]\n",
      "[0.226842135 0.078684479 0.0570418239]\n",
      "[0.517102957 0.362611622 0.303261667 ... 0.0694512427 0.0681528151 0.0652107596]\n",
      "[0.0619114339]\n",
      "[]\n",
      "[]\n",
      "[0.223358452 0.160297781 0.126987457 ... 0.0629617572 0.0534055233 0.0516108572]\n",
      "[0.605921328 0.453855604 0.304746032 ... 0.0518297851 0.0508054197 0.0503799915]\n",
      "[0.104773492 0.0681855679]\n",
      "[0.425012 0.344020665 0.186518282 ... 0.0577324629 0.0552699864 0.0523456633]\n",
      "[0.133120209 0.0814136565 0.0615399182]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.11484611 0.0636262]\n",
      "[0.120835662 0.0680604875]\n",
      "[]\n",
      "FastEstimator-Eval: step: 558; epoch: 92; focal_loss: 1.6988024; l1_loss: 0.4415907; total_loss: 2.140393; \n",
      "FastEstimator-Train: step: 558; focal_loss: 0.0020423; l1_loss: 0.0646914; total_loss: 0.0667337; examples/sec: 32.2; progress: 46.5%; \n",
      "FastEstimator-Train: step: 559; focal_loss: 0.0246855; l1_loss: 0.0567099; total_loss: 0.0813955; examples/sec: 32.3; progress: 46.6%; \n",
      "FastEstimator-Train: step: 560; focal_loss: 0.0146349; l1_loss: 0.0690437; total_loss: 0.0836786; examples/sec: 32.5; progress: 46.7%; \n",
      "FastEstimator-Train: step: 561; focal_loss: 0.0070586; l1_loss: 0.0334918; total_loss: 0.0405504; examples/sec: 32.2; progress: 46.8%; \n",
      "FastEstimator-Train: step: 562; focal_loss: 0.007839; l1_loss: 0.0665602; total_loss: 0.0743992; examples/sec: 32.0; progress: 46.8%; \n",
      "FastEstimator-Train: step: 563; focal_loss: 0.0076123; l1_loss: 0.0296258; total_loss: 0.0372381; examples/sec: 32.4; progress: 46.9%; \n",
      "[0.14430204 0.142932713 0.0874230862 ... 0.0516747832 0.0515717864 0.0504466593]\n",
      "[0.0954434574 0.0650132]\n",
      "[]\n",
      "[0.29384917 0.154097319 0.0892674 0.057182312 0.0500647724]\n",
      "[0.272388279 0.197668493 0.168616861 ... 0.0695176721 0.0619350374 0.0551639795]\n",
      "[]\n",
      "[0.162000328 0.133470595 0.0951581299 0.0861454308 0.0738834441]\n",
      "[0.127765417 0.0934150219]\n",
      "[0.15278098 0.0971749425 0.0741776824]\n",
      "[0.243690252 0.0800331533 0.0544293225]\n",
      "[0.0961455405 0.0904812217 0.0648598075 0.0638696253 0.0609805286]\n",
      "[0.197411627 0.162959635 0.121678174 ... 0.0968849957 0.0826062858 0.0700105727]\n",
      "[0.0787481368 0.0660783052]\n",
      "[0.054245621]\n",
      "[0.434345424 0.268273115]\n",
      "[0.298562765]\n",
      "[0.213661969 0.148843199 0.0754137337 ... 0.0584775209 0.0569617748 0.0547072]\n",
      "[0.0912121534 0.0688994825 0.0609659851]\n",
      "[]\n",
      "[]\n",
      "[0.184674352 0.179730475 0.156847924 ... 0.0704984367 0.0621254742 0.0599209368]\n",
      "[0.326543152 0.0884109437 0.0553498566 0.0536294]\n",
      "[]\n",
      "[0.217546284 0.123511195 0.0682357252]\n",
      "[0.0688153505 0.0524558127]\n",
      "[0.182490468 0.057770282 0.0561131537]\n",
      "[]\n",
      "[0.103321582 0.0681579113 0.0562199652]\n",
      "[]\n",
      "[0.0565607846]\n",
      "[0.0867926478 0.0590673387]\n",
      "[]\n",
      "[0.230208874 0.117543757 0.0808465779 0.0702519417 0.0560739636]\n",
      "[0.501070142 0.296494365 0.281734973 ... 0.0658270717 0.0601085424 0.052611798]\n",
      "[0.0703027248 0.0582219064]\n",
      "[]\n",
      "[]\n",
      "[0.286904931 0.229264081 0.205334961 ... 0.0514954627 0.0512780249 0.0500285029]\n",
      "[0.659938812 0.53918618 0.314241111 ... 0.0585262179 0.0567654073 0.0562779903]\n",
      "[0.0991818]\n",
      "[0.43826133 0.300617158 0.164385349 ... 0.0573845506 0.0525392592 0.0507406294]\n",
      "[0.131494612 0.0675808787]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[0.240139335 0.118137658 0.0927805901]\n",
      "FastEstimator-Eval: step: 564; epoch: 93; focal_loss: 1.7174286; l1_loss: 0.4706168; total_loss: 2.1880453; \n",
      "FastEstimator-Train: step: 564; focal_loss: 0.0337336; l1_loss: 0.0722738; total_loss: 0.1060074; examples/sec: 32.4; progress: 47.0%; \n",
      "FastEstimator-Train: step: 565; focal_loss: 0.0039953; l1_loss: 0.0700343; total_loss: 0.0740297; examples/sec: 32.2; progress: 47.1%; \n",
      "FastEstimator-Train: step: 566; focal_loss: 0.1230688; l1_loss: 0.0374126; total_loss: 0.1604815; examples/sec: 32.6; progress: 47.2%; \n",
      "FastEstimator-Train: step: 567; focal_loss: 0.0402478; l1_loss: 0.0996943; total_loss: 0.1399421; examples/sec: 31.8; progress: 47.2%; \n",
      "FastEstimator-Train: step: 568; focal_loss: 0.0065427; l1_loss: 0.0706326; total_loss: 0.0771754; examples/sec: 32.2; progress: 47.3%; \n",
      "FastEstimator-Train: step: 569; focal_loss: 0.0227763; l1_loss: 0.0524702; total_loss: 0.0752465; examples/sec: 32.0; progress: 47.4%; \n",
      "[0.088568151 0.0500916839]\n",
      "[]\n",
      "[0.186129421 0.109814972 0.0887689292 ... 0.0527829826 0.0514034927 0.0512790084]\n",
      "[0.114411622 0.0666473508]\n",
      "[]\n",
      "[0.326470733 0.179551214 0.106799752 0.0704933107]\n",
      "[0.183105946 0.115930885 0.102974206 ... 0.0584599078 0.0511383414 0.051034838]\n",
      "[]\n",
      "[0.126710653 0.124249011 0.106401742 ... 0.0683192 0.0576095581 0.0507544279]\n",
      "[0.100485772 0.0879758894]\n",
      "[0.144165367 0.141530603 0.0776445866]\n",
      "[0.334386915 0.0733867586 0.0544843674]\n",
      "[0.10204041 0.0898408592 0.0754126608 0.0624933243]\n",
      "[0.273887336 0.272538364 0.163748324 ... 0.102526486 0.0536653101 0.0509440899]\n",
      "[0.0704143047 0.0574338734]\n",
      "[]\n",
      "[0.411545813 0.373078167 0.0513857901]\n",
      "[0.283636451]\n",
      "[0.209753513 0.204883575 0.12256518 ... 0.055084765 0.0546561778 0.0505723655]\n",
      "[0.0878210962 0.0592637658]\n",
      "[]\n",
      "[]\n",
      "[0.345624804 0.256270885 0.176713675 ... 0.0649171472 0.0645851791 0.0607186258]\n",
      "[0.38690722 0.078147471 0.073472023 0.0724980831 0.0638225675 0.0510479808]\n",
      "[0.0670669377 0.0525453091]\n",
      "[0.171821862 0.113036215 0.0837252438]\n",
      "[0.0644411445 0.0591830909]\n",
      "[0.123987019 0.0550445914]\n",
      "[]\n",
      "[0.100130409 0.0820581615 0.077535063 0.0726464093 0.0562112927]\n",
      "[]\n",
      "[0.0627565086 0.0515890718]\n",
      "[0.0816337168]\n",
      "[]\n",
      "[0.220054835 0.0685640275 0.0661705732 0.061147809 0.0592242777]\n",
      "[0.602149904 0.553040206 0.453616261 ... 0.0682928264 0.0677030087 0.0534129739]\n",
      "[0.0861493945]\n",
      "[0.0527044237]\n",
      "[]\n",
      "[0.327451408 0.232468098 0.144348979 ... 0.0611397922 0.0608833432 0.0540939867]\n",
      "[0.622781575 0.576559544 0.216193825 ... 0.0637498796 0.0553232729 0.050581336]\n",
      "[0.0986334682]\n",
      "[0.488226205 0.395647734 0.276778936 ... 0.05405581 0.0531247854 0.0530428588]\n",
      "[0.0889912844 0.0776976049 0.0641041398 0.0545693636]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-Eval: step: 570; epoch: 94; focal_loss: 1.6069463; l1_loss: 0.4473956; total_loss: 2.0543418; \n",
      "FastEstimator-Train: step: 570; focal_loss: 0.008145; l1_loss: 0.0642512; total_loss: 0.0723962; examples/sec: 32.3; progress: 47.5%; \n",
      "FastEstimator-Train: step: 571; focal_loss: 0.0122166; l1_loss: 0.0355229; total_loss: 0.0477396; examples/sec: 32.1; progress: 47.6%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 572; focal_loss: 0.0039025; l1_loss: 0.0403918; total_loss: 0.0442943; examples/sec: 32.3; progress: 47.7%; \n",
      "FastEstimator-Train: step: 573; focal_loss: 0.1352267; l1_loss: 0.0887334; total_loss: 0.22396; examples/sec: 32.5; progress: 47.8%; \n",
      "FastEstimator-Train: step: 574; focal_loss: 0.0643782; l1_loss: 0.0613947; total_loss: 0.1257729; examples/sec: 32.0; progress: 47.8%; \n",
      "FastEstimator-Train: step: 575; focal_loss: 0.0116735; l1_loss: 0.0975015; total_loss: 0.1091751; examples/sec: 31.5; progress: 47.9%; \n",
      "[0.0539368689 0.0513893068]\n",
      "[0.14241007 0.101764977 0.100672901 0.0953822732 0.0878527761]\n",
      "[0.211543292 0.0745975077]\n",
      "[]\n",
      "[0.238567621 0.225959957 0.180765152 ... 0.051040709 0.0505159795 0.0501969755]\n",
      "[0.130783677 0.0905171]\n",
      "[0.0530670583]\n",
      "[0.449670523 0.306730628 0.237009346 0.0678166747 0.056915462 0.0545160174]\n",
      "[0.294426471 0.173853427 0.124061763 ... 0.0595591366 0.0525990427 0.0522417724]\n",
      "[0.0587967634]\n",
      "[0.164374471 0.133550346 0.12891382 ... 0.070884645 0.0533109307 0.0500896871]\n",
      "[0.206096292 0.162504941 0.0504389107]\n",
      "[0.202765644 0.144923538 0.0895222723 0.0512906909]\n",
      "[0.2799505 0.127345353 0.0752547085 0.0660712719 0.0543149412 0.0516658723]\n",
      "[0.16888839 0.138790905 0.122042567 0.103303879 0.0934823453 0.0602437258]\n",
      "[0.364311308 0.361527532 0.21273464 ... 0.0677027106 0.0538604856 0.0522148907]\n",
      "[0.0851787329 0.0811781883]\n",
      "[0.101979256]\n",
      "[0.529872298 0.475036293 0.0606842935]\n",
      "[0.35979569]\n",
      "[0.301136762 0.193945765 0.183119923 ... 0.0622614026 0.0579719245 0.0515903234]\n",
      "[0.0809576809 0.0702769756 0.0528589189]\n",
      "[0.0624114275]\n",
      "[0.0622450411 0.0613158643]\n",
      "[0.372124195 0.345838666 0.298564196 ... 0.0610319078 0.0548847318 0.0501534939]\n",
      "[0.427835107 0.195492268 0.0731592774 ... 0.0588647127 0.0554302335 0.0512032211]\n",
      "[0.140229911 0.0597830713 0.054913491]\n",
      "[0.209339589 0.134603709 0.118627131 0.0856061]\n",
      "[0.085768044 0.0581038892]\n",
      "[0.230486542 0.130711168 0.0702365637]\n",
      "[0.154030323 0.143169641 0.0514004827]\n",
      "[0.136779547 0.0913598239 0.0838424 ... 0.0706270039 0.0641836226 0.0558751523]\n",
      "[0.0522916019]\n",
      "[0.109842628 0.0814962387 0.0814668238 0.0572577715]\n",
      "[0.0766488612 0.0656546056 0.053160876]\n",
      "[]\n",
      "[0.270784438 0.0807347298 0.0739650726 0.0695046782 0.0582540929]\n",
      "[0.620932341 0.480751634 0.424578 ... 0.0585203469 0.057251662 0.0512050688]\n",
      "[0.0867438614 0.0693802834]\n",
      "[0.0684023798 0.0588939786]\n",
      "[]\n",
      "[0.551958799 0.287612677 0.158461511 ... 0.0588396192 0.0533162653 0.0524134636]\n",
      "[0.691463351 0.557127237 0.334513247 ... 0.052200675 0.0515118539 0.0509448349]\n",
      "[0.0932701528 0.0676900744]\n",
      "[0.628800452 0.32649672 0.219602793 ... 0.0578193367 0.0552862 0.0544316769]\n",
      "[0.159006625 0.154651076 0.134463221 0.112084359 0.0985818207 0.090017736]\n",
      "[]\n",
      "[]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 576; epoch: 95; focal_loss: 1.4507388; l1_loss: 0.4340365; total_loss: 1.8847756; \n",
      "FastEstimator-Train: step: 576; focal_loss: 0.0102468; l1_loss: 0.0622083; total_loss: 0.0724552; examples/sec: 31.9; progress: 48.0%; \n",
      "FastEstimator-Train: step: 577; focal_loss: 0.1251982; l1_loss: 0.0386206; total_loss: 0.1638188; examples/sec: 32.1; progress: 48.1%; \n",
      "FastEstimator-Train: step: 578; focal_loss: 0.0044444; l1_loss: 0.0366591; total_loss: 0.0411035; examples/sec: 31.8; progress: 48.2%; \n",
      "FastEstimator-Train: step: 579; focal_loss: 0.0376927; l1_loss: 0.0768075; total_loss: 0.1145002; examples/sec: 32.7; progress: 48.2%; \n",
      "FastEstimator-Train: step: 580; focal_loss: 0.0258956; l1_loss: 0.0569456; total_loss: 0.0828413; examples/sec: 32.1; progress: 48.3%; \n",
      "FastEstimator-Train: step: 581; focal_loss: 0.0287975; l1_loss: 0.0345908; total_loss: 0.0633883; examples/sec: 32.1; progress: 48.4%; \n",
      "[0.127629489 0.0808109343 0.0676747 0.0503315628 0.0502721369]\n",
      "[0.0592468083 0.0550985634]\n",
      "[0.0653128 0.0645512044 0.0602267087 0.0563576519 0.0514915884]\n",
      "[0.119522244 0.0746766627 0.0661603212 0.0618006]\n",
      "[0.322782457 0.0995622277]\n",
      "[0.0522664785]\n",
      "[0.13455224 0.123990834 0.104290277 ... 0.0521264076 0.0514903069 0.0501346588]\n",
      "[0.128944784 0.0919393]\n",
      "[0.0574934483 0.0561620593]\n",
      "[0.46397087 0.332202971 0.214022458 0.0903253555 0.0545791388]\n",
      "[0.21697098 0.127181947 0.120819658 ... 0.0539836287 0.0536034703 0.0529513955]\n",
      "[0.0562125742]\n",
      "[0.183622777 0.14830184 0.107866645 0.0986179411 0.0698963404 0.0632036]\n",
      "[0.222240835 0.15168041]\n",
      "[0.197773904 0.0965754688 0.0662419796]\n",
      "[0.321977615 0.168514371 0.108049929 0.101157486 0.0548406541 0.0541504622]\n",
      "[0.199832588 0.173932284 0.166881382 0.138005316 0.12211135]\n",
      "[0.309599638 0.169489235 0.165897936 ... 0.0631488 0.0607625842 0.0509253442]\n",
      "[0.085275054 0.0725564957]\n",
      "[0.113217205]\n",
      "[0.318772465 0.258996189 0.056532383]\n",
      "[0.34436667]\n",
      "[0.289399058 0.151800364 0.138166428 ... 0.0610617697 0.0556618869 0.0527589321]\n",
      "[0.077029407 0.0562130213]\n",
      "[0.0601653159]\n",
      "[0.0718662739 0.0691617131 0.0528363]\n",
      "[0.228500873 0.223083526 0.180852979 ... 0.0556835234 0.0523049235 0.0501586497]\n",
      "[0.356364101 0.0976495147 0.0918517113 ... 0.0539221466 0.0526110232 0.0506301224]\n",
      "[0.175514758 0.0692304671 0.06187433]\n",
      "[0.230396628 0.112199455 0.10549292 0.064894557]\n",
      "[0.0688805]\n",
      "[0.314367533 0.2065368 0.0807366669]\n",
      "[0.199897707 0.0541885197]\n",
      "[0.134573609 0.116298616 0.064201653 0.0587772727 0.0548859239 0.052369535]\n",
      "[]\n",
      "[0.106524169 0.104639024 0.101079851]\n",
      "[0.0878957212 0.0786491632 0.0574706197]\n",
      "[]\n",
      "[0.280510694 0.0682907701 0.0526771247]\n",
      "[0.56862843 0.419833899 0.408296704 ... 0.0629722476 0.062363416 0.058349818]\n",
      "[0.0805991888 0.0792349279 0.0601809621]\n",
      "[0.073143959 0.0692352355]\n",
      "[]\n",
      "[0.325651109 0.202934235 0.164616495 ... 0.0632807314 0.0552278161 0.0549126565]\n",
      "[0.741851926 0.573422611 0.477775812 ... 0.0539959073 0.0523150563 0.0514061153]\n",
      "[0.122474492 0.0675259829]\n",
      "[0.522995 0.229254872 0.20544979 ... 0.057483077 0.0533033 0.0516194403]\n",
      "[0.17174083 0.16209501 0.119765013 0.0870629251 0.0817313194 0.0638445616]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 582; epoch: 96; focal_loss: 1.466342; l1_loss: 0.3846288; total_loss: 1.8509707; \n",
      "FastEstimator-Train: step: 582; focal_loss: 0.1258407; l1_loss: 0.0557594; total_loss: 0.1816001; examples/sec: 31.8; progress: 48.5%; \n",
      "FastEstimator-Train: step: 583; focal_loss: 0.0049949; l1_loss: 0.0250913; total_loss: 0.0300862; examples/sec: 32.4; progress: 48.6%; \n",
      "FastEstimator-Train: step: 584; focal_loss: 0.0150284; l1_loss: 0.1332127; total_loss: 0.1482411; examples/sec: 32.2; progress: 48.7%; \n",
      "FastEstimator-Train: step: 585; focal_loss: 0.0108288; l1_loss: 0.0539693; total_loss: 0.064798; examples/sec: 32.6; progress: 48.8%; \n",
      "FastEstimator-Train: step: 586; focal_loss: 0.0254428; l1_loss: 0.0598676; total_loss: 0.0853104; examples/sec: 32.1; progress: 48.8%; \n",
      "FastEstimator-Train: step: 587; focal_loss: 0.0060257; l1_loss: 0.0375483; total_loss: 0.043574; examples/sec: 31.6; progress: 48.9%; \n",
      "[]\n",
      "[]\n",
      "[0.121397793 0.08836326 0.0763329864 ... 0.0520552099 0.0517266691 0.0511419177]\n",
      "[0.0652599931 0.0601394773]\n",
      "[0.0760257542 0.0727433 0.0692270696]\n",
      "[0.17590782 0.142605752 0.11242798 0.0840987861 0.0829176307]\n",
      "[0.343360186 0.125804275]\n",
      "[0.0691303611 0.0545045137]\n",
      "[0.135817856 0.117731392 0.116048306 ... 0.0518386662 0.05169034 0.0514550805]\n",
      "[0.177869797 0.13444683]\n",
      "[0.068121016 0.0574083626]\n",
      "[0.441706419 0.388826638 0.238843352 0.14744404 0.0536007]\n",
      "[0.155285418 0.149172723 0.149002075 ... 0.0581543744 0.0523308218 0.0513313115]\n",
      "[0.0531680286]\n",
      "[0.281227529 0.2026411 0.165771455 ... 0.053753823 0.0517402589 0.0511968732]\n",
      "[0.191214263 0.152854234 0.0546359122]\n",
      "[0.203026026 0.187412709 0.0804137588 0.0738808811 0.0710482895]\n",
      "[0.372959435 0.180758506 0.0860343 ... 0.0519001484 0.0512097776 0.0509301722]\n",
      "[0.171526819 0.16336599 0.14783597 0.109693587 0.0948020816 0.0634627938]\n",
      "[0.362069577 0.360550642 0.211286426 ... 0.0572583675 0.0502647758 0.0501403213]\n",
      "[0.084694922 0.0561496615 0.0551417768 0.0537950099]\n",
      "[0.0782563388]\n",
      "[0.572308123 0.411720097 0.0664358139]\n",
      "[0.303978533]\n",
      "[0.288243026 0.160743564 0.12359187 ... 0.0576174259 0.056193471 0.0547447205]\n",
      "[0.131264448 0.100300729 0.0609856248]\n",
      "[0.0902157426]\n",
      "[0.0803226531 0.0686712563 0.0562475622]\n",
      "[0.422792375 0.411241114 0.266325355 ... 0.0629514754 0.0556281209 0.053098768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39193356 0.127824783 0.0853924155 ... 0.0548253655 0.0547309518 0.0512434542]\n",
      "[0.136331081 0.0804271102 0.0748140514 0.0613105 0.0519703329]\n",
      "[0.230355918 0.128162771 0.0718303 0.0659736097]\n",
      "[0.0817460716]\n",
      "[0.254821837 0.179204881 0.104493618]\n",
      "[0.350571096 0.112826347 0.0835089684 0.0655981898 0.058216542]\n",
      "[0.146108806 0.112049967 0.0938916206 ... 0.0533958077 0.0526289642 0.0509883463]\n",
      "[]\n",
      "[0.105366051 0.104214609 0.103663236]\n",
      "[0.0919245481 0.0551553071]\n",
      "[]\n",
      "[0.283366144 0.0945649743 0.0724476576 0.0673503876 0.0624683499]\n",
      "[0.664865077 0.53344363 0.494829834 ... 0.0550586581 0.0546220243 0.0515293181]\n",
      "[0.0775370598 0.0732691 0.0670248568 0.0505687296]\n",
      "[0.0862831473 0.0632410645 0.0516828 0.0515810549]\n",
      "[]\n",
      "[0.185765862 0.172904849 0.116877377 ... 0.0540545285 0.0510566533 0.0504716039]\n",
      "[0.870375276 0.806942523 0.527213335 ... 0.0515859127 0.0508424938 0.0502742827]\n",
      "[0.11943233 0.0756718516]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 588; epoch: 97; focal_loss: 1.4275075; l1_loss: 0.3777509; total_loss: 1.8052584; \n",
      "FastEstimator-Train: step: 588; focal_loss: 0.0130896; l1_loss: 0.0536562; total_loss: 0.0667458; examples/sec: 31.7; progress: 49.0%; \n",
      "FastEstimator-Train: step: 589; focal_loss: 0.010784; l1_loss: 0.0450974; total_loss: 0.0558813; examples/sec: 32.1; progress: 49.1%; \n",
      "FastEstimator-Train: step: 590; focal_loss: 0.015294; l1_loss: 0.0535073; total_loss: 0.0688012; examples/sec: 31.2; progress: 49.2%; \n",
      "FastEstimator-Train: step: 591; focal_loss: 0.1272853; l1_loss: 0.0293517; total_loss: 0.156637; examples/sec: 32.6; progress: 49.2%; \n",
      "FastEstimator-Train: step: 592; focal_loss: 0.0525654; l1_loss: 0.0477359; total_loss: 0.1003012; examples/sec: 31.4; progress: 49.3%; \n",
      "FastEstimator-Train: step: 593; focal_loss: 0.0255006; l1_loss: 0.0589136; total_loss: 0.0844142; examples/sec: 32.0; progress: 49.4%; \n",
      "[0.819443643 0.527731061 0.379685283 ... 0.0646388233 0.0583612025 0.0523796976]\n",
      "[0.176852643 0.159010023 0.122072726 ... 0.101202399 0.0706281066 0.0695019066]\n",
      "[]\n",
      "[]\n",
      "[0.114373028 0.0758553147 0.0679048 ... 0.0557719469 0.0540498495 0.0524039268]\n",
      "[0.0539994538]\n",
      "[0.101298958 0.0663172901 0.0651071072 0.0647288 0.0597822368]\n",
      "[0.249042422 0.18471244 0.17905286 0.162360132 0.135181725 0.0983545184]\n",
      "[0.25414896 0.0929017067]\n",
      "[0.112666965 0.0766872466 0.0656247139]\n",
      "[0.164241016 0.123599321 0.100728452 ... 0.0513760149 0.0509560704 0.0501253903]\n",
      "[0.170033306 0.158023685]\n",
      "[0.0741268694 0.0557415187]\n",
      "[0.50846839 0.505972683 0.243155479 0.149126142 0.0808038414 0.0530430079]\n",
      "[0.404924929 0.23918587 0.168058157 ... 0.0593426824 0.0531710386 0.0518111885]\n",
      "[0.0707497]\n",
      "[0.344212323 0.224889338 0.191180468 ... 0.0673571825 0.057317704 0.0517455041]\n",
      "[0.197988451 0.164859354 0.0637185872]\n",
      "[0.290332168 0.209406346 0.0917934179 ... 0.078887552 0.0549645722 0.0549483]\n",
      "[0.439590871 0.136769503 0.113179058 ... 0.0661433935 0.0618366 0.0519875]\n",
      "[0.150984049 0.137677103 0.117826372 0.0921326 0.0850470662 0.0603773594]\n",
      "[0.558109581 0.354873985 0.270528316 ... 0.0534078181 0.0514808 0.0508694649]\n",
      "[0.0935444832 0.0756526291 0.0670312643]\n",
      "[0.0692341328 0.0504136682]\n",
      "[0.689175785 0.680552 0.0971486 ... 0.0782454312 0.0653554499 0.0547755659]\n",
      "[0.321873605]\n",
      "[0.210255 0.204190671 0.186921597 ... 0.0690568686 0.0593823791 0.0591238141]\n",
      "[0.232256949 0.0944661498 0.0934864283]\n",
      "[0.13179937]\n",
      "[0.114759058]\n",
      "[0.374607712 0.366204411 0.358280838 ... 0.0559314489 0.05420205 0.0522722304]\n",
      "[0.452942699 0.142894179 0.142839551 ... 0.0572757125 0.0550516844 0.0532653332]\n",
      "[0.174359679 0.10096243 0.085739404 0.0700362623]\n",
      "[0.294665039 0.102538049 0.0999657214 0.0916349 0.0585472286]\n",
      "[0.109122515]\n",
      "[0.209622145 0.138208479 0.0961968303]\n",
      "[0.443516165 0.112514734 0.109368861 0.102002263 0.0881887078 0.0605669916]\n",
      "[0.224680781 0.150288254 0.121276915 ... 0.0610034764 0.0545195937 0.0506671071]\n",
      "[]\n",
      "[0.0984588563 0.0953593254 0.0881962478]\n",
      "[0.0736167133]\n",
      "[]\n",
      "[0.256584048 0.124855965 0.0888595 0.0702919066 0.055999428 0.0527322888]\n",
      "[0.61721909 0.505784631 0.457428664 ... 0.0537363 0.0507530868 0.0500433743]\n",
      "[0.134414881 0.0843045413 0.0567725 0.0519035459]\n",
      "[0.0705966055 0.057916224 0.0570854545 0.0533950031]\n",
      "[]\n",
      "[0.377003282 0.374701083 0.236679137 ... 0.0516094565 0.0513293445 0.0505371392]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 594; epoch: 98; focal_loss: 1.3163685; l1_loss: 0.4293633; total_loss: 1.7457318; \n",
      "FastEstimator-Train: step: 594; focal_loss: 0.0073872; l1_loss: 0.0372465; total_loss: 0.0446337; examples/sec: 32.1; progress: 49.5%; \n",
      "FastEstimator-Train: step: 595; focal_loss: 0.1279629; l1_loss: 0.0355796; total_loss: 0.1635425; examples/sec: 32.3; progress: 49.6%; \n",
      "FastEstimator-Train: step: 596; focal_loss: 0.0019218; l1_loss: 0.0537022; total_loss: 0.055624; examples/sec: 32.1; progress: 49.7%; \n",
      "FastEstimator-Train: step: 597; focal_loss: 0.0399956; l1_loss: 0.0519725; total_loss: 0.0919682; examples/sec: 32.5; progress: 49.8%; \n",
      "FastEstimator-Train: step: 598; focal_loss: 0.0207561; l1_loss: 0.032408; total_loss: 0.0531641; examples/sec: 32.4; progress: 49.8%; \n",
      "FastEstimator-Train: step: 599; focal_loss: 0.1265831; l1_loss: 0.036736; total_loss: 0.1633191; examples/sec: 32.3; progress: 49.9%; \n",
      "[0.665789247 0.573510945 0.387533814 ... 0.0535438657 0.0521715283 0.0512172]\n",
      "[0.120392174 0.0816431642]\n",
      "[0.756636 0.31326288 0.279032528 ... 0.0609339774 0.0570835769 0.0539456606]\n",
      "[0.112355381 0.110267192 0.109894782 0.0941047668 0.0814214349 0.066957593]\n",
      "[]\n",
      "[]\n",
      "[0.0824125707 0.054595083 0.0516334176 0.0500614345]\n",
      "[0.0539859235]\n",
      "[0.126947522 0.0748222768 0.0593999922 0.0528586805]\n",
      "[0.121577919 0.103999764 0.0794245601 0.0594954193]\n",
      "[0.285822749 0.0769594312]\n",
      "[0.123174399 0.0824604332 0.0768784]\n",
      "[0.186202943 0.150858015 0.150580943 ... 0.0540418625 0.0529536 0.0500831306]\n",
      "[0.145717233 0.143227726]\n",
      "[0.0695332885 0.0581139922]\n",
      "[0.473314047 0.343870163 0.173962414 0.0620671213]\n",
      "[0.337015867 0.162512571 0.14377746 ... 0.0552769601 0.0532630384 0.0513155758]\n",
      "[]\n",
      "[0.198677212 0.171774656 0.127682537 0.118622124 0.0542524159 0.0521509349]\n",
      "[0.161683738 0.130268544]\n",
      "[0.20145905 0.141246289 0.0685076714 0.0677727163]\n",
      "[0.509092629 0.124869317 0.0987591445 ... 0.0773481131 0.0708463788 0.0657546222]\n",
      "[0.158463866 0.131426603 0.122991711 0.0908807516 0.0817513466 0.0716614425]\n",
      "[0.286589622 0.246412665 0.197992474 ... 0.0605580509 0.0587366819 0.0543166399]\n",
      "[0.0894164443 0.0771187842]\n",
      "[0.0734831691 0.0539364219]\n",
      "[0.473463833 0.443048269 0.0588328242 0.0575014651]\n",
      "[0.302983165]\n",
      "[0.186572224 0.156061888 0.127100021 ... 0.0603456795 0.0600556433 0.0531068444]\n",
      "[0.0923900306]\n",
      "[0.111335516]\n",
      "[0.0756002367]\n",
      "[0.297696471 0.225621581 0.20688954 ... 0.0679297745 0.0658151507 0.0524134636]\n",
      "[0.410524786 0.156794399 0.112675786 ... 0.0593543947 0.0593073368 0.0559741855]\n",
      "[0.170274019 0.0868667364 0.0840044618 0.0641050935]\n",
      "[0.214238882 0.0779794753 0.0775916 0.0741056502 0.0595405102 0.0534691811]\n",
      "[0.0729402602]\n",
      "[0.203386307 0.153048337 0.0816370547]\n",
      "[0.299061477 0.102334768 0.0912453234 0.0689379 0.0594614744]\n",
      "[0.171928614 0.0818860233 0.0679292083 ... 0.0585037768 0.0511338115 0.0502482653]\n",
      "[]\n",
      "[0.10186252 0.101578265 0.0955245197]\n",
      "[0.0803030431]\n",
      "[]\n",
      "[0.152880371 0.113740891 0.0673074722 0.0580063462]\n",
      "[0.544619381 0.466506541 0.451692343 ... 0.0549998879 0.0546060503 0.0533247]\n",
      "[0.115251511 0.0793374181 0.0614050031 0.0568076074]\n",
      "[0.0797660351 0.055990845 0.0552402139 0.0520038]\n",
      "FastEstimator-Eval: step: 600; epoch: 99; focal_loss: 1.4079283; l1_loss: 0.3762095; total_loss: 1.7841378; \n",
      "FastEstimator-Train: step: 600; focal_loss: 0.0042959; l1_loss: 0.0240639; total_loss: 0.0283597; examples/sec: 32.1; progress: 50.0%; \n",
      "FastEstimator-Train: step: 601; focal_loss: 0.0100166; l1_loss: 0.0354417; total_loss: 0.0454583; examples/sec: 31.7; progress: 50.1%; \n",
      "FastEstimator-Train: step: 602; focal_loss: 0.0383693; l1_loss: 0.0305638; total_loss: 0.0689331; examples/sec: 32.1; progress: 50.2%; \n",
      "FastEstimator-Train: step: 603; focal_loss: 0.0101083; l1_loss: 0.0200559; total_loss: 0.0301642; examples/sec: 32.1; progress: 50.2%; \n",
      "FastEstimator-Train: step: 604; focal_loss: 0.0021733; l1_loss: 0.0487084; total_loss: 0.0508816; examples/sec: 32.4; progress: 50.3%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 605; focal_loss: 0.0216961; l1_loss: 0.0450097; total_loss: 0.0667058; examples/sec: 32.1; progress: 50.4%; \n",
      "[0.0740400553]\n",
      "[0.644586444 0.471114635 0.288029969 ... 0.0595040321 0.0553143322 0.053287]\n",
      "[0.808142722 0.79059875 0.443745434 ... 0.0508798957 0.0505978167 0.0504776835]\n",
      "[0.183888793 0.136838138]\n",
      "[0.84818697 0.556438506 0.462191641 ... 0.0548659861 0.0534223318 0.0500307679]\n",
      "[0.198060483 0.183480531 0.149189681 ... 0.0807790756 0.0675616264 0.0577682853]\n",
      "[0.0739621818 0.069516331 0.0606388152 0.0580234826]\n",
      "[]\n",
      "[0.163294524 0.0783735514 0.0770680606 ... 0.0571720898 0.0548748672 0.0531943738]\n",
      "[0.085822016 0.0742535889]\n",
      "[0.16855827 0.127053112 0.076241225 0.0755189657 0.0647428632 0.0628911555]\n",
      "[0.224209875 0.158322304 0.107910156 0.102447 0.0640823841]\n",
      "[0.481055051 0.126831234]\n",
      "[0.124827266 0.0851430297 0.0827078819]\n",
      "[0.275860101 0.273324668 0.210600227 ... 0.0502937734 0.0502873361 0.0500060022]\n",
      "[0.218165517 0.190379918]\n",
      "[0.0992807448 0.0855632126 0.056861341]\n",
      "[0.593667507 0.467210472 0.232378 ... 0.0631971657 0.0629600883 0.0510373116]\n",
      "[0.362015396 0.225140542 0.178120464 ... 0.0546939373 0.0526206791 0.0517910123]\n",
      "[0.0573340356 0.0544286668 0.0531879365]\n",
      "[0.301337779 0.1835742 0.171734184 ... 0.0736508071 0.0677489936 0.0610404313]\n",
      "[0.186040878 0.181961328 0.0717988908]\n",
      "[0.278461337 0.145533085 0.091581434 0.0782962143 0.0552564263]\n",
      "[0.764424 0.171131909 0.115896076 ... 0.0536426902 0.0533073545 0.0509277284]\n",
      "[0.336841673 0.305269837 0.235316426 0.152486652 0.143053 0.120202392]\n",
      "[0.451899618 0.446394444 0.288788259 ... 0.0763568282 0.0525618792 0.0503768921]\n",
      "[0.1216003 0.0844106674 0.0651218593 0.0529794693 0.0516431332 0.0500736535]\n",
      "[0.0881147683 0.0651131868 0.0575848222]\n",
      "[0.692167 0.610384524 0.0694147944 0.0620739162]\n",
      "[0.361436427]\n",
      "[0.530027568 0.333547831 0.313382387 ... 0.058003664 0.0542864501 0.0526074767]\n",
      "[0.115642548 0.0656191111 0.0621170402 0.0584180355]\n",
      "[0.193225712]\n",
      "[0.148439139 0.0925959349 0.0593400598]\n",
      "[0.490532339 0.442655563 0.382386476 ... 0.0536964834 0.0532260835 0.0521971]\n",
      "[0.569338381 0.227852404 0.198322415 ... 0.0574978888 0.0570493937 0.0568232834]\n",
      "[0.213874698 0.146835804 0.140531689 0.117525011 0.0625534654 0.051145196]\n",
      "[0.273396283 0.123582512 0.0840503275 0.0776545107 0.0710552335]\n",
      "[0.0996828079]\n",
      "[0.305929303 0.263427079 0.159082979]\n",
      "[0.575622261 0.225607693 0.156791896 ... 0.0751074553 0.0694800317 0.0504089296]\n",
      "[0.165664196 0.125567257 0.118080199 ... 0.0528886616 0.0509120226 0.0506658852]\n",
      "[]\n",
      "[0.168077737 0.154224664 0.153412968 0.0608765185]\n",
      "[0.137370974]\n",
      "[]\n",
      "[0.305357337 0.119036883 0.114880741 0.0915397704]\n",
      "[0.698502302 0.656093478 0.639411569 ... 0.0527682304 0.0508521199 0.050358206]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 606; epoch: 100; focal_loss: 1.2663611; l1_loss: 0.3830901; total_loss: 1.6494511; \n",
      "FastEstimator-Train: step: 606; focal_loss: 0.0293421; l1_loss: 0.0438623; total_loss: 0.0732044; examples/sec: 31.7; progress: 50.5%; \n",
      "FastEstimator-Train: step: 607; focal_loss: 0.0168175; l1_loss: 0.0294229; total_loss: 0.0462404; examples/sec: 32.1; progress: 50.6%; \n",
      "FastEstimator-Train: step: 608; focal_loss: 0.0102455; l1_loss: 0.0321174; total_loss: 0.0423629; examples/sec: 32.3; progress: 50.7%; \n",
      "FastEstimator-Train: step: 609; focal_loss: 0.1304355; l1_loss: 0.0572278; total_loss: 0.1876634; examples/sec: 32.5; progress: 50.7%; \n",
      "FastEstimator-Train: step: 610; focal_loss: 0.0037682; l1_loss: 0.0546405; total_loss: 0.0584087; examples/sec: 32.6; progress: 50.8%; \n",
      "FastEstimator-Train: step: 611; focal_loss: 0.0834822; l1_loss: 0.0385098; total_loss: 0.121992; examples/sec: 32.1; progress: 50.9%; \n",
      "[0.158554286 0.129072964 0.114934504 ... 0.0897142 0.0689578056 0.0678541958]\n",
      "[0.144663095 0.134836853 0.0974109173 ... 0.0601699352 0.0586733818 0.0528321266]\n",
      "[0.0536519587]\n",
      "[0.765062 0.452818066 0.267481446 ... 0.0528600216 0.0519991815 0.0505093336]\n",
      "[0.813655376 0.788898826 0.386401504 ... 0.0517891943 0.0505260825 0.0502483249]\n",
      "[0.126336068 0.0908121467]\n",
      "[0.787524462 0.516176522 0.406176567 ... 0.0556258261 0.0538042486 0.0517045856]\n",
      "[0.247943223 0.202866405 0.1582039 ... 0.0702882111 0.062420398 0.0534870625]\n",
      "[0.0668933392 0.064375788 0.0536642671]\n",
      "[]\n",
      "[0.131081283 0.0842756 0.0579693615 ... 0.053855449 0.053129524 0.0520300269]\n",
      "[0.0551544428]\n",
      "[0.183697551 0.0860309601 0.080136925 ... 0.0701315105 0.0678794384 0.0636088252]\n",
      "[0.238504648 0.158979535 0.13367489 0.132951826]\n",
      "[0.390843034]\n",
      "[0.170001656 0.12692526 0.119543523 0.0633766055]\n",
      "[0.228549242 0.223935246 0.216663361 ... 0.0505251884 0.0504865646 0.0502223074]\n",
      "[0.218608081 0.180167437]\n",
      "[0.0772540271 0.0719735]\n",
      "[0.573674917 0.561899483 0.203406364 ... 0.0844249725 0.0698110163 0.0641160607]\n",
      "[0.36822176 0.30164206 0.238491863 ... 0.0547144711 0.0536572635 0.0515352488]\n",
      "[0.0925635099]\n",
      "[0.201797783 0.186175227 0.13815093 ... 0.0543794632 0.053004384 0.0505432785]\n",
      "[0.240045249 0.227028847 0.117960185]\n",
      "[0.357251585 0.197972894 0.0854204 0.0831600726 0.0785370767 0.0541737378]\n",
      "[0.62799859 0.125732243 0.105417669 ... 0.0604022145 0.0593999624 0.0554691851]\n",
      "[0.274588227 0.20898363 0.155999571 0.134151518 0.132863194]\n",
      "[0.484903753 0.432154775 0.261365086 ... 0.0697533488 0.0650261045 0.0522241592]\n",
      "[0.105205745 0.092600435 0.0540212393]\n",
      "[0.135387689]\n",
      "[0.728046656 0.558491111 0.0760581791 0.068703264]\n",
      "[0.477239609]\n",
      "[0.283931136 0.280369699 0.279585361 ... 0.0513872802 0.0513599813 0.0512743]\n",
      "[0.139061779 0.0798660815 0.0666031837 0.0606416166]\n",
      "[0.18574214]\n",
      "[0.139961839 0.0629576147]\n",
      "[0.597578406 0.431842387 0.383149713 ... 0.0688613653 0.0653738081 0.053768158]\n",
      "[0.608453333 0.271610141 0.213366389 ... 0.0533083081 0.0511631072 0.0502140224]\n",
      "[0.238081485 0.113962293 0.105288118 0.0867965221 0.0549510717]\n",
      "[0.371452451 0.15979436 0.135434598 0.0696194768]\n",
      "[0.13521871 0.058032155]\n",
      "[0.350578368 0.239225537 0.225425303 0.070712924]\n",
      "[0.530497789 0.127781272 0.108907044 ... 0.0610401034 0.0520414412 0.0515647531]\n",
      "[0.123267204 0.118758291 0.100869805 ... 0.0706164837 0.0656508207 0.0619658232]\n",
      "[0.0563198626]\n",
      "[0.165008307 0.138683408 0.128578961 0.126599073 0.0918660462 0.0878777206]\n",
      "[0.0774107873 0.0629423261 0.0567107499 0.0508404076]\n",
      "[]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 612; epoch: 101; focal_loss: 1.2160178; l1_loss: 0.3485515; total_loss: 1.5645695; \n",
      "FastEstimator-Train: step: 612; focal_loss: 0.0047548; l1_loss: 0.0287804; total_loss: 0.0335352; examples/sec: 32.2; progress: 51.0%; \n",
      "FastEstimator-Train: step: 613; focal_loss: 0.1257181; l1_loss: 0.0663618; total_loss: 0.1920799; examples/sec: 32.2; progress: 51.1%; \n",
      "FastEstimator-Train: step: 614; focal_loss: 0.0038832; l1_loss: 0.0300222; total_loss: 0.0339054; examples/sec: 32.0; progress: 51.2%; \n",
      "FastEstimator-Train: step: 615; focal_loss: 0.0225721; l1_loss: 0.0523917; total_loss: 0.0749637; examples/sec: 31.5; progress: 51.2%; \n",
      "FastEstimator-Train: step: 616; focal_loss: 0.0198473; l1_loss: 0.031192; total_loss: 0.0510393; examples/sec: 32.4; progress: 51.3%; \n",
      "FastEstimator-Train: step: 617; focal_loss: 0.0056442; l1_loss: 0.0201737; total_loss: 0.0258179; examples/sec: 31.5; progress: 51.4%; \n",
      "[0.630311131 0.17054221 0.110546112 0.0645635724 0.0629622936]\n",
      "[0.65293169 0.54473114 0.468965203 ... 0.0517397821 0.0516737103 0.0502396524]\n",
      "[0.608850956 0.569041967 0.558336258 ... 0.0606220961 0.0580249131 0.0540042818]\n",
      "[0.128935128 0.110503137 0.0834750533 0.0602817833 0.053547442 0.05100137]\n",
      "[]\n",
      "[0.602676034 0.528352916 0.305979609 ... 0.0561008751 0.0517143607 0.0502584577]\n",
      "[0.764058 0.727788746 0.409757912 ... 0.0510103405 0.0507076979 0.05065]\n",
      "[0.0925921202 0.0567567945]\n",
      "[0.89387089 0.544658422 0.511697888 ... 0.0534228384 0.0520633757 0.0513139963]\n",
      "[0.162335724 0.152179062 0.127330363 0.127085716 0.110651106]\n",
      "[0.0514283478]\n",
      "[]\n",
      "[0.0618691444 0.0611940324 0.0605741739 0.0605300963 0.0554688275 0.0543857515]\n",
      "[]\n",
      "[0.213631988 0.0809631944 0.0784362555 ... 0.0569227934 0.0551258028 0.0514359474]\n",
      "[0.365470529 0.275468588 0.220069379 ... 0.178113967 0.0883070529 0.0514380336]\n",
      "[0.308666945 0.0619976521]\n",
      "[0.168071657 0.149421394 0.118120462 0.0927588344 0.060005039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24437955 0.237897694 0.21967 ... 0.0556170344 0.0552357137 0.050699383]\n",
      "[0.164538652 0.160071969]\n",
      "[0.0680867732 0.0503178239]\n",
      "[0.530835927 0.484932095 0.270740837 0.0917578936 0.0736799836 0.0542803109]\n",
      "[0.357811928 0.357560575 0.349728078 ... 0.0530441403 0.0529876947 0.0502329171]\n",
      "[0.0786236227]\n",
      "[0.279638946 0.168292791 0.166639417 ... 0.0679416358 0.0568058789 0.0540697575]\n",
      "[0.229669362 0.202953577 0.100221038]\n",
      "[0.32693398 0.288475454 0.139288276 0.11133486 0.0878317952 0.0803086162]\n",
      "[0.501402 0.132427305 0.112009734 ... 0.0558959842 0.0505066812 0.0502975881]\n",
      "[0.240567774 0.185260773 0.151196092 0.111301243 0.08292225 0.0505020022]\n",
      "[0.525537312 0.517275631 0.286937535 ... 0.0739107728 0.0564742386 0.0533095896]\n",
      "[0.111852199 0.0666636527 0.0604133606 0.0551502705]\n",
      "[0.106141597 0.0597401261]\n",
      "[0.657068074 0.416701049 0.0846424103 0.0674446523]\n",
      "[0.40717572]\n",
      "[0.293058544 0.179199785 0.16685605 ... 0.0723373294 0.0609132946 0.0532069206]\n",
      "[0.13211149 0.131061554 0.0864995122 0.0723822415 0.0557085276 0.050113678]\n",
      "[0.208568186]\n",
      "[0.153981298]\n",
      "[0.51579082 0.504146457 0.363210261 ... 0.0560853183 0.0533924401 0.0531355739]\n",
      "[0.602536 0.273995459 0.253605336 ... 0.0629425943 0.0628933311 0.0582892299]\n",
      "[0.177909762 0.137196481 0.0720709562 0.0715193152]\n",
      "[0.421983719 0.153656453 0.10540995 0.0705877244]\n",
      "[0.128020585]\n",
      "[0.213124037 0.210315645 0.157079339]\n",
      "[0.625223517 0.178528965 0.153332353 ... 0.0767670274 0.0548724234 0.0521211922]\n",
      "[0.118243068 0.116145492 0.106144816 ... 0.0537804365 0.0533522367 0.0515668392]\n",
      "[0.0547980368]\n",
      "[0.180755496 0.135194421 0.097085923]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 618; epoch: 102; focal_loss: 1.1732974; l1_loss: 0.3591506; total_loss: 1.5324479; \n",
      "FastEstimator-Train: step: 618; focal_loss: 0.0034451; l1_loss: 0.0111239; total_loss: 0.014569; examples/sec: 31.9; progress: 51.5%; \n",
      "FastEstimator-Train: step: 619; focal_loss: 0.0234755; l1_loss: 0.0406881; total_loss: 0.0641635; examples/sec: 32.1; progress: 51.6%; \n",
      "FastEstimator-Train: step: 620; focal_loss: 0.0047784; l1_loss: 0.0318058; total_loss: 0.0365842; examples/sec: 32.2; progress: 51.7%; \n",
      "FastEstimator-Train: step: 621; focal_loss: 0.0305438; l1_loss: 0.0204896; total_loss: 0.0510334; examples/sec: 31.5; progress: 51.7%; \n",
      "FastEstimator-Train: step: 622; focal_loss: 0.0081289; l1_loss: 0.0295481; total_loss: 0.037677; examples/sec: 32.4; progress: 51.8%; \n",
      "FastEstimator-Train: step: 623; focal_loss: 0.1232206; l1_loss: 0.0326742; total_loss: 0.1558948; examples/sec: 32.6; progress: 51.9%; \n",
      "[0.127253294 0.0561525226]\n",
      "[]\n",
      "[0.419900924 0.132025272 0.0620291233]\n",
      "[0.687259436 0.562956333 0.557927 ... 0.0552461445 0.0550242662 0.052391082]\n",
      "[0.372827381 0.256051838 0.217466861 ... 0.0722543 0.0545094311 0.0510017276]\n",
      "[0.122407377 0.0924637616 0.089428544 ... 0.0781519711 0.0556293428 0.0540530384]\n",
      "[0.0596731901]\n",
      "[0.593507469 0.481990278 0.371219337 ... 0.0549723208 0.0542861223 0.0511682928]\n",
      "[0.838168263 0.769132495 0.508431375 ... 0.0515973866 0.050699234 0.0500762761]\n",
      "[0.095900923 0.0669530332]\n",
      "[0.911081851 0.487511843 0.452735603 ... 0.0540267229 0.0538669229 0.0516417623]\n",
      "[0.169522226 0.129232287 0.0953139365 0.0941565335 0.0779311359]\n",
      "[0.0579488575]\n",
      "[]\n",
      "[0.0754519105 0.0655582547 0.0629748404 ... 0.051648736 0.0512274206 0.0512240827]\n",
      "[0.0540847778]\n",
      "[0.226393193 0.130135596 0.100683182 0.0899696052 0.0533320308]\n",
      "[0.46069476 0.158977866 0.117235601 0.0938224494 0.0801365077]\n",
      "[0.386053354 0.102615]\n",
      "[0.172226608 0.153689593 0.129938543 0.0968024135 0.0664454401]\n",
      "[0.323187858 0.290129095 0.253002763 ... 0.0506813228 0.0504491925 0.0503228307]\n",
      "[0.189988464 0.175038964]\n",
      "[0.08222574 0.0604659915]\n",
      "[0.509411275 0.437323 0.321920812 0.237661719 0.0532726049 0.0509202778]\n",
      "[0.546653748 0.227802247 0.227720082 ... 0.0511133671 0.0508346856 0.0500056446]\n",
      "[0.0542109609]\n",
      "[0.355889559 0.173785597 0.141636431 ... 0.0768932104 0.068728894 0.0522809625]\n",
      "[0.194660455 0.193454921 0.0869555175]\n",
      "[0.24748531 0.227892458 0.118133187 0.0880709291 0.0575758219 0.057038188]\n",
      "[0.671581626 0.131582588 0.095127672 ... 0.0550257862 0.0536401868 0.0522904098]\n",
      "[0.185527384 0.179908365 0.168985724 0.136534959 0.0729640126]\n",
      "[0.546461523 0.475622922 0.317571193 ... 0.0562399328 0.0524122119 0.05023247]\n",
      "[0.117621273 0.0744229257 0.0610262156 0.055877775]\n",
      "[0.0831371546 0.0558620691]\n",
      "[0.581638336 0.376338512 0.0768957436 0.0712178648]\n",
      "[0.428751975]\n",
      "[0.334017456 0.27150169 0.248712867 ... 0.0577544272 0.0529175401 0.050204277]\n",
      "[0.191671908 0.0781657398 0.0579647422 0.0572806895 0.0512360632]\n",
      "[0.254987836]\n",
      "[0.219901711 0.0595188737]\n",
      "[0.3995049 0.352206051 0.341141671 ... 0.0625776052 0.0540953577 0.0517703]\n",
      "[0.649430752 0.422475666 0.27272439 ... 0.0583353639 0.0562034845 0.0522062778]\n",
      "[0.299207151 0.173534393 0.10264504 0.101295888 0.0698446929]\n",
      "[0.40629676 0.134548455 0.102103233 0.0530462563]\n",
      "[0.106423855]\n",
      "[0.288104743 0.181849092 0.111723363]\n",
      "[0.61348033 0.16436249 0.147301167 0.108748794 0.0739803 0.0623290539]\n",
      "[0.162532419 0.142110974 0.109941363 ... 0.0551885962 0.0551870763 0.0503981411]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 624; epoch: 103; focal_loss: 1.1064934; l1_loss: 0.3503346; total_loss: 1.456828; \n",
      "FastEstimator-Train: step: 624; focal_loss: 0.0356386; l1_loss: 0.0222322; total_loss: 0.0578708; examples/sec: 31.7; progress: 52.0%; \n",
      "FastEstimator-Train: step: 625; focal_loss: 0.0042004; l1_loss: 0.0185688; total_loss: 0.0227692; examples/sec: 32.0; progress: 52.1%; \n",
      "FastEstimator-Train: step: 626; focal_loss: 0.122475; l1_loss: 0.0264938; total_loss: 0.1489688; examples/sec: 32.4; progress: 52.2%; \n",
      "FastEstimator-Train: step: 627; focal_loss: 0.0136233; l1_loss: 0.0273592; total_loss: 0.0409825; examples/sec: 31.9; progress: 52.2%; \n",
      "FastEstimator-Train: step: 628; focal_loss: 0.0107907; l1_loss: 0.0295979; total_loss: 0.0403886; examples/sec: 31.8; progress: 52.3%; \n",
      "FastEstimator-Train: step: 629; focal_loss: 0.0066343; l1_loss: 0.0356778; total_loss: 0.0423121; examples/sec: 32.7; progress: 52.4%; \n",
      "[0.0525114536 0.0514395237]\n",
      "[0.245890498 0.186320722 0.140647203 0.0595399141]\n",
      "[0.110604674]\n",
      "[]\n",
      "[0.462439507 0.124462187 0.0564589202 0.0544329584]\n",
      "[0.713194668 0.673074245 0.622004032 ... 0.0633550882 0.0612025857 0.0500430167]\n",
      "[0.637155175 0.549875379 0.373650938 ... 0.0504730642 0.050349623 0.0501738787]\n",
      "[0.123597443 0.111030251 0.0859205127 ... 0.0814501643 0.0629855394 0.0585175753]\n",
      "[0.06272313]\n",
      "[0.677737772 0.402934372 0.366052449 ... 0.0568623245 0.0554431379 0.0508098304]\n",
      "[0.858797431 0.821495652 0.56385994 ... 0.0540114641 0.0529716611 0.0515777469]\n",
      "[0.0962160528 0.0792526901]\n",
      "[0.86410296 0.477956653 0.432372332 ... 0.0540472567 0.0530421138 0.0503427088]\n",
      "[0.16537863 0.145633936 0.145287871 0.114456445 0.0800494552]\n",
      "[0.0805712044 0.0599470735 0.0531204939]\n",
      "[]\n",
      "[0.0735274553 0.0694448352 0.0652198493 ... 0.0586967766 0.0557002127 0.0503194034]\n",
      "[0.0549541414 0.0527718067]\n",
      "[0.26179862 0.227347344 0.109867632 ... 0.079488337 0.0578358471 0.0570857823]\n",
      "[0.606803298 0.359135509 0.154282749 0.134076118 0.0793290138]\n",
      "[0.491109818 0.0870918632]\n",
      "[0.135903597 0.119261205 0.106194735 0.0810108781]\n",
      "[0.348593473 0.237112612 0.224868506 ... 0.0519266427 0.051849097 0.0511186123]\n",
      "[0.228832603 0.225208461]\n",
      "[0.0855058134 0.0717367828 0.0526697338]\n",
      "[0.635766864 0.528740048 0.417146146 0.291769207 0.0603709519 0.0593648851]\n",
      "[0.657157123 0.226886243 0.223361075 ... 0.0581746697 0.0570843816 0.0560269952]\n",
      "[0.0600716174 0.0562722385]\n",
      "[0.334127903 0.2098234 0.146433353 ... 0.087112546 0.0643310547 0.0598722398]\n",
      "[0.260370612 0.237390548 0.0914642215]\n",
      "[0.317219913 0.279842079 0.110143214 0.0928909481 0.060264945]\n",
      "[0.698901892 0.1623528 0.11827603 ... 0.0629949 0.0562030077 0.0553948283]\n",
      "[0.229364276 0.187237203 0.171041369 ... 0.0664850175 0.0644199848 0.0623323917]\n",
      "[0.567169189 0.438336939 0.343940496 ... 0.0755769 0.0584707856 0.0540603697]\n",
      "[0.100448489 0.0846408 0.0695532262 0.058963269]\n",
      "[0.090847522]\n",
      "[0.85958755 0.683820546 0.0861816406 0.0721432865]\n",
      "[0.544259846]\n",
      "[0.30234319 0.301525116 0.235465556 ... 0.0812705755 0.0631040335 0.0513908863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.143191397 0.0715776086 0.070925 0.0530861914]\n",
      "[0.289814264]\n",
      "[0.222952604 0.0566757619]\n",
      "[0.458432406 0.409231305 0.364371955 ... 0.0645175278 0.0551350713 0.053915292]\n",
      "[0.731317043 0.401381522 0.296282709 ... 0.0529962182 0.0516398549 0.0514159799]\n",
      "[0.357289076 0.216873616 0.129304528 0.109012991 0.0630536675]\n",
      "[0.344495356 0.134818345 0.0964551568]\n",
      "[0.115377188]\n",
      "[0.294055104 0.213707566 0.135266036]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 630; epoch: 104; focal_loss: 1.1072116; l1_loss: 0.3089; total_loss: 1.4161114; \n",
      "FastEstimator-Train: step: 630; focal_loss: 0.0020336; l1_loss: 0.0357883; total_loss: 0.0378219; examples/sec: 31.7; progress: 52.5%; \n",
      "FastEstimator-Train: step: 631; focal_loss: 0.0061269; l1_loss: 0.0175403; total_loss: 0.0236672; examples/sec: 32.0; progress: 52.6%; \n",
      "FastEstimator-Train: step: 632; focal_loss: 0.0049022; l1_loss: 0.0150664; total_loss: 0.0199686; examples/sec: 32.1; progress: 52.7%; \n",
      "FastEstimator-Train: step: 633; focal_loss: 0.0038019; l1_loss: 0.0306166; total_loss: 0.0344185; examples/sec: 31.9; progress: 52.8%; \n",
      "FastEstimator-Train: step: 634; focal_loss: 0.0287024; l1_loss: 0.0284166; total_loss: 0.057119; examples/sec: 32.4; progress: 52.8%; \n",
      "FastEstimator-Train: step: 635; focal_loss: 0.0007177; l1_loss: 0.017724; total_loss: 0.0184417; examples/sec: 32.6; progress: 52.9%; \n",
      "[0.845401645 0.263900042 0.222209543 ... 0.0573921502 0.0543835461 0.0500282347]\n",
      "[0.363695234 0.362054169 0.280039191 ... 0.0528677404 0.0515145063 0.0508735776]\n",
      "[0.0675949752 0.0649728179]\n",
      "[0.337033153 0.200985074 0.135636628 0.0689019 0.0641620457]\n",
      "[0.0825796425 0.0677241385 0.0619045198 0.056545943 0.0519582033 0.0516077578]\n",
      "[0.0629763603]\n",
      "[0.576465726 0.137506872 0.134071916 ... 0.062146306 0.0556155145 0.0502131879]\n",
      "[0.776281476 0.659790635 0.602396131 ... 0.0532569289 0.0529433787 0.0507272482]\n",
      "[0.73902607 0.597915828 0.482291 ... 0.0585058033 0.0584831536 0.0575369]\n",
      "[0.164289773 0.138566405 0.100522876 ... 0.0809244514 0.0762370527 0.0709970593]\n",
      "[0.0639128685]\n",
      "[0.727092505 0.558026791 0.555494905 ... 0.0606287122 0.0564679205 0.0546590686]\n",
      "[0.896803498 0.825375199 0.709707558 ... 0.0504785478 0.0504663 0.0503131449]\n",
      "[0.149136156 0.055644989]\n",
      "[0.901166558 0.473912954 0.458949327 ... 0.0592876077 0.0531143844 0.0519555807]\n",
      "[0.248833 0.199312627 0.171467125 0.167062432 0.166847825 0.0644692779]\n",
      "[0.094286561 0.0688621402 0.0558715761 0.0512839556]\n",
      "[0.0640703738 0.052952081]\n",
      "[0.0970798433 0.0968547165 0.0924986 ... 0.0589479804 0.0585872829 0.056272]\n",
      "[0.0506673455]\n",
      "[0.396989673 0.390716702 0.167372704 ... 0.0770332515 0.0572110713 0.0517163575]\n",
      "[0.703473151 0.481397271 0.226616502 0.21856299 0.0764882267 0.0540331]\n",
      "[0.564958215 0.0933037102]\n",
      "[0.153824151 0.150760859 0.132403821 0.112698376 0.0563029945]\n",
      "[0.376347333 0.305167913 0.298514068 ... 0.0526711047 0.0523295701 0.0507551432]\n",
      "[0.366800606 0.296906948]\n",
      "[0.0859594345 0.0674645305 0.0656426549]\n",
      "[0.72165 0.580660462 0.369822145 ... 0.0697418749 0.0663809776 0.0559296]\n",
      "[0.63583684 0.379722893 0.311518341 ... 0.0518229604 0.0515829921 0.051443994]\n",
      "[0.0717752278 0.0715093315 0.052129209]\n",
      "[0.397420108 0.365217 0.26205495 ... 0.0549667776 0.0511830747 0.0503572822]\n",
      "[0.454592645 0.399113774 0.12643376]\n",
      "[0.378366351 0.376981676 0.126956642 ... 0.0579218268 0.0555919111 0.0519745946]\n",
      "[0.454333246 0.284178197 0.149880379 ... 0.0533813238 0.0519052446 0.0502672791]\n",
      "[0.390898228 0.286235362 0.218423396 ... 0.175244182 0.0853164792 0.0579601526]\n",
      "[0.613115191 0.595969796 0.398076326 ... 0.0563950241 0.0559253097 0.0531921387]\n",
      "[0.116605729 0.101569295 0.0723366439 0.0711755157 0.0609425604 0.0575725734]\n",
      "[0.140663028 0.0802284479]\n",
      "[0.922645 0.837073386 0.131299794 ... 0.0602961183 0.05513978 0.0512226522]\n",
      "[0.667609811]\n",
      "[0.391694367 0.373385042 0.362469494 ... 0.053525269 0.0532995462 0.0513037741]\n",
      "[0.101442784 0.0724203 0.069747895 0.0540595651 0.0507951081]\n",
      "[0.342183739]\n",
      "[0.246075392 0.0604572296 0.0543659925]\n",
      "[0.575642765 0.511902094 0.460953623 ... 0.054661572 0.0526328683 0.0524449944]\n",
      "[0.798748493 0.496982962 0.456065893 ... 0.071177721 0.0668674409 0.0645512342]\n",
      "[0.35806796 0.239260048 0.107396394 ... 0.086515069 0.0618147552 0.0532201827]\n",
      "[0.280131131 0.133327395 0.103857547 0.0590578318 0.0541537106]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 636; epoch: 105; focal_loss: 1.0040416; l1_loss: 0.3284909; total_loss: 1.3325324; \n",
      "FastEstimator-Train: step: 636; focal_loss: 0.2680828; l1_loss: 0.0703886; total_loss: 0.3384714; examples/sec: 32.1; progress: 53.0%; \n",
      "FastEstimator-Train: step: 637; focal_loss: 0.0028343; l1_loss: 0.020701; total_loss: 0.0235354; examples/sec: 31.7; progress: 53.1%; \n",
      "FastEstimator-Train: step: 638; focal_loss: 0.0358619; l1_loss: 0.0249834; total_loss: 0.0608453; examples/sec: 32.1; progress: 53.2%; \n",
      "FastEstimator-Train: step: 639; focal_loss: 0.0120339; l1_loss: 0.0326834; total_loss: 0.0447172; examples/sec: 32.1; progress: 53.2%; \n",
      "FastEstimator-Train: step: 640; focal_loss: 0.0024195; l1_loss: 0.0306825; total_loss: 0.0331019; examples/sec: 32.4; progress: 53.3%; \n",
      "FastEstimator-Train: step: 641; focal_loss: 0.0094247; l1_loss: 0.0332986; total_loss: 0.0427232; examples/sec: 32.6; progress: 53.4%; \n",
      "[0.142372578]\n",
      "[0.320357323 0.279163927 0.232648015]\n",
      "[0.837869763 0.292258 0.242455065 ... 0.0647090375 0.0563476086 0.0514648557]\n",
      "[0.465669513 0.428797185 0.267045736 ... 0.0516626239 0.0513281226 0.0500904918]\n",
      "[0.0638457537 0.0634259]\n",
      "[0.323617518 0.153230816 0.116820753 0.0622132719 0.0598971546]\n",
      "[0.0810090899 0.0792842507 0.0623218119 0.0582207143 0.0542689264]\n",
      "[0.0588179231]\n",
      "[0.619608045 0.123552442 0.0506246388]\n",
      "[0.688266695 0.682462633 0.677090764 ... 0.0553117096 0.053072989 0.051064074]\n",
      "[0.54927057 0.480679959 0.358427942 ... 0.0659600198 0.057487607 0.0516493022]\n",
      "[0.177155405 0.120426625 0.112093627 ... 0.0669642091 0.0616726875 0.0559981167]\n",
      "[0.0701174438]\n",
      "[0.889401197 0.625940621 0.588518143 ... 0.0520683229 0.0514701 0.0509903729]\n",
      "[0.597737432 0.57414633 0.461615175 ... 0.0527642965 0.0511506498 0.0502104163]\n",
      "[0.173247784]\n",
      "[0.878985643 0.522923231 0.369695365 ... 0.052518189 0.0511429608 0.0505638421]\n",
      "[0.174470782 0.167147934 0.165039659 ... 0.0669304132 0.0617087483 0.0534217656]\n",
      "[0.0893226266 0.0797861516 0.0610868633 0.0511824191]\n",
      "[0.0685586929 0.057741642]\n",
      "[0.103311568 0.0770427 0.0663297772 ... 0.0621186793 0.0570218265 0.0513641834]\n",
      "[0.0525694191]\n",
      "[0.445720971 0.271595359 0.119905114 ... 0.101806551 0.0895528197 0.0744993389]\n",
      "[0.549768329 0.294885278 0.154128253 0.0704743266 0.0514204204]\n",
      "[0.517704844 0.0537239313 0.0531667769]\n",
      "[0.203838617 0.173576683 0.155923575 0.138046622 0.0597026348]\n",
      "[0.38444984 0.331693053 0.31881994 ... 0.0508452654 0.0502185822 0.0501969755]\n",
      "[0.215785801 0.196878076]\n",
      "[0.117357552 0.0754480064 0.0706212223 0.0633892417]\n",
      "[0.817641318 0.482266843 0.460765481 ... 0.0799654424 0.0595212 0.0521468818]\n",
      "[0.665159225 0.367871195 0.326638192 ... 0.0545966625 0.0537785292 0.0506671369]\n",
      "[0.0730165243 0.0690968931]\n",
      "[0.391335756 0.234669656 0.167933941 ... 0.0712600052 0.0535707474 0.0534718335]\n",
      "[0.403142482 0.324695408 0.111776352]\n",
      "[0.401792914 0.141343206 0.131746173 ... 0.0669901371 0.055619 0.0552131832]\n",
      "[0.48960644 0.247822106 0.152148724 ... 0.0598009527 0.0572369397 0.0572167039]\n",
      "[0.319438726 0.272071302 0.243110061 0.226522118 0.225558758 0.115931481]\n",
      "[0.676061153 0.342767954 0.313671231 ... 0.076869458 0.0628404 0.0621789098]\n",
      "[0.13868463 0.117270321 0.099260658 0.0760043561 0.0748885274 0.0555018187]\n",
      "[0.13938126 0.0728736818]\n",
      "[0.898933649 0.87367475 0.0710960925 0.0565802455]\n",
      "[0.588545442]\n",
      "[0.382334 0.368385077 0.207959205 ... 0.0733111203 0.0701347589 0.0554147363]\n",
      "[0.130270451 0.10505417 0.0987625718 0.0619422495 0.0526403785]\n",
      "[0.320244789]\n",
      "[0.35035032 0.0576898754]\n",
      "[0.502538085 0.502243757 0.475407183 ... 0.0722474456 0.0684568286 0.0560369194]\n",
      "[0.817498446 0.290282369 0.277986526 ... 0.0573245 0.0519357324 0.0511144102]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 642; epoch: 106; focal_loss: 0.9964695; l1_loss: 0.3307566; total_loss: 1.327226; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 642; focal_loss: 0.0028142; l1_loss: 0.0319822; total_loss: 0.0347964; examples/sec: 32.0; progress: 53.5%; \n",
      "FastEstimator-Train: step: 643; focal_loss: 0.1317086; l1_loss: 0.0299961; total_loss: 0.1617047; examples/sec: 32.1; progress: 53.6%; \n",
      "FastEstimator-Train: step: 644; focal_loss: 0.0093102; l1_loss: 0.021568; total_loss: 0.0308782; examples/sec: 32.2; progress: 53.7%; \n",
      "FastEstimator-Train: step: 645; focal_loss: 0.0062364; l1_loss: 0.0252624; total_loss: 0.0314988; examples/sec: 32.3; progress: 53.8%; \n",
      "FastEstimator-Train: step: 646; focal_loss: 0.0185435; l1_loss: 0.0391285; total_loss: 0.057672; examples/sec: 31.7; progress: 53.8%; \n",
      "FastEstimator-Train: step: 647; focal_loss: 0.134482; l1_loss: 0.0371989; total_loss: 0.1716809; examples/sec: 31.6; progress: 53.9%; \n",
      "[0.604662836 0.124921888 0.109268695 ... 0.0625639856 0.0619937479 0.052852571]\n",
      "[0.48747468 0.190838814 0.162356794 0.0664755106 0.0574393272 0.0531960428]\n",
      "[0.176826537]\n",
      "[0.44397071 0.331448883 0.265671402]\n",
      "[0.851653099 0.261478424 0.259468824 ... 0.100248545 0.0927933156 0.0597774088]\n",
      "[0.69685328 0.403782785 0.291707724 ... 0.0536539555 0.0522602499 0.051651448]\n",
      "[0.0749327242 0.061532557]\n",
      "[0.389792383 0.235071898 0.135432482 0.0685005188 0.0643469691 0.0512720942]\n",
      "[0.0867695808 0.084028393 0.0825324655 ... 0.0720076 0.0616268814 0.050458461]\n",
      "[0.0811600685 0.055767]\n",
      "[0.641899 0.137294441 0.0725855529 ... 0.058103472 0.0574518144 0.0526711643]\n",
      "[0.847691178 0.79652071 0.702023387 ... 0.0550356805 0.0530237854 0.0507938862]\n",
      "[0.604355812 0.535376966 0.454123676 ... 0.0548160076 0.0541634262 0.0511129498]\n",
      "[0.197112828 0.171277523 0.130641222 ... 0.0749912 0.0720054209 0.0573056936]\n",
      "[0.0843618512 0.0754943788 0.0636403859]\n",
      "[0.768991351 0.534109 0.530001223 ... 0.056072861 0.0552062392 0.0544669926]\n",
      "[0.888368726 0.794326305 0.603598714 ... 0.0503759682 0.050345391 0.0503193736]\n",
      "[0.1832214 0.0577918]\n",
      "[0.885127068 0.768537521 0.759153306 ... 0.0508136451 0.0503006 0.0500076413]\n",
      "[0.248215795 0.235170662 0.211063504 ... 0.0637902319 0.0588031411 0.0543442369]\n",
      "[0.119107097 0.0866450667 0.078188777 0.0618010759]\n",
      "[0.0957602561 0.0890301466]\n",
      "[0.161233127 0.10847339 0.103285015 ... 0.0528613329 0.0512622595 0.0509788692]\n",
      "[0.0635573566 0.0542815328 0.0538442135]\n",
      "[0.461317271 0.37152 0.168574899 ... 0.086270988 0.0672644079 0.0517469645]\n",
      "[0.76038909 0.410910368 0.324453086 ... 0.0910918415 0.0720413923 0.0715535]\n",
      "[0.581067264 0.0948270857 0.0534843802 0.0528968275]\n",
      "[0.236348301 0.205694556 0.184873551 0.140560567 0.0787240267]\n",
      "[0.359912246 0.345963061 0.33878082 ... 0.0508149266 0.0502209961 0.0501700938]\n",
      "[0.286459923 0.219660878]\n",
      "[0.154967695 0.113714159 0.0873207152 0.0764696896]\n",
      "[0.824004292 0.721566081 0.581709087 ... 0.0662998259 0.0625158846 0.055924356]\n",
      "[0.822316766 0.387221158 0.350984156 ... 0.0529162884 0.0513438 0.050943315]\n",
      "[0.130156398 0.08238855 0.0510884821]\n",
      "[0.892606616 0.457668453 0.430380791 ... 0.0640583336 0.0604671538 0.0518186688]\n",
      "[0.434915364 0.384187967 0.148944467]\n",
      "[0.92891 0.781354427 0.589497 ... 0.0569604039 0.0522196 0.0520065129]\n",
      "[0.64436543 0.239947349 0.167977899 ... 0.0572140813 0.0539172292 0.0517722666]\n",
      "[0.421058893 0.315067053 0.287394732 ... 0.135938674 0.0592123568 0.0552526712]\n",
      "[0.705469131 0.591228 0.388075054 ... 0.0817757547 0.0804149508 0.0614592731]\n",
      "[0.144619972 0.105141282 0.0899055 ... 0.0645886362 0.0511434972 0.0503676832]\n",
      "[0.136663467 0.084348619]\n",
      "[0.934466839 0.921919584 0.155822277 0.113968968 0.0885532796 0.0698931217]\n",
      "[0.572307527]\n",
      "[0.416772097 0.33263427 0.304637849 ... 0.0569151342 0.0568894744 0.0541636348]\n",
      "[0.134585172 0.133970886 0.124138266 ... 0.109854192 0.0722780824 0.0546087921]\n",
      "[0.522707701]\n",
      "[0.338687241 0.0725604]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 648; epoch: 107; focal_loss: 0.9455283; l1_loss: 0.2666663; total_loss: 1.2121944; \n",
      "FastEstimator-Train: step: 648; focal_loss: 0.0186177; l1_loss: 0.0231196; total_loss: 0.0417373; examples/sec: 32.0; progress: 54.0%; \n",
      "FastEstimator-Train: step: 649; focal_loss: 0.0167173; l1_loss: 0.0209803; total_loss: 0.0376976; examples/sec: 31.9; progress: 54.1%; \n",
      "FastEstimator-Train: step: 650; focal_loss: 0.1281918; l1_loss: 0.02009; total_loss: 0.1482818; examples/sec: 32.0; progress: 54.2%; \n",
      "FastEstimator-Train: step: 651; focal_loss: 0.0094777; l1_loss: 0.0428639; total_loss: 0.0523416; examples/sec: 32.1; progress: 54.2%; \n",
      "FastEstimator-Train: step: 652; focal_loss: 0.0104265; l1_loss: 0.0368777; total_loss: 0.0473042; examples/sec: 32.1; progress: 54.3%; \n",
      "FastEstimator-Train: step: 653; focal_loss: 0.1820564; l1_loss: 0.0489155; total_loss: 0.2309719; examples/sec: 32.2; progress: 54.4%; \n",
      "[0.517591953 0.509489715 0.494909942 ... 0.0557077825 0.0520330071 0.0505967736]\n",
      "[0.772820354 0.223516643 0.160266012 ... 0.0589592457 0.0557826161 0.0532209575]\n",
      "[0.525515556 0.0890821517 0.0861786604 ... 0.0584774613 0.0581568778 0.0506275296]\n",
      "[0.525624573 0.180006742 0.148478806 0.0556074381]\n",
      "[0.200897515]\n",
      "[0.445720255 0.342137158 0.282728791]\n",
      "[0.878897548 0.269088447 0.19759962 ... 0.0915674269 0.0823043883 0.0535170138]\n",
      "[0.417186379 0.364977479 0.260783046 ... 0.055704236 0.0522938073 0.0510688424]\n",
      "[0.0913617611 0.0624941]\n",
      "[0.470356345 0.228418231 0.107267112 ... 0.0732339919 0.0608947873 0.0548875332]\n",
      "[0.131283849 0.0859020054 0.0821555257 ... 0.0608037114 0.0595496 0.0588763654]\n",
      "[0.0875750184 0.0583392978]\n",
      "[0.663926661 0.155308187 0.0913135707 ... 0.0749996901 0.0670734048 0.0508455336]\n",
      "[0.794343948 0.721984088 0.720397234 ... 0.0582352579 0.0513829 0.0508392155]\n",
      "[0.318860173 0.253615469 0.218568385 ... 0.0676502 0.063488245 0.0587417185]\n",
      "[0.233345926 0.178886741 0.142556727 ... 0.0933037698 0.0690812469 0.0612514615]\n",
      "[0.116250277 0.100959569 0.061231643]\n",
      "[0.543167233 0.374763787 0.368915349 ... 0.0507534444 0.0504007638 0.0501104891]\n",
      "[0.861958385 0.760067344 0.591455042 ... 0.0538567305 0.0511425436 0.0508567691]\n",
      "[0.166377723]\n",
      "[0.917291284 0.877178907 0.731229663 ... 0.0610983372 0.0603954494 0.0590838492]\n",
      "[0.390857577 0.386248887 0.245043129 ... 0.100215375 0.0615727305 0.0560283065]\n",
      "[0.104066014 0.074662 0.0591249168 0.0505482256]\n",
      "[0.138047457 0.138010651 0.0800507367]\n",
      "[0.0984157324 0.0969989598 0.0831169784 ... 0.0651665 0.0625020862 0.0558096468]\n",
      "[0.0733985603 0.0548587441 0.0505296588]\n",
      "[0.349130869 0.328041673 0.154196769 ... 0.0558636189 0.050596267 0.0503387451]\n",
      "[0.481435478 0.377614647 0.286123961 0.0933063328 0.0894838274]\n",
      "[0.446931601 0.0921093524 0.0804938078 0.0694422424 0.0563533604 0.052334398]\n",
      "[0.299981713 0.247744173 0.192696244 0.136022061 0.118187368]\n",
      "[0.333171666 0.328527242 0.307058454 ... 0.0521780252 0.0515947938 0.0515221059]\n",
      "[0.47470206 0.372686476]\n",
      "[0.132266611 0.100168765 0.0994395 0.0546218753]\n",
      "[0.697058678 0.671663642 0.476660788 ... 0.0634790957 0.054918021 0.052392751]\n",
      "[0.727918804 0.406580538 0.349150091 ... 0.0571229458 0.0527144074 0.0519304574]\n",
      "[0.115017116 0.0669677258 0.0530709326]\n",
      "[0.391869247 0.38507539 0.383068144 ... 0.0607802868 0.0531214178 0.0524056256]\n",
      "[0.413846314 0.366045952 0.209337503]\n",
      "[0.954483867 0.494633883 0.195755899 ... 0.0624199808 0.0575274825 0.0508907735]\n",
      "[0.501731038 0.230948478 0.170693099 ... 0.064689815 0.0642102659 0.0560439825]\n",
      "[0.464455575 0.344354928 0.302036226 ... 0.238747746 0.148904741 0.0726269484]\n",
      "[0.695561409 0.571313262 0.372502416 ... 0.0522319078 0.0503675044 0.0503478646]\n",
      "[0.140119851 0.0931813419 0.0850314498 ... 0.0818185508 0.0727042258 0.0716316104]\n",
      "[0.173142403 0.0884744525]\n",
      "[0.230925024 0.159335613 0.0971814096 0.0647253096]\n",
      "[0.622773588]\n",
      "[0.526352286 0.304861605 0.285630405 ... 0.0693837702 0.0677242577 0.0541316271]\n",
      "[0.21112451 0.157268226 0.1393511 ... 0.0651436448 0.0553064942 0.0519791245]\n",
      "FastEstimator-Eval: step: 654; epoch: 108; focal_loss: 0.9560089; l1_loss: 0.2953638; total_loss: 1.2513726; \n",
      "FastEstimator-Train: step: 654; focal_loss: 0.0051307; l1_loss: 0.0213453; total_loss: 0.026476; examples/sec: 32.2; progress: 54.5%; \n",
      "FastEstimator-Train: step: 655; focal_loss: 0.012582; l1_loss: 0.0186461; total_loss: 0.0312281; examples/sec: 32.2; progress: 54.6%; \n",
      "FastEstimator-Train: step: 656; focal_loss: 0.3678661; l1_loss: 0.038783; total_loss: 0.4066491; examples/sec: 31.8; progress: 54.7%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 657; focal_loss: 0.0070171; l1_loss: 0.0309625; total_loss: 0.0379796; examples/sec: 32.2; progress: 54.8%; \n",
      "FastEstimator-Train: step: 658; focal_loss: 0.1478654; l1_loss: 0.0221709; total_loss: 0.1700362; examples/sec: 31.7; progress: 54.8%; \n",
      "FastEstimator-Train: step: 659; focal_loss: 0.1013836; l1_loss: 0.0338636; total_loss: 0.1352472; examples/sec: 32.3; progress: 54.9%; \n",
      "[0.357995808]\n",
      "[0.220165908 0.0902354419 0.0728203654 0.0567463934 0.0560470521]\n",
      "[0.500548124 0.465141207 0.423995018 ... 0.0548717678 0.051266104 0.0507295728]\n",
      "[0.353452802 0.273236454 0.248072982 ... 0.0539931953 0.0523068309 0.0504642427]\n",
      "[0.115032852 0.0977292955 0.0892079473 ... 0.0579850078 0.0543335676 0.0532668233]\n",
      "[0.523044586 0.19891122 0.119070858 ... 0.0849818 0.057290554 0.0571349561]\n",
      "[0.158453375]\n",
      "[0.395943969 0.288360655 0.198517501 0.0528742075]\n",
      "[0.918490171 0.410430759 0.32435149 ... 0.0839189887 0.0818698704 0.0556947]\n",
      "[0.439076781 0.241383374 0.23472774 ... 0.0530370772 0.0517323315 0.0502407551]\n",
      "[0.127734214 0.0604242086]\n",
      "[0.438315094 0.161022931 0.1133928 ... 0.0544986129 0.053042233 0.0511313975]\n",
      "[0.265909553 0.261695504 0.135389209 0.0718395412 0.0561049879]\n",
      "[0.114679486]\n",
      "[0.603912532 0.268089503 0.0688417554 0.0604791641]\n",
      "[0.681530476 0.590700567 0.550354123 ... 0.0531047285 0.0518760383 0.0509013534]\n",
      "[0.247982979 0.204573423 0.179503202 ... 0.0816918612 0.0773292482 0.0736503601]\n",
      "[0.350933105 0.350265771 0.186534226 ... 0.0612637103 0.0548860133 0.0526283681]\n",
      "[0.276019633 0.226093531]\n",
      "[0.681268692 0.330579877 0.28029716 ... 0.0531146228 0.0526341498 0.0517530143]\n",
      "[0.484721184 0.285057068 0.21375078 ... 0.073530525 0.0574750602 0.0503663719]\n",
      "[0.385342479 0.122191429 0.0518044233]\n",
      "[0.880949616 0.657624304 0.536794305 ... 0.0531626344 0.0516467392 0.0504897237]\n",
      "[0.512278497 0.447988629 0.204088241 ... 0.088919282 0.0860540569 0.0569228828]\n",
      "[0.188750952 0.0513221622]\n",
      "[0.337903202 0.309576571 0.125965863]\n",
      "[0.307390571 0.265606344 0.211189687 ... 0.0599530637 0.0554848313 0.0539720953]\n",
      "[0.0782847404 0.0709118843]\n",
      "[0.180827498 0.169803202 0.0700835586 ... 0.0632424057 0.0623233616 0.0521360338]\n",
      "[0.348871231 0.153663814 0.12861225]\n",
      "[0.330394864 0.310970545 0.259661734 0.0797029138 0.0690220594]\n",
      "[0.239745706 0.209948629 0.169651747 0.147114217 0.124782592]\n",
      "[0.605384946 0.424173117 0.317453712 ... 0.0522981882 0.0515025258 0.0500406921]\n",
      "[0.606908381 0.592662454 0.115076929 ... 0.0738341212 0.0560343266 0.0534275472]\n",
      "[0.212779373 0.113227695 0.0548446476]\n",
      "[0.64258945 0.544852734 0.091950953 0.0649089515 0.0637823641 0.0576275]\n",
      "[0.45170781 0.380366653 0.359442532 ... 0.0555431545 0.0507378578 0.050000757]\n",
      "[0.160600543 0.14429152 0.0783509314 0.0636226833]\n",
      "[0.468627721 0.461088955 0.325031817 ... 0.0595209301 0.0549534857 0.0541563928]\n",
      "[0.324387372 0.293781102 0.226846725]\n",
      "[0.271377206 0.187896073 0.18127501 ... 0.081677556 0.052716732 0.0524068177]\n",
      "[0.358702242 0.35691613 0.191333055 ... 0.063041091 0.0540764928 0.0527738035]\n",
      "[0.600605786 0.481060505 0.416132629 ... 0.346775234 0.261232734 0.113511831]\n",
      "[0.764220834 0.437562019 0.436939359 ... 0.053401053 0.0524613261 0.0507186353]\n",
      "[0.142110318 0.0931990743 0.0734619796 0.0558726788]\n",
      "[0.374115527 0.220467895 0.0549972057]\n",
      "[0.43421492 0.10519436 0.0514886975]\n",
      "[0.50225246]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 660; epoch: 109; focal_loss: 0.7242996; l1_loss: 0.2886615; total_loss: 1.0129611; \n",
      "FastEstimator-Train: step: 660; focal_loss: 0.2150048; l1_loss: 0.0597413; total_loss: 0.2747462; examples/sec: 31.5; progress: 55.0%; \n",
      "FastEstimator-Train: step: 661; focal_loss: 0.2195611; l1_loss: 0.0527894; total_loss: 0.2723504; examples/sec: 32.3; progress: 55.1%; \n",
      "FastEstimator-Train: step: 662; focal_loss: 0.1839271; l1_loss: 0.0277807; total_loss: 0.2117077; examples/sec: 32.3; progress: 55.2%; \n",
      "FastEstimator-Train: step: 663; focal_loss: 0.0939276; l1_loss: 0.020419; total_loss: 0.1143466; examples/sec: 32.3; progress: 55.2%; \n",
      "FastEstimator-Train: step: 664; focal_loss: 0.0377375; l1_loss: 0.0373309; total_loss: 0.0750684; examples/sec: 32.0; progress: 55.3%; \n",
      "FastEstimator-Train: step: 665; focal_loss: 0.2357869; l1_loss: 0.0255217; total_loss: 0.2613086; examples/sec: 32.2; progress: 55.4%; \n",
      "[0.372832626 0.331496686 0.305401981 ... 0.0633860528 0.054684639 0.0546788275]\n",
      "[0.292206705 0.255612701 0.233811796 ... 0.102473259 0.0581231713 0.0567826629]\n",
      "[0.460640848 0.0976055861]\n",
      "[0.261238307 0.176356882 0.161361635 ... 0.0942521691 0.0882339478 0.0846348107]\n",
      "[0.657586813 0.640027642 0.612769604 ... 0.0550800264 0.0539897084 0.0527283847]\n",
      "[0.838484168 0.618188 0.463613689 ... 0.0614847839 0.0531564653 0.0522972941]\n",
      "[0.359887064 0.247603178 0.166302502 ... 0.0774597824 0.0681222379 0.0557415187]\n",
      "[0.61380887 0.252867073 0.217436105 ... 0.084404707 0.07330212 0.0628899038]\n",
      "[0.226436883]\n",
      "[0.531394601 0.321884841 0.233373672 0.169353008 0.0559459031]\n",
      "[0.862587452 0.414592475 0.350511193 ... 0.068672955 0.0591709614 0.0523982942]\n",
      "[0.74957329 0.509777248 0.268920213 ... 0.0528866649 0.0517490208 0.0508197248]\n",
      "[0.141140789 0.0733973682 0.0650807321]\n",
      "[0.76753056 0.332586139 0.141077548 ... 0.0576162636 0.0562747717 0.0530881]\n",
      "[0.416168094 0.230372518 0.157288611 ... 0.0903044641 0.0672644079 0.0588917434]\n",
      "[0.484340549 0.103555828 0.0598839223]\n",
      "[0.687847674 0.270827413 0.143723696 0.085495472 0.0560829341 0.0536404252]\n",
      "[0.672636628 0.635088086 0.630184 ... 0.0546930134 0.0526483357 0.0502073765]\n",
      "[0.608472288 0.490839899 0.458699971 ... 0.0533077121 0.0511487722 0.0510113835]\n",
      "[0.677533269 0.594226956 0.426673472 ... 0.0697877407 0.0650273 0.0592763126]\n",
      "[0.395555705 0.337117374 0.115834713 0.0679501 0.0539856851]\n",
      "[0.917468071 0.782443166 0.649168611 ... 0.0510976315 0.0505472422 0.0501405895]\n",
      "[0.562328219 0.4515706 0.356200874 ... 0.0530609488 0.0522011817 0.0521481037]\n",
      "[0.611900032 0.49474448]\n",
      "[0.790944338 0.619503736 0.429575086 ... 0.0515873134 0.0505610406 0.0504104495]\n",
      "[0.341672122 0.243337899 0.219053626 ... 0.105542004 0.0992818773 0.0673406124]\n",
      "[0.720652699 0.119876236 0.0686015487 0.0655571818 0.0618033409 0.0554175675]\n",
      "[0.376004249 0.291019678]\n",
      "[0.494060069 0.432084918 0.377094448 ... 0.0669560134 0.0613159239 0.0531742573]\n",
      "[0.170224458 0.115751714 0.0573696792 0.0565260053 0.0536572933]\n",
      "[0.307688266 0.283178329 0.267944694 ... 0.057913959 0.0557586849 0.0500172377]\n",
      "[0.349833935 0.240190446 0.166931123]\n",
      "[0.953077078 0.835086465 0.531195462 0.139316678 0.124807239 0.0509431064]\n",
      "[0.517260849 0.385570645 0.332855344 0.237330019 0.207404315 0.0503289402]\n",
      "[0.375103951 0.323839664 0.298961282 ... 0.0516022444 0.0509602726 0.0508342087]\n",
      "[0.348218292 0.299957454 0.133668572 ... 0.055731 0.0537203848 0.0518368483]\n",
      "[0.0755701065 0.0627639592 0.051912576]\n",
      "[0.828591 0.42724 0.39895457 ... 0.0546103418 0.0533006489 0.0518056452]\n",
      "[0.22163105 0.214068681 0.211197346 ... 0.0522468686 0.0517539978 0.051046133]\n",
      "[0.477438062 0.270802796 0.185849488 0.0684026182]\n",
      "[0.779388428 0.390283614 0.370563447 ... 0.0597957969 0.0524950922 0.0503259599]\n",
      "[0.615912676 0.556180298 0.140640497 ... 0.109665632 0.0988702476 0.0708390176]\n",
      "[0.212993622 0.180454165 0.177667528 ... 0.0749212801 0.0572528839 0.0532477796]\n",
      "[0.766016126 0.503115356 0.356343955 ... 0.0807718635 0.0677982569 0.0506099463]\n",
      "[0.877807 0.710805893 0.552339852 ... 0.0902450383 0.0621242821 0.0594192147]\n",
      "[0.429056585 0.350423872 0.323395699 ... 0.0580948889 0.0558233559 0.0501094759]\n",
      "[0.136378407 0.0747685432 0.0731176436 0.0689330399 0.0682918429]\n",
      "[0.81904161 0.387479931 0.122798085 0.0677078664 0.0563578]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 666; epoch: 110; focal_loss: 0.830808; l1_loss: 0.1513729; total_loss: 0.9821809; \n",
      "FastEstimator-Train: step: 666; focal_loss: 0.0507719; l1_loss: 0.0837024; total_loss: 0.1344744; examples/sec: 31.6; progress: 55.5%; \n",
      "FastEstimator-Train: step: 667; focal_loss: 0.1585772; l1_loss: 0.0334404; total_loss: 0.1920176; examples/sec: 32.2; progress: 55.6%; \n",
      "FastEstimator-Train: step: 668; focal_loss: 0.1206241; l1_loss: 0.0211244; total_loss: 0.1417484; examples/sec: 32.1; progress: 55.7%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 669; focal_loss: 0.1795622; l1_loss: 0.0430481; total_loss: 0.2226103; examples/sec: 32.1; progress: 55.8%; \n",
      "FastEstimator-Train: step: 670; focal_loss: 0.3504708; l1_loss: 0.0494707; total_loss: 0.3999415; examples/sec: 32.3; progress: 55.8%; \n",
      "FastEstimator-Train: step: 671; focal_loss: 0.0630338; l1_loss: 0.0469104; total_loss: 0.1099442; examples/sec: 32.2; progress: 55.9%; \n",
      "[0.665555537 0.495239645 0.190000892 ... 0.0526860058 0.0513363183 0.0508416]\n",
      "[0.597489417]\n",
      "[0.302581102 0.296740711 0.283842802 ... 0.0514186323 0.0512779355 0.0507778227]\n",
      "[0.514990747 0.357604325 0.315797031 ... 0.0624733269 0.0578773618 0.0529994369]\n",
      "[0.440436602 0.0784002841]\n",
      "[0.282199919 0.276283026 0.164988637 ... 0.0631274879 0.0624605417 0.0602733493]\n",
      "[0.429455549 0.375192702 0.313664734 ... 0.0539202094 0.0527746081 0.0506733358]\n",
      "[0.670324683 0.620925 0.402837902 ... 0.0513035059 0.0507264733 0.0507079363]\n",
      "[0.293321669 0.273479551 0.224496782 ... 0.0554335713 0.0539876819 0.0526386797]\n",
      "[0.791993618 0.535897 0.321559846 ... 0.0545427203 0.0537961721 0.0500734448]\n",
      "[0.119811833 0.0559195578 0.0503750443]\n",
      "[0.449382126 0.389202684 0.368517101 ... 0.0546520352 0.0545128584 0.0532136559]\n",
      "[0.903226852 0.484555155 0.396341145 ... 0.0690278113 0.0682112277 0.0518210232]\n",
      "[0.77635324 0.618536055 0.509010315 ... 0.0527022779 0.0524199 0.0511873662]\n",
      "[0.205382466 0.0818753839]\n",
      "[0.38772136 0.363491774 0.226759464 ... 0.0565598905 0.0555957854 0.0544695258]\n",
      "[0.333024144 0.275255322 0.219895661 ... 0.0576483 0.0554268658 0.0511351526]\n",
      "[0.353230119 0.136108875 0.0710397959]\n",
      "[0.749585509 0.374465942 0.275165975 ... 0.0749557614 0.0708890557 0.0577553809]\n",
      "[0.617609262 0.399629951 0.374108374 ... 0.0534717739 0.0528410971 0.0511611104]\n",
      "[0.599697 0.524431288 0.447390497 ... 0.0567874 0.0531261265 0.0505497754]\n",
      "[0.537775159 0.419699281 0.349958718 ... 0.0540264547 0.0519554913 0.0509900451]\n",
      "[0.447844058 0.237707704 0.112168729 0.0825181603 0.074575156 0.0733538568]\n",
      "[0.716879606 0.670268595 0.63761282 ... 0.0512514412 0.0509598255 0.0503342748]\n",
      "[0.496493638 0.432927728 0.2768296 ... 0.0520435572 0.0512280166 0.0506014228]\n",
      "[0.76401186 0.741209447 0.0818867385 0.0733051 0.0634682477 0.0517295301]\n",
      "[0.795980811 0.408539653 0.398235619 ... 0.0529906154 0.0529750288 0.0504318774]\n",
      "[0.77258563 0.630141735 0.408742726 ... 0.0739129484 0.0678838193 0.0614655]\n",
      "[0.64947927 0.0573954 0.0514725149]\n",
      "[0.559954822 0.491160125 0.308242828 0.059402436]\n",
      "[0.53138876 0.344049543 0.272648335 ... 0.0560504496 0.0560494959 0.0512752533]\n",
      "[0.41091013 0.134979457 0.107317358 0.10343951 0.0572603047]\n",
      "[0.250501037 0.197573155 0.143947959 ... 0.0637447238 0.058937639 0.054151535]\n",
      "[0.503106296 0.227459699 0.198401541 ... 0.0585185885 0.0531927049 0.0528466702]\n",
      "[0.70149225 0.607289672 0.59541 ... 0.0656712055 0.0622863173 0.0613128841]\n",
      "[0.485639125 0.440205693 0.430007935 ... 0.241231233 0.0613962114 0.0602631271]\n",
      "[0.589323342 0.403009534 0.309370309 ... 0.0508127213 0.0506597459 0.0501995087]\n",
      "[0.607518196 0.597825527 0.517836273 ... 0.0822813511 0.0550974 0.0527695119]\n",
      "[0.389676839 0.134416014 0.12056008 ... 0.070682168 0.0568104684 0.0502968132]\n",
      "[0.626558185 0.623457789 0.472053945 ... 0.0640199184 0.0564386845 0.0525837243]\n",
      "[0.652632833 0.587514818 0.571537 ... 0.0516651571 0.0514550209 0.05074507]\n",
      "[0.374674737 0.313056976 0.135014951 0.121326983 0.093190223]\n",
      "[0.808295131 0.579748631 0.561214685 ... 0.0642341375 0.0585213602 0.0548159778]\n",
      "[0.678772807 0.559862256 0.325352967 0.0713793039]\n",
      "[0.29223296 0.221274346 0.200080574 ... 0.0584929287 0.0580937564 0.0580515563]\n",
      "[0.498983026 0.470507681 0.388356119 ... 0.0622940361 0.0535487235 0.0507873595]\n",
      "[0.714320123 0.511534333 0.489524722 ... 0.0591856539 0.0572242737 0.056219846]\n",
      "[0.693654358 0.631834924 0.360873342 ... 0.050814271 0.0507200956 0.0504119396]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 672; epoch: 111; focal_loss: 0.5543328; l1_loss: 0.1961285; total_loss: 0.7504613; \n",
      "FastEstimator-Train: step: 672; focal_loss: 0.083348; l1_loss: 0.0416544; total_loss: 0.1250024; examples/sec: 31.6; progress: 56.0%; \n",
      "FastEstimator-Train: step: 673; focal_loss: 0.0993884; l1_loss: 0.0515582; total_loss: 0.1509466; examples/sec: 32.6; progress: 56.1%; \n",
      "FastEstimator-Train: step: 674; focal_loss: 0.1835366; l1_loss: 0.050285; total_loss: 0.2338216; examples/sec: 32.1; progress: 56.2%; \n",
      "FastEstimator-Train: step: 675; focal_loss: 0.0848655; l1_loss: 0.0434618; total_loss: 0.1283273; examples/sec: 32.2; progress: 56.2%; \n",
      "FastEstimator-Train: step: 676; focal_loss: 0.1954767; l1_loss: 0.0408885; total_loss: 0.2363652; examples/sec: 32.1; progress: 56.3%; \n",
      "FastEstimator-Train: step: 677; focal_loss: 0.0842199; l1_loss: 0.0197446; total_loss: 0.1039645; examples/sec: 32.2; progress: 56.4%; \n",
      "[0.17686078 0.152508438 0.122718006 ... 0.0541133583 0.0509161055 0.0506005]\n",
      "[0.69653964 0.271757364 0.118721038 ... 0.0557570457 0.0523152053 0.0522126555]\n",
      "[0.743869722 0.423353016 0.371803075 ... 0.0526495278 0.0512882471 0.0500722229]\n",
      "[0.482622355]\n",
      "[0.412687 0.327462673 0.309294701 ... 0.0512283146 0.0511192083 0.0502419472]\n",
      "[0.376447499 0.292616546 0.228310138 ... 0.0541664064 0.0518100262 0.0506828427]\n",
      "[0.38834843 0.0534407794 0.0531146526]\n",
      "[0.412085801 0.327969134 0.202341408 ... 0.0909397304 0.0752954781 0.0640587211]\n",
      "[0.600944102 0.53764689 0.519176722 ... 0.0515337288 0.0515045524 0.0507944226]\n",
      "[0.76969 0.714416206 0.489654481 ... 0.053252697 0.0527358353 0.052235961]\n",
      "[0.559934855 0.486970633 0.261564046 ... 0.0539504886 0.0517747104 0.0502464771]\n",
      "[0.934226 0.409987628 0.401341885 ... 0.0519816 0.0509538352 0.0507973731]\n",
      "[0.232092291]\n",
      "[0.4504098 0.445005178 0.181946516 ... 0.067062825 0.0583709478 0.0561552346]\n",
      "[0.896026492 0.439241558 0.430303752 ... 0.0576665103 0.0527764261 0.052226454]\n",
      "[0.705652893 0.655518293 0.606764913 ... 0.0515645444 0.0511360466 0.0504252911]\n",
      "[0.158474624 0.102877557 0.0802449 0.0667468309 0.0659378469]\n",
      "[0.371632159 0.26996094 0.238413334 ... 0.0510278344 0.0509257317 0.0506803691]\n",
      "[0.531276107 0.482571512 0.17260918 ... 0.0604397953 0.0567342043 0.0509652793]\n",
      "[0.270620763 0.259668291 0.0693378448 0.0542506874 0.050608784]\n",
      "[0.703367352 0.627988935 0.220235229 ... 0.0622573793 0.061442703 0.0579665899]\n",
      "[0.523444235 0.470597267 0.460391849 ... 0.0513743162 0.0512523055 0.051188916]\n",
      "[0.571434259 0.472290695 0.414182365 ... 0.0504241 0.050375998 0.0500501096]\n",
      "[0.513984382 0.4132725 0.368617088 ... 0.0988758802 0.0871419609 0.0684412718]\n",
      "[0.481313825 0.363066792 0.127492726 ... 0.0545360446 0.0542545319 0.0521483123]\n",
      "[0.764115214 0.65023458 0.632938564 ... 0.0522763729 0.0507785082 0.0502268374]\n",
      "[0.606654 0.525092363 0.469556838 ... 0.0502400696 0.0502383709 0.0502036512]\n",
      "[0.969337583 0.645715415 0.133057266 0.103133023 0.101459563 0.0536755323]\n",
      "[0.733093262 0.555098116 0.498358 ... 0.0522509813 0.0521137714 0.0504678488]\n",
      "[0.903918386 0.861017108 0.633958817 ... 0.0554042459 0.0544047356 0.0513437092]\n",
      "[0.484726906 0.0789413154 0.0767619908 0.0521236658]\n",
      "[0.734573722 0.564692 0.0584184825 0.0515406132 0.0515142381]\n",
      "[0.729623616 0.437279 0.435656607 ... 0.0528867841 0.0516891778 0.0504936576]\n",
      "[0.474155962 0.234555304 0.117649227 0.0970523953 0.0915960073 0.0511851609]\n",
      "[0.435511827 0.314446568 0.279196441 ... 0.0637540519 0.0562418401 0.0512595177]\n",
      "[0.400168926 0.333065391 0.300989211 ... 0.057395339 0.0547045171 0.0511600971]\n",
      "[0.670850873 0.668924 0.660547137 ... 0.0760208666 0.0722780526 0.0708329082]\n",
      "[0.363223493 0.349442244 0.330675781 0.218397886 0.183894634]\n",
      "[0.500273108 0.440902591 0.42594263 ... 0.0722067356 0.0720270276 0.0718568265]\n",
      "[0.729121 0.647761106 0.597625315 ... 0.0709750354 0.067638725 0.0624685884]\n",
      "[0.200147122 0.140703708 0.119918793 ... 0.070674777 0.0661730766 0.0593073368]\n",
      "[0.884283483 0.48789379 0.370634973 ... 0.0660458505 0.0522499681 0.0509048402]\n",
      "[0.820656061 0.713347495 0.61230731 ... 0.0727230608 0.0721873343 0.0715013146]\n",
      "[0.417570531 0.339482844 0.17729184 ... 0.0657551885 0.0595520735 0.0551938117]\n",
      "[0.85692203 0.645149946 0.601063 ... 0.059470892 0.0564172566 0.0523029268]\n",
      "[0.573942542 0.563352287 0.237359434 ... 0.0825941563 0.0790261924 0.0530466437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.178957254 0.157964438 0.152145118 ... 0.053682059 0.0513151586 0.0503518283]\n",
      "[0.668167293 0.573023677 0.448783427 ... 0.0565038025 0.0555054247 0.0548448563]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 678; epoch: 112; focal_loss: 0.4312356; l1_loss: 0.1728827; total_loss: 0.6041182; \n",
      "FastEstimator-Train: step: 678; focal_loss: 0.1905103; l1_loss: 0.0224558; total_loss: 0.2129661; examples/sec: 32.3; progress: 56.5%; \n",
      "FastEstimator-Train: step: 679; focal_loss: 0.0600124; l1_loss: 0.0268528; total_loss: 0.0868652; examples/sec: 32.4; progress: 56.6%; \n",
      "FastEstimator-Train: step: 680; focal_loss: 0.1739495; l1_loss: 0.0375581; total_loss: 0.2115076; examples/sec: 32.2; progress: 56.7%; \n",
      "FastEstimator-Train: step: 681; focal_loss: 0.0755624; l1_loss: 0.0533691; total_loss: 0.1289315; examples/sec: 32.3; progress: 56.8%; \n",
      "FastEstimator-Train: step: 682; focal_loss: 0.0422541; l1_loss: 0.0195261; total_loss: 0.0617802; examples/sec: 32.1; progress: 56.8%; \n",
      "FastEstimator-Train: step: 683; focal_loss: 0.0829963; l1_loss: 0.0270832; total_loss: 0.1100795; examples/sec: 32.2; progress: 56.9%; \n",
      "[0.911796689 0.826358199 0.71535331 ... 0.0615732968 0.0552188158 0.0513519943]\n",
      "[0.715768337 0.643318892 0.490414709 ... 0.0524539351 0.0523430407 0.0519061089]\n",
      "[0.317989588 0.305432975 0.248855233 ... 0.057551682 0.0562612414 0.0542700887]\n",
      "[0.770302892 0.436645389 0.136813015 ... 0.0641020834 0.0632199645 0.0507104695]\n",
      "[0.534586668 0.302695274 0.277277976 ... 0.0524972081 0.0520301163 0.0510382652]\n",
      "[0.503824055]\n",
      "[0.479626149 0.448159754 0.423862875 ... 0.0510007143 0.0509233177 0.050571084]\n",
      "[0.36869067 0.318374515 0.312645137 ... 0.0554231405 0.0510688126 0.0508069098]\n",
      "[0.254508108 0.0704380572]\n",
      "[0.433184206 0.353444934 0.147263706 ... 0.0646489859 0.0582260787 0.0576558113]\n",
      "[0.688090563 0.651667178 0.610548139 ... 0.0558888316 0.0517780483 0.051353097]\n",
      "[0.838287055 0.708283424 0.650492609 ... 0.0508378148 0.0505823493 0.0503549576]\n",
      "[0.467815489 0.35153389 0.303234 ... 0.058146894 0.057502 0.0542644262]\n",
      "[0.309999943 0.186960876 0.125239521 ... 0.0523046255 0.0516335964 0.0504671633]\n",
      "[0.248701155]\n",
      "[0.475678355 0.376185715 0.25051111 ... 0.0903247595 0.06848827 0.0548977852]\n",
      "[0.913125753 0.591806531 0.510267 ... 0.054415524 0.0542730689 0.0530011654]\n",
      "[0.848699 0.626826882 0.532389879 ... 0.0502709746 0.0501343906 0.0500668585]\n",
      "[0.257277489 0.102121115 0.0684436262 0.0677032471 0.0650001764 0.0626856387]\n",
      "[0.323270202 0.256446838 0.23933661 ... 0.0512571335 0.0509009063 0.050494194]\n",
      "[0.64748317 0.47493583 0.359718382 ... 0.0516968071 0.0511842072 0.0505558848]\n",
      "[0.386661589 0.245186865 0.0755983591 0.0546972454 0.0544546247]\n",
      "[0.608431041 0.460907906 0.264690518 ... 0.0621754825 0.0569855273 0.0567623675]\n",
      "[0.692828 0.656770289 0.646886945 ... 0.0600119829 0.059753567 0.0592054725]\n",
      "[0.566497445 0.485736549 0.484779179 ... 0.0520725846 0.0518196523 0.0511951149]\n",
      "[0.863389254 0.847667933 0.768758595 ... 0.0655231178 0.0606078207 0.0567988753]\n",
      "[0.384619027 0.34035635 0.107506752 ... 0.0637508929 0.0606539845 0.0577211082]\n",
      "[0.777892292 0.673656642 0.585129261 ... 0.0562034547 0.0556511283 0.0556380451]\n",
      "[0.500794411 0.44042626 0.395092487 ... 0.0555919707 0.0549243689 0.0544346273]\n",
      "[0.98298192 0.698411107 0.153633863 ... 0.0907861888 0.0605130196 0.050016731]\n",
      "[0.915292 0.855639875 0.49445951 ... 0.0511484146 0.0504534543 0.0502515137]\n",
      "[0.716765463 0.682158947 0.443186074 ... 0.0515485704 0.0513781607 0.051153183]\n",
      "[0.731338 0.0948964655]\n",
      "[0.751036942 0.608511031 0.0598215163 0.0572212636]\n",
      "[0.886426032 0.838195086 0.686984241 ... 0.0531386435 0.0521971881 0.0508570373]\n",
      "[0.485457242 0.271349907 0.0802849829 ... 0.0541701615 0.0510795712 0.0506331027]\n",
      "[0.305977106 0.249861 0.22247687 ... 0.0612314343 0.0557394326 0.0537010729]\n",
      "[0.357277542 0.284870625 0.23197946 ... 0.0579861403 0.0566686392 0.0501519442]\n",
      "[0.823553801 0.796614885 0.720672131 ... 0.0559874177 0.0532684326 0.0527506471]\n",
      "[0.408115864 0.395909071 0.370518506 0.272785 0.195587337]\n",
      "[0.60329473 0.566890955 0.42810896 ... 0.0953382254 0.0953027904 0.0947767496]\n",
      "[0.718822 0.682436287 0.645777166 ... 0.0589296818 0.0510118902 0.0505175591]\n",
      "[0.27150619 0.196314782 0.145797879 ... 0.0566397309 0.0550230145 0.0514262915]\n",
      "[0.782005191 0.420956731 0.39635095 ... 0.0515539348 0.0514622033 0.050948143]\n",
      "[0.651674628 0.528711498 0.521338224 ... 0.069755584 0.0694180429 0.0689267218]\n",
      "[0.369241446 0.270542324 0.169578254 ... 0.0584910512 0.0555574894 0.0548101664]\n",
      "[0.713122666 0.682858825 0.578482032 ... 0.0595051348 0.053615272 0.0506047308]\n",
      "[0.601088524 0.570913136 0.327185392 ... 0.0862502456 0.0849258304 0.0518811047]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 684; epoch: 113; focal_loss: 0.3598683; l1_loss: 0.1506804; total_loss: 0.5105486; \n",
      "FastEstimator-Train: step: 684; focal_loss: 0.161966; l1_loss: 0.057707; total_loss: 0.219673; examples/sec: 31.9; progress: 57.0%; \n",
      "FastEstimator-Train: step: 685; focal_loss: 0.1457639; l1_loss: 0.0439676; total_loss: 0.1897315; examples/sec: 32.5; progress: 57.1%; \n",
      "FastEstimator-Train: step: 686; focal_loss: 0.1650683; l1_loss: 0.0723245; total_loss: 0.2373928; examples/sec: 31.8; progress: 57.2%; \n",
      "FastEstimator-Train: step: 687; focal_loss: 0.0629729; l1_loss: 0.0238176; total_loss: 0.0867904; examples/sec: 32.3; progress: 57.2%; \n",
      "FastEstimator-Train: step: 688; focal_loss: 0.0685634; l1_loss: 0.0476459; total_loss: 0.1162093; examples/sec: 32.2; progress: 57.3%; \n",
      "FastEstimator-Train: step: 689; focal_loss: 0.1687981; l1_loss: 0.0276045; total_loss: 0.1964025; examples/sec: 32.1; progress: 57.4%; \n",
      "[0.224155217 0.209630758 0.151243508 ... 0.0527214408 0.0506072938 0.050357312]\n",
      "[0.549386919 0.522354364 0.439928293 ... 0.0511470735 0.0509651 0.0508595705]\n",
      "[0.700380921 0.647525847 0.581615567 ... 0.0565043688 0.0560742617 0.0505709052]\n",
      "[0.640477896 0.529583454 0.394632965 ... 0.0528894365 0.0527511835 0.0527368188]\n",
      "[0.611620903 0.59991461 0.407208055 ... 0.0511257946 0.0508615375 0.0503197312]\n",
      "[0.679501653 0.269269407 0.0990222394 ... 0.0626760721 0.0581454337 0.052580595]\n",
      "[0.839243293 0.693611085 0.303864866 ... 0.0544966757 0.0520524979 0.0503207743]\n",
      "[0.562145293]\n",
      "[0.459600866 0.398853421 0.390897095 ... 0.0502996147 0.0500481427 0.0500002503]\n",
      "[0.437042236 0.29899016 0.248648167 ... 0.0572810769 0.0527904034 0.0521474779]\n",
      "[0.366318315 0.0891615152 0.0579663515]\n",
      "[0.254720926 0.176235229 0.110189229 ... 0.0556889772 0.053951472 0.0504264235]\n",
      "[0.791549683 0.772649109 0.760837615 ... 0.0513792932 0.0507445633 0.0503532]\n",
      "[0.68305403 0.668600321 0.620653629 ... 0.0510664284 0.0503748357 0.0500441492]\n",
      "[0.540437877 0.210909188 0.207113445 ... 0.0518910289 0.0516730845 0.0504671037]\n",
      "[0.531382 0.364515305 0.249979526 ... 0.0502520204 0.0502341092 0.050231427]\n",
      "[0.325351894]\n",
      "[0.631182 0.615392 0.267774522 0.0629515052 0.0590268672]\n",
      "[0.923655033 0.649750531 0.591607571 ... 0.0518283248 0.0512904525 0.0501679778]\n",
      "[0.517377138 0.472779632 0.402365625 ... 0.0516538322 0.0515261292 0.0511551499]\n",
      "[0.411827832 0.161060661 0.118960768 ... 0.0854869187 0.0581295192 0.0548881292]\n",
      "[0.612346888 0.400638163 0.36828357 ... 0.0597390234 0.0596191287 0.0584387183]\n",
      "[0.411821723 0.373523623 0.203054488 ... 0.0734562 0.0607392192 0.0580855608]\n",
      "[0.199160904 0.126310796 0.0819067061]\n",
      "[0.827529848 0.371511638 0.256032 ... 0.056483835 0.0517992377 0.0511460602]\n",
      "[0.788532495 0.774674118 0.758503675 ... 0.0796475708 0.0795339346 0.0792760849]\n",
      "[0.702742815 0.694271863 0.663663745 ... 0.0506211221 0.0505823493 0.0504902]\n",
      "[0.572547495 0.520704091 0.465961844 ... 0.0607079864 0.0514883697 0.0500889122]\n",
      "[0.410512209 0.18283549 0.158997744 ... 0.0557335317 0.0554149747 0.0502993464]\n",
      "[0.719103217 0.711468399 0.629742265 ... 0.0547177196 0.053876996 0.0536351204]\n",
      "[0.463716149 0.428879052 0.33669579 ... 0.059450984 0.0593445599 0.058997333]\n",
      "[0.938164711 0.561846673 0.0779777467 ... 0.0675959 0.0578408837 0.0503538847]\n",
      "[0.864232779 0.592505634 0.395399183 ... 0.0523581207 0.0506477058 0.0503632128]\n",
      "[0.386697978 0.37901774 0.350940645 ... 0.050260216 0.0501000285 0.0500463843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.721422672 0.0694773793 0.0670466125 ... 0.060680747 0.0570817292 0.056370616]\n",
      "[0.564496517 0.466301829 0.158254862 0.0657308102 0.0534073412]\n",
      "[0.773056388 0.501619101 0.480591863 ... 0.0520426333 0.0519253314 0.0502451062]\n",
      "[0.207465321 0.106231689 0.101066202 ... 0.0711268187 0.0609183311 0.0500826836]\n",
      "[0.452251017 0.414142817 0.265720844 ... 0.0514279 0.0509253442 0.050886631]\n",
      "[0.487859368 0.396845281 0.285999417 ... 0.0528683662 0.0521899462 0.0502327383]\n",
      "[0.83436209 0.810677171 0.804888964 ... 0.0819424093 0.0717371702 0.0506022871]\n",
      "[0.178875595 0.177881718 0.175676286 0.137518495 0.0890050232 0.0655146539]\n",
      "[0.638229609 0.637545705 0.525219381 ... 0.0800782144 0.0799779892 0.079949975]\n",
      "[0.419492126 0.306917548 0.294177622 ... 0.0685270429 0.06278494 0.0538773239]\n",
      "[0.314388245 0.294000268 0.198050797 ... 0.0506145656 0.0501817763 0.050098896]\n",
      "[0.406025231 0.243697941 0.219046324 ... 0.0527008772 0.0520302057 0.050506413]\n",
      "[0.673157752 0.5148049 0.475925237 ... 0.0921224952 0.0911407471 0.0910877883]\n",
      "[0.350154757 0.227319717 0.155920029 ... 0.0664459765 0.0514252186 0.050838232]\n",
      "FastEstimator-Eval: step: 690; epoch: 114; focal_loss: 0.2948056; l1_loss: 0.226555; total_loss: 0.5213604; \n",
      "FastEstimator-Train: step: 690; focal_loss: 0.0507374; l1_loss: 0.047901; total_loss: 0.0986384; examples/sec: 32.3; progress: 57.5%; \n",
      "FastEstimator-Train: step: 691; focal_loss: 0.1030322; l1_loss: 0.0898937; total_loss: 0.1929259; examples/sec: 32.5; progress: 57.6%; \n",
      "FastEstimator-Train: step: 692; focal_loss: 0.0563734; l1_loss: 0.0682678; total_loss: 0.1246412; examples/sec: 31.9; progress: 57.7%; \n",
      "FastEstimator-Train: step: 693; focal_loss: 0.0646522; l1_loss: 0.0319818; total_loss: 0.0966339; examples/sec: 32.0; progress: 57.8%; \n",
      "FastEstimator-Train: step: 694; focal_loss: 0.083315; l1_loss: 0.0259064; total_loss: 0.1092214; examples/sec: 32.0; progress: 57.8%; \n",
      "FastEstimator-Train: step: 695; focal_loss: 0.0979368; l1_loss: 0.0916462; total_loss: 0.189583; examples/sec: 32.3; progress: 57.9%; \n",
      "[0.813203335 0.736734211 0.585189342 ... 0.0588910282 0.0551915765 0.0513710082]\n",
      "[0.795628548 0.705333471 0.2667045 ... 0.0711615384 0.0634235442 0.0527719557]\n",
      "[0.310256 0.304381579 0.303394318 ... 0.059730649 0.0543426573 0.0536426]\n",
      "[0.739968061 0.706847847 0.645617425 ... 0.0585592687 0.0577272773 0.0574839711]\n",
      "[0.854953408 0.78516978 0.673282087 ... 0.0656468 0.055796653 0.0530703068]\n",
      "[0.659685671 0.549741 0.322580755 ... 0.0524939 0.0523616672 0.0503807664]\n",
      "[0.384801179 0.288256943 0.178193927 ... 0.0594149232 0.0567161143 0.0525401533]\n",
      "[0.717172742 0.3537862 0.145328134 ... 0.0661148727 0.0620414913 0.0541050136]\n",
      "[0.703258872 0.448892057 0.173083931 ... 0.0552218556 0.0531847775 0.0521755517]\n",
      "[0.790723443 0.0572237074]\n",
      "[0.526716769 0.497556597 0.419868499 ... 0.0520677865 0.0513131917 0.0506388545]\n",
      "[0.234763831 0.226702213 0.21891731 ... 0.0588496625 0.0558792353 0.0522097647]\n",
      "[0.398530126 0.131851733 0.0893203]\n",
      "[0.592077851 0.475842357 0.445010841 ... 0.0603861213 0.0564587116 0.0509622693]\n",
      "[0.53556633 0.517936051 0.493634 ... 0.0515768528 0.0503474772 0.0500327349]\n",
      "[0.768578291 0.726950407 0.689088702 ... 0.0508151352 0.050596267 0.0503964424]\n",
      "[0.791619658 0.491055369 0.212625 ... 0.0522208512 0.0510819852 0.0504140258]\n",
      "[0.590034604 0.477176696 0.405549884 ... 0.0515559614 0.0515037477 0.0503023267]\n",
      "[0.464687109 0.0730583668 0.0669573545 0.0627662241 0.0513116419]\n",
      "[0.682671547 0.567003906 0.491240442 ... 0.0629084706 0.0625852048 0.0542493165]\n",
      "[0.877224207 0.474129438 0.370010734 ... 0.0809932351 0.0785163939 0.0751152039]\n",
      "[0.843991458 0.615489423 0.348052919 ... 0.0507123172 0.0506219566 0.0500810742]\n",
      "[0.210679263 0.169968694 0.0901859701 0.0820146799 0.055639 0.0550405383]\n",
      "[0.426162541 0.306813478 0.239249349 ... 0.0514962673 0.0512163639 0.0501317382]\n",
      "[0.516911507 0.445103288 0.367211878 ... 0.0604802072 0.0558533669 0.0542083085]\n",
      "[0.26894629 0.193860114 0.146367848 ... 0.0870328546 0.0543395877 0.0540669858]\n",
      "[0.887910843 0.597608924 0.256505132 ... 0.0508740544 0.0501766205 0.0500938296]\n",
      "[0.731119394 0.674685955 0.609511673 ... 0.0540648103 0.0535786152 0.0535286665]\n",
      "[0.419230878 0.401123524 0.324199736 ... 0.0548422337 0.0524827242 0.0513961911]\n",
      "[0.630786061 0.606580138 0.587855 ... 0.0537570119 0.0515890121 0.0509866178]\n",
      "[0.582035244 0.580612361 0.359491169 ... 0.0577656925 0.0566986799 0.0531547666]\n",
      "[0.717217326 0.690302372 0.660829 ... 0.0519971251 0.0516631603 0.0515196025]\n",
      "[0.62053448 0.536098838 0.511180937 ... 0.0509856939 0.0509554446 0.050554961]\n",
      "[0.947457194 0.729516923 0.123231858 ... 0.0551573336 0.0519914031 0.0512265563]\n",
      "[0.864231 0.781199455 0.589059949 ... 0.050134033 0.0500901043 0.0500708818]\n",
      "[0.943618059 0.908552885 0.895799756 ... 0.0511334836 0.0508379042 0.050773114]\n",
      "[0.882111669 0.11767292 0.108655602 ... 0.0632515848 0.0604127049 0.051632911]\n",
      "[0.714072704 0.624197781 0.116798133 ... 0.0791999698 0.0671177208 0.0502996147]\n",
      "[0.723353088 0.569359779 0.539000273 ... 0.052498281 0.0515975952 0.050060004]\n",
      "[0.419315279 0.133422583 0.111461371 ... 0.0885450244 0.0796602666 0.0680857897]\n",
      "[0.499156475 0.478509218 0.354176491 ... 0.0512423515 0.050838083 0.050704509]\n",
      "[0.42661494 0.418254346 0.258722782 ... 0.0557908118 0.0523557663 0.0522750616]\n",
      "[0.853540063 0.846567631 0.769861579 ... 0.0598929524 0.0577997863 0.0567115247]\n",
      "[0.258201063 0.182775468 0.150267273 ... 0.138197243 0.0911033154 0.082434237]\n",
      "[0.558382034 0.404884577 0.375607193 ... 0.0556359887 0.0556298196 0.055486232]\n",
      "[0.873826206 0.818013 0.753701 ... 0.0514672697 0.0504644215 0.0501351357]\n",
      "[0.216587931 0.151086599 0.127943873 ... 0.0541412234 0.053185463 0.0501948]\n",
      "[0.627802908 0.597727478 0.388520151 ... 0.0620670915 0.0569387674 0.0531504154]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 696; epoch: 115; focal_loss: 0.3139359; l1_loss: 0.119206; total_loss: 0.4331418; \n",
      "FastEstimator-Train: step: 696; focal_loss: 0.0868467; l1_loss: 0.107989; total_loss: 0.1948357; examples/sec: 31.9; progress: 58.0%; \n",
      "FastEstimator-Train: step: 697; focal_loss: 0.0669673; l1_loss: 0.1543645; total_loss: 0.2213318; examples/sec: 32.2; progress: 58.1%; \n",
      "FastEstimator-Train: step: 698; focal_loss: 0.0758061; l1_loss: 0.0569527; total_loss: 0.1327588; examples/sec: 32.5; progress: 58.2%; \n",
      "FastEstimator-Train: step: 699; focal_loss: 0.0571182; l1_loss: 0.0670197; total_loss: 0.1241378; examples/sec: 32.1; progress: 58.2%; \n",
      "FastEstimator-Train: step: 700; focal_loss: 0.0412399; l1_loss: 0.1293205; total_loss: 0.1705604; examples/sec: 32.2; progress: 58.3%; \n",
      "FastEstimator-Train: step: 701; focal_loss: 0.0865317; l1_loss: 0.1577112; total_loss: 0.2442428; examples/sec: 32.2; progress: 58.4%; \n",
      "[0.72107935 0.521263659 0.479848474 ... 0.0626788437 0.0623790026 0.0623595417]\n",
      "[0.419910103 0.335987538 0.134963334 ... 0.0700875521 0.0555121 0.0525659621]\n",
      "[0.660087109 0.656909645 0.618245542 ... 0.0607589483 0.0550902188 0.0524572432]\n",
      "[0.73978889 0.710155606 0.186574101 0.0957757831 0.0616375506 0.0578982532]\n",
      "[0.266125292 0.249254495 0.150632 ... 0.0597475171 0.0553527474 0.0545283556]\n",
      "[0.466411 0.434632361 0.359852493 ... 0.0533474088 0.0529766679 0.051638037]\n",
      "[0.7757864 0.431626439 0.423574924 ... 0.0598083138 0.0515653789 0.0510444343]\n",
      "[0.519074 0.463160634 0.451816827 ... 0.0551045239 0.0550059974 0.052701205]\n",
      "[0.497260481 0.209928572 0.204824388 ... 0.066518873 0.0547471642 0.0533671677]\n",
      "[0.564160049 0.512343884 0.158530325 0.0883607268 0.0585284531 0.0523633063]\n",
      "[0.641939521 0.605249941 0.194358617 ... 0.0551574528 0.0545022488 0.0525756776]\n",
      "[0.555081487]\n",
      "[0.411549866 0.343671858 0.334839284 ... 0.0543845 0.0538318455 0.0536507368]\n",
      "[0.595638275 0.523508 0.399154365 ... 0.0571441054 0.0566638708 0.0565354526]\n",
      "[0.073461622 0.0733450055]\n",
      "[0.229603231 0.182444215 0.173097044 ... 0.079321593 0.078314513 0.0644120872]\n",
      "[0.670350254 0.640147507 0.549021184 ... 0.0513821542 0.0505697429 0.0502232]\n",
      "[0.613229513 0.484642804 0.304534554 ... 0.0521757305 0.0511977673 0.0501258969]\n",
      "[0.694785893 0.600617826 0.496548712 ... 0.0585813224 0.0585809946 0.0553487539]\n",
      "[0.278846025 0.275414258 0.161057055 ... 0.0541563034 0.0532925725 0.0528714061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.131379485 0.05545789]\n",
      "[0.211716086 0.206838369 0.13239333 ... 0.0801693201 0.0775903463 0.0522659123]\n",
      "[0.970142543 0.692684114 0.666538656 ... 0.0605958104 0.0547152758 0.0524018407]\n",
      "[0.878739 0.677323 0.387910753 ... 0.051243186 0.0511514544 0.0500181913]\n",
      "[0.30691871 0.216824532 0.0955790877 ... 0.0576221943 0.057264 0.0548370183]\n",
      "[0.4799532 0.394361526 0.368334055 ... 0.0511380732 0.0510174334 0.0508728921]\n",
      "[0.688984454 0.298311 0.141096264 ... 0.0601581931 0.0571522117 0.0559647679]\n",
      "[0.983113289 0.214941829 0.130921781 ... 0.0619567037 0.0617144108 0.0603604615]\n",
      "[0.709441 0.684812307 0.365926206 ... 0.0582359135 0.0541982353 0.0512341857]\n",
      "[0.742283106 0.664919376 0.653376937 ... 0.0516348779 0.0508626103 0.0508121252]\n",
      "[0.604221046 0.562787771 0.539108 ... 0.0531536937 0.0521126688 0.0513457358]\n",
      "[0.700054288 0.619919121 0.603332281 ... 0.0708183348 0.0702505112 0.0539055169]\n",
      "[0.494437933 0.37810573 0.265744567 ... 0.0567864776 0.0558066964 0.0554018915]\n",
      "[0.838605285 0.824834228 0.675964534 ... 0.0512634218 0.051243633 0.0511657298]\n",
      "[0.614374757 0.466320813 0.45740369 ... 0.0677522719 0.0663753748 0.0658505]\n",
      "[0.903961897 0.725824237 0.0909863114 ... 0.0760459304 0.0639195144 0.0502805412]\n",
      "[0.917215943 0.861739635 0.631993651 ... 0.0518344045 0.0513117611 0.0512653887]\n",
      "[0.526897073 0.240539879 0.224902302 ... 0.0543581843 0.0530129671 0.0514941812]\n",
      "[0.674560368 0.130310625 0.0720730424 0.0606717169 0.0505028665]\n",
      "[0.579807401 0.488176525]\n",
      "[0.890240431 0.506730735 0.411622733 ... 0.0521087646 0.0518988073 0.0510973036]\n",
      "[0.269981831 0.200788021 0.090236932 ... 0.0743569732 0.0510957539 0.0507576466]\n",
      "[0.520083845 0.355943829 0.327036977 ... 0.0538544655 0.0513374805 0.0510483086]\n",
      "[0.335956097 0.332624793 0.240814 ... 0.0541705787 0.0532057881 0.0503233671]\n",
      "[0.423284352 0.285985917 0.280214131 ... 0.0701398551 0.0661949217 0.0567268431]\n",
      "[0.339195967 0.254248857 0.251710802 0.241170287 0.095998168]\n",
      "[0.65210253 0.508608937 0.48437342 ... 0.068443954 0.0684366226 0.0682045221]\n",
      "[0.722503781 0.68685627 0.57713753 ... 0.0575603843 0.0573639572 0.0507102907]\n",
      "FastEstimator-Eval: step: 702; epoch: 116; focal_loss: 0.3682946; l1_loss: 0.2430752; total_loss: 0.6113699; \n",
      "FastEstimator-Train: step: 702; focal_loss: 0.1991626; l1_loss: 0.080599; total_loss: 0.2797616; examples/sec: 32.0; progress: 58.5%; \n",
      "FastEstimator-Train: step: 703; focal_loss: 0.1393337; l1_loss: 0.0835576; total_loss: 0.2228913; examples/sec: 32.4; progress: 58.6%; \n",
      "FastEstimator-Train: step: 704; focal_loss: 0.1074488; l1_loss: 0.0498464; total_loss: 0.1572952; examples/sec: 32.4; progress: 58.7%; \n",
      "FastEstimator-Train: step: 705; focal_loss: 0.0682074; l1_loss: 0.0554211; total_loss: 0.1236286; examples/sec: 32.4; progress: 58.8%; \n",
      "FastEstimator-Train: step: 706; focal_loss: 0.0794573; l1_loss: 0.1278542; total_loss: 0.2073114; examples/sec: 31.6; progress: 58.8%; \n",
      "FastEstimator-Train: step: 707; focal_loss: 0.0982271; l1_loss: 0.0671009; total_loss: 0.165328; examples/sec: 32.1; progress: 58.9%; \n",
      "[0.386935472 0.135577321 0.129566967 ... 0.0559680462 0.0553737879 0.0503582358]\n",
      "[0.799248517 0.446921945 0.297015786 ... 0.0558429956 0.0540042818 0.0537708104]\n",
      "[0.696023464 0.418938696 0.287938684 ... 0.0508328676 0.0504418314 0.0500170887]\n",
      "[0.245063573 0.139294684 0.110790789 ... 0.0613698363 0.0548776686 0.0531076193]\n",
      "[0.423710108 0.310491204 0.265659392 ... 0.0546685457 0.0545739233 0.0510754]\n",
      "[0.55064249 0.46711573 0.457753897 0.39742285 0.166207314]\n",
      "[0.211574286 0.200262278 0.187360466 ... 0.0626558661 0.0612310767 0.0511216819]\n",
      "[0.679993272 0.428080589 0.331262469 ... 0.0540828109 0.0520935357 0.0510902703]\n",
      "[0.817256689 0.609965861 0.518214285 ... 0.0530217588 0.0527893305 0.052531004]\n",
      "[0.344795525 0.268724471 0.239280522 ... 0.0553095639 0.0549128354 0.0533162355]\n",
      "[0.438272595 0.184768528 0.181630254 ... 0.0532525182 0.0524486899 0.0505916178]\n",
      "[0.656065464 0.216253728 0.193826795 0.0809984505 0.0610099137]\n",
      "[0.303772151 0.27058506 0.225135446 ... 0.0958058238 0.0623995662 0.0622577071]\n",
      "[0.270271242]\n",
      "[0.316700697 0.260795802 0.255918741 ... 0.0513815284 0.0510615706 0.0501584709]\n",
      "[0.517630517 0.281288326 0.19655031 ... 0.0522583723 0.0508808196 0.0501882732]\n",
      "[0.20322749 0.129245371 0.0679026842]\n",
      "[0.307125688 0.103533298 0.0941899419 ... 0.0752747059 0.0741425157 0.0510662496]\n",
      "[0.426401258 0.379413307 0.367998272 ... 0.0533741415 0.0531418324 0.0524916947]\n",
      "[0.780559 0.614353776 0.553285599 ... 0.0530439019 0.0505498648 0.0501071215]\n",
      "[0.638166726 0.532195687 0.513294637 ... 0.073369056 0.0698868632 0.0617903769]\n",
      "[0.436621219 0.397921264 0.20235309 ... 0.0526394546 0.0517424941 0.0510935187]\n",
      "[0.220524877]\n",
      "[0.843648434 0.649989247 0.614274919 ... 0.0804220736 0.0669746697 0.0606651902]\n",
      "[0.807335377 0.337106645 0.30695039 ... 0.0705022216 0.059135288 0.0563214421]\n",
      "[0.326509476 0.287252069 0.255255252 ... 0.0528523624 0.052531451 0.0503703058]\n",
      "[0.266421795 0.063490808 0.0589699447]\n",
      "[0.338062823 0.305909276 0.242833465 ... 0.0510146916 0.050260812 0.0501005948]\n",
      "[0.447911739 0.349945128 0.347429693 ... 0.0520049334 0.0518519878 0.0507035553]\n",
      "[0.525737643 0.176187754 0.0636103153 0.0507695377]\n",
      "[0.600608 0.58939594 0.182054847 ... 0.0519191623 0.0507525802 0.0502047837]\n",
      "[0.868981838 0.848079562 0.767076612 ... 0.0659185648 0.064552635 0.0644542]\n",
      "[0.608510554 0.518346906 0.496097773 ... 0.0523565412 0.0512162447 0.0509301722]\n",
      "[0.713538706 0.696517229 0.619479597 ... 0.0652881563 0.0572997034 0.0548862219]\n",
      "[0.619802833 0.185413152 0.106078595 ... 0.0586134493 0.0539515615 0.0521375835]\n",
      "[0.656649828 0.462829977 0.424159586 ... 0.0521900356 0.0502083898 0.0501264036]\n",
      "[0.810511529 0.751430154 0.713151515 ... 0.145769954 0.145650327 0.145101339]\n",
      "[0.689636 0.67759943 0.097489059 ... 0.0672002137 0.0565270185 0.0525204241]\n",
      "[0.887287378 0.617928922 0.586565137 ... 0.0532692671 0.052429527 0.0515208244]\n",
      "[0.277943015 0.26724717 0.248079568 ... 0.0518380105 0.0513542 0.0505433083]\n",
      "[0.199738353 0.119947612 0.0816730559 0.0607955158 0.0508171022]\n",
      "[0.721364558 0.611820459 0.0681498945 0.0525093377 0.0524072647]\n",
      "[0.872113466 0.434479 0.413675845 ... 0.0527519584 0.0524780154 0.0520578921]\n",
      "[0.134507149 0.121227831 0.0785671771 0.07383129 0.0670928955]\n",
      "[0.278202415 0.251357675 0.162039489 ... 0.0567435324 0.0502749085 0.0501834452]\n",
      "[0.375124842 0.245205075 0.180390596 ... 0.10329321 0.0713947415 0.054844141]\n",
      "[0.873887777 0.464840353 0.35964489 ... 0.0912377238 0.0569131076 0.0522570908]\n",
      "[0.420919538 0.204137832 0.146873564 ... 0.0947338641 0.0856282413 0.0733681917]\n",
      "FastEstimator-Eval: step: 708; epoch: 117; focal_loss: 0.4086896; l1_loss: 0.1398569; total_loss: 0.5485465; \n",
      "FastEstimator-Train: step: 708; focal_loss: 0.2567086; l1_loss: 0.0701802; total_loss: 0.3268888; examples/sec: 31.9; progress: 59.0%; \n",
      "FastEstimator-Train: step: 709; focal_loss: 0.0785798; l1_loss: 0.0455701; total_loss: 0.12415; examples/sec: 31.9; progress: 59.1%; \n",
      "FastEstimator-Train: step: 710; focal_loss: 0.064406; l1_loss: 0.0728564; total_loss: 0.1372624; examples/sec: 32.6; progress: 59.2%; \n",
      "FastEstimator-Train: step: 711; focal_loss: 0.0857347; l1_loss: 0.1728761; total_loss: 0.2586108; examples/sec: 32.0; progress: 59.2%; \n",
      "FastEstimator-Train: step: 712; focal_loss: 0.1310284; l1_loss: 0.1277498; total_loss: 0.2587782; examples/sec: 32.4; progress: 59.3%; \n",
      "FastEstimator-Train: step: 713; focal_loss: 0.1255677; l1_loss: 0.1577136; total_loss: 0.2832813; examples/sec: 32.0; progress: 59.4%; \n",
      "[0.854193807 0.713862479 0.667193055 ... 0.103638977 0.100650251 0.0988246202]\n",
      "[0.925024211 0.916107655 0.689797521 ... 0.0538036525 0.0535366535 0.0521250069]\n",
      "[0.712895632 0.44291687 0.386096746 ... 0.0601555407 0.0550016165 0.0533874333]\n",
      "[0.783618629 0.615207613 0.50862 ... 0.0531789362 0.0517334044 0.0512456]\n",
      "[0.541605592 0.494803846 0.494749844 ... 0.0575263798 0.057498008 0.0571452379]\n",
      "[0.665353954 0.25872758 0.188688904 ... 0.0620903075 0.0598524809 0.0541134477]\n",
      "[0.742753863 0.658437 0.637974918 ... 0.0571676791 0.0557864606 0.0500670969]\n",
      "[0.128039062 0.115886241 0.0787962377 0.0687270463 0.053768754 0.0501370728]\n",
      "[0.571810246 0.379679561 0.370276213 ... 0.0576548874 0.0521724522 0.0509923398]\n",
      "[0.586530685 0.443034649 0.408328623 ... 0.0547338426 0.0526718199 0.0504865944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.858209312 0.3948614 0.356950879 ... 0.0574390888 0.0530320406 0.0510483682]\n",
      "[0.722614765 0.574226439 0.431065947 ... 0.054058224 0.0528491735 0.0507943928]\n",
      "[0.8439188 0.610156357 0.591733813 ... 0.0588915646 0.0565278232 0.0537016392]\n",
      "[0.435533881 0.295226514 0.246734172 ... 0.0632313788 0.0551922321 0.0535755455]\n",
      "[0.5701316 0.497209817 0.329361379 ... 0.0599584281 0.0571017265 0.0562036633]\n",
      "[0.52953 0.0637444258]\n",
      "[0.67930603 0.560824931 0.497792482 ... 0.0521716475 0.0514104068 0.0513552427]\n",
      "[0.811264157 0.701962948 0.480892181 ... 0.0529607832 0.0514843464 0.0504640043]\n",
      "[0.904707074 0.0617035329]\n",
      "[0.413131773 0.409342438 0.253623903 ... 0.0541245341 0.0530185401 0.0508090556]\n",
      "[0.499198556 0.433604598 0.413340598 ... 0.0544272661 0.0533145368 0.0507461429]\n",
      "[0.935588896 0.701475143 0.648777843 ... 0.0514777601 0.0513827801 0.0508265793]\n",
      "[0.649469733 0.545588 0.520842373 ... 0.0511163175 0.0509785116 0.0500276089]\n",
      "[0.504907429 0.347852975 0.289457768 ... 0.0533477664 0.0532406867 0.0504409671]\n",
      "[0.496368 0.085875541 0.0581420362 0.0572587252]\n",
      "[0.912187934 0.58857578 0.209191293 ... 0.0536140203 0.052259 0.0513069034]\n",
      "[0.956268728 0.782263398 0.545674443 ... 0.0574117899 0.0546438694 0.0511381924]\n",
      "[0.651303947 0.443645984 0.390402526 ... 0.0520808399 0.050842762 0.0504564345]\n",
      "[0.694813609 0.212277114 0.171416879 0.160080284 0.0592850447]\n",
      "[0.803338706 0.599198043 0.567002654 ... 0.0733311176 0.0724589825 0.072373271]\n",
      "[0.681957543 0.22302863 0.209656209 ... 0.0550680459 0.0531945527 0.0525323451]\n",
      "[0.175564826 0.120938122 0.11759004 ... 0.0830728412 0.0798517168 0.065066129]\n",
      "[0.881544948 0.842890739 0.543298 ... 0.053979218 0.0538848937 0.0517843068]\n",
      "[0.792045057 0.508286059 0.504969776 ... 0.0574582517 0.0570600331 0.0569543839]\n",
      "[0.529805899 0.503733099 0.484651029 ... 0.0510938764 0.0505556464 0.0503468812]\n",
      "[0.829275846 0.747099519 0.712022483 ... 0.0513701141 0.0513570309 0.0500412881]\n",
      "[0.682340622 0.208950043 0.205979049 ... 0.0664273798 0.0589408576 0.0502209067]\n",
      "[0.849482179 0.665062547 0.603401899 ... 0.0533562601 0.0513983071 0.0506564975]\n",
      "[0.56401509 0.541612566 0.461466223 ... 0.0511462688 0.0507887 0.0505591929]\n",
      "[0.87183 0.733603 0.102965832 ... 0.0538451374 0.0529304445 0.0513894558]\n",
      "[0.982621312 0.8556391 0.838371396 ... 0.0513757467 0.0512343049 0.0502953529]\n",
      "[0.338630438 0.311929286 0.278065801 ... 0.0509322286 0.0506911576 0.0503542125]\n",
      "[0.597449422 0.315686762 0.127416402 ... 0.0594547093 0.0530321896 0.0511754453]\n",
      "[0.430835813 0.334581226 0.135270745 ... 0.0667426586 0.0638001 0.0541537702]\n",
      "[0.928289711 0.538601935 0.5238 ... 0.0521159768 0.0512243509 0.0505429804]\n",
      "[0.477767229 0.275146 0.203620017 ... 0.0595005453 0.0553526 0.050280869]\n",
      "[0.470906615 0.437732548 0.260772169 ... 0.051885128 0.0515463054 0.0513116121]\n",
      "[0.776751459 0.562730134 0.539398849 ... 0.0516787767 0.051138103 0.0503148139]\n",
      "FastEstimator-Eval: step: 714; epoch: 118; focal_loss: 0.2737423; l1_loss: 0.2371876; total_loss: 0.5109299; \n",
      "FastEstimator-Train: step: 714; focal_loss: 0.1548298; l1_loss: 0.1149776; total_loss: 0.2698074; examples/sec: 32.1; progress: 59.5%; \n",
      "FastEstimator-Train: step: 715; focal_loss: 0.0945834; l1_loss: 0.080933; total_loss: 0.1755165; examples/sec: 31.4; progress: 59.6%; \n",
      "FastEstimator-Train: step: 716; focal_loss: 0.1780306; l1_loss: 0.0723733; total_loss: 0.250404; examples/sec: 32.5; progress: 59.7%; \n",
      "FastEstimator-Train: step: 717; focal_loss: 0.0810067; l1_loss: 0.1757547; total_loss: 0.2567614; examples/sec: 31.6; progress: 59.8%; \n",
      "FastEstimator-Train: step: 718; focal_loss: 0.0888995; l1_loss: 0.3356708; total_loss: 0.4245703; examples/sec: 32.1; progress: 59.8%; \n",
      "FastEstimator-Train: step: 719; focal_loss: 0.1802245; l1_loss: 0.0679335; total_loss: 0.248158; examples/sec: 32.1; progress: 59.9%; \n",
      "[0.913943172 0.679620624 0.297453225 ... 0.0766519904 0.0714416802 0.0576628447]\n",
      "[0.105173826 0.0936151743 0.0897475779 ... 0.08002159 0.0701164305 0.0668875277]\n",
      "[0.732696533 0.359523028 0.347700059 ... 0.07052508 0.0699726939 0.0698977709]\n",
      "[0.874242425 0.128306717 0.127580464 ... 0.0545323193 0.0542720854 0.0501373112]\n",
      "[0.413246602 0.222254395 0.188695818 ... 0.0545117855 0.0538670421 0.0510959625]\n",
      "[0.79676497 0.466462135 0.458761305 ... 0.0713049769 0.0713006258 0.062276572]\n",
      "[0.421812534 0.404764771 0.343885392 ... 0.0529562235 0.0522554517 0.050172627]\n",
      "[0.444676399 0.190278 0.145600766 ... 0.0624995828 0.0595093369 0.0534102321]\n",
      "[0.619021297 0.490187466 0.481220156 ... 0.0560227931 0.0547636449 0.0542170107]\n",
      "[0.240028352 0.174648494 0.139213055 0.0550897121]\n",
      "[0.391835749 0.34590888 0.1902242 ... 0.0628306866 0.0604310334 0.0538456738]\n",
      "[0.740875 0.295963764 0.291295886 ... 0.0547702312 0.0527590215 0.0504445434]\n",
      "[0.833295822 0.713718653 0.710242867 ... 0.0618373752 0.054872781 0.0547700226]\n",
      "[0.404473 0.368172079 0.338309467 ... 0.0514394939 0.051045537 0.0505843163]\n",
      "[0.450191438 0.314351857 0.304798424 ... 0.0557181537 0.0545555353 0.051988095]\n",
      "[0.669623435 0.17610991 0.0991097093 0.0753025115 0.0566336513]\n",
      "[0.555831075 0.457514 0.449401617 ... 0.0719295144 0.0670123696 0.0520964861]\n",
      "[0.40121609 0.0605296493]\n",
      "[0.438730836 0.368575156 0.364099979 ... 0.0531057417 0.0528455675 0.0519163311]\n",
      "[0.275223136 0.166328341 0.147335 ... 0.0940367579 0.0719500184 0.0636821389]\n",
      "[0.876788855 0.118063271 0.0650562942 0.0635224283 0.0591627359]\n",
      "[0.441203535 0.207933009 0.111744702 ... 0.0803552568 0.0625582635 0.0622468]\n",
      "[0.370491385 0.345286667 0.310231417 ... 0.0532130897 0.0511834025 0.050727874]\n",
      "[0.702573895 0.521507204 0.450996727 ... 0.0521321893 0.0519962 0.051074177]\n",
      "[0.707895398 0.448211282 0.302271843 ... 0.0631533563 0.0582817793 0.0524986088]\n",
      "[0.217911541 0.183662623 0.183330476 ... 0.0547993183 0.0514519215 0.0507509708]\n",
      "[0.215274036 0.0558499098]\n",
      "[0.641262114 0.604847431 0.520572603 ... 0.0607627332 0.0545677543 0.054228425]\n",
      "[0.80971694 0.459573507 0.390144169 ... 0.0613728762 0.0605194867 0.0568077266]\n",
      "[0.289069682 0.255230784 0.25361684 ... 0.0520301163 0.0513665676 0.0512630939]\n",
      "[0.247515589 0.0592372417 0.0582428873]\n",
      "[0.541529238 0.414837748 0.405802608 ... 0.0505440831 0.0502980053 0.0502226651]\n",
      "[0.478037685 0.397489309 0.171626329 ... 0.0623596 0.0585561693 0.0527403951]\n",
      "[0.215845019 0.13660115 0.060793221]\n",
      "[0.660437703 0.402399242 0.252302349 ... 0.0546965 0.0510647595 0.0503797829]\n",
      "[0.549072683 0.518692374 0.478298604 ... 0.0541583598 0.0531421602 0.0507840812]\n",
      "[0.43693608 0.353767633 0.306175411 ... 0.0533062518 0.0519096851 0.0502887666]\n",
      "[0.354127049 0.330244899 0.204908282 ... 0.0624390841 0.0558815598 0.0537079573]\n",
      "[0.285793126 0.261706412 0.104732275 ... 0.0677331388 0.0584431291 0.053817749]\n",
      "[0.651280046 0.55604881 0.537205 ... 0.0514912903 0.0508275926 0.0505413413]\n",
      "[0.876223445 0.766485393 0.532597363 ... 0.0529302955 0.0509639978 0.0505479872]\n",
      "[0.165722847 0.115041316 0.101274461 ... 0.0667159259 0.0603902936 0.0509832799]\n",
      "[0.498610854 0.4473207 0.437617064 ... 0.0529390275 0.0520491 0.0518958569]\n",
      "[0.462942 0.417785555 0.374131382 ... 0.0523721874 0.0520744622 0.0518702865]\n",
      "[0.50781244 0.164395899 0.0773831904 0.0759818554 0.0509594083 0.0504393]\n",
      "[0.286741436 0.226900578 0.102588087 0.0642430186]\n",
      "[0.503503382 0.436108828 0.320488453 ... 0.0531217456 0.0519631803 0.0518572927]\n",
      "[0.323391318 0.233311057 0.144514322 ... 0.0577350259 0.0530876219 0.0518132746]\n",
      "FastEstimator-Eval: step: 720; epoch: 119; focal_loss: 0.4052098; l1_loss: 0.1795374; total_loss: 0.5847472; \n",
      "FastEstimator-Train: step: 720; focal_loss: 0.1108563; l1_loss: 0.118311; total_loss: 0.2291673; examples/sec: 32.1; progress: 60.0%; \n",
      "FastEstimator-Train: step: 721; focal_loss: 0.1030934; l1_loss: 0.0812489; total_loss: 0.1843422; examples/sec: 32.1; progress: 60.1%; \n",
      "FastEstimator-Train: step: 722; focal_loss: 0.1546015; l1_loss: 0.1001853; total_loss: 0.2547868; examples/sec: 32.3; progress: 60.2%; \n",
      "FastEstimator-Train: step: 723; focal_loss: 0.0708838; l1_loss: 0.1255669; total_loss: 0.1964507; examples/sec: 32.5; progress: 60.2%; \n",
      "FastEstimator-Train: step: 724; focal_loss: 0.0340983; l1_loss: 0.1121372; total_loss: 0.1462356; examples/sec: 32.1; progress: 60.3%; \n",
      "FastEstimator-Train: step: 725; focal_loss: 0.1328056; l1_loss: 0.0735576; total_loss: 0.2063633; examples/sec: 31.8; progress: 60.4%; \n",
      "[0.307264954 0.272939682 0.202146947 ... 0.0517326593 0.0513584 0.0502214432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.593682647 0.572064281 0.492720753 ... 0.0521681607 0.0503281951 0.0501169264]\n",
      "[0.833694816 0.605012715 0.329923272 ... 0.0550515056 0.0517785549 0.0508556366]\n",
      "[0.694702268 0.603718042 0.469261944 ... 0.061676681 0.0567061 0.0563017726]\n",
      "[0.68360877 0.550111294 0.479891181 ... 0.0608949661 0.0604490936 0.0602273345]\n",
      "[0.954952717 0.951741695 0.836497903 ... 0.0522738695 0.0519091487 0.0508750379]\n",
      "[0.447771072 0.339779109 0.241602629 ... 0.0539602935 0.052598 0.0520339608]\n",
      "[0.465078801 0.405547142 0.350104392 ... 0.0667699 0.0546488166 0.0533756316]\n",
      "[0.535529375 0.402446806 0.358587384 ... 0.0514341295 0.0507186651 0.0504982471]\n",
      "[0.927237749 0.58871007 0.356284261 ... 0.0659426153 0.0637661815 0.0548972189]\n",
      "[0.827127039 0.740852177 0.724236965 ... 0.0561836362 0.0520267785 0.0511915684]\n",
      "[0.421040535 0.408052832 0.067066133 0.0612618029]\n",
      "[0.557431281 0.519748092 0.486033738 ... 0.0639822781 0.0636205673 0.0515404642]\n",
      "[0.857348204 0.705157042 0.701877356 ... 0.0567397773 0.0540021062 0.0512959957]\n",
      "[0.978387654 0.839133 0.764011502 ... 0.0845512152 0.0703713894 0.0572185218]\n",
      "[0.698352337 0.658323646 0.580215931 ... 0.058195591 0.0566141903 0.050514698]\n",
      "[0.408148 0.305428237 0.253572285 ... 0.0559498072 0.054731667 0.0546762049]\n",
      "[0.902146101 0.602337778 0.495440364 ... 0.0849246383 0.0661433637 0.0623701215]\n",
      "[0.552607715 0.476781517 0.32595557 ... 0.0566573143 0.0531421602 0.0529074967]\n",
      "[0.855393112 0.0693563223]\n",
      "[0.575923562 0.478152484 0.460768104 ... 0.0536781549 0.0512432456 0.0500986576]\n",
      "[0.277392268 0.214292735 0.211681604 ... 0.0580590963 0.0533009171 0.0507731736]\n",
      "[0.56565 0.110784143]\n",
      "[0.973622561 0.858961821 0.250632703 ... 0.0625204742 0.0583278835 0.0555808544]\n",
      "[0.481347173 0.378435552 0.376690745 ... 0.0645112693 0.0569145083 0.0509644449]\n",
      "[0.843751431 0.781627893 0.777498841 ... 0.0559832454 0.0539481938 0.0505004227]\n",
      "[0.493583202 0.299578547 0.280112326 ... 0.0516956151 0.0515488684 0.0500874519]\n",
      "[0.638257504 0.527577162 0.393896163 ... 0.0676728487 0.0665697455 0.0530028343]\n",
      "[0.831598163 0.22355324 0.0747382939 ... 0.0613597333 0.0560158491 0.0534009635]\n",
      "[0.710126102 0.18520686 0.128777295 ... 0.0804586112 0.0609810054 0.0518192649]\n",
      "[0.870751858 0.620640397 0.278488398 ... 0.0778742135 0.0764235854 0.0736397803]\n",
      "[0.696849048 0.626666963 0.491166204 ... 0.0509613752 0.0505688488 0.0502550304]\n",
      "[0.454272747 0.177966624 0.146613598 0.13092646 0.0673536062 0.0543912947]\n",
      "[0.762585759 0.500386238 0.489583701 ... 0.0572205782 0.0558523536 0.0514403]\n",
      "[0.791124225 0.63490206 0.547973275 ... 0.0568001866 0.0537587702 0.0506934226]\n",
      "[0.224327058 0.211748242 0.125199288 ... 0.0540171564 0.0529697239 0.0508961678]\n",
      "[0.869260669 0.785176754 0.356138587 ... 0.0557733178 0.0532872975 0.0513569117]\n",
      "[0.50108552 0.309766114 0.248664558 ... 0.0522247255 0.0518736541 0.051799804]\n",
      "[0.720708728 0.707203031 0.59679234 ... 0.0533470809 0.0524747968 0.0500089526]\n",
      "[0.86711216 0.81273365 0.632616341 ... 0.0756919384 0.0550839901 0.0516598821]\n",
      "[0.806078851 0.427068383 0.288654923 ... 0.0608360469 0.0577719808 0.0526319742]\n",
      "[0.855682254 0.788032532 0.744428694 ... 0.0512253642 0.050338 0.0500654]\n",
      "[0.635181665 0.557643235 0.482479364 ... 0.0536314547 0.0533475578 0.0519818366]\n",
      "[0.666537285 0.54214859 0.230044544 ... 0.0595337749 0.0554130971 0.0502434373]\n",
      "[0.894504547 0.833209515 0.822950721 ... 0.053242147 0.0524253845 0.0512618423]\n",
      "[0.853401303 0.488181651 0.452543736 ... 0.0607527494 0.0581712425 0.0523817539]\n",
      "[0.52689755 0.0654487312 0.057299763 0.0521589518]\n",
      "[0.686963439 0.630383849 0.22751537 ... 0.0599264801 0.0541431308 0.0501105189]\n",
      "FastEstimator-Eval: step: 726; epoch: 120; focal_loss: 0.2858704; l1_loss: 0.2016945; total_loss: 0.4875648; \n",
      "FastEstimator-Train: step: 726; focal_loss: 0.0879006; l1_loss: 0.1714896; total_loss: 0.2593902; examples/sec: 31.6; progress: 60.5%; \n",
      "FastEstimator-Train: step: 727; focal_loss: 0.077605; l1_loss: 0.0974908; total_loss: 0.1750958; examples/sec: 32.2; progress: 60.6%; \n",
      "FastEstimator-Train: step: 728; focal_loss: 0.092158; l1_loss: 0.0990835; total_loss: 0.1912414; examples/sec: 32.3; progress: 60.7%; \n",
      "FastEstimator-Train: step: 729; focal_loss: 0.1379522; l1_loss: 0.087128; total_loss: 0.2250801; examples/sec: 32.5; progress: 60.8%; \n",
      "FastEstimator-Train: step: 730; focal_loss: 0.0929811; l1_loss: 0.0745222; total_loss: 0.1675033; examples/sec: 32.1; progress: 60.8%; \n",
      "FastEstimator-Train: step: 731; focal_loss: 0.0985913; l1_loss: 0.0823834; total_loss: 0.1809748; examples/sec: 32.1; progress: 60.9%; \n",
      "[0.622584224 0.614411473 0.490953952 ... 0.0519531965 0.0519069433 0.0514506698]\n",
      "[0.110174745 0.0896728039 0.0587860346 0.0568668842]\n",
      "[0.42397967 0.133375734 0.12751469 ... 0.0523042977 0.0519676208 0.0516725779]\n",
      "[0.869794309 0.734286606 0.671776414 ... 0.058871448 0.0569368 0.0546816587]\n",
      "[0.795366406 0.711933 0.541162789 ... 0.141925931 0.0793964565 0.0510449708]\n",
      "[0.521043718 0.49519816 0.385772407 ... 0.0759287477 0.0515030921 0.0514911115]\n",
      "[0.690875769 0.572313488 0.451787293 ... 0.0825661123 0.0825475752 0.0825224221]\n",
      "[0.922115386 0.801030755 0.244948775 0.176097]\n",
      "[0.520283163 0.385773659 0.349470735 ... 0.0645430088 0.0635432 0.0500478148]\n",
      "[0.728114367 0.64408356 0.392695338 ... 0.0563266873 0.0544644 0.0538335145]\n",
      "[0.667978644 0.658994317 0.591251969 ... 0.0760325789 0.0750289261 0.0730007887]\n",
      "[0.886444151 0.241213858 0.12782532 ... 0.0659008622 0.0588969886 0.0583538115]\n",
      "[0.539593935 0.386781454 0.384174228 ... 0.0596963167 0.0513246953 0.0508057773]\n",
      "[0.519180536 0.510818 0.0732303]\n",
      "[0.706371248 0.622630835 0.504480124 ... 0.0534510911 0.0525281131 0.0524207056]\n",
      "[0.753454506 0.552198708 0.516699433 ... 0.0526802838 0.0519408584 0.0514404774]\n",
      "[0.303879619 0.250280619 0.213170946 ... 0.108951986 0.0701802671 0.0529713333]\n",
      "[0.745786667 0.526565909 0.525966167 ... 0.0527771115 0.0525938272 0.0517837703]\n",
      "[0.509058177 0.257004231 0.231016695 ... 0.0519575775 0.0513356626 0.0502439737]\n",
      "[0.34119916 0.116301239 0.0647561848]\n",
      "[0.701283813 0.679214358 0.587944686 ... 0.0587747097 0.0570510328 0.0509645343]\n",
      "[0.805009 0.0642866492]\n",
      "[0.594169676 0.53268677 0.318349183 ... 0.0511253774 0.0510930717 0.0506646335]\n",
      "[0.909843 0.53928709 0.374425858 ... 0.0534152091 0.051346153 0.050640732]\n",
      "[0.334959507 0.0609460473]\n",
      "[0.568313241 0.106450647 0.0971727669 ... 0.0692921281 0.053278178 0.0515870154]\n",
      "[0.832930207 0.604522705 0.591798306 ... 0.0524183214 0.0518322587 0.0502784848]\n",
      "[0.523584247 0.502586961 0.405202687 ... 0.0505188406 0.0504033566 0.050222367]\n",
      "[0.703454435 0.668959856 0.497639209 ... 0.0605826974 0.0540849268 0.0520637929]\n",
      "[0.561794758 0.289317489 0.247413248 ... 0.0535223782 0.0527004302 0.0502370894]\n",
      "[0.549585462 0.0742335618 0.0726484954 ... 0.0625084043 0.0614947081 0.0561257]\n",
      "[0.542622447 0.448329449 0.155899644 0.0988743305]\n",
      "[0.90780282 0.538573325 0.458176941 ... 0.0542638302 0.0539337397 0.0506947041]\n",
      "[0.817551315 0.756764 0.721352041 ... 0.0585897565 0.0585012734 0.0584473]\n",
      "[0.965553164 0.227072775 0.183810353 ... 0.0563519895 0.0539917052 0.0529692173]\n",
      "[0.589411259 0.485705107 0.391867548 ... 0.0593492687 0.0566405654 0.0560884774]\n",
      "[0.331084639 0.239303678 0.115561157 ... 0.0631214678 0.0553405881 0.0528496206]\n",
      "[0.294728398 0.129085898 0.0899796486 0.0684347153 0.0674458742 0.0667859]\n",
      "[0.730731249 0.624094605 0.464740723 ... 0.0582672954 0.0553146303 0.0551936924]\n",
      "[0.863705039 0.820189834 0.696492 ... 0.0582277477 0.0580334663 0.0579436719]\n",
      "[0.772187114 0.756859303 0.697490811 ... 0.0535640121 0.0527607799 0.0512449741]\n",
      "[0.388134032 0.101862252 0.0878852606 ... 0.0620197952 0.0561144948 0.0548898]\n",
      "[0.808439851 0.783531368 0.251943886 ... 0.0598086715 0.0590999126 0.053878665]\n",
      "[0.842108607 0.81058836 0.781068325 ... 0.0510993898 0.0510188937 0.0507520735]\n",
      "[0.788458645 0.700077832 0.312786102 ... 0.0514403 0.051346004 0.051020205]\n",
      "[0.144174606 0.0944693387 0.0937634408 0.0544739068]\n",
      "[0.890018106 0.807998896 0.745668292 ... 0.0516854227 0.0502056181 0.0501765]\n",
      "[0.912187517 0.625808775 0.462320626 ... 0.0532070398 0.0527644455 0.0500367284]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 732; epoch: 121; focal_loss: 0.2589193; l1_loss: 0.1586897; total_loss: 0.4176091; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 732; focal_loss: 0.0551408; l1_loss: 0.0403481; total_loss: 0.0954889; examples/sec: 32.0; progress: 61.0%; \n",
      "FastEstimator-Train: step: 733; focal_loss: 0.1367015; l1_loss: 0.0646685; total_loss: 0.20137; examples/sec: 32.1; progress: 61.1%; \n",
      "FastEstimator-Train: step: 734; focal_loss: 0.0554771; l1_loss: 0.1249119; total_loss: 0.180389; examples/sec: 32.4; progress: 61.2%; \n",
      "FastEstimator-Train: step: 735; focal_loss: 0.11505; l1_loss: 0.062174; total_loss: 0.1772239; examples/sec: 32.5; progress: 61.3%; \n",
      "FastEstimator-Train: step: 736; focal_loss: 0.1658781; l1_loss: 0.0418784; total_loss: 0.2077566; examples/sec: 32.2; progress: 61.3%; \n",
      "FastEstimator-Train: step: 737; focal_loss: 0.0776027; l1_loss: 0.0408695; total_loss: 0.1184723; examples/sec: 32.3; progress: 61.4%; \n",
      "[0.955985665 0.248498768 0.159327239 ... 0.0537985861 0.0529943705 0.0516405702]\n",
      "[0.945326388 0.928913474 0.158995122 0.133602232 0.0778353512 0.0699996054]\n",
      "[0.617554605 0.59001112 0.578898668 ... 0.0539440513 0.051645726 0.0514689684]\n",
      "[0.396637231 0.172866225 0.120082289 ... 0.0742783248 0.0729449093 0.0565459132]\n",
      "[0.506026804 0.376378447 0.236859649 ... 0.0550996065 0.0519403815 0.0519107282]\n",
      "[0.303195775 0.15920192 0.106539369 ... 0.0523375273 0.0511039197 0.0500539839]\n",
      "[0.974581599 0.939031303 0.853774 ... 0.0623498261 0.0592421 0.0522319973]\n",
      "[0.924111605 0.886899352 0.837992072 ... 0.0712316 0.0657962561 0.0591918528]\n",
      "[0.644382596 0.635731757 0.503547609 ... 0.0761430562 0.0754322708 0.074572]\n",
      "[0.98185426 0.928323627 0.787155628 ... 0.0632324815 0.0582468212 0.0501086712]\n",
      "[0.482033968 0.407830805 0.340837955 ... 0.0549202859 0.0538683832 0.0517128408]\n",
      "[0.764558077 0.726005614 0.495076448 ... 0.059391737 0.0590270758 0.0561769903]\n",
      "[0.644122124 0.602151036 0.519455492 ... 0.0566527247 0.056407243 0.0560730398]\n",
      "[0.896680772 0.586930871 0.203505427 ... 0.0525143445 0.051669389 0.0501737]\n",
      "[0.754458785 0.602390647 0.480911136 ... 0.0531316698 0.0530373156 0.0517039597]\n",
      "[0.56606704 0.557351589 0.237753391 ... 0.0609247386 0.0516774952 0.0507034659]\n",
      "[0.515522957 0.486666024 0.436217308 ... 0.059710294 0.0559791028 0.0531970561]\n",
      "[0.794407666 0.74545759 0.6965276 ... 0.0533812046 0.0531420112 0.0520601571]\n",
      "[0.862811923 0.692137957 0.622665942 ... 0.0943532288 0.0880011618 0.0514343381]\n",
      "[0.494081169 0.382244825 0.361362696 ... 0.0509736836 0.0505127 0.0500356853]\n",
      "[0.743663728 0.607056379 0.327789843 ... 0.0608066022 0.0582052469 0.0536951125]\n",
      "[0.755023479 0.435627878 0.434146285 ... 0.0555162132 0.0551183522 0.0545116663]\n",
      "[0.606337428 0.5150038 0.459834039 ... 0.0536078513 0.0521370769 0.0519756973]\n",
      "[0.898236454 0.0613694787 0.0607742071 0.0500162244]\n",
      "[0.712843 0.57397 0.567726552 ... 0.0501642227 0.050059855 0.050053]\n",
      "[0.45802778 0.393882513 0.341570497 ... 0.0549551845 0.0536158085 0.0516268]\n",
      "[0.595521033 0.111339569 0.0619841516]\n",
      "[0.970013261 0.407686412 0.372681111 ... 0.0510479808 0.0506722331 0.050222069]\n",
      "[0.569753408 0.504523754 0.497052819 ... 0.0516378284 0.0508461 0.0507428944]\n",
      "[0.704146922 0.661107242 0.605780482 ... 0.0519791842 0.0509631634 0.0503104329]\n",
      "[0.809923649 0.500640631 0.484196097 ... 0.057919383 0.0578246117 0.053678304]\n",
      "[0.679525137 0.638109148 0.55517149 ... 0.0564675033 0.0555570126 0.053059876]\n",
      "[0.70846349 0.130850136 0.0902332962 ... 0.0689142644 0.0547023416 0.052886039]\n",
      "[0.836008847 0.753215194 0.513581157 ... 0.106045544 0.0762253106 0.0582927167]\n",
      "[0.689563096 0.675468922 0.367090911 ... 0.0537237823 0.0534044802 0.0532381833]\n",
      "[0.799844921 0.729428768 0.457316369 ... 0.0516113043 0.0515271127 0.0512606204]\n",
      "[0.343074441 0.203785658 0.203404754 0.079317838 0.0776075423 0.0725112557]\n",
      "[0.777016282 0.699475646 0.335551769 ... 0.0517722964 0.0517641902 0.050806284]\n",
      "[0.807757854 0.771913111 0.581723392 ... 0.0647227168 0.0540967882 0.050899446]\n",
      "[0.859713137 0.592241526 0.246830642 ... 0.0599181354 0.0587616861 0.0582544804]\n",
      "[0.803914428 0.531552315 0.471122622 ... 0.0541698039 0.0530302823 0.0506964624]\n",
      "[0.940735161 0.931570768 0.913040459 ... 0.106189519 0.101103812 0.0977844596]\n",
      "[0.65038377 0.646624088 0.552538633 ... 0.0515512526 0.0515132844 0.0510671139]\n",
      "[0.889698 0.818515956 0.809424877 ... 0.0527714491 0.0511245728 0.0506674945]\n",
      "[0.809925914 0.562534213 0.449099571 ... 0.0549688935 0.0544756949 0.0527552664]\n",
      "[0.912119865 0.880510628 0.668549895 ... 0.0514092147 0.0513240397 0.0506914258]\n",
      "[0.902082 0.790159225 0.676137865 ... 0.0545296371 0.0524570644 0.0517816246]\n",
      "[0.987659395 0.945629835 0.240848631 ... 0.0574505627 0.0521460772 0.0507161319]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 738; epoch: 122; focal_loss: 0.1881686; l1_loss: 0.1386559; total_loss: 0.3268245; \n",
      "FastEstimator-Train: step: 738; focal_loss: 0.0774592; l1_loss: 0.0549607; total_loss: 0.13242; examples/sec: 32.0; progress: 61.5%; \n",
      "FastEstimator-Train: step: 739; focal_loss: 0.0955941; l1_loss: 0.0902722; total_loss: 0.1858663; examples/sec: 32.1; progress: 61.6%; \n",
      "FastEstimator-Train: step: 740; focal_loss: 0.1466649; l1_loss: 0.051586; total_loss: 0.198251; examples/sec: 32.1; progress: 61.7%; \n",
      "FastEstimator-Train: step: 741; focal_loss: 0.0825009; l1_loss: 0.0552367; total_loss: 0.1377377; examples/sec: 32.6; progress: 61.8%; \n",
      "FastEstimator-Train: step: 742; focal_loss: 0.0593453; l1_loss: 0.0918941; total_loss: 0.1512394; examples/sec: 32.2; progress: 61.8%; \n",
      "FastEstimator-Train: step: 743; focal_loss: 0.0645083; l1_loss: 0.0411421; total_loss: 0.1056504; examples/sec: 32.1; progress: 61.9%; \n",
      "[0.846054196 0.65290451 0.607107103 ... 0.0514194965 0.050927043 0.0501309931]\n",
      "[0.488462955 0.440439522 0.236601502 ... 0.0527144969 0.0520614386 0.0512705445]\n",
      "[0.7324332 0.108124137 0.101153612 0.0714693666]\n",
      "[0.137619466 0.0890141726 0.0659363 0.0584649146 0.0531945229]\n",
      "[0.665379941 0.498374343 0.395565063 ... 0.0604835451 0.0508811176 0.0506106615]\n",
      "[0.151674032 0.134178758 0.121747017 ... 0.0615353882 0.0579806566 0.0572622716]\n",
      "[0.688891888 0.453747928 0.316927969 ... 0.0526532531 0.0512628257 0.0508594215]\n",
      "[0.527200878 0.493936121 0.305439711 ... 0.0649595857 0.0539709628 0.0506649]\n",
      "[0.603689671 0.579441786 0.566397905 0.0734645426 0.0638462 0.0582707822]\n",
      "[0.440875 0.335503519 0.160491347 ... 0.0692481697 0.0574216545 0.0531052649]\n",
      "[0.580094218 0.511437535 0.491241753 ... 0.0630921423 0.0630415082 0.0628641248]\n",
      "[0.625848293 0.591962934 0.530289114 ... 0.0568946302 0.0563807189 0.0508307517]\n",
      "[0.567479372 0.518006861 0.449828058 ... 0.05306831 0.0522753894 0.051704973]\n",
      "[0.782303095 0.675506234 0.646320462 ... 0.0541306138 0.0526123643 0.0521373749]\n",
      "[0.706545949 0.702861309 0.688605189 ... 0.0685037673 0.0673482418 0.0662134]\n",
      "[0.619754612 0.406225115 0.14688316 ... 0.0532162189 0.0523737073 0.0516640544]\n",
      "[0.471325785 0.335095882 0.315455914 ... 0.056512922 0.0546864867 0.0546326339]\n",
      "[0.50193572 0.400897563 0.121682078 ... 0.0627416372 0.0563382208 0.0533286631]\n",
      "[0.479112983 0.471819 0.268771857 ... 0.054633677 0.0522272587 0.0500813723]\n",
      "[0.483540177 0.422825694 0.391811311 ... 0.0511571467 0.0502903461 0.0502513051]\n",
      "[0.800674498 0.492310524 0.474092692 ... 0.0918120444 0.0862904489 0.0561105907]\n",
      "[0.499943614 0.325938284 0.308710873 ... 0.0520830452 0.0503917038 0.0503006]\n",
      "[0.466881812 0.412607253 0.364063114 ... 0.0516176224 0.0507818162 0.0504614115]\n",
      "[0.576183 0.305352122 0.0937664807 0.0621953309 0.0546067655]\n",
      "[0.725127637 0.591757417 0.443804979 ... 0.0534028709 0.0526976883 0.0522347391]\n",
      "[0.685037374]\n",
      "[0.608993649 0.567889 0.47884202 ... 0.0518370867 0.0503557622 0.0500578284]\n",
      "[0.990129471 0.859380782 0.817124 ... 0.0509744883 0.0506536663 0.0503648221]\n",
      "[0.813153386]\n",
      "[0.380363733 0.252955675 0.124572903 ... 0.0695567727 0.0542925 0.0507935]\n",
      "[0.733279467 0.658160925 0.594139576 ... 0.0526256561 0.052433759 0.0501579046]\n",
      "[0.441057295 0.429114193 0.406559736 ... 0.051469 0.0503750145 0.0501243472]\n",
      "[0.669109821 0.620535254 0.412237704 ... 0.0536463857 0.0514272153 0.0504733324]\n",
      "[0.393683314 0.294731289 0.284139603 ... 0.0563393831 0.0528507233 0.0518892109]\n",
      "[0.26660955 0.121942848 0.0642294884]\n",
      "[0.516332865 0.186274141 0.18367812 ... 0.0605387092 0.0567799211 0.0507753491]\n",
      "[0.960131824 0.716944218 0.693127513 ... 0.0548553467 0.054752022 0.0528411567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.719384193 0.458798 0.388058752 ... 0.0514713228 0.0505156219 0.0502729714]\n",
      "[0.926237881 0.287954718 0.20689249 ... 0.0950660408 0.0852174163 0.0693394542]\n",
      "[0.644742727 0.514855325 0.506853163 ... 0.0540053546 0.0537928343 0.0529681444]\n",
      "[0.321601361 0.277148038 0.0694525838 ... 0.0537130535 0.053635627 0.0526194274]\n",
      "[0.587916851 0.317831784 0.0926033854 0.0609043241]\n",
      "[0.41032818 0.347215414 0.236393839 ... 0.0554153621 0.0532570779 0.0510716438]\n",
      "[0.833414257 0.799075961 0.67195797 ... 0.0513311028 0.0510555804 0.0507684052]\n",
      "[0.578912377 0.544010162 0.49088341 ... 0.0545815527 0.0545344949 0.0501659811]\n",
      "[0.64137584 0.634209633 0.621195614 ... 0.054564178 0.0543952584 0.0521586835]\n",
      "[0.515253723 0.51384145 0.353633106 ... 0.063267529 0.058737427 0.0517099798]\n",
      "[0.694915712 0.655280232 0.62871331 ... 0.0525591373 0.051379174 0.0502901673]\n",
      "FastEstimator-Eval: step: 744; epoch: 123; focal_loss: 0.2699861; l1_loss: 0.1631771; total_loss: 0.4331632; \n",
      "FastEstimator-Train: step: 744; focal_loss: 0.0778593; l1_loss: 0.0524613; total_loss: 0.1303206; examples/sec: 32.2; progress: 62.0%; \n",
      "FastEstimator-Train: step: 745; focal_loss: 0.0956745; l1_loss: 0.0711147; total_loss: 0.1667892; examples/sec: 32.1; progress: 62.1%; \n",
      "FastEstimator-Train: step: 746; focal_loss: 0.1632776; l1_loss: 0.0821302; total_loss: 0.2454077; examples/sec: 32.3; progress: 62.2%; \n",
      "FastEstimator-Train: step: 747; focal_loss: 0.0636195; l1_loss: 0.0559499; total_loss: 0.1195694; examples/sec: 32.3; progress: 62.3%; \n",
      "FastEstimator-Train: step: 748; focal_loss: 0.1680431; l1_loss: 0.0487382; total_loss: 0.2167813; examples/sec: 32.2; progress: 62.3%; \n",
      "FastEstimator-Train: step: 749; focal_loss: 0.0523326; l1_loss: 0.0260644; total_loss: 0.078397; examples/sec: 32.1; progress: 62.4%; \n",
      "[0.693419337 0.546929717 0.543259084 ... 0.0511273444 0.0509539247 0.0505646467]\n",
      "[0.999174237 0.995042443 0.304764628 ... 0.0832007229 0.0616114438 0.0551709235]\n",
      "[0.867515147 0.621755302 0.571741402 ... 0.0523408949 0.0521402061 0.0513436198]\n",
      "[0.547894657 0.465729773 0.383270085 ... 0.0579539835 0.0543558 0.0505190492]\n",
      "[0.958935261 0.220689565 0.209690034 ... 0.0821818709 0.0770445466 0.0713615417]\n",
      "[0.699543 0.224595308 0.0933984816 ... 0.0587749183 0.054005295 0.0508473516]\n",
      "[0.747759879 0.728179157 0.62517488 ... 0.0524813831 0.051538974 0.0504571795]\n",
      "[0.976472855 0.514575303 0.232372552 ... 0.0934604406 0.0644920468 0.055861026]\n",
      "[0.750265718 0.613712549 0.438014 ... 0.0524780154 0.0508725345 0.0504238]\n",
      "[0.650425732 0.466695696 0.353946865 ... 0.0658426583 0.0560859442 0.0554974973]\n",
      "[0.879517 0.739104509 0.704709053 ... 0.0748277605 0.0550881922 0.0536133647]\n",
      "[0.821459174 0.801007628 0.389297336 ... 0.0575782359 0.0556767285 0.0537176132]\n",
      "[0.612305343 0.426347375 0.408961564 ... 0.0649176538 0.0646588206 0.0646491349]\n",
      "[0.970942259 0.950899601 0.940987229 ... 0.0610278547 0.0560823679 0.0539861321]\n",
      "[0.546768844 0.482146829 0.449792534 ... 0.0718116164 0.0694294274 0.0581609]\n",
      "[0.767368793 0.68499881 0.628139377 ... 0.0534696877 0.0527745187 0.0503447652]\n",
      "[0.691086352 0.61074394 0.605264723 ... 0.0623753369 0.0620676577 0.0618278086]\n",
      "[0.759504616 0.605032086 0.18365863 ... 0.0621596277 0.0576836169 0.051669538]\n",
      "[0.597054839 0.498235345 0.474202216 ... 0.0537077188 0.0529940724 0.0518326461]\n",
      "[0.664592147 0.663040757 0.586918831 ... 0.063741 0.0564188361 0.0521075428]\n",
      "[0.617124796 0.528120875 0.44819665 ... 0.055383116 0.0539577305 0.0509190261]\n",
      "[0.785719156 0.600424826 0.479289711 ... 0.0603441 0.0540557802 0.0535661578]\n",
      "[0.992820382 0.781944156 0.675360143 ... 0.0736518204 0.0684875548 0.0515628755]\n",
      "[0.632354 0.618077517 0.52688694 ... 0.0512728393 0.0507294238 0.0500272214]\n",
      "[0.474131346 0.3728953 0.346800894 ... 0.0580374 0.0526663065 0.0512269139]\n",
      "[0.760553837 0.399734527 0.246444225 ... 0.0840452313 0.0553671718 0.0544530749]\n",
      "[0.624298573 0.610368073 0.407529712 ... 0.0554851 0.0518206954 0.0505268276]\n",
      "[0.85458684 0.0996938646 0.0967645049 0.0551432073 0.0530953109]\n",
      "[0.580324531 0.473238915 0.447822273 ... 0.0519043505 0.0501288474 0.0500267446]\n",
      "[0.838035107 0.403241754 0.341129 ... 0.0704229474 0.0693879128 0.0562283397]\n",
      "[0.511139333 0.0845236778 0.0626624227 0.0579943061 0.0557338297]\n",
      "[0.705739737 0.691135585 0.421298712 ... 0.0573195219 0.0532464981 0.0530255437]\n",
      "[0.528862894 0.521207809 0.378567129 ... 0.0533680022 0.0506383479 0.0501389802]\n",
      "[0.737768054 0.723385096 0.635421753 ... 0.0522987545 0.0521719456 0.0519862473]\n",
      "[0.575239301 0.541661501 0.419340134 ... 0.0543644726 0.0523981452 0.0504373]\n",
      "[0.420352221 0.227457434 0.224739283 ... 0.0574997365 0.0512482822 0.0512138]\n",
      "[0.841394663 0.0801804066 0.0667525232 0.0627893209 0.0600299835 0.0527791083]\n",
      "[0.827742338 0.28722918 0.221859813 ... 0.0646527112 0.0537251234 0.0525718033]\n",
      "[0.863457203 0.678503573 0.418335199 ... 0.0557833 0.0538316667 0.0527440608]\n",
      "[0.907238841 0.693413317 0.626864076 ... 0.0513664782 0.0501339436 0.0500008762]\n",
      "[0.334997475 0.251595169 0.113469422 0.0835779607 0.0611457229 0.0505881608]\n",
      "[0.672824085 0.545777 0.486203611 ... 0.0610974133 0.0588948131 0.0578859448]\n",
      "[0.532177746 0.37473911 0.076467067 ... 0.0591608286 0.0549786091 0.0531902]\n",
      "[0.713581204 0.541739583 0.106740832 ... 0.0744647384 0.0636406243 0.0552279949]\n",
      "[0.800826132 0.540423334 0.369842261 ... 0.0543229282 0.0530771613 0.0505852103]\n",
      "[0.850689411 0.643601418 0.610284626 ... 0.0545548797 0.054476887 0.0544316471]\n",
      "[0.79212606 0.559272528 0.53672564 ... 0.0538046062 0.0513283908 0.050558269]\n",
      "[0.909717143 0.824494421 0.719608426 ... 0.0561770201 0.0551425815 0.0528956056]\n",
      "FastEstimator-Eval: step: 750; epoch: 124; focal_loss: 0.2232605; l1_loss: 0.1227879; total_loss: 0.3460484; \n",
      "FastEstimator-Train: step: 750; focal_loss: 0.0544123; l1_loss: 0.0415476; total_loss: 0.0959598; examples/sec: 32.3; progress: 62.5%; \n",
      "FastEstimator-Train: step: 751; focal_loss: 0.1095006; l1_loss: 0.0352946; total_loss: 0.1447952; examples/sec: 32.2; progress: 62.6%; \n",
      "FastEstimator-Train: step: 752; focal_loss: 0.0542007; l1_loss: 0.0486081; total_loss: 0.1028088; examples/sec: 32.2; progress: 62.7%; \n",
      "FastEstimator-Train: step: 753; focal_loss: 0.1070433; l1_loss: 0.0428895; total_loss: 0.1499328; examples/sec: 32.0; progress: 62.7%; \n",
      "FastEstimator-Train: step: 754; focal_loss: 0.1182625; l1_loss: 0.0741544; total_loss: 0.1924169; examples/sec: 32.4; progress: 62.8%; \n",
      "FastEstimator-Train: step: 755; focal_loss: 0.1795003; l1_loss: 0.1462327; total_loss: 0.3257331; examples/sec: 32.1; progress: 62.9%; \n",
      "[0.631728113 0.132865369 0.103377134 0.0993560255 0.0554001033 0.0541289449]\n",
      "[0.958231 0.822061718 0.801790297 ... 0.0520592034 0.0504348278 0.0501427054]\n",
      "[0.672532618 0.53921932 0.538966775 ... 0.0517087877 0.051106751 0.0502546728]\n",
      "[0.15580231 0.152272135 0.0586991 0.0507118106]\n",
      "[0.89998728 0.731595814 0.700766504 ... 0.0511743128 0.0506708026 0.0505375266]\n",
      "[0.836679339 0.706792951 0.557522416 ... 0.0547391772 0.0537638962 0.0530815125]\n",
      "[0.214213133 0.0973793864 0.0542530417]\n",
      "[0.438010961 0.135962248 0.0697380304 0.0548658967 0.0507026911]\n",
      "[0.869167 0.690741 0.603592694 ... 0.0518921 0.051692605 0.0503195524]\n",
      "[0.443054646 0.238355249 0.136547089 ... 0.0613454282 0.061198473 0.0555650592]\n",
      "[0.812168598 0.68926841 0.492001384 ... 0.0518864691 0.0514153242 0.0504419804]\n",
      "[0.796295047 0.70477432 0.565390825 ... 0.0633377433 0.0624142 0.0610483587]\n",
      "[0.657090664 0.456119 0.436302096 ... 0.0723168254 0.0719893575 0.0544296205]\n",
      "[0.431500435 0.353640556 0.306863368 ... 0.0518566966 0.0512090623 0.0507357121]\n",
      "[0.754829109 0.627506912 0.601617754 ... 0.0884403288 0.0869385302 0.0865076482]\n",
      "[0.947908044 0.894215 0.745913863 ... 0.0597887933 0.0586304367 0.0577765405]\n",
      "[0.669197083 0.644363761 0.563527524 ... 0.0509011745 0.0503780842 0.0501026213]\n",
      "[0.741282 0.625174761 0.562836647 ... 0.0545070767 0.0536711812 0.0527249277]\n",
      "[0.915014863 0.812327743 0.797974527 ... 0.0787043571 0.0783768 0.0780827701]\n",
      "[0.441743106 0.339554727 0.0986323357 ... 0.0570999682 0.0541192 0.0519685149]\n",
      "[0.682450891 0.568395555 0.565818429 ... 0.0544135869 0.0541076064 0.0529502332]\n",
      "[0.645678103 0.445353329 0.396556 ... 0.0617415 0.0527695715 0.0506478548]\n",
      "[0.658054948 0.575668037 0.507808626 ... 0.0556612611 0.053848803 0.0508443415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.688577414 0.664024115 0.656349719 ... 0.0538744926 0.0537202954 0.0533328354]\n",
      "[0.967129588 0.644726038 0.638837576 ... 0.065620482 0.0594682097 0.0555567741]\n",
      "[0.835100114 0.822604537 0.758526564 ... 0.0521203578 0.050886184 0.0500023663]\n",
      "[0.482033491 0.355016 0.323306352 ... 0.052485317 0.0518018 0.0503425896]\n",
      "[0.659902811 0.394383729 0.162163615 ... 0.0651066 0.0552196801 0.0537543]\n",
      "[0.753707886 0.583289146 0.502159238 ... 0.059271574 0.0578190088 0.0577769578]\n",
      "[0.540013134 0.0794286728]\n",
      "[0.674817383 0.663378716 0.643914878 ... 0.0518387258 0.0517554879 0.0509762764]\n",
      "[0.642773509 0.363275677 0.333077252 ... 0.0599576235 0.0536765158 0.0518066585]\n",
      "[0.629090667 0.0583052337]\n",
      "[0.647925377 0.375527561 0.222218215 ... 0.0629496 0.057686 0.0520711243]\n",
      "[0.742174327 0.533685923 0.511916757 ... 0.0558618903 0.054897517 0.0525180399]\n",
      "[0.803314865 0.684446335 0.63384217 ... 0.0513674617 0.0506644249 0.0504499376]\n",
      "[0.646474063 0.492065489 0.452304751 ... 0.0527798831 0.0513765216 0.0511850417]\n",
      "[0.603015363 0.547186911 0.345345974 ... 0.0532656 0.052621603 0.0517233908]\n",
      "[0.717864096 0.103057563 0.05346632 0.052364409]\n",
      "[0.728698611 0.650178194 0.561695337 ... 0.0526940525 0.05175668 0.0504514575]\n",
      "[0.917341709 0.672884822 0.659314 ... 0.0540440977 0.0505072773 0.0504647493]\n",
      "[0.814621687 0.752420425 0.691708267 ... 0.0614919662 0.0613937974 0.0609988868]\n",
      "[0.2833516 0.227339536 0.0561193228 0.0512003]\n",
      "[0.624164462 0.528702497 0.50322181 ... 0.0594100356 0.0587307513 0.0585500896]\n",
      "[0.45040673 0.446866542 0.140004158 ... 0.0531857908 0.0504670441 0.0502964556]\n",
      "[0.595984399 0.289734125 0.0834806 ... 0.0555485487 0.0541138351 0.0528500676]\n",
      "[0.681330919 0.597886503 0.5892331 ... 0.05238989 0.0518949032 0.0506221652]\n",
      "[0.63441062 0.634113491 0.600448608 ... 0.0556083024 0.0554557145 0.055149585]\n",
      "FastEstimator-Eval: step: 756; epoch: 125; focal_loss: 0.1709766; l1_loss: 0.1627411; total_loss: 0.3337177; \n",
      "FastEstimator-Train: step: 756; focal_loss: 0.0808433; l1_loss: 0.062581; total_loss: 0.1434243; examples/sec: 32.3; progress: 63.0%; \n",
      "FastEstimator-Train: step: 757; focal_loss: 0.0448181; l1_loss: 0.0467866; total_loss: 0.0916046; examples/sec: 31.7; progress: 63.1%; \n",
      "FastEstimator-Train: step: 758; focal_loss: 0.0539058; l1_loss: 0.0390045; total_loss: 0.0929103; examples/sec: 32.1; progress: 63.2%; \n",
      "FastEstimator-Train: step: 759; focal_loss: 0.0646568; l1_loss: 0.0912155; total_loss: 0.1558723; examples/sec: 32.5; progress: 63.2%; \n",
      "FastEstimator-Train: step: 760; focal_loss: 0.0810732; l1_loss: 0.0523397; total_loss: 0.1334128; examples/sec: 32.5; progress: 63.3%; \n",
      "FastEstimator-Train: step: 761; focal_loss: 0.0411873; l1_loss: 0.0384957; total_loss: 0.079683; examples/sec: 32.0; progress: 63.4%; \n",
      "[0.848911166 0.795970201 0.725927413 ... 0.0514558256 0.0510804951 0.0505440831]\n",
      "[0.856312394 0.692618728 0.642090321 ... 0.0542592704 0.05389449 0.0534381866]\n",
      "[0.647022545 0.199544311 0.198608279 ... 0.0584508479 0.0538861156 0.05005005]\n",
      "[0.859791577 0.753424287 0.726647079 ... 0.0532596409 0.0527001917 0.0525760353]\n",
      "[0.754447937 0.726126909 0.588862121 ... 0.0526767373 0.0516330302 0.0510482788]\n",
      "[0.804574 0.684832215 0.0561594963 0.0518042445]\n",
      "[0.740892768 0.731511831 0.662009478 ... 0.0505077243 0.0503386855 0.0500438809]\n",
      "[0.91239053 0.821578 0.585478246 ... 0.052490592 0.0511218309 0.0508197844]\n",
      "[0.648969233 0.0538819432 0.0537742972]\n",
      "[0.858751059 0.791214883 0.0929298103 0.0757012367 0.0606470108 0.0528042614]\n",
      "[0.885084 0.836301446 0.690372467 ... 0.0510236919 0.0509191453 0.0505357385]\n",
      "[0.343010485 0.281558037 0.0757722855 0.0640631318 0.0506170392]\n",
      "[0.793085933 0.766628265 0.549801469 ... 0.050643146 0.0505318642 0.0502516925]\n",
      "[0.897634 0.862842679 0.857388914 ... 0.0531758368 0.0509712398 0.0500720143]\n",
      "[0.838676 0.778507 0.713185549 ... 0.0903492272 0.0669342875 0.0569140315]\n",
      "[0.575032055 0.537914872 0.515974343 ... 0.0711517 0.0707812309 0.0544903874]\n",
      "[0.7795645 0.584526539 0.527529 ... 0.0787932277 0.0786811411 0.0774707496]\n",
      "[0.940327406 0.910216749 0.901076317 ... 0.0571902692 0.0559978783 0.0525905192]\n",
      "[0.648269773 0.586471736 0.346857667 ... 0.0509926379 0.0508768857 0.0501654446]\n",
      "[0.893532276 0.62158072 0.498256087 ... 0.058745265 0.0561587811 0.0554592907]\n",
      "[0.855307 0.775111675 0.692449272 ... 0.0688757896 0.0673439205 0.0672021806]\n",
      "[0.542328477 0.351952106 0.0631088912 0.0554078221 0.0522618294 0.0521461368]\n",
      "[0.800482869 0.726696789 0.666699588 ... 0.0577824116 0.0528183 0.0507470071]\n",
      "[0.53298825 0.442847669 0.269852 ... 0.0557476282 0.0529498458 0.0501229465]\n",
      "[0.701004446 0.594062209 0.590528429 ... 0.0524101853 0.0521552563 0.0504286587]\n",
      "[0.774077177 0.767272592 0.630142093 ... 0.0564663112 0.0556548238 0.0526174903]\n",
      "[0.971215844 0.82010293 0.759839892 ... 0.0680432 0.0589944422 0.0561662912]\n",
      "[0.815537572 0.536078095 0.527953386 ... 0.051751107 0.0508494079 0.0501056314]\n",
      "[0.572499514 0.384934068 0.361292928 ... 0.0567178726 0.0512298346 0.0500458181]\n",
      "[0.736032844 0.410989553 0.184273481 ... 0.0539321899 0.0516423 0.0507023931]\n",
      "[0.759401143 0.546836793 0.53252852 ... 0.0527724624 0.0517218709 0.0500495732]\n",
      "[0.786144257]\n",
      "[0.571562648 0.47737357 0.430219591 ... 0.0525566936 0.0511361957 0.0511360466]\n",
      "[0.355225801 0.237814933 0.226193815 ... 0.0814122558 0.0706579387 0.0638777]\n",
      "[0.501657724 0.0662810802 0.0549298823]\n",
      "[0.984727383 0.541130602 0.358425438 ... 0.0575659871 0.0513238609 0.050650686]\n",
      "[0.818448067 0.553768516 0.54626 ... 0.0543855727 0.0542567074 0.0509887338]\n",
      "[0.832612157 0.831766725 0.692398906 ... 0.0510707796 0.0508981645 0.0502998829]\n",
      "[0.71535182 0.638273954 0.584025383 ... 0.0516596735 0.0512802601 0.0501048565]\n",
      "[0.678567231 0.525950074 0.310677588 ... 0.0565850437 0.0540555716 0.0505027473]\n",
      "[0.645856202 0.0692494512]\n",
      "[0.861263037 0.837201476 0.676703572 ... 0.0822759569 0.066783309 0.05500561]\n",
      "[0.786174774 0.558144808 0.374999344 ... 0.0520736873 0.051230967 0.050191313]\n",
      "[0.730699718 0.655640721 0.5933761 ... 0.0562718809 0.0560058653 0.0558721721]\n",
      "[0.157178849 0.143868744 0.0515757501]\n",
      "[0.532646775 0.51998347 0.437519908 ... 0.0513050854 0.0511539 0.0509689152]\n",
      "[0.882589757 0.363882601 0.333332837 ... 0.053195864 0.0506344438 0.0503519773]\n",
      "[0.681945741 0.531746507 0.0855979 ... 0.0554462373 0.0547021925 0.0536987484]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 762; epoch: 126; focal_loss: 0.1437917; l1_loss: 0.14803; total_loss: 0.2918218; \n",
      "FastEstimator-Train: step: 762; focal_loss: 0.048581; l1_loss: 0.0374512; total_loss: 0.0860322; examples/sec: 31.9; progress: 63.5%; \n",
      "FastEstimator-Train: step: 763; focal_loss: 0.0838881; l1_loss: 0.083703; total_loss: 0.167591; examples/sec: 32.1; progress: 63.6%; \n",
      "FastEstimator-Train: step: 764; focal_loss: 0.0437925; l1_loss: 0.06675; total_loss: 0.1105426; examples/sec: 32.1; progress: 63.7%; \n",
      "FastEstimator-Train: step: 765; focal_loss: 0.028283; l1_loss: 0.0536162; total_loss: 0.0818993; examples/sec: 31.9; progress: 63.7%; \n",
      "FastEstimator-Train: step: 766; focal_loss: 0.0346462; l1_loss: 0.0355032; total_loss: 0.0701493; examples/sec: 32.6; progress: 63.8%; \n",
      "FastEstimator-Train: step: 767; focal_loss: 0.0460508; l1_loss: 0.0337569; total_loss: 0.0798077; examples/sec: 32.2; progress: 63.9%; \n",
      "[0.951496899 0.813721418 0.613313794 ... 0.0517985523 0.0517114401 0.0506845117]\n",
      "[0.951992214 0.945001602 0.886096478 ... 0.0626473427 0.0611463487 0.0602942407]\n",
      "[0.87883234 0.84216249 0.790976644 ... 0.0549506843 0.0529289544 0.0522056222]\n",
      "[0.661819577 0.562869191 0.516762316 ... 0.0737667084 0.0718306601 0.071010977]\n",
      "[0.558026791 0.480005443 0.194330573 ... 0.0589028 0.0526708066 0.0509136021]\n",
      "[0.751741409 0.65639782 0.572950959 ... 0.0519295037 0.0507026315 0.0504600704]\n",
      "[0.848620415 0.796481311 0.661220253 ... 0.0511187911 0.0507654548 0.05056867]\n",
      "[0.908340693 0.830400944 0.0601393878 0.0518194735 0.0512831807]\n",
      "[0.945544124 0.848237157 0.83934927 ... 0.0526394546 0.0520325899 0.0503697693]\n",
      "[0.835778534 0.729692 0.378567785 ... 0.0553515851 0.0528821647 0.0515193641]\n",
      "[0.902557552 0.0628865063]\n",
      "[0.937614501 0.92419076 0.0716881752 ... 0.056894213 0.0520781875 0.0507645309]\n",
      "[0.93070817 0.734192967 0.724526525 ... 0.0560193658 0.0535694063 0.050234586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.437681973 0.369197905 0.0517551601]\n",
      "[0.769713759 0.705910563 0.565941095 ... 0.0530162454 0.0514056087 0.0500372052]\n",
      "[0.903800666 0.873859525 0.85802114 ... 0.0560629368 0.0509468019 0.0507828295]\n",
      "[0.915516198 0.847102523 0.702217162 ... 0.0651109219 0.0610534251 0.0567607582]\n",
      "[0.618682444 0.61279732 0.486691773 0.456743658 0.342828691]\n",
      "[0.819221377 0.725393176 0.569992065 ... 0.0834411383 0.0834227204 0.0807135105]\n",
      "[0.964934349 0.936828792 0.903760076 ... 0.072075516 0.0585316718 0.0500297844]\n",
      "[0.769546 0.75211072 0.523225486 ... 0.0541628 0.0535402 0.0516880453]\n",
      "[0.857213855 0.734767556 0.501986742 ... 0.0604943037 0.0553568304 0.052354902]\n",
      "[0.711224675 0.693070829 0.658426583 ... 0.0678683221 0.0675451159 0.0675177574]\n",
      "[0.573623478 0.418025792 0.0688147843 0.0633159]\n",
      "[0.831242919 0.684972644 0.620907962 ... 0.0581001639 0.0563703179 0.0530548394]\n",
      "[0.461241186 0.439186484 0.178498119]\n",
      "[0.701743484 0.550097942 0.54074508 ... 0.051247 0.0505506694 0.050532341]\n",
      "[0.680594862 0.577518761 0.413544476 ... 0.0539678335 0.0524468124 0.0511994958]\n",
      "[0.910970449 0.835577369 0.723776102 ... 0.0844803154 0.0719150603 0.0540395975]\n",
      "[0.681046128 0.590613842 0.570684314 ... 0.0508084297 0.0508045256 0.0505562127]\n",
      "[0.510526776 0.493870914 0.371023893 ... 0.05212 0.0516912639 0.0514724553]\n",
      "[0.751647234 0.361544073 0.33544302 0.163994581 0.0606470406]\n",
      "[0.780526638 0.590976417 0.483853579 ... 0.0581466556 0.0553520322 0.0548891723]\n",
      "[0.87406534]\n",
      "[0.728274167 0.687814415 0.562075794 ... 0.0527080297 0.0510444641 0.0510032475]\n",
      "[0.502249479 0.3879942 0.351802081 ... 0.0612851977 0.0571121573 0.0535507202]\n",
      "[0.141482741 0.0954878628 0.0770314336 0.0632688105]\n",
      "[0.994068623 0.255002201 0.199374855 ... 0.0553390682 0.0536596179 0.0534402728]\n",
      "[0.860532701 0.792601109 0.695815146 ... 0.0512006 0.0501200855 0.0500518382]\n",
      "[0.763552725 0.607284188 0.513660729 ... 0.0556770861 0.0534239709 0.0501809418]\n",
      "[0.700101852 0.610176504 0.545297623 ... 0.0666511655 0.0560573936 0.0534290373]\n",
      "[0.639528096 0.367702663 0.311117589 ... 0.0565532446 0.0562895834 0.0532518327]\n",
      "[0.899214864 0.0677048862 0.0626077652]\n",
      "[0.685415447 0.583506882 0.270489186 ... 0.0708073676 0.0648666322 0.051407218]\n",
      "[0.918995857 0.716537595 0.560806155 ... 0.0584296584 0.0571822226 0.0537524819]\n",
      "[0.833721638 0.756677389 0.570546806 ... 0.0508632958 0.0504033267 0.0502759516]\n",
      "[0.375359267 0.316247165 0.166982144 ... 0.0662462115 0.0606707335 0.0542938411]\n",
      "[0.462355107 0.411378622 0.390903771 ... 0.0515911877 0.0514761209 0.0503130555]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 768; epoch: 127; focal_loss: 0.144342; l1_loss: 0.0696996; total_loss: 0.2140416; \n",
      "FastEstimator-Train: step: 768; focal_loss: 0.0182886; l1_loss: 0.0536708; total_loss: 0.0719594; examples/sec: 31.6; progress: 64.0%; \n",
      "FastEstimator-Train: step: 769; focal_loss: 0.0493956; l1_loss: 0.0490671; total_loss: 0.0984627; examples/sec: 31.7; progress: 64.1%; \n",
      "FastEstimator-Train: step: 770; focal_loss: 0.0454652; l1_loss: 0.082205; total_loss: 0.1276702; examples/sec: 32.2; progress: 64.2%; \n",
      "FastEstimator-Train: step: 771; focal_loss: 0.0270828; l1_loss: 0.0640442; total_loss: 0.091127; examples/sec: 31.9; progress: 64.2%; \n",
      "FastEstimator-Train: step: 772; focal_loss: 0.0216459; l1_loss: 0.0383601; total_loss: 0.060006; examples/sec: 31.8; progress: 64.3%; \n",
      "FastEstimator-Train: step: 773; focal_loss: 0.0429038; l1_loss: 0.0334775; total_loss: 0.0763813; examples/sec: 32.3; progress: 64.4%; \n",
      "[0.859552681 0.689394355 0.601066887 ... 0.0573060811 0.0564103425 0.0557597578]\n",
      "[0.811426401 0.511321902 0.078817606 0.0559133291]\n",
      "[0.970719814 0.854177237 0.704897881 ... 0.0593043864 0.0525552928 0.0525389314]\n",
      "[0.888498187 0.885262 0.845128179 ... 0.0513988733 0.0510456264 0.0509980917]\n",
      "[0.838035107 0.79424119 0.753619075 ... 0.0560748279 0.0516415238 0.0506800711]\n",
      "[0.808905 0.758343339 0.758010566 ... 0.0633975 0.0568167269 0.0524925]\n",
      "[0.743302941 0.637126327 0.510452509 ... 0.0655188859 0.054618746 0.0510225]\n",
      "[0.948121607 0.856624126 0.85348177 ... 0.0518091619 0.0505482256 0.0504785478]\n",
      "[0.888928 0.866636574 0.770810485 ... 0.0509662926 0.05031991 0.0503104925]\n",
      "[0.880915403 0.699849725 0.0806960762 0.0521960855]\n",
      "[0.973184 0.903223097 0.860928893 ... 0.0515235364 0.051055789 0.0503545403]\n",
      "[0.812992692 0.698995531 0.521277428 ... 0.0598406792 0.0596990287 0.050879]\n",
      "[0.895648241 0.0742927492]\n",
      "[0.788984358 0.484554321 0.0635772049]\n",
      "[0.923102677 0.828905225 0.70598805 ... 0.0568006635 0.0563493967 0.0520984828]\n",
      "[0.397537738 0.359207749 0.0617723763 0.0546425581 0.052095145]\n",
      "[0.77191323 0.727665603 0.60843 ... 0.056663543 0.0543141365 0.0521592796]\n",
      "[0.930450678 0.851447105 0.75638783 ... 0.060206145 0.0527113974 0.0506900549]\n",
      "[0.903848767 0.769015074 0.647398174 ... 0.109966367 0.0617176 0.0604418516]\n",
      "[0.536247671 0.470672339 0.456910372 0.449729174 0.27557081]\n",
      "[0.900231481 0.806277752 0.662689865 ... 0.072809428 0.0725193322 0.0712789]\n",
      "[0.969455302 0.963061094 0.924982607 ... 0.0591854155 0.0590212643 0.0541952848]\n",
      "[0.821171522 0.806150377 0.753184795 ... 0.0558949411 0.0550304055 0.0512431264]\n",
      "[0.856241345 0.743661284 0.530956566 ... 0.0565432 0.0540125966 0.0516225696]\n",
      "[0.707650185 0.650671244 0.637343407 ... 0.0676432848 0.0674652159 0.0673310161]\n",
      "[0.611696422 0.503110588 0.0895056725 ... 0.0594477952 0.058493346 0.0559774935]\n",
      "[0.835276 0.707958758 0.70383811 ... 0.0553157926 0.054161042 0.0519911945]\n",
      "[0.47919628 0.476353884 0.31247142 0.0596684515]\n",
      "[0.585646749 0.523228705 0.501401424 ... 0.0624503791 0.0624395907 0.0618610978]\n",
      "[0.754688621 0.707018256 0.652075052 ... 0.0558582246 0.051612705 0.0500294566]\n",
      "[0.933915555 0.854422 0.705174327 ... 0.0616924465 0.0612173975 0.0594116747]\n",
      "[0.789246321 0.752492428 0.69109261 ... 0.0548633039 0.0540828109 0.0523497462]\n",
      "[0.664790034 0.641277075 0.553418756 ... 0.0582705438 0.0576922297 0.0560917258]\n",
      "[0.651435435 0.497548848 0.155585349 0.0702269077]\n",
      "[0.782523751 0.635812044 0.461910039 ... 0.0874278247 0.0590025187 0.0539135933]\n",
      "[0.756967783]\n",
      "[0.807684779 0.800193787 0.789140582 ... 0.0524868369 0.0516895354 0.0502429903]\n",
      "[0.733222604 0.493430644 0.484746546 ... 0.0772222281 0.0658095181 0.0501236022]\n",
      "[0.279379249 0.0590403378]\n",
      "[0.984249413 0.524435222 0.115599334 ... 0.0661405 0.0612126887 0.054017067]\n",
      "[0.923502862 0.865798295 0.779924572 ... 0.0549688041 0.0528097451 0.0518493354]\n",
      "[0.792503595 0.727375329 0.584589303 ... 0.0540466607 0.0526649654 0.0501709]\n",
      "[0.791814089 0.69663471 0.489309162 ... 0.0607248545 0.0576084256 0.0502764881]\n",
      "[0.798378527 0.577324688 0.565507531 ... 0.0540085137 0.0519222021 0.050442189]\n",
      "[0.853656411 0.0863649845 0.0546003 0.0515420735]\n",
      "[0.764893413 0.707189202 0.431924522 ... 0.0737663507 0.063588649 0.0571144223]\n",
      "[0.955931664 0.768879056 0.700091958 ... 0.0611230135 0.0556893051 0.0500088036]\n",
      "[0.824415803 0.745069 0.620673537 ... 0.0522294939 0.0516521335 0.0508940518]\n",
      "FastEstimator-Eval: step: 774; epoch: 128; focal_loss: 0.0951359; l1_loss: 0.1958496; total_loss: 0.2909855; \n",
      "FastEstimator-Train: step: 774; focal_loss: 0.0245211; l1_loss: 0.1181286; total_loss: 0.1426496; examples/sec: 32.3; progress: 64.5%; \n",
      "FastEstimator-Train: step: 775; focal_loss: 0.0146073; l1_loss: 0.113059; total_loss: 0.1276664; examples/sec: 32.2; progress: 64.6%; \n",
      "FastEstimator-Train: step: 776; focal_loss: 0.0123835; l1_loss: 0.0657916; total_loss: 0.0781752; examples/sec: 32.2; progress: 64.7%; \n",
      "FastEstimator-Train: step: 777; focal_loss: 0.1787757; l1_loss: 0.0432685; total_loss: 0.2220442; examples/sec: 31.9; progress: 64.8%; \n",
      "FastEstimator-Train: step: 778; focal_loss: 0.015265; l1_loss: 0.0262809; total_loss: 0.041546; examples/sec: 32.4; progress: 64.8%; \n",
      "FastEstimator-Train: step: 779; focal_loss: 0.0275096; l1_loss: 0.0569274; total_loss: 0.084437; examples/sec: 32.5; progress: 64.9%; \n",
      "[0.835033953 0.241815954 0.232736379 ... 0.070639044 0.0575062931 0.0541020036]\n",
      "[0.822219729 0.685188055 0.652545035 ... 0.0545366704 0.0522871315 0.0508641601]\n",
      "[0.952331901 0.79660517 0.762561619 ... 0.0532563329 0.0529360175 0.0507417321]\n",
      "[0.9029634 0.472981691 0.0840204954 0.0589920282 0.0576667786]\n",
      "[0.978964567 0.881463408 0.752913952 ... 0.0541383326 0.0518869758 0.0508235693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.908306718 0.876688123 0.870435238 ... 0.0506021976 0.0504875779 0.050450176]\n",
      "[0.784340382 0.771710038 0.732365966 ... 0.0512571037 0.0503064394 0.0500558317]\n",
      "[0.877761722 0.875578821 0.86428 ... 0.0599367917 0.0544269085 0.0543575883]\n",
      "[0.836075664 0.712650478 0.699574709 ... 0.0552592278 0.051902324 0.0500296652]\n",
      "[0.983996511 0.948947906 0.92110759 ... 0.0528155565 0.0511754751 0.0503784716]\n",
      "[0.935886681 0.90455544 0.848786116 ... 0.0517741144 0.0507949293 0.0507785678]\n",
      "[0.950003326 0.788076758 0.0759184062 0.0562564433]\n",
      "[0.946236 0.909918785 0.874352872 ... 0.0525333285 0.0513377488 0.0508122444]\n",
      "[0.820026934 0.730148494 0.719498336 ... 0.0545840263 0.0511951745 0.0500143766]\n",
      "[0.929778814 0.0902944207 0.0531881452]\n",
      "[0.853752732 0.400241256 0.0722846091]\n",
      "[0.949653268 0.920603752 0.847258 ... 0.0540286899 0.0522843 0.0507109165]\n",
      "[0.598818481 0.520620465 0.0866089761 ... 0.0592666268 0.0585159957 0.0567590594]\n",
      "[0.789516866 0.776664495 0.711874545 ... 0.0525068939 0.0515041053 0.0510078967]\n",
      "[0.914007127 0.812676549 0.677604 ... 0.0543373227 0.0537662804 0.0531137586]\n",
      "[0.973247647 0.791049361 0.678828835 ... 0.068061024 0.0543355644 0.0535411239]\n",
      "[0.724650919 0.620070517 0.568241954 0.488995552 0.363012314]\n",
      "[0.895474315 0.847822666 0.647685587 ... 0.0741258 0.0735480487 0.07277897]\n",
      "[0.992393255 0.986107528 0.973237753 ... 0.0927024782 0.0843994915 0.0743326247]\n",
      "[0.783780217 0.733014941 0.617527366 ... 0.0525024831 0.0522147417 0.0514915884]\n",
      "[0.838528752 0.755009294 0.666879892 ... 0.0586026907 0.056428045 0.050909251]\n",
      "[0.71797812 0.699704766 0.685529172 ... 0.0613589 0.0598098934 0.0595127344]\n",
      "[0.7698856 0.600981295 0.0958868563 ... 0.0795675516 0.0661343932 0.0651439726]\n",
      "[0.818264306 0.800590932 0.717227936 ... 0.0589128733 0.0581870079 0.0566355884]\n",
      "[0.644608 0.636361241 0.35550347 0.0843955874 0.0632688403 0.0536974669]\n",
      "[0.587028325 0.53597492 0.476647347 ... 0.0531063378 0.0511000156 0.0507978201]\n",
      "[0.824829698 0.776900053 0.763492584 ... 0.0591262877 0.0566182137 0.0532481074]\n",
      "[0.963066459 0.950394571 0.874939084 ... 0.0623026192 0.0609365106 0.0602877736]\n",
      "[0.887190521 0.7102319 0.611339271 ... 0.0519902408 0.0519860089 0.0516339839]\n",
      "[0.736544371 0.72332859 0.517594 ... 0.0542587042 0.0538696647 0.0537455082]\n",
      "[0.82138896 0.690687954 0.30650112 ... 0.0877877772 0.0526725054 0.0518676341]\n",
      "[0.741470575 0.68144536 0.559757054 ... 0.0582331717 0.0536260903 0.0524478257]\n",
      "[0.772179842]\n",
      "[0.793771565 0.793009 0.791650295 ... 0.050893873 0.0507291853 0.0507038832]\n",
      "[0.815184593 0.476560503 0.434750825 ... 0.0558955669 0.0550207198 0.0520789921]\n",
      "[0.553678036 0.0729792118]\n",
      "[0.99408716 0.7451092 0.138923258 ... 0.06994766 0.0677727163 0.054161787]\n",
      "[0.922537208 0.795381665 0.678837299 ... 0.0546516776 0.0529963672 0.0522834063]\n",
      "[0.878964782 0.819852 0.733654201 ... 0.0504777133 0.0504035056 0.0500647724]\n",
      "[0.865346372 0.711830497 0.502252817 ... 0.0564225 0.0561127067 0.0524681807]\n",
      "[0.765001357 0.727595508 0.643228292 ... 0.0561789572 0.0524055958 0.0518972576]\n",
      "[0.50100112 0.163788617]\n",
      "[0.835722566 0.787618458 0.709592 ... 0.0762389 0.06523785 0.0559929907]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 780; epoch: 129; focal_loss: 0.0799399; l1_loss: 0.0604538; total_loss: 0.1403937; \n",
      "FastEstimator-Train: step: 780; focal_loss: 0.003916; l1_loss: 0.0763495; total_loss: 0.0802656; examples/sec: 31.7; progress: 65.0%; \n",
      "FastEstimator-Train: step: 781; focal_loss: 0.0127716; l1_loss: 0.0532377; total_loss: 0.0660093; examples/sec: 32.1; progress: 65.1%; \n",
      "FastEstimator-Train: step: 782; focal_loss: 0.0146182; l1_loss: 0.0467095; total_loss: 0.0613278; examples/sec: 32.2; progress: 65.2%; \n",
      "FastEstimator-Train: step: 783; focal_loss: 0.0097222; l1_loss: 0.044801; total_loss: 0.0545232; examples/sec: 32.2; progress: 65.2%; \n",
      "FastEstimator-Train: step: 784; focal_loss: 0.0074793; l1_loss: 0.0140926; total_loss: 0.0215719; examples/sec: 31.8; progress: 65.3%; \n",
      "FastEstimator-Train: step: 785; focal_loss: 0.0324147; l1_loss: 0.0563194; total_loss: 0.0887341; examples/sec: 32.5; progress: 65.4%; \n",
      "[0.931388438 0.73716104 0.670792043 ... 0.0583732724 0.0570393503 0.0506759584]\n",
      "[0.930388868 0.800290585 0.747555 ... 0.0571200252 0.0569318533 0.0548602045]\n",
      "[0.859648466 0.317382753 0.311063647 ... 0.0729264319 0.0704363585 0.0690627396]\n",
      "[0.938224435 0.715341091 0.681811392 ... 0.06094414 0.0596422851 0.0589670539]\n",
      "[0.814963281 0.759696066 0.673395634 ... 0.0610243082 0.0595415831 0.0540972352]\n",
      "[0.916828334 0.477283031 0.0749655664 ... 0.0559045672 0.0550739467 0.052552253]\n",
      "[0.980282128 0.978999 0.962575436 ... 0.0589027703 0.0528660417 0.0512774289]\n",
      "[0.911581039 0.872946143 0.858806193 ... 0.0511987209 0.051153034 0.0509337485]\n",
      "[0.791197598 0.789196432 0.740614831 ... 0.0533593297 0.0522440076 0.0518193841]\n",
      "[0.940318465 0.911725819 0.883811235 ... 0.0580503047 0.0537311435 0.0525714755]\n",
      "[0.857444882 0.76098454 0.598304152 ... 0.0570266545 0.0537262559 0.0511822701]\n",
      "[0.992724359 0.975629389 0.937900662 ... 0.0532405376 0.0509283841 0.0503076911]\n",
      "[0.91991353 0.89914 0.855530918 ... 0.0514965057 0.0512825549 0.050838083]\n",
      "[0.968352795 0.79948169 0.0655173063 0.0617567]\n",
      "[0.961841702 0.956358671 0.85560596 ... 0.0506131351 0.0504850447 0.0504001975]\n",
      "[0.834066749 0.703430593 0.679015756 ... 0.0545341969 0.0514249504 0.0500558913]\n",
      "[0.940609455 0.0656957924 0.0519496202 0.051297754]\n",
      "[0.846214712 0.305648983 0.060995698 0.0584762096]\n",
      "[0.951296806 0.844661117 0.763055742 ... 0.0527391732 0.0526774228 0.0516866446]\n",
      "[0.594865143 0.568726122 0.0977456 ... 0.0696879625 0.0537958443 0.0514490306]\n",
      "[0.846248209 0.807308435 0.75545907 ... 0.0575232506 0.0571891963 0.0536836684]\n",
      "[0.90308 0.796175778 0.660156846 ... 0.0533609688 0.0512945652 0.0510705709]\n",
      "[0.982082784 0.884333491 0.730975866 ... 0.106377631 0.0665977299 0.0586351752]\n",
      "[0.687458634 0.605166852 0.430350721 0.393122435 0.348790288 0.0560898483]\n",
      "[0.884494901 0.873266101 0.773216963 ... 0.0822826 0.082021594 0.0819515]\n",
      "[0.988535047 0.98830092 0.967966795 ... 0.0566671789 0.0537747145 0.0503919721]\n",
      "[0.796462893 0.782747149 0.653184831 ... 0.051207304 0.0505980551 0.0501051247]\n",
      "[0.823786 0.821211815 0.811859965 ... 0.0610885024 0.0597130954 0.0528885126]\n",
      "[0.783910155 0.781014144 0.721481085 ... 0.064285785 0.062931031 0.0628905892]\n",
      "[0.7271384 0.459011734 0.0768765509 0.073540777 0.0722724497 0.0582411885]\n",
      "[0.87139833 0.854257166 0.736839831 ... 0.0544653535 0.0533518195 0.0521142185]\n",
      "[0.804703355 0.787440896 0.512564301 ... 0.0608376861 0.0578934252 0.0531476736]\n",
      "[0.625750184 0.593961537 0.56725055 ... 0.0535323918 0.0519657135 0.051192224]\n",
      "[0.847359836 0.827034 0.790956736 ... 0.0512402058 0.0510498583 0.0506488383]\n",
      "[0.958148718 0.937841475 0.844309449 ... 0.0646579266 0.0591699183 0.0573922098]\n",
      "[0.938670158 0.691916764 0.67663604 ... 0.0513256788 0.0509970188 0.050881952]\n",
      "[0.802521229 0.697288454 0.517819464 ... 0.0675993264 0.0663173497 0.0508395433]\n",
      "[0.86253649 0.618931711 0.284331262 ... 0.0731287 0.0677666068 0.0605325401]\n",
      "[0.744524777 0.711155057 0.595864296 ... 0.0576674342 0.0537894368 0.0501703918]\n",
      "[0.848744094]\n",
      "[0.823351 0.822722793 0.707413316 ... 0.0529724956 0.0507346392 0.0502762496]\n",
      "[0.814311862 0.44377178 0.362850726 ... 0.0533802807 0.0528951585 0.0509528518]\n",
      "[0.776422918 0.106236815]\n",
      "[0.994302869 0.796208858 0.185400933 ... 0.0561504662 0.0554207861 0.0523725748]\n",
      "[0.933998227 0.766961 0.679313898 ... 0.0520419478 0.0517147779 0.0515214205]\n",
      "[0.928356469 0.843812764 0.829587698 ... 0.0511985719 0.0503988564 0.0501970053]\n",
      "[0.902491093 0.653835654 0.626906514 ... 0.0544953048 0.053996712 0.0514347255]\n",
      "[0.776585221 0.610864758 0.502389669 ... 0.0586625934 0.0563919544 0.0543226898]\n",
      "FastEstimator-Eval: step: 786; epoch: 130; focal_loss: 0.0623074; l1_loss: 0.1354669; total_loss: 0.1977742; \n",
      "FastEstimator-Train: step: 786; focal_loss: 0.0058465; l1_loss: 0.0393351; total_loss: 0.0451816; examples/sec: 31.9; progress: 65.5%; \n",
      "FastEstimator-Train: step: 787; focal_loss: 0.0113681; l1_loss: 0.0623956; total_loss: 0.0737637; examples/sec: 31.9; progress: 65.6%; \n",
      "FastEstimator-Train: step: 788; focal_loss: 0.011897; l1_loss: 0.0924742; total_loss: 0.1043712; examples/sec: 32.4; progress: 65.7%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 789; focal_loss: 0.0082821; l1_loss: 0.0323703; total_loss: 0.0406523; examples/sec: 32.1; progress: 65.8%; \n",
      "FastEstimator-Train: step: 790; focal_loss: 0.0087263; l1_loss: 0.0504311; total_loss: 0.0591574; examples/sec: 32.2; progress: 65.8%; \n",
      "FastEstimator-Train: step: 791; focal_loss: 0.007581; l1_loss: 0.0210832; total_loss: 0.0286642; examples/sec: 32.2; progress: 65.9%; \n",
      "[0.957128763 0.0679484606 0.0594261 0.0527543724]\n",
      "[0.752131581 0.649321 0.602181196 0.0785408616 0.0738808215 0.0573323667]\n",
      "[0.96915555 0.820820451 0.796492457 ... 0.0580756068 0.0555752814 0.0511514544]\n",
      "[0.961515188 0.909127176 0.847352862 ... 0.0542191565 0.0541686416 0.0541475415]\n",
      "[0.907665253 0.447690427 0.423105121 ... 0.0636073053 0.057685703 0.0523092747]\n",
      "[0.955648541 0.700032175 0.677431047 ... 0.0574179292 0.0546875298 0.0544997752]\n",
      "[0.763437867 0.760058 0.666823864 ... 0.0538520515 0.0517547429 0.0512881279]\n",
      "[0.934389234 0.434296 0.112941206 0.0595384836 0.0555502474]\n",
      "[0.980354786 0.976034105 0.908987105 ... 0.0544582605 0.050270468 0.0501604974]\n",
      "[0.937441289 0.901970208 0.878166318 ... 0.0502882 0.0502208471 0.0501618981]\n",
      "[0.813368678 0.758894324 0.727153063 ... 0.0561298728 0.0545941293 0.0534666479]\n",
      "[0.930877924 0.930564761 0.863336086 ... 0.0589924753 0.0509602726 0.050331831]\n",
      "[0.866518259 0.819446325 0.529263735 ... 0.0594679415 0.0526560545 0.0505816042]\n",
      "[0.980610371 0.977776766 0.964815199 ... 0.0514983535 0.0506519377 0.0501469672]\n",
      "[0.905896187 0.885490596 0.858593225 ... 0.0509845912 0.0504025817 0.0503820777]\n",
      "[0.969499111 0.797348499 0.0666780472 0.0621836185]\n",
      "[0.98550868 0.97116363 0.942155182 ... 0.0531413853 0.0510937572 0.050475657]\n",
      "[0.805844069 0.690373 0.666635215 ... 0.0543717146 0.0521809459 0.0510200858]\n",
      "[0.952712238 0.0502711535]\n",
      "[0.860404968 0.535554588 0.0641425252]\n",
      "[0.961991787 0.858461261 0.796837 ... 0.0525584817 0.0512022376 0.0508069396]\n",
      "[0.673590064 0.579515219 0.0709448457 0.0550875068]\n",
      "[0.865488529 0.831189811 0.817070127 ... 0.0555808246 0.0525440276 0.0501847267]\n",
      "[0.906237 0.795886159 0.626443148 ... 0.0561312735 0.0549826026 0.053511858]\n",
      "[0.972839832 0.877949476 0.709449232 ... 0.08427 0.061817646 0.0512104332]\n",
      "[0.72531569 0.692147255 0.457317412 0.448339224 0.437760592]\n",
      "[0.943229198 0.909699798 0.852285 ... 0.0949778259 0.0948434472 0.0947411358]\n",
      "[0.988829732 0.98267138 0.965485334 ... 0.0690133572 0.0594020188 0.0565112829]\n",
      "[0.880140901 0.845566869 0.650244713 ... 0.057164818 0.0560202301 0.0556126535]\n",
      "[0.852652311 0.850861669 0.837268 ... 0.0614638329 0.0604047775 0.0564553142]\n",
      "[0.871573389 0.869586706 0.816166162 ... 0.0754215717 0.0741243064 0.0739746392]\n",
      "[0.685692489 0.480429888 0.0911909342 0.0631566644 0.0542726219]\n",
      "[0.920757294 0.864065886 0.803215504 ... 0.0526808202 0.0524450839 0.0512926579]\n",
      "[0.846371114 0.832572579 0.564819574 ... 0.0547752976 0.0546584427 0.0524344146]\n",
      "[0.717625916 0.675460458 0.617226839 ... 0.0527155101 0.0514996648 0.0503425598]\n",
      "[0.856114388 0.790709138 0.762753129 ... 0.0554366708 0.0504934788 0.050372541]\n",
      "[0.951654434 0.904300094 0.795857072 ... 0.0610436499 0.056576997 0.0541011393]\n",
      "[0.945587158 0.830325127 0.770933807 ... 0.0517869 0.0508187711 0.0501285493]\n",
      "[0.822728634 0.749633968 0.695715785 ... 0.0528979897 0.0517766476 0.050127]\n",
      "[0.880981088 0.688373387 0.233044147 ... 0.0769975185 0.0597347617 0.0567891598]\n",
      "[0.754374862 0.694424272 0.692475557 ... 0.0562643707 0.0553156137 0.0546331406]\n",
      "[0.866115153 0.0564902127]\n",
      "[0.89949 0.836469054 0.819215536 ... 0.0525377393 0.052487582 0.0517828166]\n",
      "[0.926011086 0.635674655 0.571781874 ... 0.0574992895 0.0569569468 0.0532921851]\n",
      "[0.803981185 0.0750581622]\n",
      "[0.994540572 0.839975536 0.240407288 ... 0.0508548915 0.0507032275 0.0500656664]\n",
      "[0.930430472 0.867322147 0.809504271 ... 0.0533481836 0.0532051921 0.0520440936]\n",
      "[0.931791067 0.882528841 0.858850837 ... 0.0504903197 0.050421 0.0503426492]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 792; epoch: 131; focal_loss: 0.0439263; l1_loss: 0.0565154; total_loss: 0.1004417; \n",
      "FastEstimator-Train: step: 792; focal_loss: 0.0110977; l1_loss: 0.0483377; total_loss: 0.0594353; examples/sec: 32.2; progress: 66.0%; \n",
      "FastEstimator-Train: step: 793; focal_loss: 0.0079653; l1_loss: 0.0469665; total_loss: 0.0549318; examples/sec: 32.1; progress: 66.1%; \n",
      "FastEstimator-Train: step: 794; focal_loss: 0.0079158; l1_loss: 0.0383491; total_loss: 0.0462649; examples/sec: 32.3; progress: 66.2%; \n",
      "FastEstimator-Train: step: 795; focal_loss: 0.0103704; l1_loss: 0.0373975; total_loss: 0.0477679; examples/sec: 32.0; progress: 66.2%; \n",
      "FastEstimator-Train: step: 796; focal_loss: 0.0080314; l1_loss: 0.0292472; total_loss: 0.0372787; examples/sec: 32.0; progress: 66.3%; \n",
      "FastEstimator-Train: step: 797; focal_loss: 0.0041218; l1_loss: 0.0476106; total_loss: 0.0517324; examples/sec: 32.5; progress: 66.4%; \n",
      "[0.921371937 0.727380037 0.637132406 ... 0.0554212034 0.0529979467 0.0521610975]\n",
      "[0.691671491 0.675807297 0.491575211 ... 0.0549510419 0.0533822775 0.0505494475]\n",
      "[0.918566227]\n",
      "[0.652152836 0.650753081 0.648851812 0.0761916935 0.0597910583]\n",
      "[0.967020392 0.838701963 0.778838456 ... 0.0616943538 0.0512456894 0.0503579974]\n",
      "[0.917908669 0.917783856 0.807874382 ... 0.0523936749 0.0523740053 0.0502680838]\n",
      "[0.875562966 0.349203 0.333169878]\n",
      "[0.933955908 0.624864 0.620384216 ... 0.0557289124 0.0530027151 0.0519393384]\n",
      "[0.761504471 0.730373502 0.601170242 ... 0.077822268 0.0595344305 0.0568526685]\n",
      "[0.913564563 0.389752388 0.095733583 0.0518572927]\n",
      "[0.965275049 0.949845612 0.850802958 ... 0.0629918873 0.0565575957 0.0552012622]\n",
      "[0.948131323 0.916044474 0.884856582 ... 0.0544830859 0.0505735278 0.0502524674]\n",
      "[0.813157499 0.765983224 0.724437714 ... 0.0518206358 0.0517909825 0.0515108407]\n",
      "[0.918885946 0.914291859 0.836198926 ... 0.0587688088 0.0551705658 0.0510598421]\n",
      "[0.820647895 0.818816781 0.536627471 ... 0.0563065708 0.0555796623 0.052360177]\n",
      "[0.972692907 0.949247956 0.924269736 ... 0.0523633957 0.0517320335 0.0503095388]\n",
      "[0.887778163 0.86468941 0.842030764 ... 0.05114007 0.0511253476 0.0508599579]\n",
      "[0.963440537 0.77680707 0.0617854595 0.0522180796]\n",
      "[0.976554453 0.94797951 0.910503149 ... 0.0555796325 0.0534177125 0.0506222546]\n",
      "[0.718150854 0.67728132 0.620727837 ... 0.0704287291 0.0623910725 0.0511619151]\n",
      "[0.947484851]\n",
      "[0.859308362 0.609214187]\n",
      "[0.94948113 0.85103941 0.799156785 ... 0.0512407124 0.0507786572 0.0504329205]\n",
      "[0.655280769 0.562591195]\n",
      "[0.860480189 0.817068577 0.807724059 ... 0.0512862206 0.0508031547 0.0506410599]\n",
      "[0.889656246 0.772658348 0.631429434 ... 0.0555372536 0.0521893203 0.0514549]\n",
      "[0.955819666 0.887193322 0.685824811 ... 0.0556907356 0.0547080934 0.0512391031]\n",
      "[0.679750502 0.658919811 0.401626945 0.360470265 0.33326754]\n",
      "[0.920217395 0.905108571 0.813175559 ... 0.0767560601 0.0762224495 0.0759506524]\n",
      "[0.989099443 0.980164826 0.963338256 ... 0.0671106 0.0562348068 0.0528429151]\n",
      "[0.858303308 0.818474293 0.546308815 ... 0.0585128069 0.0539689064 0.0532597303]\n",
      "[0.8355636 0.792065382 0.735814 ... 0.0577678084 0.0536988974 0.0503237545]\n",
      "[0.880437195 0.868869781 0.80525291 ... 0.0563398 0.0562052727 0.0557808876]\n",
      "[0.661823392 0.483351082 0.0847899616 0.0529288352]\n",
      "[0.900841 0.822071135 0.781508565 ... 0.0586615801 0.0580223799 0.0573243201]\n",
      "[0.776883602 0.764944 0.45739767]\n",
      "[0.675359726 0.543190897 0.536867201 ... 0.0543858111 0.0536847413 0.0523694456]\n",
      "[0.81769383 0.763281107 0.744727254 ... 0.054759711 0.0544816852 0.0513216555]\n",
      "[0.953415632 0.91166079 0.774420381 ... 0.0597796738 0.0565831661 0.0565667748]\n",
      "[0.873474419 0.691223443 0.669493139 ... 0.0518767536 0.0515987277 0.0513932407]\n",
      "[0.827880144 0.738958538 0.729313672 ... 0.0531116128 0.0503526628 0.050093174]\n",
      "[0.860224962 0.642543197 0.226378649 0.0907990336 0.0517456532]\n",
      "[0.746370792 0.725322127 0.646556556 ... 0.0520912707 0.0520658791 0.0506827831]\n",
      "[0.807338119]\n",
      "[0.824326217 0.793551326 0.781335652 ... 0.0552554131 0.0532056391 0.0511087775]\n",
      "[0.894290328 0.619363487 0.544342875 ... 0.0715700686 0.0693767667 0.0664803684]\n",
      "[0.678939283]\n",
      "[0.995598555 0.810491502 0.158538401 0.0744771957 0.0511490405 0.0510787368]\n",
      "FastEstimator-Eval: step: 798; epoch: 132; focal_loss: 0.0512553; l1_loss: 0.0915176; total_loss: 0.142773; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 798; focal_loss: 0.0035538; l1_loss: 0.0269338; total_loss: 0.0304876; examples/sec: 32.1; progress: 66.5%; \n",
      "FastEstimator-Train: step: 799; focal_loss: 0.002255; l1_loss: 0.0252261; total_loss: 0.0274811; examples/sec: 32.2; progress: 66.6%; \n",
      "FastEstimator-Train: step: 800; focal_loss: 0.0041577; l1_loss: 0.0249243; total_loss: 0.029082; examples/sec: 32.1; progress: 66.7%; \n",
      "FastEstimator-Train: step: 801; focal_loss: 0.0074484; l1_loss: 0.0678288; total_loss: 0.0752772; examples/sec: 32.3; progress: 66.8%; \n",
      "FastEstimator-Train: step: 802; focal_loss: 0.0033682; l1_loss: 0.074268; total_loss: 0.0776362; examples/sec: 32.3; progress: 66.8%; \n",
      "FastEstimator-Train: step: 803; focal_loss: 0.0073864; l1_loss: 0.0445856; total_loss: 0.051972; examples/sec: 32.0; progress: 66.9%; \n",
      "[0.898854911 0.857657254 0.812520504 ... 0.0518444479 0.0506154895 0.0503623784]\n",
      "[0.898656726 0.838658571 0.798720241 ... 0.0536016226 0.0513634682 0.0507010221]\n",
      "[0.928447962 0.761899114 0.66076088 ... 0.0583285391 0.0525134802 0.0516932607]\n",
      "[0.772160649 0.718902826 0.414105445 ... 0.0731957853 0.0655652583 0.0517801344]\n",
      "[0.891431093]\n",
      "[0.754396915 0.733354211 0.6859442 0.0740197 0.0546923876]\n",
      "[0.967615485 0.849040329 0.777016521 ... 0.0652915835 0.058603555 0.0541914701]\n",
      "[0.891796947 0.838626742 0.777320921 ... 0.0526723862 0.0514183939 0.0503521264]\n",
      "[0.863558531 0.370469034 0.300627738 0.0525042713]\n",
      "[0.933440804 0.680571854 0.676045477 ... 0.0513550639 0.0511031747 0.0508446693]\n",
      "[0.768636763 0.735036 0.590235531 ... 0.0767520368 0.0677057803 0.0645743]\n",
      "[0.926323295 0.451366067 0.080814451]\n",
      "[0.965907335 0.936414301 0.826386809 ... 0.0606030822 0.0558848679 0.0502440035]\n",
      "[0.958396554 0.932551146 0.906553268 ... 0.0518243 0.0517858267 0.0512183905]\n",
      "[0.865610063 0.838264465 0.791583657 ... 0.0555453 0.0537589192 0.0507222712]\n",
      "[0.904955387 0.898137391 0.824765563 ... 0.064540416 0.0578635633 0.0509411097]\n",
      "[0.839713037 0.812954426 0.655604482 ... 0.0582114458 0.0531477928 0.0504473746]\n",
      "[0.965790272 0.941594 0.865874052 ... 0.0508688092 0.0504877865 0.0502898395]\n",
      "[0.899691522 0.877532899 0.84832418 ... 0.0510520935 0.0504853427 0.05046767]\n",
      "[0.964178264 0.790059209 0.0609948337]\n",
      "[0.966792822 0.96318543 0.922393858 ... 0.0545812547 0.0517604649 0.050788641]\n",
      "[0.701171398 0.696628153 0.68309474 ... 0.0727884471 0.0655727088 0.0599658191]\n",
      "[0.941842616]\n",
      "[0.875115752 0.669414639]\n",
      "[0.947108328 0.869520664 0.807030082 ... 0.0526019335 0.0521633327 0.0517854393]\n",
      "[0.663591862 0.651673496]\n",
      "[0.874002755 0.81997782 0.805243611 ... 0.0562523 0.0507298112 0.0502363443]\n",
      "[0.897444248 0.788372397 0.684083581 ... 0.0530310273 0.052013427 0.0506385863]\n",
      "[0.953841925 0.902391434 0.761117697 ... 0.0978732407 0.0874757469 0.0602398813]\n",
      "[0.737387478 0.689296901 0.465676963 0.413508624 0.410808]\n",
      "[0.915420651 0.911987185 0.817434549 ... 0.0712300241 0.0707697272 0.0702238679]\n",
      "[0.987064481 0.971288562 0.953066885 ... 0.0665737391 0.0542888343 0.0505467653]\n",
      "[0.862723589 0.837082863 0.560562313 ... 0.06446293 0.0582313836 0.0506331027]\n",
      "[0.816714406 0.772368371 0.675934196 ... 0.0724297464 0.0516406596 0.0511868]\n",
      "[0.908717632 0.893665075 0.84530127 ... 0.0556195676 0.0552964807 0.0550673604]\n",
      "[0.756736636 0.55782789 0.0778216124 0.0646933]\n",
      "[0.890191317 0.803911269 0.755202174 ... 0.059586972 0.0580450892 0.0520427823]\n",
      "[0.771440506 0.763479948 0.441213518]\n",
      "[0.66778034 0.536664963 0.503713071 ... 0.0517781973 0.0504288077 0.0503508151]\n",
      "[0.800267577 0.760927439 0.7562536 ... 0.0535480976 0.0517304242 0.0516257882]\n",
      "[0.9265728 0.916502535 0.808400035 ... 0.0692609251 0.0662615 0.0601998568]\n",
      "[0.822543859 0.609699905 0.597238123 ... 0.0537444949 0.0527985394 0.0510721803]\n",
      "[0.872823596 0.829383194 0.783180952 ... 0.0529613197 0.0519351661 0.0505832136]\n",
      "[0.849867463 0.588373542 0.236083567 0.0623247325]\n",
      "[0.783240139 0.767108798 0.718226194 ... 0.0605861247 0.0589969754 0.0572379231]\n",
      "[0.804256201]\n",
      "[0.762084186 0.747728229 0.735843837 ... 0.0535903871 0.0511890948 0.0510386527]\n",
      "[0.862291455 0.637238145 0.495756716 ... 0.0578709841 0.0532394052 0.0522299409]\n",
      "FastEstimator-Eval: step: 804; epoch: 133; focal_loss: 0.0475302; l1_loss: 0.1016653; total_loss: 0.1491954; \n",
      "FastEstimator-Train: step: 804; focal_loss: 0.0040789; l1_loss: 0.0466631; total_loss: 0.0507421; examples/sec: 31.6; progress: 67.0%; \n",
      "FastEstimator-Train: step: 805; focal_loss: 0.0026322; l1_loss: 0.0585989; total_loss: 0.0612312; examples/sec: 32.1; progress: 67.1%; \n",
      "FastEstimator-Train: step: 806; focal_loss: 0.0028277; l1_loss: 0.0583493; total_loss: 0.061177; examples/sec: 31.9; progress: 67.2%; \n",
      "FastEstimator-Train: step: 807; focal_loss: 0.0075747; l1_loss: 0.0346015; total_loss: 0.0421762; examples/sec: 32.2; progress: 67.2%; \n",
      "FastEstimator-Train: step: 808; focal_loss: 0.0031191; l1_loss: 0.0520949; total_loss: 0.055214; examples/sec: 32.0; progress: 67.3%; \n",
      "FastEstimator-Train: step: 809; focal_loss: 0.0029468; l1_loss: 0.0820621; total_loss: 0.085009; examples/sec: 32.2; progress: 67.4%; \n",
      "[0.779509425]\n",
      "[0.995211065 0.821510434 0.163057178 0.0544676781]\n",
      "[0.912976 0.865171432 0.856296539 ... 0.0560690165 0.0522841811 0.0509913862]\n",
      "[0.93558538 0.890388131 0.880860925 ... 0.0544491112 0.0507563353 0.050334543]\n",
      "[0.944510818 0.84017837 0.737058461 ... 0.0696433783 0.06552279 0.0544911623]\n",
      "[0.812327862 0.76904422 0.539115071 ... 0.0672640502 0.055951 0.0501729548]\n",
      "[0.916669548]\n",
      "[0.778678238 0.770177841 0.744329453 0.0611050427 0.0594331324]\n",
      "[0.984565735 0.90019 0.866042733 ... 0.0549688041 0.0542375445 0.050629288]\n",
      "[0.949980497 0.848745108 0.817177534 ... 0.0510016978 0.0509230494 0.0507651865]\n",
      "[0.909699559 0.464898854 0.400108278 0.0551337]\n",
      "[0.955943227 0.788951099 0.775304735 ... 0.0518183112 0.0514565408 0.0505609214]\n",
      "[0.821471334 0.780185223 0.670815825 ... 0.0736288726 0.0712690055 0.0530944765]\n",
      "[0.956518531 0.586816192 0.085965395]\n",
      "[0.973699093 0.966737509 0.861774445 ... 0.0707510412 0.0573887825 0.0501340032]\n",
      "[0.974347949 0.956008196 0.941654444 ... 0.0505778491 0.0505068302 0.0504414141]\n",
      "[0.89606756 0.884914 0.847669303 ... 0.0572661757 0.0571292937 0.0510213673]\n",
      "[0.94350493 0.938358307 0.894910336 ... 0.067786485 0.057199806 0.0571473241]\n",
      "[0.884237885 0.866778672 0.696164906 0.057698369 0.050732702]\n",
      "[0.978009343 0.965350151 0.895740628 ... 0.0550265312 0.0543356836 0.0525702238]\n",
      "[0.920380533 0.898507357 0.879802704 ... 0.0516005456 0.0509119332 0.050791055]\n",
      "[0.972271681 0.832948446 0.0744790137 0.052185744]\n",
      "[0.982649624 0.973473668 0.928631783 ... 0.0545661449 0.053088367 0.0528158844]\n",
      "[0.797641575 0.760124683 0.759234786 ... 0.0617861152 0.0588996708 0.0510419309]\n",
      "[0.93429184]\n",
      "[0.923786 0.802621365]\n",
      "[0.963078499 0.91959846 0.880181313 ... 0.0533317626 0.0512486696 0.0504092574]\n",
      "[0.727173 0.704834938]\n",
      "[0.892919123 0.851199865 0.84098357 ... 0.055837363 0.0541103482 0.0535731614]\n",
      "[0.92621088 0.823018789 0.758827627 ... 0.056997776 0.0545380712 0.0508812368]\n",
      "[0.955461 0.906907201 0.755486131 ... 0.0840879381 0.0658885241 0.0607235134]\n",
      "[0.824755788 0.785167217 0.620349 0.619745 0.556530774]\n",
      "[0.955670238 0.93962127 0.867912114 ... 0.0764558 0.0761260092 0.0753083825]\n",
      "[0.990931332 0.973069549 0.958670735 ... 0.0703281462 0.0571306646 0.0560874343]\n",
      "[0.908668637 0.906459 0.705009937 ... 0.0516075492 0.0507725775 0.0500200391]\n",
      "[0.859268546 0.805771112 0.720814 ... 0.0556846559 0.0543453097 0.0515634418]\n",
      "[0.942274213 0.925736845 0.908340394 ... 0.0619163811 0.0614220202 0.0609123111]\n",
      "[0.788074613 0.584768295 0.0722819 0.0591549575]\n",
      "[0.934057713 0.860592961 0.797466278 ... 0.0579501092 0.0559326708 0.0521045923]\n",
      "[0.840736151 0.829768956 0.556394875]\n",
      "[0.726354718 0.627049506 0.594982564 ... 0.0546731353 0.0523250401 0.0519702435]\n",
      "[0.846218884 0.807095945 0.798833 ... 0.0521523058 0.0512576401 0.0503431559]\n",
      "[0.937400401 0.918413877 0.824372 ... 0.0662225485 0.0571166873 0.0506662428]\n",
      "[0.881777644 0.763180852 0.739855647 ... 0.0527407825 0.0525457561 0.0501672626]\n",
      "[0.875728965 0.81241703 0.798275769 ... 0.0545624495 0.054115355 0.0523953736]\n",
      "[0.889365256 0.628568053 0.293562025 0.0566301048]\n",
      "[0.826861739 0.819119 0.788050294 ... 0.0617873669 0.0608076453 0.0550303757]\n",
      "[0.82135427]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 810; epoch: 134; focal_loss: 0.0280739; l1_loss: 0.0490426; total_loss: 0.0771165; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 810; focal_loss: 0.0038973; l1_loss: 0.0425238; total_loss: 0.0464211; examples/sec: 32.0; progress: 67.5%; \n",
      "FastEstimator-Train: step: 811; focal_loss: 0.0014403; l1_loss: 0.0460901; total_loss: 0.0475303; examples/sec: 32.3; progress: 67.6%; \n",
      "FastEstimator-Train: step: 812; focal_loss: 0.0048634; l1_loss: 0.0263232; total_loss: 0.0311866; examples/sec: 32.1; progress: 67.7%; \n",
      "FastEstimator-Train: step: 813; focal_loss: 0.0052426; l1_loss: 0.0215707; total_loss: 0.0268132; examples/sec: 31.7; progress: 67.8%; \n",
      "FastEstimator-Train: step: 814; focal_loss: 0.0028361; l1_loss: 0.0431941; total_loss: 0.0460302; examples/sec: 31.6; progress: 67.8%; \n",
      "FastEstimator-Train: step: 815; focal_loss: 0.0022976; l1_loss: 0.0443682; total_loss: 0.0466659; examples/sec: 32.1; progress: 67.9%; \n",
      "[0.870610356 0.801984072 0.786675096 ... 0.0501703918 0.0500993729 0.050011754]\n",
      "[0.914631844 0.707089543 0.686568499 ... 0.0602876544 0.0535699129 0.0510770679]\n",
      "[0.878510714]\n",
      "[0.997774 0.834094286 0.165726751]\n",
      "[0.917093396 0.873713 0.855567575 ... 0.0574997962 0.0573526621 0.0544371]\n",
      "[0.946894467 0.913199365 0.905113459 ... 0.0556352735 0.0542721152 0.0519345701]\n",
      "[0.941556334 0.835572898 0.731240511 ... 0.053484261 0.0514840186 0.0508699715]\n",
      "[0.773542047 0.75628221 0.599668384 ... 0.0706708431 0.0614204407 0.050658375]\n",
      "[0.933925867 0.052313298]\n",
      "[0.793400168 0.785115719 0.781280398 0.0727886856 0.053409487]\n",
      "[0.981448829 0.887446165 0.878931642 ... 0.0701558 0.0603840947 0.055152297]\n",
      "[0.96592921 0.889838696 0.834187508 ... 0.0522355437 0.0512462556 0.050971359]\n",
      "[0.917950034 0.521535635 0.493295848 0.0548397601]\n",
      "[0.959772289 0.768520832 0.753647685 ... 0.0525426269 0.0515958965 0.0510143638]\n",
      "[0.856751919 0.803365231 0.623730123 ... 0.0663065 0.0563059151 0.0531845689]\n",
      "[0.972075105 0.650770962 0.0874167383]\n",
      "[0.973479688 0.968928576 0.910164237 ... 0.0612942278 0.0603677928 0.0501859486]\n",
      "[0.971084535 0.946877 0.936885476 ... 0.0505696535 0.050355047 0.0500159562]\n",
      "[0.875905156 0.856622636 0.812887192 ... 0.053792417 0.0534676909 0.0523974895]\n",
      "[0.944958627 0.936498523 0.88256681 ... 0.0552024841 0.051743865 0.0516572297]\n",
      "[0.892849207 0.875143588 0.711775959 0.0631816387 0.051877439 0.0504732728]\n",
      "[0.980761 0.964224815 0.892334342 ... 0.0525613725 0.0520691872 0.0505647361]\n",
      "[0.915260196 0.899225831 0.896902323 ... 0.0516891479 0.0514493287 0.0512842834]\n",
      "[0.98688513 0.901 0.0795633495 0.0612253845]\n",
      "[0.989073813 0.963842094 0.933073759 ... 0.0528534353 0.0514502227 0.05042395]\n",
      "[0.8094244 0.793844938 0.775816798 ... 0.0626038909 0.0599143803 0.0524151921]\n",
      "[0.955641091]\n",
      "[0.949638963 0.869039178]\n",
      "[0.967575788 0.945118308 0.911756694 ... 0.0530383885 0.0515304208 0.0508785844]\n",
      "[0.81163013 0.765430391]\n",
      "[0.884508 0.853981256 0.833036542 ... 0.0529642403 0.0509756804 0.0500404537]\n",
      "[0.906729579 0.79769516 0.746217847 ... 0.0793667734 0.0556696057 0.0517504513]\n",
      "[0.974659801 0.948108912 0.819896519 ... 0.0882631242 0.085208267 0.0743999481]\n",
      "[0.865924299 0.822037339 0.681664 0.648635745 0.643177]\n",
      "[0.962849915 0.938294888 0.839499652 ... 0.07251212 0.0701834261 0.069943279]\n",
      "[0.991497755 0.978178 0.963118911 ... 0.0867856741 0.0800832212 0.0533382595]\n",
      "[0.925408125 0.92311275 0.773855925 ... 0.0513841808 0.0507341027 0.0506899953]\n",
      "[0.856821656 0.832951427 0.782776415 ... 0.0617658794 0.0603394806 0.0528893471]\n",
      "[0.941889822 0.925872266 0.912897 ... 0.0538529158 0.0536709726 0.0533792377]\n",
      "[0.811061502 0.608704805 0.0655582547 0.0654870868 0.0530368388]\n",
      "[0.943483 0.878764153 0.825001538 ... 0.0586697757 0.0506487489 0.0503590405]\n",
      "[0.894762874 0.884192467 0.624729753 0.0514443517]\n",
      "[0.73139137 0.680391 0.644202232 ... 0.0564408302 0.052402854 0.0507113039]\n",
      "[0.866551101 0.843376577 0.813155413 ... 0.0551597476 0.0545848906 0.0528080165]\n",
      "[0.9452672 0.933322906 0.854556382 ... 0.0782623291 0.065954864 0.0579906106]\n",
      "[0.888652 0.817039371 0.802473664 ... 0.0509958863 0.0509595275 0.050864011]\n",
      "[0.845870435 0.788160205 0.760339856 ... 0.0536223948 0.0532610118 0.0513365865]\n",
      "[0.925042212 0.669261456 0.335446894 0.0607250929]\n",
      "FastEstimator-Eval: step: 816; epoch: 135; focal_loss: 0.0254057; l1_loss: 0.0807965; total_loss: 0.1062022; \n",
      "FastEstimator-Train: step: 816; focal_loss: 0.0019962; l1_loss: 0.0327759; total_loss: 0.0347721; examples/sec: 31.8; progress: 68.0%; \n",
      "FastEstimator-Train: step: 817; focal_loss: 0.003878; l1_loss: 0.0321973; total_loss: 0.0360753; examples/sec: 31.8; progress: 68.1%; \n",
      "FastEstimator-Train: step: 818; focal_loss: 0.00134; l1_loss: 0.023387; total_loss: 0.024727; examples/sec: 32.1; progress: 68.2%; \n",
      "FastEstimator-Train: step: 819; focal_loss: 0.0017611; l1_loss: 0.0639733; total_loss: 0.0657344; examples/sec: 32.0; progress: 68.2%; \n",
      "FastEstimator-Train: step: 820; focal_loss: 0.0038409; l1_loss: 0.0315861; total_loss: 0.035427; examples/sec: 32.4; progress: 68.3%; \n",
      "FastEstimator-Train: step: 821; focal_loss: 0.0017275; l1_loss: 0.0222887; total_loss: 0.0240162; examples/sec: 32.4; progress: 68.4%; \n",
      "[0.84450829 0.826824725 0.765146 ... 0.0635378361 0.059373349 0.0531928241]\n",
      "[0.881083369]\n",
      "[0.890224218 0.817942 0.800733805 ... 0.0535010397 0.0526515841 0.0524800718]\n",
      "[0.872252941 0.737614036 0.713420033 ... 0.0575074255 0.0537545085 0.0525057]\n",
      "[0.91908741]\n",
      "[0.997915387 0.83654058 0.152554244 0.0507344]\n",
      "[0.929670334 0.895125628 0.874793291 ... 0.0532688498 0.0516281724 0.0513084233]\n",
      "[0.94651556 0.914529085 0.898312449 ... 0.0520276129 0.051551491 0.0508669615]\n",
      "[0.943086147 0.859428287 0.716351807 ... 0.0511333942 0.051045239 0.0504247248]\n",
      "[0.76813525 0.766543746 0.624609649 ... 0.0646562576 0.0625779927 0.0538286269]\n",
      "[0.939649463 0.0619805157 0.0526208878]\n",
      "[0.832182944 0.812042415 0.800468147 0.0645684898]\n",
      "[0.982189655 0.864556134 0.863507748 ... 0.0596117973 0.0538633466 0.0529483259]\n",
      "[0.957847 0.846633554 0.821911454 ... 0.0521249175 0.0519191623 0.0512271523]\n",
      "[0.935264587 0.587046385 0.522470593 0.055228889 0.0512353182]\n",
      "[0.961354 0.78716445 0.76698637 ... 0.0521485507 0.0515311658 0.0501599]\n",
      "[0.810042739 0.749909699 0.582186818 0.0924645066 0.0618962944 0.0522262156]\n",
      "[0.959273696 0.631708562 0.0792964697]\n",
      "[0.979725122 0.9752056 0.959536195 ... 0.0603262484 0.0528165698 0.0504903793]\n",
      "[0.977532506 0.958277583 0.942911506 ... 0.0529083 0.052310884 0.0517931879]\n",
      "[0.898064375 0.878989518 0.840753376 ... 0.0524286032 0.0519662797 0.0518579781]\n",
      "[0.946847081 0.936906278 0.866671324 ... 0.0750801563 0.068164587 0.050524503]\n",
      "[0.897976 0.868593097 0.70680964 0.0633757114]\n",
      "[0.981218696 0.972411931 0.905956745 ... 0.0540382862 0.0537546277 0.0527986884]\n",
      "[0.927020669 0.914098322 0.884918332 ... 0.0505762398 0.050273329 0.0500109196]\n",
      "[0.989361167 0.918571174 0.0658489466 0.063334316]\n",
      "[0.990906358 0.971079588 0.945812583 ... 0.0507108569 0.0505968034 0.0505305827]\n",
      "[0.809647202 0.809253454 0.79007566 ... 0.0674081743 0.0611943 0.0606308281]\n",
      "[0.96442914]\n",
      "[0.926422954 0.819902182]\n",
      "[0.970568299 0.943079591 0.927378476 ... 0.0513892174 0.050265342 0.0501121581]\n",
      "[0.783379316 0.697278857]\n",
      "[0.895570636 0.862426043 0.851519585 ... 0.0588294268 0.0569098592 0.0567228794]\n",
      "[0.904066443 0.794731379 0.727783322 ... 0.076594919 0.0726128221 0.0721451342]\n",
      "[0.980909586 0.963093162 0.855173528 ... 0.0952468216 0.0883393586 0.0638296902]\n",
      "[0.826708436 0.799871802 0.644552648 0.612816632 0.596552134]\n",
      "[0.972605 0.943759322 0.853390634 ... 0.070517689 0.0704220235 0.0703701377]\n",
      "[0.987471759 0.961951613 0.943218708 ... 0.101048082 0.0697720945 0.0669668913]\n",
      "[0.940286756 0.935405433 0.779067159 ... 0.0556204617 0.0553469062 0.0524808168]\n",
      "[0.871436357 0.844461501 0.776457787 ... 0.0728149116 0.0625940561 0.0502826869]\n",
      "[0.950694799 0.938097835 0.926354647 ... 0.0510823429 0.0507101417 0.0500788689]\n",
      "[0.795559 0.599638522 0.064627409 0.0588859916 0.0502762794]\n",
      "[0.942657471 0.888243616 0.846718788 ... 0.0570443869 0.0536875725 0.051514715]\n",
      "[0.899008036 0.885162234 0.64649868]\n",
      "[0.725490332 0.634914339 0.6267398 ... 0.0566389859 0.0516576469 0.0508275032]\n",
      "[0.869624615 0.828151226 0.813777864 ... 0.0518620908 0.05147475 0.0509879887]\n",
      "[0.946512938 0.932973 0.851059794 ... 0.0635563135 0.0595730245 0.0560300052]\n",
      "[0.911938 0.858972788 0.826106429 ... 0.0515114963 0.0506387949 0.0503970087]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 822; epoch: 136; focal_loss: 0.0222377; l1_loss: 0.0299583; total_loss: 0.052196; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 822; focal_loss: 0.0017645; l1_loss: 0.0286269; total_loss: 0.0303914; examples/sec: 32.2; progress: 68.5%; \n",
      "FastEstimator-Train: step: 823; focal_loss: 0.0034753; l1_loss: 0.0420045; total_loss: 0.0454798; examples/sec: 32.6; progress: 68.6%; \n",
      "FastEstimator-Train: step: 824; focal_loss: 0.0013789; l1_loss: 0.0340077; total_loss: 0.0353866; examples/sec: 32.1; progress: 68.7%; \n",
      "FastEstimator-Train: step: 825; focal_loss: 0.0018059; l1_loss: 0.0182239; total_loss: 0.0200298; examples/sec: 32.3; progress: 68.8%; \n",
      "FastEstimator-Train: step: 826; focal_loss: 0.0026228; l1_loss: 0.0529361; total_loss: 0.0555589; examples/sec: 32.0; progress: 68.8%; \n",
      "FastEstimator-Train: step: 827; focal_loss: 0.0014477; l1_loss: 0.0365591; total_loss: 0.0380068; examples/sec: 31.9; progress: 68.9%; \n",
      "[0.879352 0.874007642 0.856362939 ... 0.0589324832 0.0568523109 0.0522651672]\n",
      "[0.910331428 0.669420838 0.288983107 0.0501722395]\n",
      "[0.860603929 0.835634828 0.784956217 ... 0.0646173656 0.062820971 0.0598535836]\n",
      "[0.902821124]\n",
      "[0.900947332 0.853997231 0.84906435 ... 0.0573412776 0.0539471507 0.0523690879]\n",
      "[0.824999094 0.754627347 0.747488797 ... 0.0683964491 0.0655913353 0.0547913]\n",
      "[0.918055415]\n",
      "[0.99757874 0.818466544 0.134630531]\n",
      "[0.935640812 0.918543756 0.898242712 ... 0.0557605326 0.0513070524 0.0504071414]\n",
      "[0.943890333 0.902662754 0.880256414 ... 0.0536477268 0.0520617664 0.0505042672]\n",
      "[0.942106426 0.883054554 0.72236 ... 0.0676425397 0.0561024547 0.0542710125]\n",
      "[0.777787 0.776284099 0.652640641 ... 0.061167568 0.0591270626 0.0514892638]\n",
      "[0.935535252 0.0553591251]\n",
      "[0.85868156 0.8230443 0.80668056]\n",
      "[0.987114429 0.896415114 0.875983477 ... 0.0651172698 0.0556925535 0.0524849296]\n",
      "[0.952460766 0.824296415 0.806021273 ... 0.0537498295 0.0516428947 0.0514113307]\n",
      "[0.938937783 0.63408637 0.53420496 0.0529588461 0.0508784354]\n",
      "[0.958067417 0.801107943 0.783453047 ... 0.0516689122 0.0514677763 0.050729841]\n",
      "[0.783650756 0.759337664 0.612441063 0.0660957098 0.0597836673 0.0532883704]\n",
      "[0.949578881 0.607121348 0.0626163185]\n",
      "[0.983287 0.979872942 0.979069948 ... 0.0790938437 0.0560748875 0.0538491]\n",
      "[0.982878923 0.967612565 0.953963578 ... 0.0520522594 0.0516499281 0.050994575]\n",
      "[0.917895079 0.913797 0.884776711 ... 0.0547811389 0.0524499416 0.0513477325]\n",
      "[0.945004106 0.921767831 0.862571061 ... 0.0747852325 0.0724666417 0.0585161746]\n",
      "[0.899638832 0.866716146 0.733833671 0.0535465777]\n",
      "[0.978287458 0.96175158 0.926744103 ... 0.0526643097 0.0522712469 0.0515274405]\n",
      "[0.928426385 0.920521855 0.874628663 ... 0.050647229 0.0502511263 0.0500065386]\n",
      "[0.986069441 0.906525254 0.0630245805 0.0561825037]\n",
      "[0.990953445 0.961979508 0.959444582 ... 0.0529057682 0.0523500443 0.0515754819]\n",
      "[0.818948388 0.802225888 0.801564157 ... 0.0627717674 0.0611222386 0.0521192253]\n",
      "[0.95191139]\n",
      "[0.916336358 0.813704848]\n",
      "[0.977921605 0.942868233 0.941165924 ... 0.053471 0.0528876185 0.0510242]\n",
      "[0.751612365 0.68566823]\n",
      "[0.906833112 0.865704775 0.862375557 ... 0.0591246188 0.0549352765 0.0500955284]\n",
      "[0.922614336 0.814662516 0.780817628 ... 0.0825218558 0.0806601942 0.0699416101]\n",
      "[0.976263881 0.95162034 0.827259302 ... 0.0742442906 0.0693641901 0.0545976162]\n",
      "[0.80168885 0.790706336 0.628781796 0.594728947 0.585733175]\n",
      "[0.975416124 0.951032043 0.877837062 ... 0.0685612 0.0681116 0.0678957701]\n",
      "[0.985689163 0.939983368 0.929723918 ... 0.062695533 0.0609768927 0.0516561568]\n",
      "[0.938529491 0.929472625 0.80746305 ... 0.0552514791 0.0532445908 0.0521103144]\n",
      "[0.874094605 0.846256256 0.740631 0.733258963 0.058662653 0.05728513]\n",
      "[0.961132646 0.938382328 0.924237 ... 0.0531308949 0.0518863499 0.0513825119]\n",
      "[0.784708798 0.635067165 0.0597967803 0.0512141585]\n",
      "[0.943520069 0.88604486 0.858623207 ... 0.0549490452 0.0537583232 0.0525913537]\n",
      "[0.874259233 0.850344419 0.630031943]\n",
      "[0.737126768 0.612771153 0.593995035 ... 0.0542908609 0.0537312329 0.0512517095]\n",
      "[0.882840395 0.835769236 0.828716874 ... 0.0565723777 0.0529381931 0.0512352586]\n",
      "FastEstimator-Eval: step: 828; epoch: 137; focal_loss: 0.0165289; l1_loss: 0.1064249; total_loss: 0.1229538; \n",
      "FastEstimator-Train: step: 828; focal_loss: 0.0027036; l1_loss: 0.0339543; total_loss: 0.0366579; examples/sec: 32.0; progress: 69.0%; \n",
      "FastEstimator-Train: step: 829; focal_loss: 0.0016301; l1_loss: 0.0722878; total_loss: 0.0739179; examples/sec: 32.4; progress: 69.1%; \n",
      "FastEstimator-Train: step: 830; focal_loss: 0.0013228; l1_loss: 0.0487057; total_loss: 0.0500284; examples/sec: 32.2; progress: 69.2%; \n",
      "FastEstimator-Train: step: 831; focal_loss: 0.0030287; l1_loss: 0.0402286; total_loss: 0.0432573; examples/sec: 32.2; progress: 69.2%; \n",
      "FastEstimator-Train: step: 832; focal_loss: 0.000848; l1_loss: 0.0898789; total_loss: 0.0907268; examples/sec: 32.2; progress: 69.3%; \n",
      "FastEstimator-Train: step: 833; focal_loss: 0.002864; l1_loss: 0.0363031; total_loss: 0.0391671; examples/sec: 32.2; progress: 69.4%; \n",
      "[0.947719932 0.927648842 0.853022277 ... 0.0527558327 0.0505545437 0.0501674414]\n",
      "[0.933056295 0.90822649 0.824760556 ... 0.0562645197 0.0519194 0.0501622558]\n",
      "[0.875266075 0.87069422 0.851788878 ... 0.0567168 0.0557985902 0.0511539578]\n",
      "[0.908685684 0.711259723 0.278827131 0.0659231842]\n",
      "[0.88263917 0.853254318 0.820195794 ... 0.0559470952 0.0539060235 0.0503650308]\n",
      "[0.909607172]\n",
      "[0.907139957 0.898916066 0.874131262 ... 0.0592472553 0.058860302 0.0522645414]\n",
      "[0.825929046 0.795945168 0.775944114 ... 0.0547988117 0.0545443892 0.0523991]\n",
      "[0.894927323]\n",
      "[0.998092055 0.847118139 0.170649588]\n",
      "[0.939322472 0.934191585 0.915414214 ... 0.062944591 0.0578698218 0.0555274189]\n",
      "[0.950876117 0.918783247 0.886706471 ... 0.0521836281 0.0514529049 0.0511685]\n",
      "[0.945454955 0.896938145 0.745318294 ... 0.0635886192 0.0582213104 0.0546900332]\n",
      "[0.818503 0.815824091 0.718689919 ... 0.0616960824 0.0554441512 0.0516937673]\n",
      "[0.941608965]\n",
      "[0.865172803 0.855009317 0.832305551 0.051636517]\n",
      "[0.992625475 0.930259585 0.896398485 ... 0.0532745421 0.0530082881 0.0524726808]\n",
      "[0.96917 0.872027755 0.830293298 ... 0.0505976379 0.0503363 0.0501662195]\n",
      "[0.954656124 0.658727109 0.5582816 0.0514476597]\n",
      "[0.971035421 0.840897202 0.8231076 ... 0.0538059771 0.0532218516 0.0526168942]\n",
      "[0.836684585 0.83542335 0.623980641 ... 0.0528720617 0.0520959795 0.051527679]\n",
      "[0.964535 0.622195244 0.0593856275]\n",
      "[0.983022749 0.982805371 0.98265183 ... 0.0806862414 0.0573145747 0.0543468595]\n",
      "[0.984631777 0.970325589 0.956497669 ... 0.0522925556 0.051414907 0.0510214567]\n",
      "[0.93504262 0.93122685 0.909228563 ... 0.0550801754 0.053596586 0.0513962805]\n",
      "[0.958270431 0.941124797 0.8824054 ... 0.0825454593 0.0758489072 0.066876322]\n",
      "[0.911115646 0.894085884 0.774838269]\n",
      "[0.984051466 0.963645697 0.943270922 ... 0.0537572801 0.0530446768 0.0512703955]\n",
      "[0.939207673 0.935737848 0.902713537 ... 0.0521712 0.0515336096 0.0506645739]\n",
      "[0.988410473 0.914933205 0.0711149]\n",
      "[0.992940068 0.974883199 0.97255826 ... 0.0535169244 0.0523618162 0.0511362553]\n",
      "[0.841638684 0.838258862 0.825998664 ... 0.0625532269 0.0574070215 0.0502953231]\n",
      "[0.960293829]\n",
      "[0.943251 0.866432428]\n",
      "[0.984360039 0.952510536 0.934910178 ... 0.0510081351 0.050732702 0.0503934324]\n",
      "[0.799270809 0.766410887]\n",
      "[0.922033966 0.894124746 0.865479708 ... 0.0575507 0.0538765192 0.0533702374]\n",
      "[0.942984343 0.836586595 0.82104063 ... 0.0755597949 0.0710089505 0.0500045717]\n",
      "[0.981307507 0.960405648 0.848035932 ... 0.091897428 0.0863929093 0.0633933842]\n",
      "[0.859757543 0.852592468 0.726184 0.711472213 0.651887119]\n",
      "[0.985259056 0.960439682 0.910781264 ... 0.0762569 0.0761825144 0.0753080249]\n",
      "[0.988282681 0.960834801 0.937281 ... 0.0883132815 0.0653304458 0.0621049106]\n",
      "[0.946026921 0.928749 0.807274699 ... 0.0565038025 0.0528020263 0.0505830944]\n",
      "[0.881352782 0.847916365 0.762368679 ... 0.0565118194 0.0515173972 0.0512942374]\n",
      "[0.968539834 0.949180245 0.936499 ... 0.0511341691 0.0503981411 0.0503209531]\n",
      "[0.848165751 0.736564577 0.0657983422 0.0506078]\n",
      "[0.957221329 0.908504248 0.872761965 ... 0.0565824211 0.0519596338 0.0518377125]\n",
      "[0.888855636 0.864386201 0.654513776]\n",
      "FastEstimator-Eval: step: 834; epoch: 138; focal_loss: 0.0141975; l1_loss: 0.0430969; total_loss: 0.0572944; \n",
      "FastEstimator-Train: step: 834; focal_loss: 0.001713; l1_loss: 0.0139329; total_loss: 0.0156459; examples/sec: 31.9; progress: 69.5%; \n",
      "FastEstimator-Train: step: 835; focal_loss: 0.0019044; l1_loss: 0.0366859; total_loss: 0.0385902; examples/sec: 32.5; progress: 69.6%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 836; focal_loss: 0.0011162; l1_loss: 0.0404308; total_loss: 0.041547; examples/sec: 32.2; progress: 69.7%; \n",
      "FastEstimator-Train: step: 837; focal_loss: 0.001691; l1_loss: 0.036279; total_loss: 0.0379699; examples/sec: 32.2; progress: 69.8%; \n",
      "FastEstimator-Train: step: 838; focal_loss: 0.0007753; l1_loss: 0.0583227; total_loss: 0.059098; examples/sec: 31.7; progress: 69.8%; \n",
      "FastEstimator-Train: step: 839; focal_loss: 0.0007995; l1_loss: 0.0610665; total_loss: 0.061866; examples/sec: 31.7; progress: 69.9%; \n",
      "[0.797545314 0.691628754 0.654227138 ... 0.0537872314 0.0516819358 0.0500812531]\n",
      "[0.927046061 0.860946298 0.860409379 ... 0.061542213 0.0598086715 0.0520520508]\n",
      "[0.966795325 0.941554666 0.865298271 ... 0.0577817857 0.0544731915 0.0521793365]\n",
      "[0.933338583 0.914041758 0.8358531 ... 0.059900254 0.0566075146 0.0550605059]\n",
      "[0.908043563 0.903879166 0.901364803 ... 0.0597094 0.0587637424 0.0518798232]\n",
      "[0.925958037 0.706524789 0.286892295 0.0668620765]\n",
      "[0.899970114 0.866781831 0.846556842 ... 0.0545483828 0.0534287393 0.0525916815]\n",
      "[0.858197212]\n",
      "[0.903845549 0.902314603 0.877813697 ... 0.0564687252 0.0559628904 0.0558667779]\n",
      "[0.828012 0.79046613 0.787341 ... 0.052194953 0.0512533486 0.0511817336]\n",
      "[0.850043535]\n",
      "[0.998489201 0.856864631 0.18267566]\n",
      "[0.94118762 0.930521131 0.903834879 ... 0.0566282272 0.0526095629 0.0506759286]\n",
      "[0.955829263 0.924452066 0.886917531 ... 0.0586790442 0.0568873882 0.0523096919]\n",
      "[0.949287057 0.906825483 0.763174832 ... 0.0589655042 0.0583387613 0.0582032502]\n",
      "[0.845223308 0.80472517 0.727662206 ... 0.0634288192 0.0618495941 0.055585593]\n",
      "[0.942024708]\n",
      "[0.844391882 0.818406105 0.810567 0.0519633]\n",
      "[0.993172646 0.927033305 0.886726379 ... 0.0597445071 0.0547978 0.0537994504]\n",
      "[0.975146055 0.903489649 0.864008188 ... 0.0565257967 0.0538216233 0.0520471632]\n",
      "[0.958737612 0.636433423 0.527632296]\n",
      "[0.975138187 0.842028379 0.834815502 ... 0.0513650775 0.0511060059 0.0504148304]\n",
      "[0.856573045 0.831950545 0.659649909 0.0675082505 0.059633702 0.0521366]\n",
      "[0.967105865 0.676378489 0.0626479089]\n",
      "[0.982147098 0.98043716 0.980123 ... 0.0802426934 0.0535307825 0.0521621108]\n",
      "[0.981592715 0.965398788 0.95208168 ... 0.0531814098 0.0524584651 0.0516660213]\n",
      "[0.944521427 0.928086519 0.902646065 ... 0.0543469489 0.0516421795 0.0510970354]\n",
      "[0.965232432 0.956642747 0.897460818 ... 0.0818247199 0.0664479434 0.0651004]\n",
      "[0.913086951 0.898591876 0.706646919]\n",
      "[0.986872077 0.977489471 0.950784802 ... 0.0530243218 0.0522196293 0.051944524]\n",
      "[0.945774198 0.943060935 0.910828352 ... 0.0524083674 0.0520613492 0.0511522889]\n",
      "[0.99079752 0.935571969 0.0702676475]\n",
      "[0.993265271 0.98120141 0.976936579 ... 0.0527326167 0.0521117449 0.0500372946]\n",
      "[0.848720074 0.838981509 0.835866868 ... 0.0627567172 0.0609571338 0.055155158]\n",
      "[0.961826086]\n",
      "[0.949709296 0.876361966]\n",
      "[0.98242569 0.939796567 0.925187528 ... 0.0538364649 0.0532355309 0.0519022644]\n",
      "[0.786217391 0.756418347]\n",
      "[0.922935486 0.901963711 0.874635935 ... 0.052361995 0.0507599115 0.0503790081]\n",
      "[0.941243827 0.835009813 0.832530558 ... 0.0804607868 0.0589552224 0.0537508726]\n",
      "[0.982723951 0.968630552 0.859421253 ... 0.58720243 0.0854672492 0.0590593517]\n",
      "[0.855127573 0.826995611 0.718037784 0.692051947 0.662808061]\n",
      "[0.987817764 0.965284824 0.919818878 ... 0.0717646778 0.0709299743 0.0698314607]\n",
      "[0.990543 0.966807127 0.945763588 0.939584255 0.082457155 0.064312011]\n",
      "[0.954753757 0.938388407 0.807957292 ... 0.0521892309 0.0517510474 0.050398469]\n",
      "[0.894895077 0.849557638 0.783872366 0.750371695 0.0597533]\n",
      "[0.968368888 0.959436655 0.945202589 ... 0.0522002578 0.0519557893 0.0517315865]\n",
      "[0.860024095 0.728672743 0.0624717176]\n",
      "FastEstimator-Eval: step: 840; epoch: 139; focal_loss: 0.0144362; l1_loss: 0.0414142; total_loss: 0.0558504; \n",
      "FastEstimator-Train: step: 840; focal_loss: 0.0011634; l1_loss: 0.0351237; total_loss: 0.0362871; examples/sec: 32.2; progress: 70.0%; \n",
      "FastEstimator-Train: step: 841; focal_loss: 0.0029275; l1_loss: 0.0289702; total_loss: 0.0318976; examples/sec: 32.6; progress: 70.1%; \n",
      "FastEstimator-Train: step: 842; focal_loss: 0.0017292; l1_loss: 0.0289652; total_loss: 0.0306944; examples/sec: 32.2; progress: 70.2%; \n",
      "FastEstimator-Train: step: 843; focal_loss: 0.0011537; l1_loss: 0.02827; total_loss: 0.0294238; examples/sec: 31.9; progress: 70.2%; \n",
      "FastEstimator-Train: step: 844; focal_loss: 0.0024313; l1_loss: 0.025826; total_loss: 0.0282573; examples/sec: 31.9; progress: 70.3%; \n",
      "FastEstimator-Train: step: 845; focal_loss: 0.001357; l1_loss: 0.0498877; total_loss: 0.0512447; examples/sec: 32.2; progress: 70.4%; \n",
      "[0.956584215 0.916223466 0.880012751 ... 0.0586346686 0.0516279042 0.0508027673]\n",
      "[0.91091156 0.891320288 0.699275851]\n",
      "[0.777502656 0.665040433 0.658669055 ... 0.0562764406 0.0542309 0.0519008934]\n",
      "[0.930744112 0.882153153 0.873045802 ... 0.0592568219 0.0579526424 0.050098151]\n",
      "[0.976152301 0.961400628 0.898010612 ... 0.0654982626 0.0568336844 0.0536008775]\n",
      "[0.916446209 0.877456665 0.81060648 ... 0.0609271526 0.0542709231 0.0504977107]\n",
      "[0.896147728 0.891122699 0.878415167 ... 0.0570683181 0.0532277226 0.0524928868]\n",
      "[0.955481589 0.7496714 0.321562469 0.068695426]\n",
      "[0.908192873 0.880614281 0.855017066 ... 0.0549904406 0.0544159412 0.0542876422]\n",
      "[0.909002423]\n",
      "[0.879358172 0.872739077 0.845748127 ... 0.0538879335 0.0533444 0.0505387783]\n",
      "[0.805352807 0.771801591 0.755452514 ... 0.0905703 0.0890300274 0.0830010474]\n",
      "[0.896931171]\n",
      "[0.999061823 0.859246969 0.159698099]\n",
      "[0.944984198 0.930187464 0.917665601 ... 0.056963414 0.056099534 0.0526439548]\n",
      "[0.95775187 0.920030475 0.904144287 ... 0.0568765104 0.0527656376 0.0515613854]\n",
      "[0.947269738 0.901492715 0.778267503 ... 0.0717624128 0.0620961189 0.0571009815]\n",
      "[0.841151357 0.784324408 0.719939113 ... 0.0610461831 0.060349524 0.0507374704]\n",
      "[0.953346848]\n",
      "[0.843829453 0.8320328 0.822911263 0.0563554168 0.0556099415]\n",
      "[0.993131399 0.944125533 0.907158673 ... 0.0601819456 0.058406204 0.0501767695]\n",
      "[0.972504079 0.885822 0.869168162 ... 0.0534475446 0.052267164 0.0506612957]\n",
      "[0.953158319 0.576732278 0.511012673 0.0527664721]\n",
      "[0.973084509 0.853549898 0.844658494 ... 0.0545706451 0.0517418385 0.051441431]\n",
      "[0.876973271 0.848709464 0.725512087 0.0753251314 0.0540919 0.0501407087]\n",
      "[0.972211063 0.709538341 0.0605896115]\n",
      "[0.981272042 0.97997731 0.978931427 ... 0.154212296 0.082256794 0.0745947659]\n",
      "[0.982223928 0.967622697 0.959244668 ... 0.0515360236 0.0500754714 0.0500480235]\n",
      "[0.947234035 0.929786384 0.90408808 ... 0.052738905 0.0520372689 0.0507804751]\n",
      "[0.969091654 0.960035 0.900494456 ... 0.109149396 0.0847669542 0.069496274]\n",
      "[0.922760963 0.886222243 0.69533813]\n",
      "[0.986250639 0.970506072 0.956666946 ... 0.0623503327 0.0548666716 0.0527510941]\n",
      "[0.939872503 0.936552703 0.905306101 ... 0.0507129729 0.0504867733 0.0501342118]\n",
      "[0.994243503 0.953905106 0.0666336715 0.0545140207]\n",
      "[0.99138093 0.977140307 0.969360411 ... 0.0553301573 0.053578347 0.0523610115]\n",
      "[0.84102273 0.838867366 0.828993082 ... 0.0564151704 0.0536560714 0.051135242]\n",
      "[0.978498697]\n",
      "[0.956932545 0.883835077]\n",
      "[0.982542515 0.935375333 0.926848888 ... 0.0741852224 0.0633554459 0.0545820892]\n",
      "[0.851160049 0.797612309]\n",
      "[0.921289206 0.901366949 0.879708171 ... 0.0524742 0.0509195626 0.050396055]\n",
      "[0.944042802 0.848813772 0.83071208 ... 0.0848186612 0.0605327189 0.0518738627]\n",
      "[0.987048924 0.976762772 0.884719253 ... 0.0745097697 0.0738927722 0.0625006557]\n",
      "[0.850888729 0.800634086 0.684356034 0.650633514 0.604257166]\n",
      "[0.98137635 0.968323112 0.92579484 ... 0.061822474 0.0618146956 0.0615978539]\n",
      "[0.989945769 0.971522808 0.954185188 0.935774744 0.078057915 0.0621547103]\n",
      "[0.959402919 0.94745481 0.841259301 ... 0.0529651344 0.0514911413 0.0504642427]\n",
      "[0.900100708 0.873137832 0.804532647 0.782330155 0.0549192131]\n",
      "FastEstimator-Eval: step: 846; epoch: 140; focal_loss: 0.0123163; l1_loss: 0.0803883; total_loss: 0.0927046; \n",
      "FastEstimator-Train: step: 846; focal_loss: 0.0023555; l1_loss: 0.1010005; total_loss: 0.103356; examples/sec: 32.1; progress: 70.5%; \n",
      "FastEstimator-Train: step: 847; focal_loss: 0.0008385; l1_loss: 0.0343792; total_loss: 0.0352177; examples/sec: 32.2; progress: 70.6%; \n",
      "FastEstimator-Train: step: 848; focal_loss: 0.0005277; l1_loss: 0.0403452; total_loss: 0.0408728; examples/sec: 32.7; progress: 70.7%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 849; focal_loss: 0.0008533; l1_loss: 0.0347343; total_loss: 0.0355876; examples/sec: 32.2; progress: 70.8%; \n",
      "FastEstimator-Train: step: 850; focal_loss: 0.0013265; l1_loss: 0.0183581; total_loss: 0.0196847; examples/sec: 32.2; progress: 70.8%; \n",
      "FastEstimator-Train: step: 851; focal_loss: 0.0030012; l1_loss: 0.0210178; total_loss: 0.0240191; examples/sec: 32.1; progress: 70.9%; \n",
      "[0.979982615 0.972171128 0.968289495 ... 0.0509839058 0.0508106351 0.0500619709]\n",
      "[0.83627516 0.698421717 0.0596551 0.0523320138]\n",
      "[0.965890527 0.934509277 0.900572658 ... 0.0594161153 0.0558886826 0.0529549718]\n",
      "[0.904986262 0.880728126 0.717078805]\n",
      "[0.835329294 0.72068435 0.719867587 ... 0.0577878952 0.0527943373 0.0523260534]\n",
      "[0.942605495 0.887712479 0.876561522 ... 0.0629632473 0.0581015348 0.0536645055]\n",
      "[0.970537901 0.937955737 0.854250133 ... 0.149129659 0.118032753 0.0501561463]\n",
      "[0.950315893 0.937846541 0.8874439 ... 0.0521388054 0.0513887703 0.0502964556]\n",
      "[0.887974262 0.88322109 0.865748703 ... 0.0542595685 0.0529722571 0.0526337326]\n",
      "[0.954963684 0.763169408 0.330359966 0.0532649755]\n",
      "[0.932888 0.907315731 0.883272409 ... 0.0556162894 0.0544424057 0.0532144606]\n",
      "[0.910813689]\n",
      "[0.92925179 0.922936618 0.898404121 ... 0.0542262495 0.0510621369 0.0507949]\n",
      "[0.845158 0.843784273 0.799928129 ... 0.0584692657 0.055996567 0.05406183]\n",
      "[0.887849569]\n",
      "[0.998821497 0.867692649 0.161697567]\n",
      "[0.958973408 0.947026312 0.929486156 ... 0.0523472428 0.0522126853 0.0518947244]\n",
      "[0.962168157 0.929874182 0.925947785 ... 0.0543274879 0.0514139831 0.0509473085]\n",
      "[0.954770803 0.912112892 0.793082774 ... 0.0590500832 0.0582459569 0.0522708595]\n",
      "[0.872485757 0.822612047 0.756544113 ... 0.0600438714 0.0586276054 0.0574075]\n",
      "[0.960762858]\n",
      "[0.883803844 0.841508329 0.839610815]\n",
      "[0.995643735 0.963355064 0.940353215 ... 0.0543526709 0.0518027842 0.050766468]\n",
      "[0.979683936 0.911851883 0.878214598 ... 0.0527018 0.05106619 0.050663054]\n",
      "[0.96288836 0.613595784 0.57399708 0.0539066195]\n",
      "[0.977789402 0.897034168 0.892342567 ... 0.0535019338 0.0515626073 0.0502644479]\n",
      "[0.87432313 0.843811393 0.770263374 0.0631338656 0.0574257374 0.0545770824]\n",
      "[0.967357755 0.746592164 0.0607693791]\n",
      "[0.987604618 0.986193061 0.985361218 ... 0.130229622 0.0881606936 0.0733462572]\n",
      "[0.990458786 0.981677294 0.976133 ... 0.0520195067 0.0518511236 0.050113976]\n",
      "[0.958853841 0.944727957 0.924911618 ... 0.053999573 0.0521966219 0.0508811772]\n",
      "[0.971149623 0.963589191 0.90528965 ... 0.0701792538 0.0570513 0.0552297831]\n",
      "[0.936533093 0.905498505 0.65885973]\n",
      "[0.988533914 0.98021841 0.961275935 ... 0.0523338616 0.0509740412 0.0502491891]\n",
      "[0.952665091 0.951673388 0.92013824 ... 0.0513251722 0.0511506796 0.0509040952]\n",
      "[0.990608275 0.937849581 0.0608919263 0.0549814105]\n",
      "[0.996783614 0.986858249 0.983659 ... 0.0531709492 0.0528951 0.050740689]\n",
      "[0.869638324 0.868549049 0.861142516 ... 0.0619933 0.0569871068 0.0511003435]\n",
      "[0.965552092]\n",
      "[0.942607105 0.861418784]\n",
      "[0.987224102 0.941413641 0.933577478 ... 0.0582137406 0.0559630096 0.0559215248]\n",
      "[0.804891229 0.748653173]\n",
      "[0.93567431 0.926997542 0.906083584 ... 0.0543005168 0.0536226332 0.0511576831]\n",
      "[0.953305602 0.876962245 0.855127752 ... 0.0549843311 0.0542038679 0.0521118343]\n",
      "[0.983752191 0.967945933 0.853799224 ... 0.0633604527 0.0587259829 0.0520458221]\n",
      "[0.823203564 0.785940051 0.673736 0.651367188 0.639891]\n",
      "[0.990224719 0.97862637 0.950197101 ... 0.0690881 0.0687352121 0.068664968]\n",
      "[0.99125737 0.957529247 0.943262219 0.93613863 0.0780592859 0.0571565628]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 852; epoch: 141; focal_loss: 0.0083472; l1_loss: 0.0340782; total_loss: 0.0424254; \n",
      "FastEstimator-Train: step: 852; focal_loss: 0.0009352; l1_loss: 0.0393992; total_loss: 0.0403344; examples/sec: 31.9; progress: 71.0%; \n",
      "FastEstimator-Train: step: 853; focal_loss: 0.0007716; l1_loss: 0.0211053; total_loss: 0.021877; examples/sec: 32.3; progress: 71.1%; \n",
      "FastEstimator-Train: step: 854; focal_loss: 0.0011141; l1_loss: 0.0437711; total_loss: 0.0448852; examples/sec: 32.6; progress: 71.2%; \n",
      "FastEstimator-Train: step: 855; focal_loss: 0.0008135; l1_loss: 0.0537818; total_loss: 0.0545953; examples/sec: 32.2; progress: 71.2%; \n",
      "FastEstimator-Train: step: 856; focal_loss: 0.0019695; l1_loss: 0.028216; total_loss: 0.0301855; examples/sec: 32.2; progress: 71.3%; \n",
      "FastEstimator-Train: step: 857; focal_loss: 0.0011423; l1_loss: 0.0292231; total_loss: 0.0303654; examples/sec: 32.2; progress: 71.4%; \n",
      "[0.972832382 0.969443381 0.84172219 ... 0.0542526841 0.0527181327 0.0526851416]\n",
      "[0.920756 0.901513577 0.86327 ... 0.0520088375 0.0514315069 0.0504566431]\n",
      "[0.979531646 0.967416406 0.964626551 ... 0.0512446463 0.0511933565 0.0511266]\n",
      "[0.900325716 0.803051949 0.0682337582 0.0550810397]\n",
      "[0.966334462 0.933358133 0.910984755 ... 0.0616480708 0.0611975491 0.0559438765]\n",
      "[0.925229311 0.899930596 0.728991389]\n",
      "[0.86712873 0.762798667 0.760697961 ... 0.0663491786 0.0557950437 0.0542882085]\n",
      "[0.943562031 0.92153132 0.900917053 ... 0.0627385378 0.0586131513 0.056030333]\n",
      "[0.970921159 0.953054249 0.896785796 ... 0.113897115 0.0531052053 0.0520599186]\n",
      "[0.952749729 0.950867176 0.896455586 ... 0.0526186526 0.0520378351 0.0511728227]\n",
      "[0.909063518 0.885777473 0.883897305 ... 0.0530735552 0.050830096 0.0505254567]\n",
      "[0.959078312 0.78556025 0.330193251 0.0596069098]\n",
      "[0.938925564 0.904875398 0.881432176 ... 0.0604282618 0.0586720407 0.0528758764]\n",
      "[0.917455673]\n",
      "[0.925117373 0.924541473 0.898467541 ... 0.0512402654 0.050749898 0.0505616963]\n",
      "[0.890399456 0.833256781 0.827241302 ... 0.0850704312 0.077632308 0.062576741]\n",
      "[0.9367]\n",
      "[0.999271274 0.876157045 0.177244157]\n",
      "[0.961075783 0.956185579 0.940957963 ... 0.0541224182 0.0509074628 0.0504772961]\n",
      "[0.963653564 0.929244 0.918019652 ... 0.0527465641 0.0523373783 0.0519947112]\n",
      "[0.962851882 0.903845429 0.830150485 ... 0.0693280101 0.0524329543 0.052295953]\n",
      "[0.893146873 0.867499828 0.811156154 ... 0.0656396747 0.0539141 0.0500291288]\n",
      "[0.957070768]\n",
      "[0.91405797 0.904194236 0.896890283]\n",
      "[0.995151281 0.967925847 0.938014865 ... 0.0704870522 0.0560653508 0.0537464917]\n",
      "[0.985775352 0.910761952 0.908697248 ... 0.0537373424 0.0520906746 0.0511024296]\n",
      "[0.95689857 0.651729 0.596765339 0.0533571541]\n",
      "[0.98121 0.907116 0.895735264 ... 0.0521768928 0.0521059632 0.0517061949]\n",
      "[0.895482063 0.886917472 0.800935745 0.0633589923 0.0578548908 0.0557847023]\n",
      "[0.977293313 0.755122602 0.0555847287]\n",
      "[0.990268946 0.9884938 0.98558867 ... 0.105660737 0.0854285359 0.0527320504]\n",
      "[0.984004259 0.969939113 0.964495182 ... 0.0508482456 0.0506398976 0.0502673388]\n",
      "[0.957142115 0.938913941 0.917630196 ... 0.053755343 0.0525125861 0.0520394444]\n",
      "[0.971602917 0.964700341 0.912491798 ... 0.0812320113 0.0801874101 0.0672702491]\n",
      "[0.932153 0.914627254 0.74443686]\n",
      "[0.987939715 0.974039793 0.955586255 ... 0.0527783036 0.0516781807 0.0515172482]\n",
      "[0.966395676 0.963012695 0.933646 ... 0.0523060858 0.0512546897 0.0502814949]\n",
      "[0.989668846 0.93297112 0.0609923]\n",
      "[0.996331453 0.98506546 0.97849524 ... 0.0509758592 0.0505000949 0.0502771139]\n",
      "[0.902059078 0.884037375 0.880845785 ... 0.0603034496 0.0548991263 0.0509642363]\n",
      "[0.976381719]\n",
      "[0.959260464 0.900576293]\n",
      "[0.988961816 0.952701569 0.945374489 ... 0.0581460297 0.0563327074 0.0559328198]\n",
      "[0.854144335 0.815015495]\n",
      "[0.928661 0.908672333 0.89519465 ... 0.0523920953 0.0520008504 0.0510129631]\n",
      "[0.949347377 0.892143369 0.862591 ... 0.0708983541 0.0552212 0.0527538359]\n",
      "[0.988643289 0.977538526 0.894716501 ... 0.0815912783 0.0619199872 0.0558511019]\n",
      "[0.877481818 0.845532537 0.774874687 0.753996551 0.707688]\n",
      "FastEstimator-Eval: step: 858; epoch: 142; focal_loss: 0.0068065; l1_loss: 0.0356441; total_loss: 0.0424506; \n",
      "FastEstimator-Train: step: 858; focal_loss: 0.0009907; l1_loss: 0.0189232; total_loss: 0.0199139; examples/sec: 32.3; progress: 71.5%; \n",
      "FastEstimator-Train: step: 859; focal_loss: 0.0015755; l1_loss: 0.0592224; total_loss: 0.0607979; examples/sec: 32.3; progress: 71.6%; \n",
      "FastEstimator-Train: step: 860; focal_loss: 0.000665; l1_loss: 0.0270634; total_loss: 0.0277284; examples/sec: 32.6; progress: 71.7%; \n",
      "FastEstimator-Train: step: 861; focal_loss: 0.0010873; l1_loss: 0.0347731; total_loss: 0.0358604; examples/sec: 31.6; progress: 71.8%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 862; focal_loss: 0.0018637; l1_loss: 0.0407947; total_loss: 0.0426584; examples/sec: 32.0; progress: 71.8%; \n",
      "FastEstimator-Train: step: 863; focal_loss: 0.0009118; l1_loss: 0.0208697; total_loss: 0.0217816; examples/sec: 32.1; progress: 71.9%; \n",
      "[0.988226235 0.979676485 0.942842841 ... 0.063388288 0.0627319813 0.0616832078]\n",
      "[0.986588597 0.951426744 0.921721041 0.911263108 0.0762671232 0.0572445095]\n",
      "[0.969943404 0.965094328 0.809645176 ... 0.0610096157 0.0522919297 0.0521710813]\n",
      "[0.928738534 0.910721242 0.857566655 ... 0.0604988337 0.0525117517 0.0505128801]\n",
      "[0.980156481 0.964541912 0.963017344 ... 0.050863117 0.0506315827 0.0504248142]\n",
      "[0.901982486 0.791793823 0.0658608079 0.0542175472]\n",
      "[0.968123674 0.93746686 0.91489768 ... 0.0575587451 0.0554938 0.0514782071]\n",
      "[0.93000412 0.901458 0.763736367]\n",
      "[0.863455534 0.771876574 0.757409096 ... 0.0594409108 0.053013891 0.0529858768]\n",
      "[0.939145 0.906911969 0.887225807 ... 0.0642320514 0.0615943372 0.0555223525]\n",
      "[0.971750736 0.946821868 0.88433814 ... 0.109886736 0.0527538359 0.0504225492]\n",
      "[0.949550033 0.94355613 0.879266083 ... 0.0525925457 0.0520429909 0.0518741]\n",
      "[0.904619873 0.874657035 0.866862893 ... 0.0526203513 0.0504961908 0.0500237644]\n",
      "[0.952779 0.756670415 0.298315972 0.0628673136]\n",
      "[0.938499808 0.89655745 0.88821125 ... 0.0528177917 0.0520839691 0.0511260033]\n",
      "[0.906470537]\n",
      "[0.91859591 0.915182829 0.888132095 ... 0.0524225831 0.0520373285 0.0511007607]\n",
      "[0.921181321 0.820951462 0.817015529 ... 0.0762770474 0.0687410533 0.0529158115]\n",
      "[0.921280384]\n",
      "[0.999013066 0.866669059 0.192404658]\n",
      "[0.963090777 0.958960831 0.941762924 ... 0.0532980263 0.052041173 0.0518142]\n",
      "[0.959586382 0.921747 0.912823439 ... 0.0564085245 0.0523478687 0.0508532524]\n",
      "[0.965100527 0.90308249 0.815122485 ... 0.0640860498 0.0543197393 0.0529640615]\n",
      "[0.882384777 0.831557274 0.776517 ... 0.0578448772 0.0550731421 0.0541703403]\n",
      "[0.957253933]\n",
      "[0.900200963 0.882539213 0.873111248]\n",
      "[0.996052 0.975526333 0.947231174 ... 0.0532224774 0.0523456037 0.0512885749]\n",
      "[0.983123779 0.916866899 0.870254457 ... 0.053658843 0.050991118 0.0507460535]\n",
      "[0.9577564 0.672024369 0.60321 0.0504938066]\n",
      "[0.982483089 0.919734359 0.90976721 ... 0.053166002 0.052969873 0.0526050329]\n",
      "[0.899142683 0.888976932 0.830007136 0.0527226925]\n",
      "[0.972744346 0.723338842 0.0505408943]\n",
      "[0.990611672 0.988304138 0.98705709 ... 0.368223786 0.099018842 0.0830121934]\n",
      "[0.983049631 0.969283462 0.963958621 ... 0.0516894758 0.0511566401 0.0506158769]\n",
      "[0.95982331 0.939014912 0.917170346 ... 0.0555970967 0.0552042425 0.0511365533]\n",
      "[0.976194322 0.969576657 0.924482584 ... 0.069337815 0.0659767389 0.0653407]\n",
      "[0.937602758 0.906994939 0.644812107 0.0555728376]\n",
      "[0.986190438 0.967039943 0.959244907 ... 0.0612883866 0.0534835458 0.0511111319]\n",
      "[0.966317654 0.963989735 0.93188 ... 0.0510133803 0.0502374768 0.0502119064]\n",
      "[0.985991657 0.915352106 0.055904448]\n",
      "[0.995226 0.981916249 0.977175891 ... 0.0608992577 0.060027808 0.0543477535]\n",
      "[0.880286455 0.877945662 0.877676964 ... 0.0589990616 0.0517629683 0.0504775345]\n",
      "[0.979846716]\n",
      "[0.962719202 0.905841291]\n",
      "[0.988262475 0.945471287 0.942775071 ... 0.0560632646 0.0542505085 0.0503779948]\n",
      "[0.871282816 0.845702112]\n",
      "[0.929446101 0.907929063 0.893297732 ... 0.0548065603 0.0545442104 0.0528851151]\n",
      "[0.960285425 0.904475451 0.865433514 ... 0.10858953 0.0590439439 0.052146405]\n",
      "FastEstimator-Eval: step: 864; epoch: 143; focal_loss: 0.006946; l1_loss: 0.0590295; total_loss: 0.0659755; \n",
      "FastEstimator-Train: step: 864; focal_loss: 0.0009016; l1_loss: 0.0410512; total_loss: 0.0419529; examples/sec: 31.9; progress: 72.0%; \n",
      "FastEstimator-Train: step: 865; focal_loss: 0.001609; l1_loss: 0.0453132; total_loss: 0.0469222; examples/sec: 31.9; progress: 72.1%; \n",
      "FastEstimator-Train: step: 866; focal_loss: 0.0005801; l1_loss: 0.0461502; total_loss: 0.0467303; examples/sec: 32.7; progress: 72.2%; \n",
      "FastEstimator-Train: step: 867; focal_loss: 0.0007757; l1_loss: 0.0213549; total_loss: 0.0221305; examples/sec: 32.3; progress: 72.2%; \n",
      "FastEstimator-Train: step: 868; focal_loss: 0.0006416; l1_loss: 0.0388519; total_loss: 0.0394935; examples/sec: 31.8; progress: 72.3%; \n",
      "FastEstimator-Train: step: 869; focal_loss: 0.0013843; l1_loss: 0.0188183; total_loss: 0.0202026; examples/sec: 32.1; progress: 72.4%; \n",
      "[0.983896494 0.972332239 0.849279404 ... 0.75881815 0.0567116439 0.0542280674]\n",
      "[0.844335914 0.839109063 0.782252 0.768086314 0.753769636]\n",
      "[0.989984035 0.980593562 0.951879859 ... 0.057927072 0.0577872694 0.0577679873]\n",
      "[0.984252453 0.919263363 0.906703949 0.876819134 0.0715343952 0.056931138]\n",
      "[0.97400403 0.968781471 0.793887079 ... 0.0793524384 0.0608835518 0.0586591959]\n",
      "[0.942848802 0.91388166 0.864807427 ... 0.0588859916 0.0503107 0.0500995219]\n",
      "[0.982424617 0.973459542 0.972377181 ... 0.0516079366 0.0513113141 0.0507665873]\n",
      "[0.856330395 0.722405851 0.0552716255]\n",
      "[0.969233871 0.942328215 0.914747477 ... 0.0561874211 0.0550119579 0.0502856076]\n",
      "[0.928474903 0.892958879 0.790933609]\n",
      "[0.855722308 0.769735038 0.752879143 ... 0.0638851821 0.0538082719 0.0506142676]\n",
      "[0.938694954 0.909195423 0.866333544 ... 0.0662772357 0.061116457 0.0500070453]\n",
      "[0.968573451 0.920883894 0.833672881 ... 0.72853291 0.127189308 0.107306957]\n",
      "[0.958121061 0.949137032 0.897035956 ... 0.0549321473 0.0506053567 0.0503584146]\n",
      "[0.917274892 0.914428592 0.900000334 ... 0.0690183043 0.0628396869 0.0591088235]\n",
      "[0.942413807 0.720719695 0.274848759 0.0583659112]\n",
      "[0.947957635 0.914828479 0.907242537 ... 0.0533059835 0.0517652333 0.0508011281]\n",
      "[0.920245171]\n",
      "[0.922562361 0.913543701 0.900101423 ... 0.056242913 0.0557805598 0.0505626202]\n",
      "[0.957381129 0.825443923 0.819617093 ... 0.0704802275 0.0588172078 0.0516025424]\n",
      "[0.891973615]\n",
      "[0.99806881 0.860065937 0.196007669]\n",
      "[0.965981662 0.956172347 0.934937358 ... 0.0522513688 0.0502330661 0.050216794]\n",
      "[0.959596813 0.923258424 0.917118311 ... 0.0519541502 0.0505360365 0.0501067936]\n",
      "[0.964669347 0.918555617 0.81158936 ... 0.0627989173 0.059104085 0.058862]\n",
      "[0.888578534 0.825915635 0.767305076 ... 0.0537380278 0.0518912077 0.0510021448]\n",
      "[0.961585522]\n",
      "[0.899383426 0.829279661 0.818382621]\n",
      "[0.996536136 0.976784229 0.949864447 ... 0.0626579523 0.0585686862 0.0534362197]\n",
      "[0.98457408 0.940240502 0.893216848 ... 0.0574510098 0.0510098934 0.0509377122]\n",
      "[0.966002285 0.700857341 0.643183947 0.0560596585]\n",
      "[0.982640624 0.935508966 0.927640676 ... 0.0544950366 0.0542427897 0.0503968]\n",
      "[0.880706072 0.85464263 0.852494 0.0526304245]\n",
      "[0.966017723 0.731019199 0.0518080294]\n",
      "[0.991644323 0.989051044 0.988493741 ... 0.772701263 0.0882153511 0.0720094442]\n",
      "[0.983940363 0.971203685 0.962946355 ... 0.0515898466 0.0515235364 0.0502534509]\n",
      "[0.966568828 0.942086339 0.917712033 ... 0.0569333136 0.0562640727 0.0549105704]\n",
      "[0.975993395 0.970070243 0.921649158 ... 0.0613962412 0.0567072034 0.0519288778]\n",
      "[0.945159197 0.904571891 0.5944345]\n",
      "[0.986969948 0.981543601 0.96413815 ... 0.0658281446 0.0653013885 0.0580725968]\n",
      "[0.966724515 0.964558959 0.943912208 ... 0.0510884523 0.0507234931 0.0504820645]\n",
      "[0.98389554 0.909259856 0.0513892174]\n",
      "[0.99623543 0.984470129 0.981805682 ... 0.0566288531 0.051454097 0.0513406098]\n",
      "[0.885026515 0.867049336 0.866315126 ... 0.0592037737 0.0574166775 0.0508197844]\n",
      "[0.966066837]\n",
      "[0.952669501 0.881228209]\n",
      "[0.985750675 0.94166708 0.92705816 ... 0.0544037223 0.0520098507 0.0506912172]\n",
      "[0.812760115 0.79107]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 870; epoch: 144; focal_loss: 0.0067182; l1_loss: 0.0335264; total_loss: 0.0402446; \n",
      "FastEstimator-Train: step: 870; focal_loss: 0.0011676; l1_loss: 0.0380393; total_loss: 0.0392069; examples/sec: 31.8; progress: 72.5%; \n",
      "FastEstimator-Train: step: 871; focal_loss: 0.0010589; l1_loss: 0.0187553; total_loss: 0.0198142; examples/sec: 32.1; progress: 72.6%; \n",
      "FastEstimator-Train: step: 872; focal_loss: 0.001022; l1_loss: 0.032719; total_loss: 0.033741; examples/sec: 32.5; progress: 72.7%; \n",
      "FastEstimator-Train: step: 873; focal_loss: 0.0006056; l1_loss: 0.0307164; total_loss: 0.031322; examples/sec: 32.5; progress: 72.8%; \n",
      "FastEstimator-Train: step: 874; focal_loss: 0.001537; l1_loss: 0.0375497; total_loss: 0.0390867; examples/sec: 32.1; progress: 72.8%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 875; focal_loss: 0.0005565; l1_loss: 0.0216857; total_loss: 0.0222422; examples/sec: 31.9; progress: 72.9%; \n",
      "[0.940528631 0.918619454 0.917161226 ... 0.0563088655 0.0510513484 0.0502783954]\n",
      "[0.970626235 0.918814838 0.899016201 ... 0.0966052115 0.0768665373 0.0523972213]\n",
      "[0.989470601 0.982217789 0.886840165 0.865125418 0.782918692 0.0613679588]\n",
      "[0.862078905 0.861681104 0.801786602 0.796282947 0.757941246]\n",
      "[0.987024486 0.980204582 0.941722631 ... 0.0601262748 0.0598073 0.0579756796]\n",
      "[0.987735271 0.939078391 0.914279699 0.908046246 0.0746070743 0.0578594804]\n",
      "[0.97851 0.971387506 0.815289617 ... 0.064363122 0.0623963773 0.0511934757]\n",
      "[0.942163408 0.914179444 0.883928418 ... 0.0654030144 0.0530032516 0.0516548753]\n",
      "[0.982181191 0.973061919 0.969640255 ... 0.0508372486 0.0507825911 0.0503291786]\n",
      "[0.901428 0.803266287 0.0606952608 0.051209718]\n",
      "[0.970137656 0.946533084 0.91647017 ... 0.0627652109 0.0536979437 0.0525535345]\n",
      "[0.942878366 0.913023949 0.796125174]\n",
      "[0.846806228 0.779361367 0.761412144 ... 0.0753973126 0.0586408377 0.0516991317]\n",
      "[0.947443962 0.931750655 0.909185946 ... 0.0607390106 0.0544053316 0.0527738929]\n",
      "[0.978198647 0.954510808 0.90612042 ... 0.835290313 0.159685701 0.130477428]\n",
      "[0.941994 0.926150918 0.898060679 ... 0.0521846414 0.0521419942 0.0521095693]\n",
      "[0.915649712 0.908150673 0.885848165 ... 0.0651106536 0.0549757183 0.0530073047]\n",
      "[0.961065173 0.760857582 0.307159424 0.0610185266]\n",
      "[0.954395056 0.913746 0.900427 ... 0.052761972 0.050666064 0.0504844189]\n",
      "[0.949556947]\n",
      "[0.922293425 0.905230641 0.882954 ... 0.0555123389 0.0519744158 0.0511889756]\n",
      "[0.917503357 0.849214673 0.836454868 ... 0.06624493 0.0647670329 0.0584219694]\n",
      "[0.944654226]\n",
      "[0.998423 0.864914179 0.186948448]\n",
      "[0.964862645 0.953145385 0.946621776 ... 0.0570292175 0.0547396541 0.0542681217]\n",
      "[0.961892 0.932979941 0.922912598 ... 0.0535241961 0.053250432 0.0525275469]\n",
      "[0.964086294 0.91661495 0.849833965 ... 0.0656099916 0.0549635887 0.0504715741]\n",
      "[0.902895629 0.864193141 0.810584664 ... 0.0544042587 0.0521405041 0.0502226353]\n",
      "[0.96582973]\n",
      "[0.907506108 0.890770137 0.88685]\n",
      "[0.996777952 0.982585788 0.951550961 ... 0.0579781532 0.053368479 0.0506058633]\n",
      "[0.987095952 0.928187132 0.887434959 ... 0.0521033406 0.05166 0.0506033599]\n",
      "[0.962645113 0.679414153 0.654160202 0.0638991594 0.0530973375]\n",
      "[0.983361483 0.941446424 0.931962729 ... 0.0551318228 0.0524339974 0.0518316627]\n",
      "[0.896283269 0.890237212 0.884659171 ... 0.0513522625 0.0510069132 0.0500509143]\n",
      "[0.973971725 0.750638962]\n",
      "[0.992471218 0.989798188 0.988178074 ... 0.0917356908 0.0903441608 0.0719265342]\n",
      "[0.987658143 0.978464067 0.970006824 ... 0.0505044758 0.0501289964 0.0500533]\n",
      "[0.968951 0.940575898 0.913206577 ... 0.0528772473 0.0525971353 0.0508125722]\n",
      "[0.970583081 0.960954666 0.902185738 ... 0.0593809187 0.0585788488 0.0579032]\n",
      "[0.950857162 0.91535759 0.751233]\n",
      "[0.988832235 0.984614611 0.967161417 ... 0.065782845 0.0648289323 0.0613691509]\n",
      "[0.969144344 0.96880734 0.943268657 ... 0.0509081185 0.0505548716 0.0500676036]\n",
      "[0.990095854 0.937161565 0.0521563]\n",
      "[0.996029675 0.982927561 0.982502937 ... 0.0555603504 0.0530125201 0.0510505438]\n",
      "[0.912879586 0.893731713 0.888437152 ... 0.0660864711 0.0638233125 0.0513149202]\n",
      "[0.971698642]\n",
      "[0.96164459 0.899599791]\n",
      "FastEstimator-Eval: step: 876; epoch: 145; focal_loss: 0.0053445; l1_loss: 0.0487801; total_loss: 0.0541246; \n",
      "FastEstimator-Train: step: 876; focal_loss: 0.0005281; l1_loss: 0.017921; total_loss: 0.0184491; examples/sec: 32.0; progress: 73.0%; \n",
      "FastEstimator-Train: step: 877; focal_loss: 0.0015688; l1_loss: 0.0435374; total_loss: 0.0451062; examples/sec: 32.2; progress: 73.1%; \n",
      "FastEstimator-Train: step: 878; focal_loss: 0.0024419; l1_loss: 0.0343922; total_loss: 0.0368341; examples/sec: 32.1; progress: 73.2%; \n",
      "FastEstimator-Train: step: 879; focal_loss: 0.0005581; l1_loss: 0.0396706; total_loss: 0.0402287; examples/sec: 32.6; progress: 73.2%; \n",
      "FastEstimator-Train: step: 880; focal_loss: 0.0006317; l1_loss: 0.0364458; total_loss: 0.0370775; examples/sec: 32.2; progress: 73.3%; \n",
      "FastEstimator-Train: step: 881; focal_loss: 0.0013364; l1_loss: 0.0138765; total_loss: 0.0152128; examples/sec: 31.1; progress: 73.4%; \n",
      "[0.986165583 0.952709556 0.943560898 ... 0.0520334542 0.051153332 0.0506566465]\n",
      "[0.833967805 0.804317236]\n",
      "[0.958890915 0.941138744 0.940005302 ... 0.0548127294 0.0524355173 0.0508233905]\n",
      "[0.975000858 0.926029086 0.908708334 ... 0.0960146785 0.0560564101 0.0536364019]\n",
      "[0.987993836 0.979933143 0.879095554 0.86535275 0.794204473 0.0556730032]\n",
      "[0.84537816 0.828538775 0.790924907 0.773083091 0.758292794]\n",
      "[0.991505444 0.981619954 0.950842381 ... 0.0657781065 0.0637508333 0.0633140802]\n",
      "[0.989781618 0.931859612 0.924898088 0.89301753 0.0721297562 0.070448339]\n",
      "[0.984474361 0.982116461 0.85887754 ... 0.0624130666 0.0511974692 0.050714761]\n",
      "[0.945663095 0.908122301 0.871908069 0.844221473 0.056049794]\n",
      "[0.987821937 0.983030617 0.975575209 ... 0.0509556532 0.0506833196 0.0504522622]\n",
      "[0.886310458 0.801282406 0.0639548]\n",
      "[0.975641966 0.951351404 0.92632 ... 0.0526507497 0.0521695 0.0518629253]\n",
      "[0.910060883 0.866693 0.783826828]\n",
      "[0.884389102 0.79347676 0.775244236 ... 0.0642815828 0.0555277467 0.0531128049]\n",
      "[0.947944164 0.925224543 0.890828252 ... 0.0621034801 0.0591128767 0.0567366779]\n",
      "[0.976262689 0.939398706 0.867519 ... 0.789439201 0.139696211 0.128157049]\n",
      "[0.957178771 0.941571 0.924993038 ... 0.0515499413 0.0514446497 0.0503012836]\n",
      "[0.918116271 0.911949277 0.878570437 ... 0.0732822418 0.0564801693 0.0502470434]\n",
      "[0.950153947 0.762045383 0.270181358 0.0556169748]\n",
      "[0.962235808 0.932823956 0.915330529 ... 0.0545620918 0.0519273579 0.051363498]\n",
      "[0.904862583]\n",
      "[0.94595629 0.931825876 0.91576314 ... 0.0557336807 0.0545191169 0.0509442389]\n",
      "[0.891573906 0.883191228 0.865565181 ... 0.0645466745 0.059273392 0.0532796383]\n",
      "[0.910151899]\n",
      "[0.997964263 0.871537566 0.206089646]\n",
      "[0.970472455 0.964517117 0.962396085 ... 0.0508742929 0.0507487655 0.0504084229]\n",
      "[0.966306388 0.949032068 0.925995827 ... 0.0540973842 0.0539650321 0.0528085232]\n",
      "[0.962958574 0.927400231 0.871670127 ... 0.0651216805 0.0649975538 0.0523833036]\n",
      "[0.902989 0.846779108 0.800212741 ... 0.0526917279 0.0516334474 0.0501364172]\n",
      "[0.957580805]\n",
      "[0.926886916 0.885160208 0.878775239]\n",
      "[0.998257756 0.989422917 0.967339158 ... 0.0588814318 0.052105397 0.0504475236]\n",
      "[0.985172689 0.935126305 0.909466267 ... 0.0525646508 0.0511360466 0.0507212579]\n",
      "[0.971910954 0.733931124 0.694678187]\n",
      "[0.986414492 0.956679642 0.956160843 ... 0.0518709123 0.0510332 0.0507067144]\n",
      "[0.887370825 0.882914841 0.878277 0.0547122657 0.0528543293 0.0524356067]\n",
      "[0.968661606 0.777400255]\n",
      "[0.994369268 0.991841793 0.990686119 ... 0.0873262882 0.0716605783 0.0694743395]\n",
      "[0.992889345 0.986964345 0.980419695 ... 0.0517025888 0.0510894656 0.0501133502]\n",
      "[0.977276206 0.959367633 0.940131783 ... 0.0534401536 0.0525998771 0.0521896482]\n",
      "[0.96991384 0.958921194 0.910304368 ... 0.0575563908 0.0550377667 0.051969707]\n",
      "[0.961506 0.921187282 0.700877488]\n",
      "[0.989497304 0.988933802 0.972498178 ... 0.0657268167 0.0619432926 0.0560110509]\n",
      "[0.971592546 0.970249414 0.949965954 ... 0.053775996 0.0534254611 0.0500319]\n",
      "[0.987341523 0.930201948]\n",
      "[0.997561574 0.989290476 0.989040256 ... 0.0563837588 0.0534220338 0.0507535934]\n",
      "[0.910722136 0.8999964 0.896849036 ... 0.0654042363 0.0595490932 0.0507753491]\n",
      "FastEstimator-Eval: step: 882; epoch: 146; focal_loss: 0.0036107; l1_loss: 0.0424499; total_loss: 0.0460606; \n",
      "FastEstimator-Train: step: 882; focal_loss: 0.0001998; l1_loss: 0.03597; total_loss: 0.0361698; examples/sec: 32.3; progress: 73.5%; \n",
      "FastEstimator-Train: step: 883; focal_loss: 0.0008022; l1_loss: 0.0317049; total_loss: 0.032507; examples/sec: 32.0; progress: 73.6%; \n",
      "FastEstimator-Train: step: 884; focal_loss: 0.0009566; l1_loss: 0.0219803; total_loss: 0.0229369; examples/sec: 32.2; progress: 73.7%; \n",
      "FastEstimator-Train: step: 885; focal_loss: 0.0010094; l1_loss: 0.0273255; total_loss: 0.028335; examples/sec: 32.4; progress: 73.8%; \n",
      "FastEstimator-Train: step: 886; focal_loss: 0.0010947; l1_loss: 0.0257722; total_loss: 0.0268669; examples/sec: 32.1; progress: 73.8%; \n",
      "FastEstimator-Train: step: 887; focal_loss: 0.0009955; l1_loss: 0.0175917; total_loss: 0.0185871; examples/sec: 32.3; progress: 73.9%; \n",
      "[0.966595173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96040535 0.902467]\n",
      "[0.988695383 0.962635279 0.956064224 ... 0.0566265 0.051807344 0.0516478717]\n",
      "[0.860649586 0.849151134]\n",
      "[0.96236527 0.944600701 0.944356918 ... 0.0541586578 0.0526125431 0.0523253679]\n",
      "[0.973619938 0.921426535 0.91575 ... 0.114045888 0.0520474315 0.051722914]\n",
      "[0.988221645 0.979706526 0.881405592 0.876795053 0.806850791 0.0568434894]\n",
      "[0.849513292 0.834024668 0.81482023 0.777703047 0.766858459]\n",
      "[0.993812144 0.982426584 0.960620642 ... 0.0724314451 0.0707576 0.0707142651]\n",
      "[0.993204 0.950639725 0.94633019 0.929328561 0.0798342526 0.0679717958]\n",
      "[0.985421717 0.984297514 0.860358477 ... 0.0631547 0.0547643 0.0514837801]\n",
      "[0.947953343 0.915977 0.896204233 0.859866619 0.0519766808]\n",
      "[0.989653289 0.986101329 0.978489041 ... 0.0517760515 0.051666528 0.0509934723]\n",
      "[0.906697392 0.841789961 0.0696144402 0.0530832708]\n",
      "[0.98140192 0.956484437 0.933813155 ... 0.0600841343 0.0532211661 0.051420778]\n",
      "[0.918244958 0.885816276 0.823516846]\n",
      "[0.916996717 0.8319695 0.817633927 ... 0.0561198592 0.0550552309 0.0516077876]\n",
      "[0.9529742 0.93373704 0.919020474 ... 0.0692947805 0.0624457598 0.0597037673]\n",
      "[0.988902509 0.965945125 0.902766645 ... 0.158597916 0.0528077185 0.0518138111]\n",
      "[0.970060587 0.953710556 0.934590936 ... 0.0507840216 0.0500711203 0.0500567853]\n",
      "[0.938897729 0.927703 0.907125354 ... 0.0571711659 0.0551865101 0.0527566075]\n",
      "[0.960309684 0.808316112 0.278872 0.0595193207]\n",
      "[0.967431188 0.938753486 0.921119153 ... 0.0526223779 0.051890105 0.0518327951]\n",
      "[0.897938371]\n",
      "[0.954475582 0.95170927 0.935103178 ... 0.0583520234 0.0564228594 0.0506463945]\n",
      "[0.897626281 0.887342393 0.882828116 ... 0.064653188 0.0560777485 0.0545020401]\n",
      "[0.852051]\n",
      "[0.999220967 0.903595448 0.196438372]\n",
      "[0.974496722 0.970322251 0.965022326 ... 0.0505762696 0.0505722165 0.0500058532]\n",
      "[0.972137034 0.954631925 0.934683561 ... 0.0578286648 0.0530735254 0.0514993668]\n",
      "[0.963110805 0.934101939 0.885166 ... 0.066125989 0.0644474328 0.0608120561]\n",
      "[0.907217741 0.857021391 0.824297667 ... 0.0532464385 0.0530214906 0.0503763258]\n",
      "[0.959674716]\n",
      "[0.932396293 0.913134456 0.900178671]\n",
      "[0.998497963 0.991832078 0.973327398 ... 0.072779 0.07239151 0.0647012]\n",
      "[0.990582228 0.936345637 0.919872403 ... 0.0518259108 0.0511051416 0.0503544509]\n",
      "[0.974069953 0.809226155 0.74424243]\n",
      "[0.988529921 0.96113956 0.956327379 ... 0.052069366 0.0519787073 0.0511653423]\n",
      "[0.909138083 0.909086585 0.903434277 0.0582497418 0.0532683134 0.0509212]\n",
      "[0.975059032 0.804655671]\n",
      "[0.995022535 0.992737889 0.991372 ... 0.813163161 0.0930713713 0.079298228]\n",
      "[0.994230807 0.988986433 0.983988285 ... 0.0510568917 0.050657779 0.0506477952]\n",
      "[0.977867603 0.964605 0.948899209 ... 0.0523954928 0.0515112579 0.0512065291]\n",
      "[0.979090333 0.969589412 0.939500332 ... 0.0747509897 0.0651184618 0.0587520599]\n",
      "[0.96262157 0.923271179 0.663351476]\n",
      "[0.992812514 0.990986824 0.972997725 ... 0.0540737212 0.0527708828 0.0514776707]\n",
      "[0.9744519 0.971104145 0.96085465 ... 0.0540138483 0.0539720953 0.0531385243]\n",
      "[0.988734126 0.936473966 0.0512727499]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 888; epoch: 147; focal_loss: 0.0027077; l1_loss: 0.0269361; total_loss: 0.0296438; \n",
      "FastEstimator-Train: step: 888; focal_loss: 0.000981; l1_loss: 0.0191496; total_loss: 0.0201306; examples/sec: 31.7; progress: 74.0%; \n",
      "FastEstimator-Train: step: 889; focal_loss: 0.0009619; l1_loss: 0.0490451; total_loss: 0.050007; examples/sec: 32.2; progress: 74.1%; \n",
      "FastEstimator-Train: step: 890; focal_loss: 0.0004782; l1_loss: 0.0324299; total_loss: 0.0329081; examples/sec: 31.9; progress: 74.2%; \n",
      "FastEstimator-Train: step: 891; focal_loss: 0.0023212; l1_loss: 0.0281891; total_loss: 0.0305103; examples/sec: 32.5; progress: 74.2%; \n",
      "FastEstimator-Train: step: 892; focal_loss: 0.0007161; l1_loss: 0.0156535; total_loss: 0.0163696; examples/sec: 31.7; progress: 74.3%; \n",
      "FastEstimator-Train: step: 893; focal_loss: 0.0006885; l1_loss: 0.0308885; total_loss: 0.031577; examples/sec: 31.7; progress: 74.4%; \n",
      "[0.99782306 0.988455176 0.980466187 ... 0.0564367175 0.0557448864 0.0545824766]\n",
      "[0.928894818 0.921588659 0.914157867 ... 0.0663637519 0.0557497144 0.0553277731]\n",
      "[0.977726579]\n",
      "[0.968354046 0.912284136]\n",
      "[0.982697248 0.964144707 0.957958937 ... 0.0644347072 0.0633693039 0.0538150668]\n",
      "[0.883112669 0.851109]\n",
      "[0.953258276 0.933484733 0.933439553 ... 0.0564515 0.050755769 0.0505292118]\n",
      "[0.965308189 0.904762089 0.899149776 ... 0.503888309 0.257013023 0.103384286]\n",
      "[0.987869 0.978527546 0.885292411 0.880907893 0.814712644 0.0742012]\n",
      "[0.856566072 0.827348709 0.826128721 0.788634837 0.756183267]\n",
      "[0.992880046 0.981119156 0.957018614 ... 0.0598243177 0.0587995946 0.0585846901]\n",
      "[0.994274139 0.953323483 0.942584515 0.938834429 0.0728652775 0.0618592501]\n",
      "[0.983034253 0.981195331 0.825176537 ... 0.0606473684 0.0564447939 0.052791208]\n",
      "[0.94627142 0.919662952 0.903059661 0.882525086 0.0585315824]\n",
      "[0.988873899 0.980974197 0.977794766 ... 0.0510044694 0.050742656 0.050034076]\n",
      "[0.902084231 0.830560207 0.059049964 0.0565499365]\n",
      "[0.97861433 0.954180717 0.920391679 ... 0.0664479434 0.0544850826 0.051761955]\n",
      "[0.942708075 0.923185 0.868045211]\n",
      "[0.895911157 0.821890354 0.801769257 ... 0.055159241 0.0522752702 0.0508625209]\n",
      "[0.948148131 0.939800858 0.9320876 ... 0.0589888692 0.0573786497 0.0548924506]\n",
      "[0.994634867 0.985238492 0.952587 ... 0.174226493 0.0658771396 0.0564922392]\n",
      "[0.972391844 0.948987246 0.929277658 ... 0.0540236235 0.0519766808 0.0515255928]\n",
      "[0.914063931 0.89346242 0.875882924 ... 0.130231053 0.0839659572 0.0706229806]\n",
      "[0.970437407 0.80213058 0.290822655 0.0522571802]\n",
      "[0.963028848 0.9336555 0.914814711 ... 0.061373502 0.0568905175 0.0554564595]\n",
      "[0.926787853]\n",
      "[0.948667526 0.945812821 0.915869176 ... 0.0529839098 0.0524116457 0.0520059466]\n",
      "[0.896809757 0.886113346 0.854965925 ... 0.0578484237 0.0559993386 0.0502112508]\n",
      "[0.886772692]\n",
      "[0.999512136 0.909696519 0.14869532]\n",
      "[0.975443602 0.967704 0.954653561 ... 0.0603302717 0.0545579493 0.0519615114]\n",
      "[0.974935293 0.950289488 0.937627554 ... 0.0567113459 0.0521848202 0.0509442389]\n",
      "[0.962235093 0.928313911 0.878029168 ... 0.0612347722 0.0599559247 0.0538874269]\n",
      "[0.902988315 0.858642161 0.832784891 ... 0.0519863069 0.05177477 0.0515571833]\n",
      "[0.966995716]\n",
      "[0.920689464 0.919232488 0.887658536]\n",
      "[0.997634649 0.989281058 0.962881804 ... 0.0775608718 0.0598766506 0.0506947637]\n",
      "[0.991143346 0.922812 0.911335945 ... 0.0566633344 0.0549862683 0.0511457026]\n",
      "[0.961190462 0.803164 0.753501892 0.052998215]\n",
      "[0.987487853 0.954333544 0.937968 ... 0.0511943698 0.0509923398 0.0505926311]\n",
      "[0.912856162 0.912051797 0.901558876 0.056884557]\n",
      "[0.97369194 0.799007416]\n",
      "[0.994853377 0.992491126 0.991212964 ... 0.0910973549 0.0839372873 0.0777654946]\n",
      "[0.993702114 0.988735735 0.983039737 ... 0.0506741107 0.0502390265 0.0500731468]\n",
      "[0.97437346 0.951996803 0.931919217 ... 0.0519175529 0.0518870056 0.0510715842]\n",
      "[0.98623687 0.979930818 0.956387222 ... 0.0751337409 0.0730880797 0.0583556592]\n",
      "[0.959674358 0.921155 0.663040876]\n",
      "[0.990811825 0.989520967 0.971270084 ... 0.0537489653 0.053124845 0.0514501929]\n",
      "FastEstimator-Eval: step: 894; epoch: 148; focal_loss: 0.0027399; l1_loss: 0.0574865; total_loss: 0.0602264; \n",
      "FastEstimator-Train: step: 894; focal_loss: 0.0005576; l1_loss: 0.0415984; total_loss: 0.0421559; examples/sec: 32.0; progress: 74.5%; \n",
      "FastEstimator-Train: step: 895; focal_loss: 0.0004592; l1_loss: 0.064262; total_loss: 0.0647212; examples/sec: 31.9; progress: 74.6%; \n",
      "FastEstimator-Train: step: 896; focal_loss: 0.0004305; l1_loss: 0.0387378; total_loss: 0.0391682; examples/sec: 32.2; progress: 74.7%; \n",
      "FastEstimator-Train: step: 897; focal_loss: 0.003547; l1_loss: 0.0251149; total_loss: 0.0286618; examples/sec: 32.6; progress: 74.8%; \n",
      "FastEstimator-Train: step: 898; focal_loss: 0.0005351; l1_loss: 0.0299295; total_loss: 0.0304645; examples/sec: 32.5; progress: 74.8%; \n",
      "FastEstimator-Train: step: 899; focal_loss: 0.0004229; l1_loss: 0.0260466; total_loss: 0.0264695; examples/sec: 32.2; progress: 74.9%; \n",
      "[0.969307303 0.966152072 0.956120431 ... 0.0520093143 0.0517471433 0.0508874655]\n",
      "[0.984027743 0.917762041]\n",
      "[0.997656822 0.987152755 0.986605048 ... 0.0563866198 0.0525834858 0.0511529446]\n",
      "[0.919591188 0.901468515 0.899202943 ... 0.113074213 0.0576683 0.0518113077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.974216759]\n",
      "[0.953282475 0.873267889]\n",
      "[0.984329164 0.969413579 0.952729464 ... 0.0639014542 0.0520906746 0.0514981151]\n",
      "[0.83167243 0.777287304]\n",
      "[0.958627582 0.942722797 0.941391945 ... 0.0574969947 0.0563043356 0.0560064316]\n",
      "[0.972395301 0.921062827 0.912425816 ... 0.262530506 0.0800351202 0.0690264404]\n",
      "[0.983410597 0.971685529 0.886279583 0.844846845 0.811576128]\n",
      "[0.83698976 0.802505732 0.795507789 0.79308331 0.718308806]\n",
      "[0.994649053 0.9837116 0.962363243 ... 0.0554858744 0.054491967 0.0542697906]\n",
      "[0.983044 0.906983733 0.880253673 0.841587067 0.0630940199 0.0573455393]\n",
      "[0.987634897 0.985719323 0.849816501 ... 0.0575243533 0.0547577739 0.0509500504]\n",
      "[0.952017903 0.932458401 0.905144274 0.880702376 0.0660816431 0.0575920343]\n",
      "[0.989687085 0.987596273 0.982499182 ... 0.0519664288 0.050960362 0.0502238572]\n",
      "[0.870270371 0.767701566]\n",
      "[0.974037051 0.954182386 0.924227357 ... 0.0555329621 0.0535712838 0.0515583754]\n",
      "[0.942373 0.908268452 0.861322522]\n",
      "[0.891737461 0.807399571 0.801724553 ... 0.0618497431 0.0537257493 0.052972734]\n",
      "[0.949407816 0.945093513 0.905943573 ... 0.0595393181 0.0583088398 0.0568751395]\n",
      "[0.983113408 0.949019909 0.871313572 ... 0.801923692 0.132545412 0.116374075]\n",
      "[0.978541851 0.960192502 0.945262671 ... 0.0521974564 0.0511513948 0.050090462]\n",
      "[0.924785 0.890721679 0.885660768 ... 0.097224772 0.0925270617 0.066819638]\n",
      "[0.966808 0.785402119 0.278219521]\n",
      "[0.969932437 0.95023334 0.932857633 ... 0.0607249737 0.0590485632 0.0504739583]\n",
      "[0.940812707]\n",
      "[0.950620294 0.948096752 0.93207705 ... 0.0550733805 0.0513575077 0.0504442751]\n",
      "[0.939449787 0.90352577 0.85706234 ... 0.0774607062 0.0529836118 0.0522711873]\n",
      "[0.905730247]\n",
      "[0.998470426 0.891960561 0.193868339]\n",
      "[0.978823543 0.966481209 0.954011798 ... 0.0566923618 0.0515210629 0.0510060489]\n",
      "[0.977269411 0.953068733 0.947542787 ... 0.0591792762 0.056458205 0.0538669229]\n",
      "[0.962283611 0.936368287 0.864239812 ... 0.062122792 0.0592305362 0.0508777201]\n",
      "[0.909304202 0.882027805 0.829448 ... 0.0521610379 0.0511122942 0.051016748]\n",
      "[0.974254429]\n",
      "[0.918153346 0.881457329 0.852469802]\n",
      "[0.997737765 0.989315808 0.972390056 ... 0.117637992 0.0786309242 0.065944314]\n",
      "[0.987799048 0.928206205 0.920212388 ... 0.0535743237 0.0529077947 0.050263077]\n",
      "[0.973511577 0.862502694 0.791123629 0.0613054633]\n",
      "[0.986073911 0.958813906 0.938596606 ... 0.0536621213 0.0527228713 0.0526479483]\n",
      "[0.910681367 0.898203 0.854899883 0.0533011556]\n",
      "[0.968411922 0.804021239]\n",
      "[0.995084763 0.992735803 0.992312312 ... 0.0768036544 0.0737372935 0.0666770339]\n",
      "[0.994041383 0.98977071 0.983132243 ... 0.052696079 0.0520986319 0.0501161218]\n",
      "[0.982802629 0.957780123 0.939207911 ... 0.0528063178 0.0519942045 0.0512706041]\n",
      "[0.979228735 0.968007386 0.935628951 ... 0.0579202771 0.0547114909 0.0503153801]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 900; epoch: 149; focal_loss: 0.0027254; l1_loss: 0.0201164; total_loss: 0.0228419; \n",
      "FastEstimator-Train: step: 900; focal_loss: 0.0008069; l1_loss: 0.0325871; total_loss: 0.033394; examples/sec: 32.0; progress: 75.0%; \n",
      "FastEstimator-Train: step: 901; focal_loss: 0.001718; l1_loss: 0.0269448; total_loss: 0.0286628; examples/sec: 32.2; progress: 75.1%; \n",
      "FastEstimator-Train: step: 902; focal_loss: 0.0003673; l1_loss: 0.0326994; total_loss: 0.0330667; examples/sec: 32.3; progress: 75.2%; \n",
      "FastEstimator-Train: step: 903; focal_loss: 0.0007348; l1_loss: 0.0095927; total_loss: 0.0103275; examples/sec: 31.9; progress: 75.2%; \n",
      "FastEstimator-Train: step: 904; focal_loss: 0.0004657; l1_loss: 0.0141968; total_loss: 0.0146624; examples/sec: 32.7; progress: 75.3%; \n",
      "FastEstimator-Train: step: 905; focal_loss: 0.0004375; l1_loss: 0.0384011; total_loss: 0.0388386; examples/sec: 32.3; progress: 75.4%; \n",
      "[0.968684793 0.937649488 0.87049669]\n",
      "[0.990267873 0.989989519 0.971234798 ... 0.0516856909 0.0515582561 0.0509041548]\n",
      "[0.966589928 0.966400623 0.948414564 ... 0.0520229638 0.0519566238 0.0516120195]\n",
      "[0.986765325 0.933014035]\n",
      "[0.99725163 0.989385426 0.988084197 ... 0.0562445223 0.0534480214 0.0504349172]\n",
      "[0.918404162 0.901454329 0.900368333 ... 0.136940539 0.121538043 0.0568036735]\n",
      "[0.966203928]\n",
      "[0.952737689 0.878595829]\n",
      "[0.989634097 0.965133548 0.960899234 ... 0.0736614466 0.0570083857 0.0513198078]\n",
      "[0.856863856 0.824743032]\n",
      "[0.961592615 0.942345619 0.94122684 ... 0.0616120696 0.060949862 0.0536884665]\n",
      "[0.96780777 0.917871356 0.914723039 ... 0.546630502 0.256484449 0.0870353878]\n",
      "[0.986354709 0.974702358 0.892495334 0.859503865 0.822756231 0.067643851]\n",
      "[0.856185913 0.855504751 0.836452 0.823194683 0.790132046]\n",
      "[0.993872583 0.984598637 0.956071496 ... 0.065297842 0.0630553365 0.0615192056]\n",
      "[0.976589322 0.894782603 0.859398663 0.804288864 0.0615479946 0.0568603873]\n",
      "[0.988119 0.986668 0.880277812 ... 0.0532486141 0.050901413 0.0507106185]\n",
      "[0.952923298 0.936188579 0.905217648 0.889948905 0.0702666938 0.0584630966]\n",
      "[0.988864541 0.988006353 0.980240703 ... 0.0508985519 0.0503224432 0.0502609611]\n",
      "[0.88124764 0.815787792 0.0521883667]\n",
      "[0.974280238 0.954703212 0.941512465 ... 0.0574363768 0.0558322966 0.0529339]\n",
      "[0.929730594 0.882238209 0.815728903]\n",
      "[0.911976814 0.845354557 0.818783641 ... 0.0678201914 0.060675621 0.0565511286]\n",
      "[0.954650164 0.946471214 0.901441872 ... 0.0573281348 0.0543732643 0.0511691868]\n",
      "[0.965976954 0.92242372 0.850663066 ... 0.178984255 0.12403211 0.0867237151]\n",
      "[0.973527074 0.959898353 0.951356113 ... 0.0524780154 0.0513176918 0.0501008928]\n",
      "[0.938916206 0.912371755 0.909570873 ... 0.0676819682 0.0670787394 0.0506105423]\n",
      "[0.968192697 0.833662033 0.296481371 0.0518569648]\n",
      "[0.973919272 0.951828361 0.93636477 ... 0.0565386713 0.0564938486 0.0539634824]\n",
      "[0.916204751]\n",
      "[0.950827479 0.945015371 0.933785498 ... 0.0559580922 0.0549528599 0.0531620979]\n",
      "[0.921198606 0.907610893 0.862665951 ... 0.0563892126 0.055516839 0.0516289175]\n",
      "[0.930562496]\n",
      "[0.997465372 0.872205734 0.235330611]\n",
      "[0.980118 0.966661692 0.963207066 ... 0.0543108 0.0508145094 0.050478071]\n",
      "[0.978481829 0.954620481 0.952338 ... 0.061188072 0.0563679934 0.0529499054]\n",
      "[0.962059259 0.941743493 0.895301402 ... 0.0579436421 0.0530530512 0.0511503518]\n",
      "[0.925334156 0.912965178 0.856856942 ... 0.0536451042 0.0524404943 0.0523652434]\n",
      "[0.969860792]\n",
      "[0.913379 0.907027602 0.891735375]\n",
      "[0.998417854 0.991528273 0.97557044 ... 0.0534738898 0.0525770783 0.0519750118]\n",
      "[0.988624334 0.920192063 0.912610769 ... 0.0514664352 0.0513193309 0.0512988567]\n",
      "[0.975356102 0.896960497 0.811137497 0.0523551106 0.051549077]\n",
      "[0.987430573 0.960406363 0.936361909 ... 0.0519888103 0.0505316257 0.0500496328]\n",
      "[0.912662148 0.902257502 0.870153666 0.0537423491 0.0515878797 0.0501613319]\n",
      "[0.977272213 0.825333536]\n",
      "[0.993958 0.992048383 0.990945578 ... 0.0819349289 0.0691643953 0.0518132746]\n",
      "[0.991322637 0.985994399 0.979078412 ... 0.0541163385 0.0532460511 0.0502664745]\n",
      "FastEstimator-Eval: step: 906; epoch: 150; focal_loss: 0.0021349; l1_loss: 0.0641644; total_loss: 0.0662993; \n",
      "FastEstimator-Train: step: 906; focal_loss: 0.0004289; l1_loss: 0.0329586; total_loss: 0.0333875; examples/sec: 31.9; progress: 75.5%; \n",
      "FastEstimator-Train: step: 907; focal_loss: 0.0010665; l1_loss: 0.0323435; total_loss: 0.03341; examples/sec: 32.1; progress: 75.6%; \n",
      "FastEstimator-Train: step: 908; focal_loss: 0.0007585; l1_loss: 0.0203076; total_loss: 0.0210661; examples/sec: 32.2; progress: 75.7%; \n",
      "FastEstimator-Train: step: 909; focal_loss: 0.0014221; l1_loss: 0.0334593; total_loss: 0.0348814; examples/sec: 32.3; progress: 75.8%; \n",
      "FastEstimator-Train: step: 910; focal_loss: 0.0004875; l1_loss: 0.0491545; total_loss: 0.049642; examples/sec: 32.6; progress: 75.8%; \n",
      "FastEstimator-Train: step: 911; focal_loss: 0.000613; l1_loss: 0.0602304; total_loss: 0.0608434; examples/sec: 32.3; progress: 75.9%; \n",
      "[0.98735106 0.972350895 0.958058953 ... 0.0525909662 0.0515323877 0.0508184433]\n",
      "[0.971721 0.959288836 0.925788045 ... 0.093703419 0.09250772 0.0832132399]\n",
      "[0.969435334 0.946767807 0.923099399]\n",
      "[0.99132 0.991285 0.972954035 ... 0.0537104 0.0536060035 0.0521171093]\n",
      "[0.973026454 0.972816527 0.954012156 ... 0.0507073402 0.0505027473 0.0501896739]\n",
      "[0.992134511 0.954933047]\n",
      "[0.997501731 0.991630852 0.990275383 ... 0.0591339469 0.0543565452 0.0526912212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93921572 0.929042459 0.916933894 ... 0.063839823 0.0540422499 0.0520345271]\n",
      "[0.968748212]\n",
      "[0.965303898 0.908185482]\n",
      "[0.990685284 0.973594666 0.968287468 ... 0.0716958344 0.0628718734 0.0513574481]\n",
      "[0.90646708 0.882569909]\n",
      "[0.968536615 0.954532564 0.947164297 ... 0.0627558529 0.0581674874 0.0564645529]\n",
      "[0.97164917 0.918342 0.917755842 ... 0.271827906 0.104556233 0.0703784227]\n",
      "[0.992759526 0.985837579 0.914718866 0.903414786 0.8412]\n",
      "[0.882458 0.879746914 0.874957681 0.837980628 0.826498747]\n",
      "[0.994650841 0.987159371 0.964103103 ... 0.0689727068 0.0686681867 0.0683665276]\n",
      "[0.986402512 0.919077158 0.9162817 0.889813185 0.0686297715 0.0579316914]\n",
      "[0.99042809 0.989152133 0.896249413 ... 0.0657588243 0.0640679896 0.0581184328]\n",
      "[0.959008336 0.933353424 0.913450956 0.91016382 0.0692138672]\n",
      "[0.991342664 0.989661515 0.983756304 ... 0.0509416163 0.0505082309 0.0500374436]\n",
      "[0.923262835 0.887289762 0.0593176484 0.0528619289]\n",
      "[0.9799335 0.961394787 0.947336793 ... 0.0587359071 0.0521206558 0.0500487089]\n",
      "[0.936597168 0.896257222 0.825583935]\n",
      "[0.926814914 0.869334459 0.83430028 ... 0.0636104345 0.0632630885 0.0520769656]\n",
      "[0.957171261 0.948095322 0.92288053 ... 0.0550563633 0.0546659231 0.0512985587]\n",
      "[0.982792497 0.969087 0.941622853 ... 0.867693543 0.163645089 0.111200809]\n",
      "[0.972401738 0.963727951 0.95699358 ... 0.0511496961 0.0510933101 0.0504488647]\n",
      "[0.945862293 0.932002366 0.921528101 ... 0.0886451602 0.0694839656 0.05039379]\n",
      "[0.982001662 0.887850821 0.343031168 0.0535769463]\n",
      "[0.976735651 0.959984899 0.945710182 ... 0.0559843481 0.0535416305 0.0515717268]\n",
      "[0.908156514]\n",
      "[0.955283165 0.950139642 0.945453405 ... 0.0527879894 0.0521586537 0.0519473553]\n",
      "[0.918289125 0.915661 0.887170792 ... 0.0689611435 0.065292865 0.0504971743]\n",
      "[0.948062658]\n",
      "[0.999028206 0.899946928 0.237138331]\n",
      "[0.982091784 0.97545141 0.971255 ... 0.0530756116 0.0506888628 0.0501660705]\n",
      "[0.98186481 0.957751513 0.954111755 ... 0.0741077363 0.0651657283 0.0570674539]\n",
      "[0.968268573 0.951033354 0.918832779 ... 0.0545556843 0.0540004075 0.0521253347]\n",
      "[0.934176087 0.927251458 0.885052323 ... 0.0551933646 0.0539424717 0.0504100323]\n",
      "[0.963421643]\n",
      "[0.939467907 0.922738552 0.916245818]\n",
      "[0.998846889 0.993665695 0.980237246 ... 0.0554533 0.0525909662 0.0525627732]\n",
      "[0.992286205 0.935647368 0.925755262 ... 0.0520307422 0.0518330634 0.0511720181]\n",
      "[0.980475664 0.912971139 0.814956188 0.0516137183]\n",
      "[0.990905404 0.968964756 0.955609918 ... 0.0511685 0.050450176 0.0500976741]\n",
      "[0.922070622 0.914955854 0.898614466 0.0625519156 0.0538248718 0.0515146255]\n",
      "[0.983182192 0.836521149]\n",
      "FastEstimator-Eval: step: 912; epoch: 151; focal_loss: 0.0016256; l1_loss: 0.0230575; total_loss: 0.024683; \n",
      "FastEstimator-Train: step: 912; focal_loss: 0.000533; l1_loss: 0.058453; total_loss: 0.058986; examples/sec: 32.4; progress: 76.0%; \n",
      "FastEstimator-Train: step: 913; focal_loss: 0.0006198; l1_loss: 0.0111566; total_loss: 0.0117764; examples/sec: 32.2; progress: 76.1%; \n",
      "FastEstimator-Train: step: 914; focal_loss: 0.0008532; l1_loss: 0.0575768; total_loss: 0.0584301; examples/sec: 31.8; progress: 76.2%; \n",
      "FastEstimator-Train: step: 915; focal_loss: 0.0007474; l1_loss: 0.0394755; total_loss: 0.0402229; examples/sec: 31.4; progress: 76.2%; \n",
      "FastEstimator-Train: step: 916; focal_loss: 0.0009488; l1_loss: 0.0429146; total_loss: 0.0438634; examples/sec: 32.6; progress: 76.3%; \n",
      "FastEstimator-Train: step: 917; focal_loss: 0.0003183; l1_loss: 0.0240377; total_loss: 0.024356; examples/sec: 32.3; progress: 76.4%; \n",
      "[0.995077372 0.994256496 0.992245138 ... 0.0627891719 0.0579711795 0.0536396801]\n",
      "[0.993033171 0.988612413 0.984451532 ... 0.0561392 0.0522610545 0.0517806113]\n",
      "[0.987893641 0.973251581 0.957921267 ... 0.0572125316 0.054474473 0.052942723]\n",
      "[0.972972631 0.957621336 0.930718064 ... 0.0806190073 0.0803484321 0.0649769902]\n",
      "[0.966870427 0.935628355 0.841598153]\n",
      "[0.990790248 0.990602851 0.972901225 ... 0.0532289445 0.0522454977 0.0508504808]\n",
      "[0.968553245 0.966022 0.957067966 ... 0.0508848131 0.0503002405 0.0500569642]\n",
      "[0.985116959 0.925094426]\n",
      "[0.997821093 0.98964572 0.985962451 ... 0.0569835305 0.0515053272 0.0514901876]\n",
      "[0.930262327 0.925379395 0.909564674 ... 0.157550067 0.135447234 0.0582188368]\n",
      "[0.967700362]\n",
      "[0.957127094 0.880653]\n",
      "[0.986703753 0.970886588 0.965527952 ... 0.0731981099 0.0717818141 0.0504765809]\n",
      "[0.889076233 0.862580955]\n",
      "[0.969501734 0.953365207 0.951928139 ... 0.0563351512 0.0555728674 0.0509010851]\n",
      "[0.97903353 0.924330235 0.917333126 ... 0.513203144 0.297973812 0.0852520764]\n",
      "[0.990090609 0.982260227 0.904021859 0.883090138 0.84051311]\n",
      "[0.838713884 0.826929629 0.825951815 0.800886035 0.746417344]\n",
      "[0.99546051 0.98432529 0.972253799 ... 0.0637629926 0.0634526908 0.0634129047]\n",
      "[0.990091622 0.917835 0.913481712 0.892350197 0.0554438531]\n",
      "[0.990668535 0.990109921 0.888763964 ... 0.061104387 0.0590031743 0.0509617031]\n",
      "[0.956697 0.933006167 0.922384739 0.90551424 0.0645828545]\n",
      "[0.99214685 0.990488172 0.987347543 ... 0.0532067716 0.0517468452 0.0507318377]\n",
      "[0.885314345 0.832813]\n",
      "[0.978279948 0.963600397 0.941052794 ... 0.0575107932 0.0522566438 0.050331831]\n",
      "[0.930438936 0.882575274 0.837484241]\n",
      "[0.910759211 0.851653159 0.835589647 ... 0.0697723329 0.0582173765 0.0576035082]\n",
      "[0.952816844 0.948193312 0.895741582 ... 0.0517171025 0.0506186485 0.0500516593]\n",
      "[0.978015363 0.949027 0.875314951 ... 0.775030077 0.121793 0.0991914272]\n",
      "[0.978610218 0.966665268 0.960878134 ... 0.0547780395 0.052085191 0.0520641804]\n",
      "[0.928662181 0.912743092 0.909469843 ... 0.0878101885 0.0699107945 0.0610958636]\n",
      "[0.968071282 0.808025122 0.249751836 0.0548717678]\n",
      "[0.974646568 0.96249795 0.948697627 ... 0.0583817959 0.0570428669 0.0550425053]\n",
      "[0.923261642]\n",
      "[0.952134609 0.947186232 0.945313692 ... 0.0516432822 0.0516222417 0.0503807962]\n",
      "[0.953133702 0.922790468 0.86710608 ... 0.0815750659 0.0793201625 0.0517188609]\n",
      "[0.927865267]\n",
      "[0.998842597 0.90095067 0.19558385]\n",
      "[0.977554381 0.969392598 0.968224525 ... 0.06080845 0.0565320849 0.0540299416]\n",
      "[0.978812516 0.952680171 0.945588827 ... 0.064791292 0.0548380613 0.0516476929]\n",
      "[0.960178852 0.946496189 0.901270509 ... 0.0585340858 0.0557644665 0.0518255532]\n",
      "[0.90853107 0.889080465 0.853752851 ... 0.0589782596 0.0517534614 0.051440984]\n",
      "[0.966178775]\n",
      "[0.922815323 0.880058229 0.856227636]\n",
      "[0.998856544 0.993277 0.979002595 ... 0.0522253811 0.0512104928 0.0506245792]\n",
      "[0.9898206 0.941442132 0.929901898 ... 0.0521778464 0.052084595 0.0515474677]\n",
      "[0.977541327 0.893972278 0.811600506 0.0552348495 0.0506366789]\n",
      "[0.988211036 0.971710443 0.960630894 ... 0.0507388115 0.050662607 0.0504679084]\n",
      "FastEstimator-Eval: step: 918; epoch: 152; focal_loss: 0.0018057; l1_loss: 0.0293028; total_loss: 0.0311085; \n",
      "FastEstimator-Train: step: 918; focal_loss: 0.0003056; l1_loss: 0.0223443; total_loss: 0.0226499; examples/sec: 32.2; progress: 76.5%; \n",
      "FastEstimator-Train: step: 919; focal_loss: 0.0010753; l1_loss: 0.0168411; total_loss: 0.0179164; examples/sec: 32.4; progress: 76.6%; \n",
      "FastEstimator-Train: step: 920; focal_loss: 0.00062; l1_loss: 0.0349874; total_loss: 0.0356075; examples/sec: 31.7; progress: 76.7%; \n",
      "FastEstimator-Train: step: 921; focal_loss: 0.000845; l1_loss: 0.0295868; total_loss: 0.0304318; examples/sec: 32.4; progress: 76.8%; \n",
      "FastEstimator-Train: step: 922; focal_loss: 0.0003038; l1_loss: 0.0236147; total_loss: 0.0239185; examples/sec: 32.6; progress: 76.8%; \n",
      "FastEstimator-Train: step: 923; focal_loss: 0.0006177; l1_loss: 0.0433824; total_loss: 0.0440001; examples/sec: 32.5; progress: 76.9%; \n",
      "[0.923206449 0.901777923 0.89462328 0.0509671569 0.0500977635]\n",
      "[0.979210496 0.827527642]\n",
      "[0.994025469 0.993065715 0.991204441 ... 0.0729666352 0.0635024 0.0503579974]\n",
      "[0.990780592 0.985212445 0.982340038 ... 0.0528956056 0.0522623658 0.050742954]\n",
      "[0.98701036 0.967818558 0.948158 ... 0.0612988472 0.05406183 0.0508580208]\n",
      "[0.976948202 0.958874822 0.937558234 ... 0.0701827407 0.0698016882 0.0610054433]\n",
      "[0.970313549 0.937231898 0.879653454]\n",
      "[0.99166739 0.990312934 0.969578385 ... 0.0524359345 0.0509898961 0.0501624942]\n",
      "[0.964969039 0.962758 0.953681111 ... 0.051887393 0.051707983 0.0500203669]\n",
      "[0.982228518 0.903824687]\n",
      "[0.997870445 0.989712656 0.98427248 ... 0.0633803904 0.0633632243 0.0578578711]\n",
      "[0.926821 0.919415832 0.91085 ... 0.764073908 0.128728807 0.0625279844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.982706904]\n",
      "[0.970320165 0.91313]\n",
      "[0.986598134 0.969181776 0.968540549 ... 0.0684419572 0.0585094094 0.0575584471]\n",
      "[0.893200815 0.881037772]\n",
      "[0.959422112 0.947104 0.932830215 ... 0.0584973693 0.053303808 0.0516652763]\n",
      "[0.97731328 0.924516201 0.912564754 ... 0.314264238 0.0948779 0.0524593294]\n",
      "[0.985141337 0.974673808 0.903345525 0.843259573 0.842518 0.0525993705]\n",
      "[0.87249589 0.867417276 0.866572738 0.814622283 0.811412573]\n",
      "[0.995847344 0.983018041 0.973513722 ... 0.059833914 0.0596835613 0.0581290722]\n",
      "[0.991942286 0.946393132 0.935236216 0.924261093 0.0522845089]\n",
      "[0.988976717 0.988500118 0.877146721 ... 0.074760288 0.0678450167 0.055328697]\n",
      "[0.951635301 0.943366051 0.923526943 0.91792357 0.066852]\n",
      "[0.991507351 0.989513755 0.987754345 ... 0.0517450273 0.0517393351 0.0512526333]\n",
      "[0.876730561 0.839425921]\n",
      "[0.980628967 0.966766238 0.938717604 ... 0.0599773228 0.0520034134 0.0516348779]\n",
      "[0.94787997 0.907974243 0.853567123]\n",
      "[0.908908 0.866111279 0.851853967 ... 0.0581329763 0.0526091456 0.0515399873]\n",
      "[0.959144235 0.946673274 0.910063744 ... 0.0556783676 0.0513969064 0.0510931909]\n",
      "[0.972373843 0.9436993 0.876313 ... 0.728885233 0.107184649 0.0787999332]\n",
      "[0.983120203 0.964836597 0.958600044 ... 0.0538124442 0.0505260527 0.0501822233]\n",
      "[0.93061173 0.921812475 0.903983712 ... 0.0916519463 0.0797238052 0.0691594183]\n",
      "[0.970443606 0.798942327 0.236960471 0.0808705389]\n",
      "[0.972950339 0.951497912 0.937825203 ... 0.0570881069 0.0561515391 0.0544384718]\n",
      "[0.941186666]\n",
      "[0.944547236 0.939543247 0.938826442 ... 0.0541375875 0.0528937876 0.0528442562]\n",
      "[0.952464819 0.925362349 0.886384726 ... 0.105317682 0.0761156678 0.0554764569]\n",
      "[0.944380641]\n",
      "[0.999126911 0.903185129 0.204956889]\n",
      "[0.973203778 0.969041824 0.964030325 ... 0.0527200699 0.0517455637 0.050970912]\n",
      "[0.979350328 0.949223638 0.946799517 ... 0.0594218671 0.0577436388 0.0572563708]\n",
      "[0.953500748 0.935182214 0.888273239 ... 0.0680818558 0.0656833649 0.0576343536]\n",
      "[0.900406957 0.887131572 0.852553368 ... 0.0674104095 0.0520783365 0.0511122942]\n",
      "[0.973231077 0.0509254336 0.0507175922]\n",
      "[0.90861845 0.865130305 0.829424]\n",
      "[0.998721 0.992654204 0.976131439 ... 0.134446859 0.0862396657 0.0611189]\n",
      "[0.990613461 0.933556318 0.927910089 ... 0.064702183 0.0643082261 0.054299593]\n",
      "FastEstimator-Eval: step: 924; epoch: 153; focal_loss: 0.0017326; l1_loss: 0.040076; total_loss: 0.0418085; \n",
      "FastEstimator-Train: step: 924; focal_loss: 0.0003036; l1_loss: 0.0194085; total_loss: 0.019712; examples/sec: 32.3; progress: 77.0%; \n",
      "FastEstimator-Train: step: 925; focal_loss: 0.0009179; l1_loss: 0.0329496; total_loss: 0.0338675; examples/sec: 32.1; progress: 77.1%; \n",
      "FastEstimator-Train: step: 926; focal_loss: 0.0008408; l1_loss: 0.0530445; total_loss: 0.0538853; examples/sec: 32.4; progress: 77.2%; \n",
      "FastEstimator-Train: step: 927; focal_loss: 0.0004298; l1_loss: 0.0553521; total_loss: 0.0557819; examples/sec: 31.6; progress: 77.2%; \n",
      "FastEstimator-Train: step: 928; focal_loss: 0.000279; l1_loss: 0.0247662; total_loss: 0.0250452; examples/sec: 32.5; progress: 77.3%; \n",
      "FastEstimator-Train: step: 929; focal_loss: 0.0014401; l1_loss: 0.0485534; total_loss: 0.0499935; examples/sec: 32.5; progress: 77.4%; \n",
      "[0.98321563 0.93814 0.853458047 0.067502588 0.0534072816]\n",
      "[0.989430547 0.973581672 0.973008037 ... 0.0534189939 0.0532173216 0.0518457294]\n",
      "[0.917063594 0.916684031 0.900183439 0.0563591123]\n",
      "[0.977387369 0.860965729]\n",
      "[0.99527514 0.993992448 0.992850542 ... 0.0691479445 0.0588721931 0.0524187088]\n",
      "[0.992157459 0.986960053 0.986271381 ... 0.0524743497 0.0519070327 0.0512966812]\n",
      "[0.990958 0.975279 0.957511663 ... 0.0614615381 0.0584946275 0.0566983223]\n",
      "[0.979860961 0.964340329 0.943770647 ... 0.0733684897 0.06872648 0.0504320562]\n",
      "[0.976620138 0.944416285 0.892258048]\n",
      "[0.99301362 0.992079675 0.971213698 ... 0.0574377477 0.0510655344 0.0508078337]\n",
      "[0.972596526 0.969288588 0.962140918 ... 0.0509920716 0.0508293211 0.0503118038]\n",
      "[0.977426887 0.88936162]\n",
      "[0.998579 0.993129313 0.991138697 ... 0.0650123954 0.0633744 0.0503121]\n",
      "[0.935599506 0.932853103 0.926454842 ... 0.160976261 0.13341248 0.0611925125]\n",
      "[0.983144164]\n",
      "[0.95814991 0.886326969]\n",
      "[0.988673568 0.975052118 0.967628717 ... 0.0588606894 0.0535897315 0.0503982902]\n",
      "[0.809190631 0.787488103]\n",
      "[0.957726479 0.954841077 0.934441566 ... 0.0564701855 0.0530144572 0.0508525372]\n",
      "[0.978566289 0.932031572 0.914993286 ... 0.436936557 0.347349316 0.0893016458]\n",
      "[0.976446867 0.96164012 0.891838908 0.839879036 0.817604184 0.0505076051]\n",
      "[0.852337241 0.847916126 0.834180355 0.818137884 0.768097162]\n",
      "[0.997044742 0.98788619 0.982892275 ... 0.0588283837 0.058762908 0.0585246384]\n",
      "[0.993577719 0.939868331 0.929865539 0.924441159]\n",
      "[0.991116762 0.990514338 0.886241138 ... 0.0757863522 0.0728506446 0.0549975038]\n",
      "[0.960394323 0.949410677 0.93320775 0.908535957 0.0619020164]\n",
      "[0.993959546 0.991924405 0.990804553 ... 0.0506260097 0.0501709282 0.0500927269]\n",
      "[0.868361592 0.806192875]\n",
      "[0.98123312 0.966509 0.941703081 ... 0.0640165508 0.0639680326 0.0564177334]\n",
      "[0.935528755 0.88847661 0.855901957]\n",
      "[0.930401266 0.888047814 0.881344914 ... 0.0784404576 0.0642022491 0.0545346737]\n",
      "[0.95939678 0.952050567 0.904478908 ... 0.0639138818 0.0564848781 0.0529893041]\n",
      "[0.971991658 0.931172967 0.827390194 ... 0.701584101 0.0996525 0.0804952681]\n",
      "[0.989738703 0.978854358 0.967948616 ... 0.0518885851 0.0506303906 0.050617516]\n",
      "[0.938772082 0.926162 0.915182531 ... 0.0869418681 0.0798589289 0.0731903]\n",
      "[0.969906926 0.803909242 0.236156791 0.0628148913]\n",
      "[0.978407264 0.959241807 0.944400907 ... 0.0599693954 0.0574417412 0.0515360832]\n",
      "[0.927192271]\n",
      "[0.957943916 0.954010189 0.953367949 ... 0.0565294623 0.0548045933 0.0530657172]\n",
      "[0.966576457 0.947074711 0.922586799 ... 0.0735734105 0.0700029135 0.0623775125]\n",
      "[0.938984752]\n",
      "[0.998823047 0.907259464 0.204664707]\n",
      "[0.978080869 0.976442456 0.969165206 ... 0.0568057 0.0551923215 0.0526863635]\n",
      "[0.982288 0.958170116 0.949577808 ... 0.0580880046 0.0552640855 0.0537586212]\n",
      "[0.958471656 0.945765674 0.902835 ... 0.0634728372 0.0604032278 0.0567928851]\n",
      "[0.91339922 0.896268964 0.865196288 ... 0.840157509 0.134147406 0.0832389]\n",
      "[0.973797262]\n",
      "[0.920118 0.873096704 0.837854147]\n",
      "FastEstimator-Eval: step: 930; epoch: 154; focal_loss: 0.0014209; l1_loss: 0.0244851; total_loss: 0.025906; \n",
      "FastEstimator-Train: step: 930; focal_loss: 0.0005719; l1_loss: 0.0208784; total_loss: 0.0214503; examples/sec: 32.3; progress: 77.5%; \n",
      "FastEstimator-Train: step: 931; focal_loss: 0.0003738; l1_loss: 0.0681338; total_loss: 0.0685076; examples/sec: 32.4; progress: 77.6%; \n",
      "FastEstimator-Train: step: 932; focal_loss: 0.0005769; l1_loss: 0.0479001; total_loss: 0.048477; examples/sec: 32.2; progress: 77.7%; \n",
      "FastEstimator-Train: step: 933; focal_loss: 0.0004762; l1_loss: 0.0131322; total_loss: 0.0136084; examples/sec: 32.3; progress: 77.8%; \n",
      "FastEstimator-Train: step: 934; focal_loss: 0.0004849; l1_loss: 0.0371611; total_loss: 0.037646; examples/sec: 32.2; progress: 77.8%; \n",
      "FastEstimator-Train: step: 935; focal_loss: 0.0006329; l1_loss: 0.0224771; total_loss: 0.02311; examples/sec: 32.5; progress: 77.9%; \n",
      "[0.999108076 0.995579123 0.981092095 ... 0.0688473 0.0547486246 0.0504233539]\n",
      "[0.986183107 0.943212509 0.935312092 ... 0.0555460751 0.0520707369 0.0514476895]\n",
      "[0.976740062 0.928443313 0.854622185 0.0685062706 0.0512193441]\n",
      "[0.987998068 0.973590136 0.970966578 ... 0.0534688532 0.0508838892 0.0505181849]\n",
      "[0.926383436 0.92223376 0.888343334 0.0578524172 0.0504898727]\n",
      "[0.974148631 0.865662]\n",
      "[0.995590568 0.994052768 0.99316746 ... 0.059720248 0.0584461093 0.0559165776]\n",
      "[0.993870676 0.989532292 0.98839432 ... 0.053894937 0.0505077243 0.0502751172]\n",
      "[0.98939985 0.967446804 0.94457072 ... 0.0568403 0.0534138978 0.0523357689]\n",
      "[0.981099 0.961769104 0.946204066 ... 0.0839377046 0.0607113242 0.0528957248]\n",
      "[0.974014342 0.937131286 0.871940732]\n",
      "[0.992739677 0.99113965 0.978040338 ... 0.051412344 0.0513042212 0.0511408746]\n",
      "[0.971433163 0.968378782 0.964463592 ... 0.0518373847 0.0518046916 0.0502636731]\n",
      "[0.984286785 0.920818508]\n",
      "[0.998318493 0.992778063 0.992343783 ... 0.0535787344 0.0527052 0.0501881242]\n",
      "[0.929720402 0.924209654 0.922989249 ... 0.17432636 0.129677385 0.0674039125]\n",
      "[0.98054719]\n",
      "[0.956564963 0.886475444]\n",
      "[0.986418426 0.972277403 0.961963296 ... 0.109108597 0.0552717447 0.0535951853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.816430211 0.765811086]\n",
      "[0.964180231 0.961146235 0.942639709 ... 0.0535874069 0.05302 0.0517349839]\n",
      "[0.976660609 0.93137145 0.90653193 ... 0.433971047 0.344106734 0.0759563148]\n",
      "[0.978521466 0.968624711 0.900921941 0.853558183 0.853194]\n",
      "[0.820752263 0.812842369 0.808144689 0.786672235 0.729143143]\n",
      "[0.996460617 0.986513197 0.978723884 ... 0.0612683 0.060963124 0.0595947802]\n",
      "[0.992846131 0.9399966 0.917860508 0.913852 0.0840957761]\n",
      "[0.989554644 0.988038898 0.895920873 ... 0.0691849 0.0626558661 0.0541936457]\n",
      "[0.960595369 0.949829102 0.935446262 0.900075614 0.0644493401]\n",
      "[0.993511319 0.992420733 0.989019752 ... 0.053196311 0.0512495637 0.0505553782]\n",
      "[0.876845241 0.799962759]\n",
      "[0.977295101 0.961348772 0.940017104 ... 0.0627031326 0.0609891415 0.0544193685]\n",
      "[0.93514967 0.888810158 0.860485137]\n",
      "[0.918018341 0.867808759 0.86435163 ... 0.0721326768 0.0591856837 0.0507456064]\n",
      "[0.955173314 0.946622729 0.900416493 ... 0.0570127368 0.0520332456 0.050033927]\n",
      "[0.979360104 0.944316 0.880553484 ... 0.119774848 0.107132465 0.0959459841]\n",
      "[0.989886045 0.981863797 0.96934545 ... 0.0534925759 0.053475976 0.0506516099]\n",
      "[0.922032833 0.921911597 0.914292097 ... 0.0814667046 0.0750694871 0.0666897893]\n",
      "[0.967078805 0.772287488 0.231930882 0.052667886]\n",
      "[0.980077386 0.958994508 0.940670311 ... 0.057777673 0.0565188229 0.0556836128]\n",
      "[0.933636546]\n",
      "[0.9555161 0.951881588 0.948010564 ... 0.0532742739 0.0510123968 0.0505423546]\n",
      "[0.965408742 0.942937255 0.912480831 ... 0.0735789239 0.0605767369 0.0601940155]\n",
      "[0.929405391]\n",
      "[0.998820066 0.915602684 0.184826553]\n",
      "[0.976543903 0.970466793 0.963651061 ... 0.0547378361 0.0519181192 0.0504498184]\n",
      "[0.9798733 0.964222 0.954849 ... 0.0517559052 0.0514140427 0.0504954755]\n",
      "[0.958588123 0.947775602 0.919508576 ... 0.0658978224 0.0617708862 0.0582470894]\n",
      "[0.904967785 0.886826396 0.873869538 ... 0.144854099 0.0839329958 0.0504269]\n",
      "FastEstimator-Eval: step: 936; epoch: 155; focal_loss: 0.0014666; l1_loss: 0.083492; total_loss: 0.0849586; \n",
      "FastEstimator-Train: step: 936; focal_loss: 0.0008444; l1_loss: 0.0831434; total_loss: 0.0839879; examples/sec: 31.7; progress: 78.0%; \n",
      "FastEstimator-Train: step: 937; focal_loss: 0.0003975; l1_loss: 0.0714153; total_loss: 0.0718128; examples/sec: 32.2; progress: 78.1%; \n",
      "FastEstimator-Train: step: 938; focal_loss: 0.000329; l1_loss: 0.0237788; total_loss: 0.0241079; examples/sec: 32.4; progress: 78.2%; \n",
      "FastEstimator-Train: step: 939; focal_loss: 0.0007983; l1_loss: 0.0449523; total_loss: 0.0457506; examples/sec: 31.9; progress: 78.2%; \n",
      "FastEstimator-Train: step: 940; focal_loss: 0.000513; l1_loss: 0.0385439; total_loss: 0.0390569; examples/sec: 32.3; progress: 78.3%; \n",
      "FastEstimator-Train: step: 941; focal_loss: 0.0003979; l1_loss: 0.043723; total_loss: 0.0441209; examples/sec: 32.6; progress: 78.4%; \n",
      "[0.978451908]\n",
      "[0.954721153 0.932502866 0.931240678 0.0743811131]\n",
      "[0.999221921 0.995955229 0.982995927 ... 0.0572149754 0.0525383949 0.0517809391]\n",
      "[0.993644416 0.953322053 0.945334673 ... 0.0527400374 0.0502602458 0.0501599908]\n",
      "[0.978552103 0.9348979 0.870430291 0.0931508243 0.053796351]\n",
      "[0.992948949 0.978124619 0.976457775 ... 0.0506826341 0.0501404405 0.0501030684]\n",
      "[0.959076047 0.944224834 0.937752724 0.0613569915 0.0585228503]\n",
      "[0.987357616 0.885742664]\n",
      "[0.996543825 0.995230198 0.994765162 ... 0.0778182447 0.0699258149 0.0524510145]\n",
      "[0.997391462 0.995040834 0.993030488 ... 0.0527234077 0.0511885 0.0506219566]\n",
      "[0.990420699 0.966764212 0.945252061 ... 0.0575653 0.0536867678 0.0510859191]\n",
      "[0.9869349 0.970984459 0.962534487 ... 0.120414048 0.103427529 0.0657850504]\n",
      "[0.975007355 0.954598844 0.932759762]\n",
      "[0.994125 0.992676139 0.982378244 ... 0.0545170307 0.0538516343 0.0526299775]\n",
      "[0.972996473 0.972066879 0.96834451 ... 0.0519591272 0.0506375432 0.0504536629]\n",
      "[0.993996143 0.961306095]\n",
      "[0.998470366 0.994272113 0.993900657 ... 0.0537211597 0.0524166524 0.0503407419]\n",
      "[0.94647485 0.941204965 0.940028787 ... 0.112849295 0.0845789909 0.0611468852]\n",
      "[0.988413334]\n",
      "[0.980836511 0.951167345]\n",
      "[0.989146948 0.978194952 0.975835085 ... 0.0709119737 0.0534163713 0.0533959866]\n",
      "[0.894549489 0.845197082]\n",
      "[0.974923372 0.967391372 0.960682452 ... 0.0556980968 0.0546519756 0.0523856878]\n",
      "[0.980693102 0.943401337 0.915047586 ... 0.094863981 0.0664073229 0.0525704622]\n",
      "[0.990669847 0.98721385 0.932805657 0.924662709 0.886803567 0.0599741638]\n",
      "[0.909080148 0.905641735 0.899143457 0.87473917 0.847852588]\n",
      "[0.997349918 0.988890231 0.979545295 ... 0.0587456822 0.0573009849 0.0569751859]\n",
      "[0.99491179 0.96324873 0.958414316 0.951873243]\n",
      "[0.990127265 0.988692403 0.901573837 ... 0.0662896931 0.0622063577 0.0554213524]\n",
      "[0.962556243 0.955018 0.941350102 0.935790777 0.0728928447]\n",
      "[0.995589674 0.993840337 0.991097331 ... 0.0504883826 0.0504776239 0.0500118732]\n",
      "[0.918753862 0.893345177 0.0545695722]\n",
      "[0.983050883 0.969176173 0.950118065 ... 0.0674804747 0.0579421222 0.0564410388]\n",
      "[0.960754871 0.929903269 0.8875494]\n",
      "[0.924604714 0.880828261 0.877032042 ... 0.058256 0.0570405424 0.0558234453]\n",
      "[0.967520595 0.958140492 0.944898248 ... 0.0572682321 0.050588578 0.0500028133]\n",
      "[0.988182187 0.976462066 0.933221102 ... 0.89051342 0.162980825 0.135693192]\n",
      "[0.992024 0.98542577 0.971680641 ... 0.0515509844 0.0511631966 0.0507861972]\n",
      "[0.93043977 0.923044562 0.918028235 ... 0.0804240704 0.0743823349 0.0637367368]\n",
      "[0.98267889 0.828288794 0.292454422 0.0656009912]\n",
      "[0.984005511 0.968167663 0.949554563 ... 0.0593195856 0.0558841228 0.0526625216]\n",
      "[0.980597377]\n",
      "[0.962100148 0.961757779 0.954907238 ... 0.0564714372 0.0552692115 0.0515302122]\n",
      "[0.96838516 0.949324489 0.934536338 ... 0.0761485696 0.0695549548 0.0529537201]\n",
      "[0.949137568]\n",
      "[0.999583364 0.939647317 0.218988568]\n",
      "[0.981276631 0.974228263 0.969109118 ... 0.0565471053 0.0562163293 0.0509371758]\n",
      "[0.986037731 0.970114112 0.963118076 ... 0.0655579865 0.060464263 0.0551459193]\n",
      "FastEstimator-Eval: step: 942; epoch: 156; focal_loss: 0.0009819; l1_loss: 0.0487135; total_loss: 0.0496954; \n",
      "FastEstimator-Train: step: 942; focal_loss: 0.0007924; l1_loss: 0.0302928; total_loss: 0.0310853; examples/sec: 32.2; progress: 78.5%; \n",
      "FastEstimator-Train: step: 943; focal_loss: 0.0002072; l1_loss: 0.0630802; total_loss: 0.0632874; examples/sec: 32.4; progress: 78.6%; \n",
      "FastEstimator-Train: step: 944; focal_loss: 0.0003749; l1_loss: 0.042305; total_loss: 0.0426799; examples/sec: 32.3; progress: 78.7%; \n",
      "FastEstimator-Train: step: 945; focal_loss: 0.0005117; l1_loss: 0.0888161; total_loss: 0.0893278; examples/sec: 32.3; progress: 78.8%; \n",
      "FastEstimator-Train: step: 946; focal_loss: 0.0006522; l1_loss: 0.0517674; total_loss: 0.0524195; examples/sec: 32.3; progress: 78.8%; \n",
      "FastEstimator-Train: step: 947; focal_loss: 0.0008127; l1_loss: 0.0617886; total_loss: 0.0626013; examples/sec: 32.5; progress: 78.9%; \n",
      "[0.955732822 0.952758789 0.942774773 ... 0.0614003241 0.0560171 0.05159235]\n",
      "[0.924022555 0.902288914 0.898124337 ... 0.0530664921 0.0510909259 0.0503134429]\n",
      "[0.964398682]\n",
      "[0.928902745 0.86356777 0.859427]\n",
      "[0.999171853 0.995830417 0.979417562 ... 0.105105639 0.0699884 0.0677565932]\n",
      "[0.98699522 0.952968717 0.936119795 ... 0.0556595325 0.0540784299 0.0533346236]\n",
      "[0.980767429 0.939969182 0.861802816 0.0572477]\n",
      "[0.989329 0.979270458 0.974112689 ... 0.0533470511 0.05214867 0.0511723459]\n",
      "[0.927780628 0.927491426 0.896202624 0.0605414808]\n",
      "[0.976634145 0.861649156]\n",
      "[0.994375467 0.994351923 0.991313159 ... 0.771800578 0.361927718 0.0643889308]\n",
      "[0.99501 0.991780818 0.990419507 ... 0.0539371371 0.0516049862 0.0506638885]\n",
      "[0.992079377 0.970474 0.948542 ... 0.0679315627 0.0652247667 0.0561332107]\n",
      "[0.97915709 0.955133915 0.940714 ... 0.0736391246 0.0647875369 0.0609181225]\n",
      "[0.975793839 0.948595166 0.886248767]\n",
      "[0.988316774 0.988222659 0.981426954 ... 0.0533416569 0.0517936647 0.0501116216]\n",
      "[0.962849617 0.96105206 0.960369945 ... 0.0556672513 0.053678453 0.0514660776]\n",
      "[0.988630772 0.942905784]\n",
      "[0.997870684 0.99344492 0.990634918 ... 0.0559643507 0.0535074472 0.0513754189]\n",
      "[0.928024232 0.926229715 0.92555964 ... 0.748119295 0.251473427 0.143229663]\n",
      "[0.972927928]\n",
      "[0.955603361 0.901439667]\n",
      "[0.985777378 0.975942552 0.963698208 ... 0.267554015 0.101555705 0.0561216176]\n",
      "[0.828394771 0.7716012]\n",
      "[0.97036624 0.969123602 0.940046549 ... 0.0560832918 0.05081743 0.0500667393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.980029345 0.949716 0.919297218 ... 0.449196786 0.396700591 0.0773110688]\n",
      "[0.97876358 0.972199917 0.90846777 0.867001295 0.861978769]\n",
      "[0.891652 0.872557402 0.869345427 0.849787 0.847208261]\n",
      "[0.997444093 0.986020803 0.970826149 ... 0.0599572957 0.0594287813 0.058716923]\n",
      "[0.992760718 0.943412423 0.907202899 0.8962304 0.0908973813]\n",
      "[0.992568374 0.991239667 0.891717672 ... 0.066228 0.0647281408 0.0540353954]\n",
      "[0.940707147 0.937490821 0.922140658 0.858680606 0.0687733293 0.055297792]\n",
      "[0.995448351 0.993905783 0.99190259 ... 0.0504125953 0.0502918959 0.0501615703]\n",
      "[0.891245604 0.818029881]\n",
      "[0.975187182 0.957164645 0.937841654 ... 0.0711938739 0.0571653545 0.0505075157]\n",
      "[0.896031797 0.828553438 0.820901394]\n",
      "[0.9232 0.875717163 0.871485233 ... 0.155656844 0.0583992898 0.0572593212]\n",
      "[0.95199883 0.951859236 0.916822195 ... 0.0636319518 0.0611003935 0.0566411316]\n",
      "[0.972578526 0.929459 0.872691274 ... 0.771763921 0.111585796 0.106024534]\n",
      "[0.990640461 0.981754 0.97166121 ... 0.0525617599 0.0514724851 0.0510952473]\n",
      "[0.937421262 0.935370684 0.930987477 ... 0.0668850541 0.0629462302 0.0614074469]\n",
      "[0.963190436 0.780616283 0.245431185 0.0504048169]\n",
      "[0.982596517 0.965405703 0.944649816 ... 0.370849341 0.0662736297 0.0535620451]\n",
      "[0.954355]\n",
      "[0.962953329 0.953058362 0.951880634 ... 0.0561907887 0.0526698232 0.0500929952]\n",
      "[0.971027076 0.950377524 0.926727891 ... 0.060346216 0.0520369411 0.0512647629]\n",
      "[0.906701088]\n",
      "[0.997522116 0.894747555 0.208944201]\n",
      "FastEstimator-Eval: step: 948; epoch: 157; focal_loss: 0.0013086; l1_loss: 0.1099767; total_loss: 0.1112853; \n",
      "FastEstimator-Train: step: 948; focal_loss: 0.0003654; l1_loss: 0.0863138; total_loss: 0.0866793; examples/sec: 32.2; progress: 79.0%; \n",
      "FastEstimator-Train: step: 949; focal_loss: 0.0006971; l1_loss: 0.0963979; total_loss: 0.097095; examples/sec: 32.3; progress: 79.1%; \n",
      "FastEstimator-Train: step: 950; focal_loss: 0.0004971; l1_loss: 0.0526916; total_loss: 0.0531887; examples/sec: 32.2; progress: 79.2%; \n",
      "FastEstimator-Train: step: 951; focal_loss: 0.0002772; l1_loss: 0.0380393; total_loss: 0.0383165; examples/sec: 32.2; progress: 79.2%; \n",
      "FastEstimator-Train: step: 952; focal_loss: 0.0004099; l1_loss: 0.0319053; total_loss: 0.0323152; examples/sec: 32.3; progress: 79.3%; \n",
      "FastEstimator-Train: step: 953; focal_loss: 0.0004059; l1_loss: 0.0940162; total_loss: 0.0944221; examples/sec: 32.4; progress: 79.4%; \n",
      "[0.983851433 0.979863167 0.979284406 ... 0.0556446612 0.0530367494 0.0510377288]\n",
      "[0.98791045 0.976597428 0.967301488 ... 0.0604384243 0.0564876795 0.0508399]\n",
      "[0.967991829 0.959562361 0.951522708 ... 0.0598494112 0.054638207 0.052829653]\n",
      "[0.944914699 0.922366381 0.911383271 ... 0.0873723328 0.067507 0.0597514212]\n",
      "[0.972887874]\n",
      "[0.92907095 0.927177548 0.908554792 0.0648466945]\n",
      "[0.999469578 0.9967978 0.979282498 ... 0.0829609 0.0573038459 0.0530855358]\n",
      "[0.991045356 0.955881536 0.939576626 ... 0.0552964509 0.0547769666 0.0516492426]\n",
      "[0.986550212 0.96208 0.875478148 0.0549509823]\n",
      "[0.993939877 0.981768727 0.980613053 ... 0.0519622564 0.0515773594 0.0511204302]\n",
      "[0.954949379 0.951277733 0.931860566 0.0617479682 0.0550264716]\n",
      "[0.990410209 0.88808012]\n",
      "[0.994761527 0.993664742 0.991282463 ... 0.0806631744 0.069591552 0.0693517625]\n",
      "[0.992155135 0.990527868 0.988609314 ... 0.0548030436 0.0546644926 0.0546266139]\n",
      "[0.994190156 0.979516208 0.962182879 ... 0.0632604659 0.0612384081 0.0543884933]\n",
      "[0.979713798 0.96242857 0.948395967 ... 0.103077531 0.0775200725 0.071760118]\n",
      "[0.979695082 0.959351182 0.935648918]\n",
      "[0.990909219 0.989353776 0.9800843 ... 0.059209168 0.0556062162 0.0510439575]\n",
      "[0.979222417 0.97488445 0.964990258 ... 0.0523395538 0.0506271124 0.0500944555]\n",
      "[0.992761075 0.95627439]\n",
      "[0.997597218 0.995722651 0.990452766 ... 0.0554182529 0.0545626283 0.050144583]\n",
      "[0.942606449 0.935845733 0.934979796 ... 0.0866259038 0.0772486925 0.0509084165]\n",
      "[0.988988]\n",
      "[0.978929758 0.94282645]\n",
      "[0.991105 0.976658523 0.974613786 ... 0.0642941 0.0627591312 0.0550814569]\n",
      "[0.928542733 0.910256565]\n",
      "[0.974168539 0.966866374 0.930870116 ... 0.0656713545 0.0629306138 0.0592366755]\n",
      "[0.982851386 0.954970121 0.929449 ... 0.128018856 0.0570867062 0.0513554513]\n",
      "[0.989130497 0.984908104 0.925114632 0.919436097 0.862414837]\n",
      "[0.942582 0.941147 0.938628614 0.924329698 0.899472237]\n",
      "[0.997821867 0.990480542 0.979412436 ... 0.0543028414 0.054249078 0.0533079803]\n",
      "[0.993029237 0.95942241 0.95637548 0.939565301 0.0713798106]\n",
      "[0.994307041 0.992472112 0.895300746 ... 0.0598740876 0.0552476346 0.054864198]\n",
      "[0.936306119 0.934129596 0.909740329 0.870901 0.0562931299 0.052922368]\n",
      "[0.995092452 0.994756341 0.99247992 ... 0.0535284281 0.0525921285 0.0519553125]\n",
      "[0.935950875 0.913984716 0.0635145903]\n",
      "[0.983086348 0.970055 0.942125559 ... 0.0731546581 0.0614881814 0.0580298]\n",
      "[0.905587733 0.845971465 0.812229633]\n",
      "[0.94194454 0.905481458 0.889035046 ... 0.0643536747 0.0627521 0.0613103211]\n",
      "[0.967979 0.962037086 0.944622219 ... 0.0717961192 0.0715638697 0.0611806512]\n",
      "[0.963841617 0.953289509 0.906124055 ... 0.808843374 0.123692721 0.0659911931]\n",
      "[0.9877702 0.980108738 0.973433256 ... 0.0544135869 0.0537744462 0.0520866513]\n",
      "[0.958424866 0.95410347 0.9451859 ... 0.074404 0.0660364628 0.0602132082]\n",
      "[0.978976 0.878726959 0.285959899 0.0867089629]\n",
      "[0.983654737 0.962552309 0.946309924 ... 0.0591222346 0.0538941026 0.0536576807]\n",
      "[0.94354]\n",
      "[0.96701324 0.952491879 0.948328853 ... 0.0576397479 0.0573942363 0.052945137]\n",
      "[0.972780943 0.959558249 0.944872618 ... 0.072293967 0.0576210618 0.051074028]\n",
      "FastEstimator-Eval: step: 954; epoch: 158; focal_loss: 0.0010581; l1_loss: 0.0447329; total_loss: 0.045791; \n",
      "FastEstimator-Train: step: 954; focal_loss: 0.0010707; l1_loss: 0.053842; total_loss: 0.0549128; examples/sec: 32.2; progress: 79.5%; \n",
      "FastEstimator-Train: step: 955; focal_loss: 0.0005324; l1_loss: 0.0464336; total_loss: 0.046966; examples/sec: 32.2; progress: 79.6%; \n",
      "FastEstimator-Train: step: 956; focal_loss: 0.0005145; l1_loss: 0.1131121; total_loss: 0.1136266; examples/sec: 32.4; progress: 79.7%; \n",
      "FastEstimator-Train: step: 957; focal_loss: 0.000233; l1_loss: 0.0261744; total_loss: 0.0264074; examples/sec: 32.3; progress: 79.8%; \n",
      "FastEstimator-Train: step: 958; focal_loss: 0.0004351; l1_loss: 0.0529991; total_loss: 0.0534342; examples/sec: 32.3; progress: 79.8%; \n",
      "FastEstimator-Train: step: 959; focal_loss: 0.0004479; l1_loss: 0.083272; total_loss: 0.0837199; examples/sec: 32.4; progress: 79.9%; \n",
      "[0.959195256]\n",
      "[0.998467207 0.901578 0.206872851]\n",
      "[0.981076896 0.980872512 0.979557455 ... 0.0574425161 0.0560810864 0.0526145399]\n",
      "[0.986300826 0.975955 0.970671475 ... 0.0588683188 0.0578414202 0.0575071871]\n",
      "[0.960792184 0.951409161 0.916063428 ... 0.0810599923 0.0664353371 0.0588189363]\n",
      "[0.924497128 0.918970823 0.890566647 ... 0.165365338 0.0690805316 0.0569947064]\n",
      "[0.978621244]\n",
      "[0.921656609 0.861028075 0.830957294]\n",
      "[0.999370575 0.996854305 0.983815789 ... 0.0749719441 0.0650718808 0.0569662154]\n",
      "[0.991192281 0.958309889 0.926326871 ... 0.0578028858 0.0572190881 0.0540772378]\n",
      "[0.979278326 0.970310092 0.891364336 0.0552182794]\n",
      "[0.99122858 0.984249 0.981544733 ... 0.0557352602 0.0531094372 0.0504208803]\n",
      "[0.923211813 0.922485709 0.916478753 0.0576138198]\n",
      "[0.987194419 0.889485955]\n",
      "[0.995277703 0.993926048 0.990592241 ... 0.0633760095 0.0608886778 0.0507377684]\n",
      "[0.993648767 0.991630495 0.99046123 ... 0.0531555414 0.0522032082 0.0501958132]\n",
      "[0.994522154 0.981648445 0.96543777 ... 0.0531025231 0.0525338054 0.052521497]\n",
      "[0.986816406 0.973007 0.959570706 ... 0.0821777582 0.0645376444 0.0512375236]\n",
      "[0.977181673 0.945288956 0.880453944]\n",
      "[0.98991251 0.989544392 0.982842088 ... 0.053068161 0.0525591373 0.050762713]\n",
      "[0.975870609 0.974028468 0.964506805 ... 0.0518586636 0.0515628159 0.0502248406]\n",
      "[0.985763669 0.931763351]\n",
      "[0.998315692 0.994135261 0.990696192 ... 0.0521558821 0.0521301627 0.0518039465]\n",
      "[0.937514842 0.936974645 0.933588445 ... 0.188696712 0.153865188 0.0570420921]\n",
      "[0.978736043]\n",
      "[0.973999739 0.930329204]\n",
      "[0.990843594 0.975728154 0.96549964 ... 0.0569327772 0.0538268685 0.0501559079]\n",
      "[0.918341339 0.881051779]\n",
      "[0.970153928 0.966283381 0.939645767 ... 0.0606075525 0.0532173812 0.0504142344]\n",
      "[0.983890414 0.959219217 0.934371054 ... 0.432374537 0.0888643 0.0504433513]\n",
      "[0.98258853 0.974426508 0.917409062 0.873199046 0.858343 0.0581385493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.937135816 0.932798445 0.931853771 0.908491373 0.907819092]\n",
      "[0.997946918 0.989834428 0.987761617 ... 0.0614237189 0.0567100644 0.0565746129]\n",
      "[0.993097782 0.946521521 0.932652771 0.9314906 0.0721493363]\n",
      "[0.991121888 0.990930319 0.920196235 ... 0.0742862225 0.0664850771 0.0644314]\n",
      "[0.950694442 0.947881222 0.927879 0.877893567 0.0538193882 0.0513020158]\n",
      "[0.995110035 0.994844198 0.992538154 ... 0.0517925918 0.0513912737 0.0510068238]\n",
      "[0.920451283 0.856397212 0.0512179434]\n",
      "[0.981122077 0.973933697 0.947257757 ... 0.0577824116 0.0551607907 0.0500663221]\n",
      "[0.890592456 0.821444631 0.820183277]\n",
      "[0.938385844 0.90528667 0.887911558 ... 0.0679930747 0.0608599782 0.0539661944]\n",
      "[0.96161747 0.94772613 0.943173528 ... 0.0637236834 0.0609933436 0.0530236065]\n",
      "[0.97603178 0.942931414 0.886331916 ... 0.114480346 0.107264489 0.0828826427]\n",
      "[0.989503145 0.9827407 0.973493218 ... 0.0524298549 0.0505481958 0.0504063666]\n",
      "[0.946013 0.933565259 0.931873858 ... 0.09673208 0.0574520528 0.0564605]\n",
      "[0.972046375 0.838743091 0.238538444 0.0710068345]\n",
      "[0.981310368 0.958248615 0.950453341 ... 0.0578452647 0.0544174314 0.0511609316]\n",
      "[0.921734333]\n",
      "FastEstimator-Eval: step: 960; epoch: 159; focal_loss: 0.0010349; l1_loss: 0.0943733; total_loss: 0.0954083; \n",
      "FastEstimator-Train: step: 960; focal_loss: 0.0007953; l1_loss: 0.0574778; total_loss: 0.0582731; examples/sec: 31.9; progress: 80.0%; \n",
      "FastEstimator-Train: step: 961; focal_loss: 0.0003354; l1_loss: 0.0415542; total_loss: 0.0418896; examples/sec: 32.3; progress: 80.1%; \n",
      "FastEstimator-Train: step: 962; focal_loss: 0.0003223; l1_loss: 0.0689118; total_loss: 0.0692341; examples/sec: 32.2; progress: 80.2%; \n",
      "FastEstimator-Train: step: 963; focal_loss: 0.0002632; l1_loss: 0.0655377; total_loss: 0.0658009; examples/sec: 31.8; progress: 80.2%; \n",
      "FastEstimator-Train: step: 964; focal_loss: 0.0018909; l1_loss: 0.0867746; total_loss: 0.0886655; examples/sec: 31.7; progress: 80.3%; \n",
      "FastEstimator-Train: step: 965; focal_loss: 0.0003932; l1_loss: 0.0535906; total_loss: 0.0539838; examples/sec: 32.1; progress: 80.4%; \n",
      "[0.972163856 0.961298466 0.958026886 ... 0.0552051663 0.0507281721 0.0505867]\n",
      "[0.950032473 0.927782655 0.883122683 ... 0.525163949 0.0830876529 0.0552784503]\n",
      "[0.966829]\n",
      "[0.999175727 0.924248874 0.231824547]\n",
      "[0.985045433 0.980920613 0.977365732 ... 0.0575630367 0.0539490283 0.0508142412]\n",
      "[0.990628541 0.980316639 0.979101658 ... 0.0576035678 0.0518717766 0.0503400564]\n",
      "[0.966721773 0.962558031 0.94255513 ... 0.0869683921 0.0817716718 0.059994787]\n",
      "[0.9374547 0.926471829 0.921616197 ... 0.0620892346 0.0584490895 0.054754436]\n",
      "[0.976862907]\n",
      "[0.932415724 0.875041962 0.858095765]\n",
      "[0.99936837 0.996556163 0.988583207 ... 0.107752204 0.080380857 0.0540283322]\n",
      "[0.99568522 0.960644 0.93964 ... 0.0531392097 0.0530692637 0.0503594875]\n",
      "[0.97744596 0.973022223 0.902701199 0.0585168898]\n",
      "[0.993995547 0.986347795 0.980438352 ... 0.0550004542 0.0548898578 0.0523458123]\n",
      "[0.957144737 0.940272 0.936577082 0.0551075041]\n",
      "[0.991981626 0.913324654]\n",
      "[0.996450067 0.995822191 0.992829859 ... 0.075194329 0.0534586906 0.0529218]\n",
      "[0.996512651 0.993948579 0.993524134 ... 0.0550409853 0.0540330112 0.0519925356]\n",
      "[0.994796634 0.979524493 0.961945474 ... 0.0570650697 0.0567440689 0.0542711914]\n",
      "[0.992939234 0.985147834 0.977876365 ... 0.0718984 0.0629239678 0.0512081981]\n",
      "[0.978316903 0.958068371 0.918953419]\n",
      "[0.993188143 0.991901517 0.986767292 ... 0.0539142489 0.0536893308 0.0523439348]\n",
      "[0.978248239 0.977187634 0.968510211 ... 0.0522696674 0.0513533056 0.0503358841]\n",
      "[0.991835117 0.955115318]\n",
      "[0.998814106 0.994181752 0.993646145 ... 0.0518283844 0.0513008535 0.0504015684]\n",
      "[0.949905038 0.947320223 0.939200878 ... 0.123836249 0.0819456 0.0537117422]\n",
      "[0.982743204]\n",
      "[0.982652307 0.957116127]\n",
      "[0.992479384 0.981746614 0.977526784 ... 0.0586186945 0.0557467043 0.0545030534]\n",
      "[0.936940312 0.890819252]\n",
      "[0.973603725 0.969626784 0.957901299 ... 0.0526370406 0.0524762869 0.0514265895]\n",
      "[0.987926245 0.97076416 0.952392101 ... 0.486686409 0.102178186 0.0752768219]\n",
      "[0.986393 0.981898189 0.927367806 ... 0.883503675 0.0521365106 0.050943166]\n",
      "[0.961091757 0.958663106 0.954172134 0.941110492 0.933126092]\n",
      "[0.998769283 0.993138433 0.991346717 ... 0.0563536584 0.054913044 0.0546258688]\n",
      "[0.9960953 0.962011814 0.961925626 0.959418476]\n",
      "[0.991743922 0.990733862 0.933121443 ... 0.0565692782 0.0535650551 0.0518860519]\n",
      "[0.9720788 0.958772779 0.941285372 0.920476675 0.058857739]\n",
      "[0.997227 0.994709849 0.994404554 ... 0.0522528 0.0519804358 0.0518339574]\n",
      "[0.946535408 0.888453066]\n",
      "[0.988020241 0.983450711 0.964033604 ... 0.0550291538 0.0505812764 0.0500957966]\n",
      "[0.904230714 0.847938061 0.847599685]\n",
      "[0.957448125 0.927601695 0.904711068 ... 0.0540601313 0.0531105399 0.0507461131]\n",
      "[0.964387 0.958102226 0.936123848 ... 0.0777154565 0.0763498545 0.0715272427]\n",
      "[0.988329053 0.968916297 0.921274841 ... 0.865218639 0.144968212 0.13450262]\n",
      "[0.993942797 0.988438845 0.976094306 ... 0.0551529825 0.0522280037 0.0506740808]\n",
      "[0.965348482 0.952036142 0.949420035 ... 0.0925255418 0.0549162924 0.0504266024]\n",
      "[0.983828902 0.861512423 0.27170366 0.0823306739]\n",
      "FastEstimator-Eval: step: 966; epoch: 160; focal_loss: 0.0007528; l1_loss: 0.0462203; total_loss: 0.0469732; \n",
      "FastEstimator-Train: step: 966; focal_loss: 0.0003023; l1_loss: 0.0653733; total_loss: 0.0656756; examples/sec: 32.3; progress: 80.5%; \n",
      "FastEstimator-Train: step: 967; focal_loss: 0.0005281; l1_loss: 0.0449619; total_loss: 0.04549; examples/sec: 32.0; progress: 80.6%; \n",
      "FastEstimator-Train: step: 968; focal_loss: 0.0004621; l1_loss: 0.0311459; total_loss: 0.0316079; examples/sec: 32.3; progress: 80.7%; \n",
      "FastEstimator-Train: step: 969; focal_loss: 0.0003095; l1_loss: 0.0441056; total_loss: 0.0444151; examples/sec: 32.2; progress: 80.8%; \n",
      "FastEstimator-Train: step: 970; focal_loss: 0.0004885; l1_loss: 0.031044; total_loss: 0.0315325; examples/sec: 31.9; progress: 80.8%; \n",
      "FastEstimator-Train: step: 971; focal_loss: 0.0002405; l1_loss: 0.0399726; total_loss: 0.0402131; examples/sec: 32.4; progress: 80.9%; \n",
      "[0.985325396 0.962217 0.952320933 ... 0.415465 0.0586057901 0.052083075]\n",
      "[0.940747857]\n",
      "[0.967133522 0.959508777 0.948355556 ... 0.0584358275 0.0566209555 0.0517568588]\n",
      "[0.948973894 0.91835773 0.899892688 ... 0.511238 0.0667180419 0.0550942123]\n",
      "[0.960510731]\n",
      "[0.99848485 0.911572278 0.161325961]\n",
      "[0.984708905 0.978357673 0.977339 ... 0.057982862 0.0576125979 0.0504061878]\n",
      "[0.986792326 0.982794762 0.974291086 ... 0.0614322126 0.052226603 0.0508205295]\n",
      "[0.966578 0.961102486 0.954314709 ... 0.0634048 0.0574352741 0.0571092665]\n",
      "[0.927903116 0.917083144 0.911771536 ... 0.0672498643 0.0614141822 0.0554903746]\n",
      "[0.971674621]\n",
      "[0.936703205 0.883503675 0.87387836]\n",
      "[0.999370158 0.996714473 0.987211823 ... 0.0790144205 0.0770698488 0.0539093614]\n",
      "[0.990835071 0.961200356 0.936107516 ... 0.0510206223 0.0504539 0.0503986776]\n",
      "[0.98126936 0.969343305 0.892734528 0.0556768775]\n",
      "[0.991363049 0.984405 0.976832688 ... 0.0534791052 0.051649034 0.0502460301]\n",
      "[0.945002556 0.939099073 0.901061654 0.056432724]\n",
      "[0.982370615 0.883089781]\n",
      "[0.995913625 0.995506167 0.992210627 ... 0.0594849 0.057710439 0.0542937815]\n",
      "[0.993022561 0.991588116 0.987790346 ... 0.0552398562 0.055214107 0.0517141223]\n",
      "[0.992070258 0.963358343 0.931603193 ... 0.0552217662 0.0548737943 0.0526088774]\n",
      "[0.991932511 0.98383081 0.977801323 ... 0.0598180294 0.0539420247 0.0507469177]\n",
      "[0.980156422 0.944642603 0.874650359]\n",
      "[0.989654899 0.988864899 0.985497952 ... 0.0565627813 0.052654326 0.0507171452]\n",
      "[0.975647926 0.971768618 0.970943153 ... 0.0517053902 0.0507582426 0.0503563583]\n",
      "[0.993061781 0.960612893]\n",
      "[0.998071432 0.993956685 0.992421031 ... 0.0836351216 0.0659584105 0.0551544726]\n",
      "[0.951734722 0.945556581 0.943057656 ... 0.198761433 0.146432012 0.0574534535]\n",
      "[0.978790522]\n",
      "[0.971990108 0.921758533]\n",
      "[0.988540709 0.978115439 0.961144209 ... 0.0716341138 0.0571682453 0.0548027158]\n",
      "[0.935290635 0.862098098]\n",
      "[0.973397076 0.973020434 0.953089476 ... 0.0621947348 0.0564692914 0.0564147234]\n",
      "[0.982396722 0.960684121 0.956562519 ... 0.49324137 0.419585705 0.073348105]\n",
      "[0.98654747 0.984482825 0.927354217 0.924912512 0.884645164]\n",
      "[0.910579264 0.901214719 0.895293355 0.88216722 0.839020431]\n",
      "[0.998045146 0.987799406 0.982893109 ... 0.0523028076 0.0512301624 0.0506652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.996904135 0.960899949 0.95716095 0.942347527]\n",
      "[0.993842244 0.993228436 0.937894702 ... 0.0517613 0.0503233075 0.050265789]\n",
      "[0.973918378 0.959869146 0.937526226 0.898635745 0.0592221618]\n",
      "[0.997356653 0.994035304 0.992372572 ... 0.0512903631 0.0506452918 0.0503663123]\n",
      "[0.940405488 0.86832428]\n",
      "[0.982095838 0.981964707 0.960575 ... 0.0572196543 0.0542551577 0.0510094166]\n",
      "[0.862799108 0.827291965 0.808608055]\n",
      "[0.951067626 0.92469275 0.917409062 ... 0.060944885 0.0555166602 0.0516949892]\n",
      "[0.950114489 0.938418925 0.936762452 ... 0.0778161883 0.0612257421 0.0536166728]\n",
      "[0.992162466 0.978321075 0.936132133 ... 0.895850301 0.16355744 0.153845042]\n",
      "[0.993904829 0.987887621 0.979735672 ... 0.0555112064 0.054056406 0.052546382]\n",
      "FastEstimator-Eval: step: 972; epoch: 161; focal_loss: 0.0008599; l1_loss: 0.0647693; total_loss: 0.0656292; \n",
      "FastEstimator-Train: step: 972; focal_loss: 0.000311; l1_loss: 0.0500548; total_loss: 0.0503658; examples/sec: 32.4; progress: 81.0%; \n",
      "FastEstimator-Train: step: 973; focal_loss: 0.0005149; l1_loss: 0.0574557; total_loss: 0.0579706; examples/sec: 32.6; progress: 81.1%; \n",
      "FastEstimator-Train: step: 974; focal_loss: 0.0002902; l1_loss: 0.0351061; total_loss: 0.0353963; examples/sec: 32.3; progress: 81.2%; \n",
      "FastEstimator-Train: step: 975; focal_loss: 0.0004946; l1_loss: 0.0330684; total_loss: 0.033563; examples/sec: 32.4; progress: 81.2%; \n",
      "FastEstimator-Train: step: 976; focal_loss: 0.0003972; l1_loss: 0.0437461; total_loss: 0.0441433; examples/sec: 32.1; progress: 81.3%; \n",
      "FastEstimator-Train: step: 977; focal_loss: 0.0001886; l1_loss: 0.0492629; total_loss: 0.0494515; examples/sec: 32.0; progress: 81.4%; \n",
      "[0.975142956 0.970216036 0.968503237 ... 0.116494596 0.0996403694 0.061794132]\n",
      "[0.975576222 0.811189234 0.222756177 0.0637256205]\n",
      "[0.987427652 0.970747888 0.956437647 ... 0.0597400963 0.0529561341 0.0526458323]\n",
      "[0.948440194]\n",
      "[0.972705483 0.970894217 0.955787182 ... 0.0527660847 0.052708298 0.0510673821]\n",
      "[0.96293056 0.952436864 0.951507092 ... 0.059786588 0.0574343503 0.055427283]\n",
      "[0.943807721]\n",
      "[0.999134421 0.925058246 0.169416219]\n",
      "[0.98549813 0.985171556 0.982533813 ... 0.0587488115 0.0534965694 0.0500336587]\n",
      "[0.990234077 0.98414731 0.975513756 ... 0.0516723394 0.0506155789 0.0504337847]\n",
      "[0.967147112 0.965248704 0.962830365 ... 0.0643622577 0.0638630092 0.0569335222]\n",
      "[0.927097678 0.917625606 0.913254738 ... 0.183556974 0.0882203281 0.063148886]\n",
      "[0.971396327]\n",
      "[0.961479425 0.930383086 0.926358223 0.0805916488]\n",
      "[0.999635577 0.997873664 0.991684437 ... 0.0812912583 0.0741483 0.0585414767]\n",
      "[0.995568633 0.970317483 0.957333326 ... 0.051166743 0.051047653 0.0501264036]\n",
      "[0.987815738 0.97031033 0.905292511 0.055198282]\n",
      "[0.993941307 0.986756563 0.986465454 ... 0.0532139242 0.0512872934 0.0505099893]\n",
      "[0.960986853 0.943703473 0.929569364 0.0593254566]\n",
      "[0.985105038 0.876651227]\n",
      "[0.996784449 0.996410489 0.994386613 ... 0.0609473 0.0580187142 0.0539510846]\n",
      "[0.99242568 0.992212772 0.986318231 ... 0.0511790216 0.0501569808 0.0500906706]\n",
      "[0.991983771 0.957990408 0.927969575 ... 0.0618174076 0.0589263439 0.054769814]\n",
      "[0.994252324 0.988578677 0.98403877 ... 0.0578758121 0.0574216843 0.0534424186]\n",
      "[0.983431101 0.95457685 0.869758129]\n",
      "[0.991645813 0.991498947 0.986906 ... 0.0571372211 0.0519265831 0.0507621765]\n",
      "[0.978390694 0.976412833 0.973895 ... 0.0515105724 0.0509849787 0.0500814617]\n",
      "[0.996423 0.976278603]\n",
      "[0.998278737 0.995781779 0.995133519 ... 0.0524657071 0.0510531366 0.0506235361]\n",
      "[0.96020627 0.955915332 0.954333544 ... 0.227762222 0.153689027 0.0679567158]\n",
      "[0.982604682]\n",
      "[0.982830286 0.946262062]\n",
      "[0.989265 0.981956 0.973210573 ... 0.0610979199 0.0586714447 0.0513048768]\n",
      "[0.945324779 0.900797725]\n",
      "[0.982380748 0.980659604 0.961057901 ... 0.0589285791 0.0579741 0.0510621369]\n",
      "[0.983648062 0.964769125 0.956545413 ... 0.403112531 0.0873993337 0.0779174864]\n",
      "[0.99184072 0.990922213 0.949657559 0.941295564 0.906423569]\n",
      "[0.935254693 0.930359 0.929847121 0.911116362 0.8907125]\n",
      "[0.99856329 0.98826158 0.973833084 ... 0.0510586798 0.0507199168 0.050283134]\n",
      "[0.997772217 0.976269126 0.968394756 0.966418147]\n",
      "[0.996023595 0.995989919 0.940138936 ... 0.0568068027 0.0552611947 0.0529060066]\n",
      "[0.976993859 0.95891583 0.945098042 0.918273687 0.0602461696]\n",
      "[0.998137236 0.995488882 0.994333744 ... 0.0545046628 0.054017216 0.0521899462]\n",
      "[0.941816 0.89076674]\n",
      "[0.987949967 0.986189246 0.96605891 ... 0.0564489663 0.0549361706 0.0511696935]\n",
      "[0.89378047 0.874000251 0.859067559]\n",
      "[0.944377899 0.923432 0.908350587 ... 0.0612747371 0.0533325672 0.0521615148]\n",
      "[0.958763897 0.944895744 0.941896677 ... 0.053889811 0.05384022 0.0531230271]\n",
      "FastEstimator-Eval: step: 978; epoch: 162; focal_loss: 0.000678; l1_loss: 0.0278893; total_loss: 0.0285673; \n",
      "FastEstimator-Train: step: 978; focal_loss: 0.0005063; l1_loss: 0.0404963; total_loss: 0.0410026; examples/sec: 32.3; progress: 81.5%; \n",
      "FastEstimator-Train: step: 979; focal_loss: 0.0010322; l1_loss: 0.0353872; total_loss: 0.0364194; examples/sec: 32.2; progress: 81.6%; \n",
      "FastEstimator-Train: step: 980; focal_loss: 0.0004653; l1_loss: 0.0252846; total_loss: 0.0257499; examples/sec: 32.2; progress: 81.7%; \n",
      "FastEstimator-Train: step: 981; focal_loss: 0.0005104; l1_loss: 0.0265141; total_loss: 0.0270245; examples/sec: 32.3; progress: 81.8%; \n",
      "FastEstimator-Train: step: 982; focal_loss: 0.0004448; l1_loss: 0.0213629; total_loss: 0.0218077; examples/sec: 32.1; progress: 81.8%; \n",
      "FastEstimator-Train: step: 983; focal_loss: 0.0002318; l1_loss: 0.0350155; total_loss: 0.0352472; examples/sec: 32.2; progress: 81.9%; \n",
      "[0.990821183 0.974339485 0.945313 ... 0.869611144 0.143539041 0.12587294]\n",
      "[0.99634856 0.991343737 0.985336185 ... 0.0520865321 0.0516525805 0.0507797301]\n",
      "[0.974178493 0.969736695 0.964557827 ... 0.0993468463 0.0782878399 0.0502275825]\n",
      "[0.982337177 0.869543254 0.247189105 0.0627599359]\n",
      "[0.989645302 0.972173452 0.956214428 ... 0.0681784153 0.0567609072 0.0556255281]\n",
      "[0.936256051]\n",
      "[0.976942658 0.972765326 0.949479342 ... 0.0515752137 0.0510316789 0.0508006811]\n",
      "[0.977022886 0.973584771 0.962836444 ... 0.0670056939 0.0610212088 0.0553198457]\n",
      "[0.912796855]\n",
      "[0.999262452 0.929926038 0.187405556]\n",
      "[0.987578869 0.98717 0.985286057 ... 0.056886971 0.055187881 0.0526241958]\n",
      "[0.991453111 0.982130527 0.977638364 ... 0.0533390343 0.0524832 0.0523645]\n",
      "[0.96585083 0.961986601 0.960791111 ... 0.0978853703 0.0582507849 0.0550315976]\n",
      "[0.937100172 0.935440779 0.934286714 ... 0.152117819 0.0675873458 0.0651366115]\n",
      "[0.964301]\n",
      "[0.97542876 0.954625607 0.943337917 0.0993485451]\n",
      "[0.999662399 0.998085439 0.992831469 ... 0.0754542649 0.0646578074 0.0552436113]\n",
      "[0.99696064 0.976056933 0.962110639 ... 0.0552459359 0.0540712774 0.0531221032]\n",
      "[0.985249043 0.964823961 0.908219337 0.0516116023]\n",
      "[0.994213104 0.988629043 0.988243222 ... 0.051366657 0.0510672033 0.0505764782]\n",
      "[0.964090824 0.947869062 0.937884927 0.0603201389]\n",
      "[0.986160398 0.874617219]\n",
      "[0.997943878 0.996668 0.996148825 ... 0.0639967 0.0575388968 0.0528151095]\n",
      "[0.993817449 0.992154181 0.988944292 ... 0.05244115 0.0509339869 0.0505365133]\n",
      "[0.994673729 0.974825382 0.953069508 ... 0.056437403 0.0555773675 0.0519465208]\n",
      "[0.993920386 0.985911131 0.980110765 ... 0.0815216303 0.068179816 0.0520206392]\n",
      "[0.981461406 0.960264921 0.866497874]\n",
      "[0.991425872 0.990454674 0.988049269 ... 0.054069519 0.0506304502 0.0500076711]\n",
      "[0.983753204 0.979582429 0.975442767 ... 0.0515116155 0.0512310266 0.0500255227]\n",
      "[0.996929646 0.980346]\n",
      "[0.998563647 0.996223152 0.994582891 ... 0.0547567606 0.0545856953 0.0543728471]\n",
      "[0.96199882 0.960525155 0.956216335 ... 0.863919735 0.138393819 0.0623993278]\n",
      "[0.975735664]\n",
      "[0.984859526 0.958797455]\n",
      "[0.990456939 0.983207345 0.979706764 ... 0.0536456108 0.0531850159 0.0500265658]\n",
      "[0.939273 0.901869655]\n",
      "[0.984172821 0.980872869 0.962844849 ... 0.0534757376 0.0513721108 0.0502507389]\n",
      "[0.985942364 0.968939722 0.964905858 ... 0.519231617 0.394496858 0.0923264623]\n",
      "[0.991585 0.991293311 0.9481107 0.942599475 0.912087321]\n",
      "[0.949955165 0.944524765 0.943381071 0.924098969 0.919598639 0.0515483916]\n",
      "[0.99888432 0.989359856 0.980304718 ... 0.0597352386 0.0590169132 0.0576905608]\n",
      "[0.993117273 0.957533777 0.953896761 0.947190642 0.0790422559]\n",
      "[0.997023225 0.996441245 0.941459179 ... 0.0542047322 0.0540683866 0.052298069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.971312523 0.947927833 0.932774484 0.910289049 0.058888495]\n",
      "[0.997984648 0.995246291 0.994708061 ... 0.0514047742 0.0507008731 0.0500239432]\n",
      "[0.94590044 0.895130038 0.0513501465]\n",
      "[0.990263939 0.984804869 0.967282593 ... 0.05978477 0.0590226054 0.0553343892]\n",
      "[0.905868649 0.884653747 0.880261898]\n",
      "FastEstimator-Eval: step: 984; epoch: 163; focal_loss: 0.0005124; l1_loss: 0.0301284; total_loss: 0.0306408; \n",
      "FastEstimator-Train: step: 984; focal_loss: 0.0004055; l1_loss: 0.0316203; total_loss: 0.0320258; examples/sec: 32.0; progress: 82.0%; \n",
      "FastEstimator-Train: step: 985; focal_loss: 0.0002933; l1_loss: 0.0227162; total_loss: 0.0230096; examples/sec: 32.5; progress: 82.1%; \n",
      "FastEstimator-Train: step: 986; focal_loss: 0.0005895; l1_loss: 0.0349508; total_loss: 0.0355402; examples/sec: 32.1; progress: 82.2%; \n",
      "FastEstimator-Train: step: 987; focal_loss: 0.000682; l1_loss: 0.023743; total_loss: 0.024425; examples/sec: 32.3; progress: 82.2%; \n",
      "FastEstimator-Train: step: 988; focal_loss: 0.0003391; l1_loss: 0.0220497; total_loss: 0.0223888; examples/sec: 32.2; progress: 82.3%; \n",
      "FastEstimator-Train: step: 989; focal_loss: 0.0003699; l1_loss: 0.039757; total_loss: 0.0401269; examples/sec: 32.5; progress: 82.4%; \n",
      "[0.954859793 0.923076034 0.910658 ... 0.0757394135 0.0645195842 0.0507337749]\n",
      "[0.966074169 0.960345447 0.939976215 ... 0.0619848669 0.0578012168 0.0509086549]\n",
      "[0.990285754 0.976574779 0.943222761 ... 0.873719573 0.140966088 0.112599075]\n",
      "[0.996636808 0.992423773 0.986197472 ... 0.0516896546 0.0508042574 0.0508026779]\n",
      "[0.974229395 0.97231406 0.969471693 ... 0.101752549 0.101522028 0.0676297843]\n",
      "[0.987687886 0.897138953 0.25445497 0.0689863861]\n",
      "[0.990943313 0.973578095 0.959320068 ... 0.0619413257 0.0607066154 0.0532523692]\n",
      "[0.935629964]\n",
      "[0.979428887 0.971416831 0.952459455 ... 0.0545593798 0.0544068217 0.0519606173]\n",
      "[0.981605649 0.971557379 0.956960678 ... 0.056523174 0.0540478826 0.0526823699]\n",
      "[0.930004954]\n",
      "[0.999602675 0.941651106 0.215673983]\n",
      "[0.988061488 0.987760544 0.983931422 ... 0.0552450418 0.0530508459 0.0506489873]\n",
      "[0.99199307 0.982869387 0.978076637 ... 0.0543248057 0.0542880893 0.0528944433]\n",
      "[0.963800669 0.962900758 0.955009401 ... 0.0732980072 0.0591115057 0.0560021698]\n",
      "[0.953220725 0.952903867 0.952451468 ... 0.0763345659 0.0529853106 0.0508275628]\n",
      "[0.961589932]\n",
      "[0.970302701 0.954696536 0.932467818]\n",
      "[0.999571621 0.997554243 0.991211057 ... 0.0729331672 0.0717957 0.0670774]\n",
      "[0.997125387 0.97824 0.968432784 ... 0.0545808077 0.0511891544 0.0506912172]\n",
      "[0.985031545 0.97091186 0.909625471]\n",
      "[0.994543552 0.988898873 0.987947345 ... 0.0530457795 0.0525388122 0.0513303876]\n",
      "[0.970067 0.947768331 0.945910931 0.0548988581]\n",
      "[0.988999546 0.880098343]\n",
      "[0.998088956 0.996657848 0.996116817 ... 0.0650789738 0.062702179 0.0523534715]\n",
      "[0.99561727 0.993482351 0.992367148 ... 0.0547803938 0.0530179143 0.0521564186]\n",
      "[0.996008515 0.983934343 0.96844238 ... 0.0514189601 0.0509924293 0.0503708422]\n",
      "[0.994880795 0.98629725 0.980271816 ... 0.0720534325 0.0670187175 0.0509532094]\n",
      "[0.979928315 0.963145256 0.86146915]\n",
      "[0.99126637 0.989112 0.988090396 ... 0.057454437 0.0512065589 0.0511641502]\n",
      "[0.983440161 0.978907 0.97846961 ... 0.0523180664 0.0512363 0.050992012]\n",
      "[0.996963799 0.98014605]\n",
      "[0.99868691 0.996201038 0.994146347 ... 0.0551226437 0.0539175868 0.0529488921]\n",
      "[0.966026843 0.962918222 0.961575389 ... 0.400105983 0.175877 0.130877465]\n",
      "[0.977015495]\n",
      "[0.988155067 0.969486475]\n",
      "[0.993091166 0.982740641 0.982230186 ... 0.0525807738 0.051841855 0.0500433743]\n",
      "[0.950484693 0.919252634]\n",
      "[0.98189652 0.978449941 0.957315743 ... 0.0538025498 0.0530695915 0.0504339635]\n",
      "[0.987782955 0.966811776 0.965197921 ... 0.397114217 0.100114435 0.0511519909]\n",
      "[0.992098868 0.991745412 0.949789345 0.943899572 0.910171628]\n",
      "[0.955178082 0.947086573 0.94576329 0.927134275 0.923515737 0.0528463125]\n",
      "[0.999074936 0.990849137 0.986926794 ... 0.0593891442 0.0589033365 0.0583715737]\n",
      "[0.988785 0.95187062 0.944211602 0.942265034 0.0727873445]\n",
      "[0.996844172 0.996080637 0.933666468 ... 0.0552279353 0.0547755361 0.0505583584]\n",
      "[0.969927907 0.946216226 0.929033637 0.91396594 0.0557458103]\n",
      "[0.997514844 0.995042205 0.994630694 ... 0.0525726378 0.0523343682 0.0501595736]\n",
      "[0.954928815 0.914265513]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 990; epoch: 164; focal_loss: 0.000483; l1_loss: 0.0146927; total_loss: 0.0151757; \n",
      "FastEstimator-Train: step: 990; focal_loss: 0.0001585; l1_loss: 0.0203937; total_loss: 0.0205522; examples/sec: 31.2; progress: 82.5%; \n",
      "FastEstimator-Train: step: 991; focal_loss: 0.000325; l1_loss: 0.01456; total_loss: 0.014885; examples/sec: 32.7; progress: 82.6%; \n",
      "FastEstimator-Train: step: 992; focal_loss: 0.0002852; l1_loss: 0.0100505; total_loss: 0.0103357; examples/sec: 32.2; progress: 82.7%; \n",
      "FastEstimator-Train: step: 993; focal_loss: 0.0002973; l1_loss: 0.0272805; total_loss: 0.0275778; examples/sec: 32.3; progress: 82.8%; \n",
      "FastEstimator-Train: step: 994; focal_loss: 0.0006688; l1_loss: 0.0304366; total_loss: 0.0311054; examples/sec: 32.4; progress: 82.8%; \n",
      "FastEstimator-Train: step: 995; focal_loss: 0.0002247; l1_loss: 0.0208545; total_loss: 0.0210792; examples/sec: 32.3; progress: 82.9%; \n",
      "[0.99116385 0.981018424 0.966443956 ... 0.0924808085 0.0662041306 0.0541677475]\n",
      "[0.90545392 0.894092202 0.892993867]\n",
      "[0.950157642 0.917426705 0.90035975 ... 0.0809540749 0.0751340091 0.0532010794]\n",
      "[0.963539839 0.960973501 0.929717481 ... 0.225248963 0.0609805286 0.0529422462]\n",
      "[0.9907372 0.976090789 0.937920034 ... 0.86785984 0.130832344 0.112371385]\n",
      "[0.996005774 0.991366327 0.98746264 ... 0.0521577299 0.0504665673 0.0503637195]\n",
      "[0.977979302 0.974344134 0.974100947 ... 0.127227664 0.0995310247 0.0788386166]\n",
      "[0.984434962 0.860205293 0.212521225 0.0579853952]\n",
      "[0.990045607 0.970630646 0.958866358 ... 0.85570395 0.055357486 0.0533578396]\n",
      "[0.931832075]\n",
      "[0.978981 0.968389869 0.961022675 ... 0.0527301133 0.051551193 0.0514184237]\n",
      "[0.963556886 0.961913824 0.950659156 ... 0.0642581 0.0504015684 0.0502483547]\n",
      "[0.933209658]\n",
      "[0.999611497 0.945537329 0.196899146]\n",
      "[0.983976 0.983876944 0.979703665 ... 0.0590587556 0.0537817776 0.0502313673]\n",
      "[0.988908947 0.982503 0.97176981 ... 0.0578538179 0.0519201458 0.0500798523]\n",
      "[0.959520936 0.947702885 0.945014954 ... 0.0572008193 0.0556722581 0.055235]\n",
      "[0.955351 0.955180526 0.950860083 ... 0.888560653 0.146901429 0.0737259388]\n",
      "[0.960564256]\n",
      "[0.954055667 0.905582666 0.856521308]\n",
      "[0.999592304 0.997394383 0.990303457 ... 0.0666240752 0.064853996 0.0572259128]\n",
      "[0.994760275 0.976951361 0.966481209 ... 0.0545339286 0.0545243323 0.0539582968]\n",
      "[0.985950589 0.975426733 0.905071616]\n",
      "[0.992853165 0.987308741 0.986050606 ... 0.0526136756 0.0518152118 0.0506738424]\n",
      "[0.96343708 0.940081537 0.920353055 0.0507980287]\n",
      "[0.983002305 0.86150676]\n",
      "[0.997756958 0.996123791 0.995022893 ... 0.0623997152 0.0558298528 0.0532362163]\n",
      "[0.995942354 0.993794262 0.99320358 ... 0.05100739 0.0509212911 0.0501287878]\n",
      "[0.996283233 0.985127866 0.969343126 ... 0.0543131232 0.052219063 0.0519436]\n",
      "[0.995061159 0.986358285 0.980214715 ... 0.0816225708 0.0583059788 0.0533309579]\n",
      "[0.981391072 0.958625913 0.789231896]\n",
      "[0.989062428 0.988280654 0.988010347 ... 0.0533239245 0.0516015291 0.050268054]\n",
      "[0.981586695 0.977623165 0.972355783 ... 0.0512595177 0.0505667627 0.0504818559]\n",
      "[0.995127559 0.970492]\n",
      "[0.998633146 0.99506259 0.994952559 ... 0.0571973324 0.0539622307 0.0539224148]\n",
      "[0.958966434 0.956099391 0.952291608 ... 0.282578886 0.162991434 0.121786237]\n",
      "[0.972164452]\n",
      "[0.98410368 0.957018852]\n",
      "[0.993195713 0.976953328 0.972502589 ... 0.315147936 0.0688501298 0.0522221923]\n",
      "[0.940161705 0.897757232]\n",
      "[0.97938931 0.979200721 0.952867508 ... 0.0538122952 0.0503860116 0.0501898229]\n",
      "[0.985623181 0.95952034 0.957122505 ... 0.480956346 0.381621212 0.0857411]\n",
      "[0.990260482 0.989201307 0.94093 0.937078476 0.90076673]\n",
      "[0.926441491 0.910969138 0.908839762 0.904523849 0.873164773]\n",
      "[0.998886704 0.99086988 0.988757312 ... 0.0589611828 0.0564581752 0.056342423]\n",
      "[0.986534476 0.93736583 0.932952642 0.918197513 0.0676682889]\n",
      "[0.99627018 0.995943069 0.936175346 ... 0.0602905154 0.0577459335 0.0553144217]\n",
      "[0.968215704 0.949414432 0.92973268 0.896472812]\n",
      "FastEstimator-Eval: step: 996; epoch: 165; focal_loss: 0.0005546; l1_loss: 0.0214107; total_loss: 0.0219653; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 996; focal_loss: 0.0004361; l1_loss: 0.0204588; total_loss: 0.0208949; examples/sec: 32.0; progress: 83.0%; \n",
      "FastEstimator-Train: step: 997; focal_loss: 0.0004519; l1_loss: 0.0251263; total_loss: 0.0255783; examples/sec: 32.6; progress: 83.1%; \n",
      "FastEstimator-Train: step: 998; focal_loss: 0.0002649; l1_loss: 0.0194086; total_loss: 0.0196735; examples/sec: 32.4; progress: 83.2%; \n",
      "FastEstimator-Train: step: 999; focal_loss: 0.0001961; l1_loss: 0.0451895; total_loss: 0.0453856; examples/sec: 32.3; progress: 83.2%; \n",
      "FastEstimator-Train: step: 1000; focal_loss: 0.0002084; l1_loss: 0.0095798; total_loss: 0.0097882; examples/sec: 32.2; progress: 83.3%; \n",
      "FastEstimator-Train: step: 1001; focal_loss: 0.0002541; l1_loss: 0.0366024; total_loss: 0.0368565; examples/sec: 32.3; progress: 83.4%; \n",
      "[0.996795 0.992903471 0.992664754 ... 0.053617 0.0512571335 0.0504978597]\n",
      "[0.959214449 0.915042758]\n",
      "[0.991349936 0.98136735 0.965367675 ... 0.077465266 0.0539001524 0.0514493]\n",
      "[0.919910312 0.907902718 0.896579444]\n",
      "[0.940035224 0.918301344 0.90225 ... 0.0807875395 0.0710930526 0.0531872809]\n",
      "[0.96961385 0.966640353 0.932854414 ... 0.24692139 0.0632341504 0.0550706387]\n",
      "[0.993142 0.984277606 0.955986083 ... 0.902924 0.146410525 0.129971474]\n",
      "[0.994262636 0.987557 0.986942291 ... 0.0516673625 0.0510475636 0.0501873791]\n",
      "[0.968564391 0.967534125 0.965466082 ... 0.0867529511 0.0858150423 0.0696644187]\n",
      "[0.986092567 0.870601296 0.237341821 0.0568783879]\n",
      "[0.989478111 0.965630531 0.95532 ... 0.378965765 0.0584414601 0.0534419715]\n",
      "[0.925704598]\n",
      "[0.977068901 0.966632366 0.964448333 ... 0.0515530705 0.0512194633 0.0511115789]\n",
      "[0.951391339 0.942083597 0.933365107 ... 0.0729382634 0.0612985492 0.0517487228]\n",
      "[0.957747936]\n",
      "[0.999630928 0.947190583 0.201622337]\n",
      "[0.983763158 0.981655478 0.978549957 ... 0.0654596686 0.0592561364 0.0563545227]\n",
      "[0.990590692 0.982584298 0.968521953 ... 0.0604639649 0.0532490611 0.0524013042]\n",
      "[0.957455635 0.950289786 0.945834696 ... 0.0567417145 0.0541835129 0.0522857606]\n",
      "[0.953312695 0.943181157 0.936825037 ... 0.888001919 0.137735337 0.0701043606]\n",
      "[0.969551206]\n",
      "[0.966818333 0.927638054 0.879909396]\n",
      "[0.999604106 0.997802138 0.990812182 ... 0.0771049261 0.0667244792 0.0603616238]\n",
      "[0.994631886 0.973192811 0.96261549 ... 0.0528392792 0.0515053868 0.0504646897]\n",
      "[0.984330773 0.976182342 0.903462887]\n",
      "[0.994082451 0.985546708 0.984156966 ... 0.0535725355 0.0527484417 0.0514588654]\n",
      "[0.969485879 0.947267115 0.935165882]\n",
      "[0.984721541 0.866278648]\n",
      "[0.997718692 0.995383859 0.995354176 ... 0.0561549067 0.0533621311 0.0508029461]\n",
      "[0.996456861 0.995279908 0.993831 ... 0.0530430377 0.0528168976 0.0504954457]\n",
      "[0.995495498 0.979320168 0.957452536 ... 0.0502873659 0.0502848625 0.0501109362]\n",
      "[0.995629549 0.988341689 0.983210683 ... 0.0846121907 0.0608106852 0.0582698286]\n",
      "[0.982812047 0.964555264 0.82505089]\n",
      "[0.99105 0.98787266 0.987430573 ... 0.0519053042 0.0514359176 0.0510363281]\n",
      "[0.980207622 0.978931963 0.973642468 ... 0.0516943336 0.0512639 0.0508746803]\n",
      "[0.995891035 0.973378778]\n",
      "[0.998591065 0.994813442 0.993852615 ... 0.0565354228 0.0557247102 0.0542766154]\n",
      "[0.965078712 0.964152217 0.957959175 ... 0.200121433 0.126083881 0.0595181882]\n",
      "[0.979295075]\n",
      "[0.985718369 0.957539558]\n",
      "[0.992697 0.976643085 0.975894 ... 0.302518249 0.064596504 0.060141474]\n",
      "[0.953523636 0.91963172]\n",
      "[0.980124354 0.979019523 0.955051899 ... 0.0578128695 0.0555817783 0.0513442159]\n",
      "[0.982537448 0.958916426 0.952637196 ... 0.464606225 0.353483677 0.0829199851]\n",
      "[0.993011594 0.992227674 0.956102848 0.948712826 0.920120597]\n",
      "[0.929160357 0.919327378 0.909950137 0.90722537 0.876382172]\n",
      "[0.998472095 0.993357778 0.989971042 ... 0.0544199944 0.0535098 0.0534305274]\n",
      "[0.992848516 0.958100617 0.955676556 0.946248829]\n",
      "FastEstimator-Eval: step: 1002; epoch: 166; focal_loss: 0.0004626; l1_loss: 0.0176681; total_loss: 0.0181307; \n",
      "FastEstimator-Train: step: 1002; focal_loss: 0.0004645; l1_loss: 0.0175167; total_loss: 0.0179812; examples/sec: 31.9; progress: 83.5%; \n",
      "FastEstimator-Train: step: 1003; focal_loss: 0.000205; l1_loss: 0.0176175; total_loss: 0.0178225; examples/sec: 32.2; progress: 83.6%; \n",
      "FastEstimator-Train: step: 1004; focal_loss: 0.0006386; l1_loss: 0.0229363; total_loss: 0.0235749; examples/sec: 32.5; progress: 83.7%; \n",
      "FastEstimator-Train: step: 1005; focal_loss: 0.0002321; l1_loss: 0.0181174; total_loss: 0.0183495; examples/sec: 32.3; progress: 83.8%; \n",
      "FastEstimator-Train: step: 1006; focal_loss: 0.0002578; l1_loss: 0.0116578; total_loss: 0.0119157; examples/sec: 32.3; progress: 83.8%; \n",
      "FastEstimator-Train: step: 1007; focal_loss: 0.0002437; l1_loss: 0.0262161; total_loss: 0.0264598; examples/sec: 32.3; progress: 83.9%; \n",
      "[0.997208357 0.996339083 0.936501622 ... 0.0629120171 0.0564354062 0.0559110641]\n",
      "[0.96955812 0.95960021 0.939091682 0.899090648]\n",
      "[0.997811556 0.994241 0.994057 ... 0.0515906513 0.0511752069 0.0502985716]\n",
      "[0.960955262 0.905861437]\n",
      "[0.992940366 0.981768429 0.968962312 ... 0.0731904805 0.0605865419 0.053925544]\n",
      "[0.914806962 0.901713 0.897868633]\n",
      "[0.945190549 0.92824 0.911757588 ... 0.0893393755 0.0679691136 0.0522910058]\n",
      "[0.972743452 0.970959902 0.942603648 ... 0.0604599416 0.0565559268 0.055234611]\n",
      "[0.994033575 0.98332727 0.952152252 ... 0.891476274 0.145813763 0.137753427]\n",
      "[0.994755924 0.989308476 0.9891119 ... 0.0538964272 0.052344203 0.0510843694]\n",
      "[0.976155281 0.974401295 0.97125268 ... 0.0947796106 0.0849770606 0.0703508854]\n",
      "[0.986311913 0.889710069 0.260911316 0.0524432063]\n",
      "[0.990961969 0.96936655 0.957910895 ... 0.888858795 0.0582944155 0.0567939878]\n",
      "[0.890498042]\n",
      "[0.981796622 0.972199678 0.967032254 ... 0.0525912046 0.0517282486 0.0508750677]\n",
      "[0.960460067 0.949886501 0.94276011 ... 0.0578930676 0.0526809096 0.0524570942]\n",
      "[0.958129704]\n",
      "[0.999480903 0.944636464 0.208705157]\n",
      "[0.985937953 0.984773397 0.981908 ... 0.0610613227 0.0604050159 0.0603504479]\n",
      "[0.992625833 0.9891361 0.974357963 ... 0.0541501939 0.0536212027 0.0504802167]\n",
      "[0.965395212 0.958523512 0.956647515 ... 0.069144547 0.0661909 0.0564859807]\n",
      "[0.953447521 0.943622351 0.939719558 ... 0.901203036 0.151181072 0.0672687888]\n",
      "[0.968599141]\n",
      "[0.976709187 0.932175159 0.883319259]\n",
      "[0.999661922 0.998297334 0.991812527 ... 0.0648703873 0.0607263446 0.0500917137]\n",
      "[0.994813323 0.975684524 0.96377033 ... 0.0528094172 0.0524275303 0.0520277321]\n",
      "[0.986119747 0.978058457 0.913382471]\n",
      "[0.995343745 0.98886025 0.985470176 ... 0.0519176424 0.0507265925 0.0505318344]\n",
      "[0.969526529 0.952022672 0.937092185 0.0502720475]\n",
      "[0.984971046 0.882543325]\n",
      "[0.997883797 0.995944679 0.995702863 ... 0.859086871 0.0556663573 0.0518580377]\n",
      "[0.997327685 0.996802 0.994778633 ... 0.0547429621 0.0521853864 0.0504556298]\n",
      "[0.996052623 0.980205595 0.959082365 ... 0.0567079782 0.053524375 0.0517686]\n",
      "[0.996126533 0.988653541 0.984677 ... 0.0659550428 0.0568542778 0.0534517467]\n",
      "[0.984912455 0.971708596 0.835770249]\n",
      "[0.992379785 0.990332127 0.988811493 ... 0.0571615398 0.0541200638 0.052226603]\n",
      "[0.98461175 0.983827174 0.977589726 ... 0.0532996356 0.0515219271 0.0513205528]\n",
      "[0.994946837 0.970119953]\n",
      "[0.99889338 0.995868862 0.992711544 ... 0.0589163303 0.0563397706 0.0562620163]\n",
      "[0.974674582 0.968597889 0.956178904 ... 0.181851178 0.134919643 0.0679218471]\n",
      "[0.979799271]\n",
      "[0.983450055 0.952922821]\n",
      "[0.993132234 0.981584311 0.978133678 ... 0.0582152903 0.0534496307 0.0527657568]\n",
      "[0.927485824 0.891789436]\n",
      "[0.984561563 0.982022405 0.95958066 ... 0.0560605526 0.055138588 0.0500293672]\n",
      "[0.983721733 0.963812351 0.954063892 ... 0.491240799 0.352403522 0.0845571756]\n",
      "[0.988638043 0.987746239 0.957490206 0.930741549 0.925807714]\n",
      "[0.937016308 0.92485249 0.919271946 0.917869031 0.885718346 0.0524756]\n",
      "FastEstimator-Eval: step: 1008; epoch: 167; focal_loss: 0.0003719; l1_loss: 0.0159477; total_loss: 0.0163196; \n",
      "FastEstimator-Train: step: 1008; focal_loss: 0.0001364; l1_loss: 0.0142063; total_loss: 0.0143427; examples/sec: 32.0; progress: 84.0%; \n",
      "FastEstimator-Train: step: 1009; focal_loss: 0.0007966; l1_loss: 0.0114116; total_loss: 0.0122082; examples/sec: 32.5; progress: 84.1%; \n",
      "FastEstimator-Train: step: 1010; focal_loss: 0.000377; l1_loss: 0.0259345; total_loss: 0.0263114; examples/sec: 32.5; progress: 84.2%; \n",
      "FastEstimator-Train: step: 1011; focal_loss: 0.000292; l1_loss: 0.0143266; total_loss: 0.0146186; examples/sec: 31.8; progress: 84.2%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 1012; focal_loss: 0.0002402; l1_loss: 0.0218912; total_loss: 0.0221314; examples/sec: 31.6; progress: 84.3%; \n",
      "FastEstimator-Train: step: 1013; focal_loss: 0.0003992; l1_loss: 0.0214087; total_loss: 0.0218079; examples/sec: 32.3; progress: 84.4%; \n",
      "[0.998777211 0.994294524 0.991793931 ... 0.0543783903 0.0541574061 0.0536851585]\n",
      "[0.998126864 0.982479632 0.982001662 0.973354459]\n",
      "[0.997649431 0.996812224 0.948853314 ... 0.0523585379 0.0507357419 0.0503874421]\n",
      "[0.972418666 0.958664179 0.939477384 0.925540686 0.053442]\n",
      "[0.998575747 0.99485743 0.994660378 ... 0.0528208911 0.0512529612 0.0502161384]\n",
      "[0.967268944 0.92636013]\n",
      "[0.993156075 0.980145 0.96842134 ... 0.135749251 0.0732949376 0.0551602542]\n",
      "[0.931008458 0.93062371 0.90858984]\n",
      "[0.950852334 0.928631663 0.91677928 ... 0.0694794059 0.0585950315 0.0507801473]\n",
      "[0.973861516 0.973652124 0.951243162 ... 0.0712149739 0.0538214743 0.0510072112]\n",
      "[0.995548129 0.98947978 0.973397791 ... 0.920421 0.157217681 0.156938672]\n",
      "[0.993193507 0.9912 0.989962697 ... 0.0541843176 0.052089572 0.051540643]\n",
      "[0.976074338 0.974780679 0.969727516 ... 0.0962738097 0.095257014 0.0718102157]\n",
      "[0.990175962 0.908670843 0.28799209 0.0601617396]\n",
      "[0.991564274 0.973222196 0.961613178 ... 0.898522615 0.0646849 0.0551949441]\n",
      "[0.930165768]\n",
      "[0.981790781 0.968414366 0.962817192 ... 0.0548661649 0.05077672 0.0503661335]\n",
      "[0.96478194 0.955202699 0.94406873 ... 0.0616907775 0.0601685941 0.0516658723]\n",
      "[0.962827325]\n",
      "[0.999678671 0.950876474 0.22710371]\n",
      "[0.987996221 0.98664546 0.98447454 ... 0.0519326031 0.0518174171 0.050293535]\n",
      "[0.993042529 0.991615832 0.974578559 ... 0.0587157309 0.0577440858 0.0524571836]\n",
      "[0.965532243 0.963743925 0.959437191 ... 0.0626174212 0.0587194562 0.0527228713]\n",
      "[0.958007157 0.952778459 0.945115447 ... 0.0745343 0.0632864535 0.0525801182]\n",
      "[0.967594922]\n",
      "[0.979703903 0.955828547 0.920404077]\n",
      "[0.999741197 0.99842906 0.99373579 ... 0.0781324506 0.0689375699 0.0555041134]\n",
      "[0.996343374 0.977236092 0.968283176 ... 0.0528157055 0.0519800186 0.0514508486]\n",
      "[0.986171842 0.974018812 0.911327064]\n",
      "[0.995739758 0.987250865 0.985279858 ... 0.0553130507 0.0525536239 0.0518116653]\n",
      "[0.975763738 0.956064582 0.952910542]\n",
      "[0.989424229 0.897386]\n",
      "[0.997873306 0.996268272 0.996074796 ... 0.327161878 0.0573161244 0.0557985604]\n",
      "[0.996096 0.995687068 0.992486596 ... 0.055265069 0.054685384 0.050588727]\n",
      "[0.996443748 0.981653571 0.961551309 ... 0.0518531799 0.0504153967 0.050095737]\n",
      "[0.996491194 0.987641335 0.985674 ... 0.063228339 0.0594822764 0.0589408278]\n",
      "[0.987469554 0.974241853 0.881420374]\n",
      "[0.992916107 0.98936671 0.988640904 ... 0.0530504584 0.0523509085 0.0511026382]\n",
      "[0.987147093 0.985279322 0.98 ... 0.0528048873 0.050945282 0.0507788062]\n",
      "[0.995698214 0.97368145]\n",
      "[0.99868 0.995329201 0.994121909 ... 0.0558910072 0.0556371808 0.0544505715]\n",
      "[0.977404952 0.970469594 0.966353178 ... 0.206122875 0.13841188 0.0776645243]\n",
      "[0.986857653]\n",
      "[0.98616153 0.962553263]\n",
      "[0.992946267 0.984254718 0.983943284 ... 0.0670679212 0.0620480478 0.0518452525]\n",
      "[0.937310576 0.895347118]\n",
      "[0.985953271 0.983408511 0.952939272 ... 0.0606781244 0.0535931289 0.0505884588]\n",
      "[0.987759 0.970112324 0.966187596 ... 0.372748882 0.0902360082 0.0751686692]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 1014; epoch: 168; focal_loss: 0.0003572; l1_loss: 0.0137371; total_loss: 0.0140943; \n",
      "FastEstimator-Train: step: 1014; focal_loss: 0.0001764; l1_loss: 0.0257803; total_loss: 0.0259567; examples/sec: 32.2; progress: 84.5%; \n",
      "FastEstimator-Train: step: 1015; focal_loss: 0.0001401; l1_loss: 0.0102594; total_loss: 0.0103995; examples/sec: 32.2; progress: 84.6%; \n",
      "FastEstimator-Train: step: 1016; focal_loss: 0.000837; l1_loss: 0.0239586; total_loss: 0.0247956; examples/sec: 32.5; progress: 84.7%; \n",
      "FastEstimator-Train: step: 1017; focal_loss: 0.0001206; l1_loss: 0.0087747; total_loss: 0.0088953; examples/sec: 32.1; progress: 84.8%; \n",
      "FastEstimator-Train: step: 1018; focal_loss: 0.0002394; l1_loss: 0.0255268; total_loss: 0.0257662; examples/sec: 32.0; progress: 84.8%; \n",
      "FastEstimator-Train: step: 1019; focal_loss: 0.0003423; l1_loss: 0.0247219; total_loss: 0.0250641; examples/sec: 32.3; progress: 84.9%; \n",
      "[0.975953221 0.973354 0.948773146 0.928728819 0.899891853 0.0523638725]\n",
      "[0.949174523 0.944986463 0.933893 0.922257066 0.91465354 0.056430757]\n",
      "[0.998941779 0.992799938 0.991585314 ... 0.0530668199 0.0523404181 0.050421983]\n",
      "[0.996213615 0.973105311 0.965733051 0.948876 0.125497848]\n",
      "[0.997415483 0.997217119 0.959946036 ... 0.0576138794 0.0557159185 0.0502426326]\n",
      "[0.974408507 0.955427468 0.947004914 0.923475266 0.0543013215]\n",
      "[0.998889208 0.995189965 0.994929552 ... 0.0526491702 0.052177608 0.0512028933]\n",
      "[0.967611313 0.914428473]\n",
      "[0.992164195 0.977247 0.967319608 ... 0.14293462 0.0673541725 0.0558722615]\n",
      "[0.920634031 0.917077541 0.896115839]\n",
      "[0.955940843 0.93056047 0.920326293 ... 0.0687223077 0.0580189228 0.0522328019]\n",
      "[0.975865662 0.97247231 0.957779765 ... 0.0736279786 0.0643963814 0.0500744879]\n",
      "[0.991037488 0.97948426 0.948130965 ... 0.880156696 0.134812474 0.109766573]\n",
      "[0.994629443 0.99215138 0.989885092 ... 0.0502954125 0.0502756834 0.050219059]\n",
      "[0.976457 0.975539267 0.973801911 ... 0.103003114 0.0651030838 0.0516457856]\n",
      "[0.987634 0.895430565 0.260234535 0.0571802855]\n",
      "[0.992063046 0.976740062 0.967742562 ... 0.896318674 0.0553253591 0.054627]\n",
      "[0.945090413]\n",
      "[0.979697526 0.966806829 0.959124088 ... 0.0519683361 0.0516583323 0.0505513251]\n",
      "[0.971874833 0.968886256 0.944361 ... 0.0727187395 0.0597189367 0.0549282432]\n",
      "[0.939121842]\n",
      "[0.999495745 0.946651042 0.241550446]\n",
      "[0.990050197 0.98883909 0.986375809 ... 0.0587267876 0.0562730134 0.0555194914]\n",
      "[0.992141366 0.99148953 0.975419521 ... 0.0541923344 0.0532772541 0.0527498722]\n",
      "[0.962418318 0.95982933 0.958447874 ... 0.0633479953 0.0592677 0.057710737]\n",
      "[0.963293195 0.958953738 0.952367425 ... 0.913640141 0.140987098 0.0737379491]\n",
      "[0.96301353]\n",
      "[0.979768634 0.952333212 0.912852049]\n",
      "[0.999807537 0.998610735 0.994943 ... 0.0767194927 0.0618779063 0.0574577451]\n",
      "[0.995950818 0.977932 0.967584252 ... 0.0528861284 0.0522091091 0.0520439744]\n",
      "[0.983692527 0.975175738 0.917266488 0.0513790846]\n",
      "[0.99486959 0.987678647 0.98613441 ... 0.0523234 0.0516691208 0.0501588881]\n",
      "[0.968161702 0.950650215 0.939741969]\n",
      "[0.987717867 0.905690372]\n",
      "[0.997873 0.996508 0.9963 ... 0.306966305 0.054759264 0.0519987047]\n",
      "[0.994350135 0.99414432 0.989389539 ... 0.0535565913 0.0529111922 0.0507513583]\n",
      "[0.996883512 0.984242857 0.965899467 ... 0.052190274 0.0506891906 0.050352931]\n",
      "[0.995804548 0.984623075 0.979418516 ... 0.0607824028 0.0575560629 0.052318126]\n",
      "[0.989082813 0.975377798 0.903326452]\n",
      "[0.992649317 0.989765167 0.988877654 ... 0.0561470687 0.055160135 0.0531751812]\n",
      "[0.987073481 0.98283267 0.981944323 ... 0.0513730943 0.0513131917 0.0507828295]\n",
      "[0.99454838 0.968818486]\n",
      "[0.998644948 0.99612695 0.995407224 ... 0.0531515479 0.0503537059 0.0502960086]\n",
      "[0.978221178 0.969655693 0.963624418 ... 0.188542008 0.139962107 0.0669044554]\n",
      "[0.983464897]\n",
      "[0.980718613 0.950719118]\n",
      "[0.992507458 0.984501839 0.982071817 ... 0.0592004359 0.0545549393 0.0540643334]\n",
      "[0.929171562 0.864963055]\n",
      "FastEstimator-Eval: step: 1020; epoch: 169; focal_loss: 0.0003536; l1_loss: 0.0145662; total_loss: 0.0149198; \n",
      "FastEstimator-Train: step: 1020; focal_loss: 0.0002804; l1_loss: 0.0080186; total_loss: 0.0082989; examples/sec: 32.5; progress: 85.0%; \n",
      "FastEstimator-Train: step: 1021; focal_loss: 0.0002406; l1_loss: 0.0115139; total_loss: 0.0117545; examples/sec: 31.8; progress: 85.1%; \n",
      "FastEstimator-Train: step: 1022; focal_loss: 0.0003326; l1_loss: 0.0165746; total_loss: 0.0169072; examples/sec: 32.5; progress: 85.2%; \n",
      "FastEstimator-Train: step: 1023; focal_loss: 0.0003639; l1_loss: 0.0241173; total_loss: 0.0244812; examples/sec: 32.6; progress: 85.2%; \n",
      "FastEstimator-Train: step: 1024; focal_loss: 0.0002618; l1_loss: 0.0138857; total_loss: 0.0141475; examples/sec: 31.9; progress: 85.3%; \n",
      "FastEstimator-Train: step: 1025; focal_loss: 0.0002608; l1_loss: 0.0334199; total_loss: 0.0336807; examples/sec: 32.3; progress: 85.4%; \n",
      "[0.987651825 0.982955217 0.950875163 ... 0.0546700954 0.0516258478 0.0511147678]\n",
      "[0.989634097 0.966945112 0.963289499 ... 0.380033255 0.0808563232 0.0762282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97965008 0.97929883 0.951482475 0.92953521 0.905668378]\n",
      "[0.946169376 0.941562951 0.937114358 0.922866106 0.914208055 0.0557510555]\n",
      "[0.999071836 0.992252827 0.990837216 ... 0.0528009236 0.0524427891 0.0518265069]\n",
      "[0.994203806 0.962822556 0.950416267 0.936582923 0.102259785]\n",
      "[0.997210622 0.99702239 0.964310884 ... 0.0544236 0.0512115061 0.0504781604]\n",
      "[0.97569859 0.961482286 0.960817933 0.937583566 0.0550815761]\n",
      "[0.998828173 0.99487 0.994773149 ... 0.057831496 0.053951025 0.050950855]\n",
      "[0.968694925 0.929339945]\n",
      "[0.992390633 0.981626511 0.968175292 ... 0.0718601644 0.0559736192 0.0536877513]\n",
      "[0.927933216 0.922405243 0.896871]\n",
      "[0.955868125 0.926138401 0.924708366 ... 0.0671156645 0.0560723841 0.0529504716]\n",
      "[0.977623403 0.976008117 0.963540196 ... 0.0624527931 0.0605899394 0.0593805]\n",
      "[0.984116554 0.971352577 0.941106319 ... 0.858342648 0.13402018 0.0782780945]\n",
      "[0.996472955 0.992553949 0.990954399 ... 0.0504122972 0.0503222048 0.0501238704]\n",
      "[0.978891 0.977778554 0.975735486 ... 0.0639808178 0.05425632 0.053186]\n",
      "[0.98772949 0.900559425 0.267017603 0.0528425574]\n",
      "[0.992674291 0.977314711 0.971609473 ... 0.0603256524 0.0569090545 0.0568160713]\n",
      "[0.941913128]\n",
      "[0.978441954 0.973641932 0.965944052 ... 0.0539825559 0.0534415245 0.0523766577]\n",
      "[0.972244382 0.95846957 0.95343405 ... 0.0749048889 0.0546267927 0.0531951487]\n",
      "[0.951345503]\n",
      "[0.999332666 0.9420681 0.236484915]\n",
      "[0.991470814 0.991417944 0.987375736 ... 0.0574731529 0.0525238812 0.0500353873]\n",
      "[0.992360651 0.99030292 0.975257039 ... 0.0604912341 0.0601537824 0.0591755509]\n",
      "[0.963373661 0.96123594 0.960909724 ... 0.061856 0.0580286384 0.0575294495]\n",
      "[0.962458134 0.957677484 0.957118928 ... 0.917726636 0.146987259 0.067263335]\n",
      "[0.967365861]\n",
      "[0.981068492 0.95710218 0.912245512]\n",
      "[0.999856949 0.998826921 0.99582088 ... 0.0723438859 0.0551170409 0.0549910069]\n",
      "[0.996939957 0.979947925 0.97156918 ... 0.0528180301 0.0513547063 0.0511892438]\n",
      "[0.985756159 0.978281438 0.92899555]\n",
      "[0.994614482 0.989368498 0.987170577 ... 0.0521217585 0.0520315766 0.0516738]\n",
      "[0.969822109 0.953333735 0.94430232]\n",
      "[0.989126742 0.910809517]\n",
      "[0.997728229 0.996447146 0.996072173 ... 0.89045006 0.055859834 0.053602457]\n",
      "[0.996100187 0.995368 0.991131902 ... 0.0517177582 0.0513731241 0.0504048169]\n",
      "[0.997009873 0.985348344 0.967642426 ... 0.0548377633 0.0534461141 0.0502470434]\n",
      "[0.994876266 0.984386146 0.975279927 ... 0.0733546615 0.0570541322 0.0516789854]\n",
      "[0.990178645 0.976526618 0.92308867]\n",
      "[0.992171407 0.989619434 0.989568472 ... 0.0560881495 0.0547818542 0.0518288612]\n",
      "[0.986917138 0.982991695 0.982062936 ... 0.0514322221 0.0510813892 0.0507693887]\n",
      "[0.995536089 0.972067833]\n",
      "[0.998996139 0.997043312 0.996037722 ... 0.0538894236 0.0521105826 0.0511435568]\n",
      "[0.978908539 0.970241785 0.967101157 ... 0.191692024 0.156066537 0.073752284]\n",
      "[0.984748065]\n",
      "[0.982005537 0.953590274]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 1026; epoch: 170; focal_loss: 0.0003548; l1_loss: 0.0114957; total_loss: 0.0118505; \n",
      "FastEstimator-Train: step: 1026; focal_loss: 0.0001463; l1_loss: 0.014385; total_loss: 0.0145313; examples/sec: 31.7; progress: 85.5%; \n",
      "FastEstimator-Train: step: 1027; focal_loss: 0.0001184; l1_loss: 0.007125; total_loss: 0.0072434; examples/sec: 32.4; progress: 85.6%; \n",
      "FastEstimator-Train: step: 1028; focal_loss: 0.0008546; l1_loss: 0.0257787; total_loss: 0.0266333; examples/sec: 32.5; progress: 85.7%; \n",
      "FastEstimator-Train: step: 1029; focal_loss: 0.0002437; l1_loss: 0.0376991; total_loss: 0.0379428; examples/sec: 32.5; progress: 85.8%; \n",
      "FastEstimator-Train: step: 1030; focal_loss: 0.0003222; l1_loss: 0.0445748; total_loss: 0.0448971; examples/sec: 32.3; progress: 85.8%; \n",
      "FastEstimator-Train: step: 1031; focal_loss: 0.0004881; l1_loss: 0.0158944; total_loss: 0.0163824; examples/sec: 32.2; progress: 85.9%; \n",
      "[0.99360919 0.985682487 0.985227287 ... 0.07344383 0.0700322092 0.0598322153]\n",
      "[0.954275 0.931643367]\n",
      "[0.989159644 0.986704588 0.967326403 ... 0.0544220209 0.0525075495 0.051877439]\n",
      "[0.988454223 0.962461889 0.961943865 ... 0.499510407 0.373920023 0.0709348]\n",
      "[0.987603724 0.985793591 0.959463716 0.93683517 0.930226564]\n",
      "[0.930639 0.929804683 0.922091961 0.903879523 0.899078965 0.0532339215]\n",
      "[0.999166787 0.993599057 0.991894901 ... 0.051281631 0.051115185 0.0509567559]\n",
      "[0.993597746 0.955514789 0.943280399 0.926846266 0.0882390141]\n",
      "[0.997106671 0.996908486 0.956406951 ... 0.0622670949 0.061720252 0.0506878197]\n",
      "[0.978232 0.968621492 0.965571761 0.947563767 0.0523845851]\n",
      "[0.9987849 0.995827317 0.994694412 ... 0.0548931956 0.0530487299 0.0508609116]\n",
      "[0.968691945 0.934331417]\n",
      "[0.993158758 0.984485269 0.971227705 ... 0.0600705147 0.05768314 0.0506589711]\n",
      "[0.930647433 0.924507737 0.896423817]\n",
      "[0.954868197 0.923459589 0.922917485 ... 0.0516456664 0.0512804389 0.0504951775]\n",
      "[0.978956103 0.978641808 0.963290334 ... 0.0650936067 0.0647569597 0.0628151]\n",
      "[0.982361436 0.969273686 0.940611482 ... 0.851685762 0.132372439 0.0785755813]\n",
      "[0.997236967 0.992371202 0.991738677 ... 0.0544554293 0.0536302924 0.0525097847]\n",
      "[0.978251576 0.976961493 0.975772858 ... 0.0967041552 0.0612789094 0.0516636074]\n",
      "[0.991168261 0.921762168 0.305122375]\n",
      "[0.993582249 0.972663641 0.965390682 ... 0.494994819 0.0621260405 0.0545650423]\n",
      "[0.925014377]\n",
      "[0.980923235 0.977949798 0.967663527 ... 0.0538090169 0.0536723733 0.0533904731]\n",
      "[0.969388485 0.951849818 0.945796728 ... 0.879182875 0.597030044 0.0631686747]\n",
      "[0.965025127]\n",
      "[0.999355555 0.942406416 0.209460378]\n",
      "[0.990850925 0.990480185 0.986312747 ... 0.0580748022 0.0566824079 0.0507608354]\n",
      "[0.993634939 0.989100575 0.982486606 ... 0.0542213023 0.0528990626 0.0526830852]\n",
      "[0.969863 0.968227148 0.965541244 ... 0.0593612194 0.0575689375 0.0526988804]\n",
      "[0.955248713 0.953422546 0.952197254 ... 0.918314755 0.146062046 0.0572648346]\n",
      "[0.970484436]\n",
      "[0.986167312 0.969082057 0.9277426]\n",
      "[0.999812424 0.99867624 0.994784 ... 0.0741137266 0.0695947707 0.0645550191]\n",
      "[0.997651339 0.981716156 0.970213413 ... 0.0510157645 0.0509755611 0.0503214598]\n",
      "[0.986577034 0.97707969 0.93095392]\n",
      "[0.994333744 0.988507509 0.987677276 ... 0.051460892 0.0508490205 0.0500246882]\n",
      "[0.977242231 0.967381835 0.950806141 0.0575165451]\n",
      "[0.988199115 0.906709671]\n",
      "[0.998112261 0.997005701 0.996211469 ... 0.96438396 0.90988487 0.0573544502]\n",
      "[0.997920752 0.997317791 0.994425654 ... 0.0546382666 0.0534938872 0.0506462157]\n",
      "[0.996421576 0.98354876 0.963698745 ... 0.0546008945 0.0514801443 0.0508435369]\n",
      "[0.994890809 0.984133959 0.979542375 ... 0.0750509501 0.0622546077 0.0508184433]\n",
      "[0.987830162 0.974883318 0.926388085]\n",
      "[0.990884364 0.990875721 0.990116179 ... 0.0541501641 0.0519219637 0.050288707]\n",
      "[0.988721132 0.983694553 0.982885122 ... 0.0556974411 0.0528784692 0.0523886085]\n",
      "[0.995968282 0.973844945]\n",
      "[0.999197721 0.996365726 0.995466113 ... 0.0518531799 0.0511312187 0.050019443]\n",
      "[0.978747249 0.976359189 0.974156916 ... 0.193423629 0.152863741 0.0637714565]\n",
      "FastEstimator-Eval: step: 1032; epoch: 171; focal_loss: 0.0002989; l1_loss: 0.013862; total_loss: 0.0141609; \n",
      "FastEstimator-Train: step: 1032; focal_loss: 0.0002642; l1_loss: 0.0167011; total_loss: 0.0169653; examples/sec: 32.4; progress: 86.0%; \n",
      "FastEstimator-Train: step: 1033; focal_loss: 0.0001664; l1_loss: 0.0190967; total_loss: 0.0192631; examples/sec: 32.3; progress: 86.1%; \n",
      "FastEstimator-Train: step: 1034; focal_loss: 0.0001789; l1_loss: 0.033896; total_loss: 0.0340749; examples/sec: 32.2; progress: 86.2%; \n",
      "FastEstimator-Train: step: 1035; focal_loss: 0.0001034; l1_loss: 0.0439584; total_loss: 0.0440618; examples/sec: 32.5; progress: 86.2%; \n",
      "FastEstimator-Train: step: 1036; focal_loss: 0.0002114; l1_loss: 0.0216734; total_loss: 0.0218847; examples/sec: 32.4; progress: 86.3%; \n",
      "FastEstimator-Train: step: 1037; focal_loss: 0.0002361; l1_loss: 0.0198528; total_loss: 0.0200888; examples/sec: 32.3; progress: 86.4%; \n",
      "[0.980419874]\n",
      "[0.979090691 0.945544541]\n",
      "[0.992242217 0.984420061 0.983266771 ... 0.290377796 0.0719876885 0.0601285696]\n",
      "[0.935021639 0.90589273]\n",
      "[0.989614725 0.985755 0.962720156 ... 0.0539177954 0.0529097021 0.0508663058]\n",
      "[0.99088794 0.970243692 0.965384662 ... 0.558850527 0.373460025 0.060167551]\n",
      "[0.98448056 0.982429266 0.95795846 0.937151313 0.916874528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9248631 0.922335505 0.92173934 0.906282663 0.896382689 0.0563687384]\n",
      "[0.999329805 0.994101763 0.993508041 ... 0.0519072413 0.0507842898 0.0506363809]\n",
      "[0.996080279 0.968080878 0.947391748 0.921318173 0.0979743]\n",
      "[0.998008966 0.997288465 0.953228533 ... 0.0541307032 0.0513356924 0.0512887239]\n",
      "[0.976473331 0.963578224 0.962343216 0.934206665]\n",
      "[0.999112844 0.996815324 0.99589777 ... 0.054446876 0.0543829501 0.0505403876]\n",
      "[0.965428054 0.901393414]\n",
      "[0.993909717 0.984258175 0.969554543 ... 0.0683645904 0.063857913 0.0621712804]\n",
      "[0.912342906 0.909073114 0.898583531]\n",
      "[0.944823861 0.916793585 0.912161827 ... 0.103150994 0.0851315558 0.0597860813]\n",
      "[0.977058887 0.976176798 0.970231116 ... 0.0647547841 0.0612030625 0.0537332892]\n",
      "[0.98449862 0.967917085 0.93182987 ... 0.108332485 0.0911786854 0.066110909]\n",
      "[0.99730432 0.993507385 0.992193103 ... 0.0527473688 0.050457 0.0502204299]\n",
      "[0.975804925 0.975721359 0.969468713 ... 0.128074944 0.07730335 0.059743762]\n",
      "[0.990686297 0.919788361 0.298094094]\n",
      "[0.993301034 0.976031303 0.967927516 ... 0.910148621 0.890769422 0.0597844422]\n",
      "[0.934745252]\n",
      "[0.984573722 0.979988754 0.970214605 ... 0.0540137887 0.0532225072 0.0505571365]\n",
      "[0.970455825 0.951451063 0.943003476 ... 0.869401932 0.609208941 0.0508318543]\n",
      "[0.953006148]\n",
      "[0.999329448 0.942362905 0.194754958]\n",
      "[0.988586664 0.988223076 0.984405279 ... 0.0619778037 0.0555534363 0.0515574515]\n",
      "[0.993301511 0.98957324 0.98608005 ... 0.0519513488 0.0511128902 0.0500980318]\n",
      "[0.973135591 0.97233361 0.972278237 ... 0.0753518641 0.0563339 0.0538110137]\n",
      "[0.955370903 0.953109622 0.952469468 0.931282282 0.91501224 0.149049401]\n",
      "[0.9642272]\n",
      "[0.989041924 0.964266896 0.91876179]\n",
      "[0.999790549 0.998654366 0.994375408 ... 0.0662197471 0.0619957447 0.0551536977]\n",
      "[0.997348428 0.98541069 0.974920511 ... 0.0525490344 0.050522089 0.0502392948]\n",
      "[0.987631559 0.976342678 0.929161429]\n",
      "[0.993644357 0.989958763 0.987869203 ... 0.0511986315 0.0510227978 0.0505068898]\n",
      "[0.979695797 0.971936822 0.941331744 0.0665006638]\n",
      "[0.983295679 0.895529509]\n",
      "[0.99844873 0.997628689 0.996794522 ... 0.906245351 0.381140411 0.0508287549]\n",
      "[0.998066545 0.997337878 0.994865298 ... 0.0545854867 0.0536550283 0.050257057]\n",
      "[0.996560931 0.984097242 0.964759946 ... 0.051035434 0.0505984128 0.050368011]\n",
      "[0.996308446 0.985219 0.976591 ... 0.0666010082 0.064878583 0.0550602674]\n",
      "[0.986158609 0.974434 0.90321511]\n",
      "[0.991311312 0.990398526 0.989337802 ... 0.0561184 0.0536625981 0.0522387028]\n",
      "[0.991483569 0.986543477 0.975243 ... 0.0540870428 0.0528633296 0.0510113239]\n",
      "[0.993812084 0.966949284]\n",
      "FastEstimator-Eval: step: 1038; epoch: 172; focal_loss: 0.0002878; l1_loss: 0.0289391; total_loss: 0.029227; \n",
      "FastEstimator-Train: step: 1038; focal_loss: 0.0002945; l1_loss: 0.0303653; total_loss: 0.0306598; examples/sec: 32.3; progress: 86.5%; \n",
      "FastEstimator-Train: step: 1039; focal_loss: 0.000309; l1_loss: 0.0431883; total_loss: 0.0434974; examples/sec: 32.3; progress: 86.6%; \n",
      "FastEstimator-Train: step: 1040; focal_loss: 0.0005455; l1_loss: 0.0320759; total_loss: 0.0326214; examples/sec: 32.3; progress: 86.7%; \n",
      "FastEstimator-Train: step: 1041; focal_loss: 0.000293; l1_loss: 0.0222003; total_loss: 0.0224934; examples/sec: 32.6; progress: 86.8%; \n",
      "FastEstimator-Train: step: 1042; focal_loss: 0.0001038; l1_loss: 0.0148637; total_loss: 0.0149675; examples/sec: 32.0; progress: 86.8%; \n",
      "FastEstimator-Train: step: 1043; focal_loss: 0.0002282; l1_loss: 0.0108703; total_loss: 0.0110985; examples/sec: 32.3; progress: 86.9%; \n",
      "[0.998991311 0.996287584 0.995495 ... 0.0560564697 0.0551939 0.0534089506]\n",
      "[0.976012349 0.973008156 0.971975923 ... 0.186099589 0.155253053 0.0753034353]\n",
      "[0.985756755]\n",
      "[0.987530947 0.96882844]\n",
      "[0.993006945 0.987768769 0.985749066 ... 0.134531796 0.0665689111 0.0545189083]\n",
      "[0.960478306 0.929341078]\n",
      "[0.988739192 0.983131409 0.959339 ... 0.0619924963 0.0588576198 0.050336659]\n",
      "[0.991416872 0.974803865 0.970512331 ... 0.376735568 0.0727597475 0.0568776131]\n",
      "[0.988174081 0.987916112 0.96246767 0.941307604 0.940970302]\n",
      "[0.955524266 0.954245 0.952103 0.93533659 0.932750046 0.0624101162]\n",
      "[0.999323666 0.995358467 0.994257092 ... 0.0535860658 0.0528548062 0.0503370762]\n",
      "[0.998325586 0.981980801 0.980868578 0.966440439]\n",
      "[0.997543573 0.99725616 0.960095 ... 0.0537884235 0.0528766513 0.0505462]\n",
      "[0.977341115 0.966528058 0.958633304 0.947221637 0.054389745]\n",
      "[0.999159694 0.996358871 0.995781481 ... 0.0534150302 0.0532169938 0.0504421592]\n",
      "[0.975055754 0.923865914]\n",
      "[0.994786918 0.983651042 0.971817 ... 0.0730130672 0.0546361208 0.052930057]\n",
      "[0.942259252 0.94121778 0.926006436]\n",
      "[0.948764 0.931698799 0.913890421 ... 0.0647905171 0.0604733229 0.0552949607]\n",
      "[0.977997839 0.977803707 0.971650958 ... 0.0881776512 0.0706022084 0.0503228307]\n",
      "[0.993393362 0.988870621 0.968357563 ... 0.924438059 0.141731918 0.121994317]\n",
      "[0.996116638 0.993961453 0.992001355 ... 0.0549967 0.0526585281 0.050358057]\n",
      "[0.974902391 0.973116517 0.966468811 ... 0.10496524 0.0848511755 0.0673430264]\n",
      "[0.991800189 0.92606914 0.314484894]\n",
      "[0.994115 0.977111757 0.970829964 ... 0.912540078 0.0599407256 0.057759285]\n",
      "[0.970082164]\n",
      "[0.982614875 0.978892505 0.968285859 ... 0.0556269884 0.0524715185 0.0508679152]\n",
      "[0.970693946 0.963732362 0.948613107 ... 0.889926553 0.649317324 0.0522756577]\n",
      "[0.965800107]\n",
      "[0.999734879 0.956218719 0.227200419]\n",
      "[0.988862276 0.987467229 0.983860433 ... 0.0530488491 0.0523666441 0.0513892472]\n",
      "[0.994957 0.991312921 0.985228181 ... 0.0605612099 0.0538269877 0.053168416]\n",
      "[0.97799319 0.973936141 0.971956849 ... 0.0671817064 0.0654585063 0.05385831]\n",
      "[0.957068563 0.956762791 0.954719186 ... 0.928724408 0.149971068 0.0525464118]\n",
      "[0.969070315]\n",
      "[0.985803246 0.971744657 0.94434762 0.0755908489]\n",
      "[0.999822855 0.998644292 0.995031059 ... 0.0667477846 0.055274725 0.0534712374]\n",
      "[0.997723818 0.986196041 0.97429359 ... 0.0593243539 0.0588373244 0.0569237471]\n",
      "[0.988841653 0.981702626 0.933844805]\n",
      "[0.99545908 0.989582062 0.988826632 ... 0.0503214896 0.0502895713 0.0502110124]\n",
      "[0.984804451 0.968914509 0.952018738 0.0642543435]\n",
      "[0.987846673 0.89902091]\n",
      "[0.997579 0.996780157 0.996634483 ... 0.908130765 0.0527628064 0.0512565076]\n",
      "[0.998348 0.997850299 0.995469213 ... 0.0505107343 0.0502575934 0.0501405895]\n",
      "[0.99669528 0.983743429 0.964100242 ... 0.0534572303 0.0527787805 0.0516030192]\n",
      "[0.997934 0.990831614 0.986744523 ... 0.0696601868 0.059635222 0.057695359]\n",
      "[0.987751245 0.977549791 0.938521266]\n",
      "[0.992226243 0.991460562 0.990937293 ... 0.0527691841 0.0523662269 0.0501709878]\n",
      "FastEstimator-Eval: step: 1044; epoch: 173; focal_loss: 0.0002382; l1_loss: 0.0214933; total_loss: 0.0217316; \n",
      "FastEstimator-Train: step: 1044; focal_loss: 0.0002916; l1_loss: 0.0192937; total_loss: 0.0195853; examples/sec: 32.5; progress: 87.0%; \n",
      "FastEstimator-Train: step: 1045; focal_loss: 0.0001111; l1_loss: 0.032879; total_loss: 0.0329901; examples/sec: 32.2; progress: 87.1%; \n",
      "FastEstimator-Train: step: 1046; focal_loss: 0.000342; l1_loss: 0.0095329; total_loss: 0.0098749; examples/sec: 31.7; progress: 87.2%; \n",
      "FastEstimator-Train: step: 1047; focal_loss: 0.0002066; l1_loss: 0.0139898; total_loss: 0.0141964; examples/sec: 32.1; progress: 87.2%; \n",
      "FastEstimator-Train: step: 1048; focal_loss: 0.0001536; l1_loss: 0.0196426; total_loss: 0.0197962; examples/sec: 32.6; progress: 87.3%; \n",
      "FastEstimator-Train: step: 1049; focal_loss: 0.0003722; l1_loss: 0.0364116; total_loss: 0.0367838; examples/sec: 32.3; progress: 87.4%; \n",
      "[0.99176681 0.983218431 0.978161454 ... 0.0565034151 0.0543603897 0.052749157]\n",
      "[0.992720604 0.96663928]\n",
      "[0.999032676 0.996208668 0.995438695 ... 0.058549583 0.0538343787 0.0532961786]\n",
      "[0.974344969 0.969995618 0.968545079 ... 0.303950429 0.162691593 0.15850991]\n",
      "[0.982447088]\n",
      "[0.978467107 0.948753119]\n",
      "[0.991957366 0.986704648 0.983105719 ... 0.308207691 0.0804724693 0.0608967841]\n",
      "[0.948719859 0.900654256]\n",
      "[0.988900185 0.982266188 0.96164459 ... 0.0607910454 0.0604465902 0.060234338]\n",
      "[0.991630197 0.976396203 0.970849752 ... 0.373725832 0.0659188926 0.0584004223]\n",
      "[0.986787736 0.984331727 0.955919862 0.937219739 0.932411194]\n",
      "[0.943399429 0.940599084 0.938516855 0.926788688 0.91388762 0.0579862297]\n",
      "[0.999261081 0.993574142 0.990184903 ... 0.0510165393 0.0502098501 0.0500510335]\n",
      "[0.99824661 0.980633557 0.965639949 0.940211356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9973979 0.997233748 0.964444757 ... 0.0521481931 0.0519691408 0.0512999]\n",
      "[0.973345757 0.963052273 0.950844109 0.917611361 0.0534599721]\n",
      "[0.999230206 0.996096194 0.995823622 ... 0.0519674718 0.0517619252 0.0509726107]\n",
      "[0.972533762 0.903024673]\n",
      "[0.992974162 0.979554653 0.9713341 ... 0.0763351917 0.0575474501 0.0569527447]\n",
      "[0.919188738 0.914989233 0.911106348]\n",
      "[0.953430295 0.935216784 0.926241517 ... 0.0706892312 0.0506110787 0.0504923165]\n",
      "[0.980948627 0.970191479 0.962477684 ... 0.0630600154 0.0559602976 0.0534963906]\n",
      "[0.99053371 0.980034 0.94910264 ... 0.897099 0.123606116 0.110646337]\n",
      "[0.996332407 0.993434429 0.991652 ... 0.0564774871 0.0542211831 0.0501496196]\n",
      "[0.974349141 0.972078562 0.968316436 ... 0.15008983 0.0935572684 0.0569135547]\n",
      "[0.986255527 0.898531 0.269768476]\n",
      "[0.994748652 0.977309108 0.975004 ... 0.892649055 0.0524658561 0.0516456664]\n",
      "[0.965612531]\n",
      "[0.979616165 0.979038417 0.96524179 ... 0.0513460338 0.0509076118 0.0508337319]\n",
      "[0.973913789 0.972252131 0.942583203 ... 0.891038656 0.654999256 0.052013129]\n",
      "[0.945790112]\n",
      "[0.999312401 0.943643808 0.214893341]\n",
      "[0.990643382 0.987106204 0.983621716 ... 0.0536706746 0.0515975356 0.0511708558]\n",
      "[0.993658066 0.992693782 0.985295951 ... 0.054243952 0.0529228151 0.0505592227]\n",
      "[0.975095749 0.972119451 0.96359694 ... 0.0779686272 0.0550194383 0.0513904393]\n",
      "[0.963167429 0.955710649 0.952287555 ... 0.864914536 0.145734489 0.0504250824]\n",
      "[0.96160686]\n",
      "[0.978842318 0.957145214 0.916707158]\n",
      "[0.999836564 0.998755634 0.995459557 ... 0.0707805753 0.0647383332 0.0631090105]\n",
      "[0.996118546 0.986092448 0.970672846 ... 0.0514534712 0.0505284667 0.0503757]\n",
      "[0.988547802 0.985456347 0.941438675]\n",
      "[0.993689895 0.990454316 0.990014 ... 0.0540606081 0.0521078706 0.0509285331]\n",
      "[0.972804546 0.95609045 0.917944789 0.0596531928]\n",
      "[0.984006703 0.897310555]\n",
      "[0.995976686 0.995678306 0.994776785 ... 0.968918204 0.87222147 0.05417642]\n",
      "[0.99830097 0.997522712 0.995270789 ... 0.0528416336 0.0514315069 0.0511136949]\n",
      "[0.997006655 0.984008849 0.963332534 ... 0.0536155403 0.0528785884 0.0504791439]\n",
      "[0.997115076 0.98787117 0.98127687 ... 0.0679771602 0.0605276823 0.0595808029]\n",
      "FastEstimator-Eval: step: 1050; epoch: 174; focal_loss: 0.0002818; l1_loss: 0.0286781; total_loss: 0.0289599; \n",
      "FastEstimator-Train: step: 1050; focal_loss: 0.000141; l1_loss: 0.0230207; total_loss: 0.0231616; examples/sec: 31.8; progress: 87.5%; \n",
      "FastEstimator-Train: step: 1051; focal_loss: 0.000248; l1_loss: 0.0171821; total_loss: 0.0174302; examples/sec: 32.2; progress: 87.6%; \n",
      "FastEstimator-Train: step: 1052; focal_loss: 0.0001926; l1_loss: 0.0135994; total_loss: 0.013792; examples/sec: 31.8; progress: 87.7%; \n",
      "FastEstimator-Train: step: 1053; focal_loss: 0.0003541; l1_loss: 0.0113193; total_loss: 0.0116733; examples/sec: 32.4; progress: 87.8%; \n",
      "FastEstimator-Train: step: 1054; focal_loss: 7.83e-05; l1_loss: 0.0151281; total_loss: 0.0152064; examples/sec: 32.5; progress: 87.8%; \n",
      "FastEstimator-Train: step: 1055; focal_loss: 0.0002101; l1_loss: 0.0140653; total_loss: 0.0142754; examples/sec: 32.2; progress: 87.9%; \n",
      "[0.992036819 0.979944944 0.956546545]\n",
      "[0.993052065 0.991970897 0.99160707 ... 0.0535485744 0.0525300801 0.0509249568]\n",
      "[0.992598355 0.985720515 0.981613815 ... 0.0511452854 0.0511011779 0.0501315]\n",
      "[0.995706201 0.976453]\n",
      "[0.999268889 0.996862054 0.996551394 ... 0.0577833056 0.0565848053 0.0544241965]\n",
      "[0.97610122 0.971051 0.970176518 ... 0.193230569 0.149422318 0.0879985392]\n",
      "[0.990647793]\n",
      "[0.984217525 0.962757111]\n",
      "[0.993529558 0.987833261 0.987724185 ... 0.0824781358 0.0660002232 0.0648140311]\n",
      "[0.96335876 0.93332386]\n",
      "[0.990706325 0.985896409 0.966884673 ... 0.0585600138 0.057369113 0.0517849028]\n",
      "[0.992227435 0.97360909 0.969872 ... 0.380498827 0.0763644576 0.0618900061]\n",
      "[0.99256134 0.991535723 0.964923501 0.952955842 0.94532156]\n",
      "[0.95901978 0.956196308 0.956095576 0.939787865 0.935389757 0.0584230423]\n",
      "[0.999257803 0.994084835 0.990412 ... 0.0527116656 0.0508835614 0.0507215858]\n",
      "[0.997637928 0.977708936 0.971467793 0.952687]\n",
      "[0.998052359 0.997629702 0.964914858 ... 0.0519965291 0.0517057478 0.0516574681]\n",
      "[0.972524047 0.965639353 0.955569863 0.931949 0.0551776588]\n",
      "[0.999250114 0.996482491 0.99581039 ... 0.0505019426 0.0503519773 0.0502391458]\n",
      "[0.978879571 0.939247]\n",
      "[0.994634748 0.981718361 0.973182738 ... 0.0762668848 0.0583956242 0.0516573489]\n",
      "[0.939766765 0.935074747 0.923253655]\n",
      "[0.958330691 0.942793787 0.935563505 ... 0.0580565631 0.0559974909 0.0504037142]\n",
      "[0.980187893 0.977961898 0.972022474 ... 0.0795032382 0.0613243878 0.0598715246]\n",
      "[0.989979386 0.984105706 0.960849166 ... 0.911026359 0.140012354 0.090469569]\n",
      "[0.997248054 0.993852317 0.992986679 ... 0.0583504438 0.0554319024 0.0538057685]\n",
      "[0.975976825 0.973994136 0.971330583 ... 0.136435866 0.084641248 0.0579572022]\n",
      "[0.991045117 0.924691856 0.308125645]\n",
      "[0.99526155 0.981381476 0.981158 ... 0.0637429059 0.0578493178 0.0567831099]\n",
      "[0.966107905]\n",
      "[0.983603597 0.980713129 0.969192863 ... 0.0578443706 0.0557414 0.054002434]\n",
      "[0.972665429 0.969971418 0.953829765 ... 0.66536957 0.0557622612 0.0523321927]\n",
      "[0.963500857]\n",
      "[0.999487877 0.951649904 0.232615262]\n",
      "[0.992858529 0.990965247 0.986248 ... 0.0526186526 0.0524297059 0.051715523]\n",
      "[0.995082378 0.993902743 0.987279415 ... 0.0613362491 0.052580744 0.0507043302]\n",
      "[0.979480743 0.972693443 0.96828711 ... 0.0683710277 0.060798198 0.0521714687]\n",
      "[0.968650341 0.960048914 0.956995487 ... 0.936115146 0.151136637 0.0521635115]\n",
      "[0.968768597]\n",
      "[0.975791335 0.969765604 0.928765297]\n",
      "[0.999860764 0.99915278 0.996288717 ... 0.0741715729 0.0674151778 0.0548894703]\n",
      "[0.997239411 0.987260461 0.974823773 ... 0.0565727651 0.0510730147 0.0503619611]\n",
      "[0.989213347 0.986268759 0.946679652]\n",
      "[0.995460749 0.99336642 0.991913736 ... 0.0524672866 0.0522259474 0.0506251454]\n",
      "[0.98025775 0.962373495 0.950980783 0.05985865]\n",
      "[0.989132404 0.911644]\n",
      "[0.99647671 0.994789064 0.99400413 ... 0.967867374 0.886522651 0.051338166]\n",
      "[0.998198926 0.997288406 0.995408475 ... 0.0521685481 0.0511605144 0.0506997406]\n",
      "FastEstimator-Eval: step: 1056; epoch: 175; focal_loss: 0.0002236; l1_loss: 0.0143089; total_loss: 0.0145324; \n",
      "FastEstimator-Train: step: 1056; focal_loss: 0.0001558; l1_loss: 0.0249829; total_loss: 0.0251387; examples/sec: 32.1; progress: 88.0%; \n",
      "FastEstimator-Train: step: 1057; focal_loss: 0.0001479; l1_loss: 0.0192473; total_loss: 0.0193951; examples/sec: 32.1; progress: 88.1%; \n",
      "FastEstimator-Train: step: 1058; focal_loss: 0.0001432; l1_loss: 0.0132203; total_loss: 0.0133635; examples/sec: 32.2; progress: 88.2%; \n",
      "FastEstimator-Train: step: 1059; focal_loss: 0.000493; l1_loss: 0.0197864; total_loss: 0.0202794; examples/sec: 32.4; progress: 88.2%; \n",
      "FastEstimator-Train: step: 1060; focal_loss: 0.0002289; l1_loss: 0.0400695; total_loss: 0.0402984; examples/sec: 32.5; progress: 88.3%; \n",
      "FastEstimator-Train: step: 1061; focal_loss: 0.0002008; l1_loss: 0.0360322; total_loss: 0.036233; examples/sec: 32.3; progress: 88.4%; \n",
      "[0.996823668 0.983952284 0.962042391 ... 0.0529273748 0.051232785 0.0508629382]\n",
      "[0.996836483 0.98837018 0.979330659 ... 0.0720219 0.0712522268 0.0620402098]\n",
      "[0.991416812 0.975904226 0.939246058]\n",
      "[0.993213177 0.99083817 0.989348412 ... 0.0544210374 0.0531035364 0.05101946]\n",
      "[0.99339211 0.985773921 0.980055034 ... 0.0548946857 0.0544573963 0.0527832508]\n",
      "[0.995041251 0.974123836]\n",
      "[0.99927032 0.996095479 0.995047271 ... 0.0603554249 0.0580335557 0.0503026247]\n",
      "[0.971365571 0.967756212 0.964860916 ... 0.17931515 0.125934869 0.073299855]\n",
      "[0.987203896]\n",
      "[0.979583263 0.949779928]\n",
      "[0.993497 0.989124775 0.984549165 ... 0.0592333078 0.0527693033 0.05150491]\n",
      "[0.949785 0.905025601]\n",
      "[0.991020918 0.988804102 0.973587155 ... 0.0566455424 0.0560606718 0.0556145608]\n",
      "[0.989130378 0.964693248 0.962253094 ... 0.508805692 0.367017806 0.0565029979]\n",
      "[0.991360426 0.989216328 0.964840531 0.949391603 0.945726633]\n",
      "[0.929253697 0.926344931 0.926137924 0.920757711 0.888584435 0.0546579957]\n",
      "[0.999057293 0.993506432 0.992845237 ... 0.053091377 0.0529330969 0.0514417887]\n",
      "[0.997341156 0.972997069 0.957698822 0.92284435 0.104818732]\n",
      "[0.998145103 0.997868896 0.968296647 ... 0.0541099608 0.0535850823 0.0513097942]\n",
      "[0.97289443 0.967805147 0.963110507 0.932002366 0.0534474254]\n",
      "[0.998857796 0.996094108 0.99372983 ... 0.0534185469 0.0526340306 0.0508897901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.975497 0.91794]\n",
      "[0.993739605 0.977100134 0.969733953 ... 0.0736436546 0.0665171742 0.0560541153]\n",
      "[0.937812328 0.932341933 0.927023053]\n",
      "[0.953803897 0.93892765 0.936814845 ... 0.10090965 0.0806000233 0.0679352283]\n",
      "[0.97721529 0.976297 0.970689178 ... 0.0682659745 0.0638000071 0.0532950461]\n",
      "[0.991286397 0.982503176 0.957021356 ... 0.899774194 0.126107723 0.0941292644]\n",
      "[0.997501791 0.993994832 0.993249893 ... 0.0569611788 0.0535824 0.0524053276]\n",
      "[0.974723637 0.972013593 0.970196784 ... 0.15179345 0.079400748 0.0503405929]\n",
      "[0.989311218 0.90819931 0.277479738]\n",
      "[0.995056093 0.977268815 0.974778175 ... 0.92861867 0.894518614 0.0516808927]\n",
      "[0.954551458]\n",
      "[0.983312488 0.977702141 0.965306878 ... 0.0534710288 0.0520528853 0.0517279804]\n",
      "[0.970039248 0.955344856 0.937042892 ... 0.886612475 0.640746713 0.0606476963]\n",
      "[0.963027477]\n",
      "[0.9993 0.95152843 0.202760905]\n",
      "[0.990979195 0.990930915 0.98563838 ... 0.0544178784 0.0527929962 0.0504693389]\n",
      "[0.993940234 0.993804216 0.984887 ... 0.0537514687 0.0523222089 0.0511361659]\n",
      "[0.980497956 0.974160433 0.972833872 ... 0.0626604557 0.057261914 0.0530552268]\n",
      "[0.965626121 0.956893206 0.951739728 0.924882233 0.912494779 0.138549089]\n",
      "[0.970937133]\n",
      "[0.966892183 0.943166733 0.877394319]\n",
      "[0.999880612 0.999183774 0.996794581 ... 0.079698354 0.0719699562 0.067177]\n",
      "[0.996141493 0.985332489 0.978056669 ... 0.0561441481 0.0525785685 0.0512421429]\n",
      "[0.986789823 0.98473084 0.944979548]\n",
      "[0.993963778 0.993159533 0.992908597 ... 0.0504491925 0.0502864718 0.050152719]\n",
      "[0.978875697 0.965661883 0.935773611 0.061041832]\n",
      "[0.984452963 0.907912254]\n",
      "FastEstimator-Eval: step: 1062; epoch: 176; focal_loss: 0.0002472; l1_loss: 0.0266692; total_loss: 0.0269164; \n",
      "FastEstimator-Train: step: 1062; focal_loss: 0.0002766; l1_loss: 0.0303692; total_loss: 0.0306458; examples/sec: 31.8; progress: 88.5%; \n",
      "FastEstimator-Train: step: 1063; focal_loss: 0.0001975; l1_loss: 0.0087963; total_loss: 0.0089938; examples/sec: 32.2; progress: 88.6%; \n",
      "FastEstimator-Train: step: 1064; focal_loss: 0.0001917; l1_loss: 0.0170327; total_loss: 0.0172244; examples/sec: 32.3; progress: 88.7%; \n",
      "FastEstimator-Train: step: 1065; focal_loss: 0.0001452; l1_loss: 0.0267059; total_loss: 0.0268511; examples/sec: 32.3; progress: 88.8%; \n",
      "FastEstimator-Train: step: 1066; focal_loss: 0.0001402; l1_loss: 0.0305698; total_loss: 0.03071; examples/sec: 32.7; progress: 88.8%; \n",
      "FastEstimator-Train: step: 1067; focal_loss: 0.000278; l1_loss: 0.0352205; total_loss: 0.0354984; examples/sec: 32.1; progress: 88.9%; \n",
      "[0.996461868 0.994777799 0.994775951 ... 0.969195604 0.907414436 0.0500303209]\n",
      "[0.998573899 0.998295903 0.997072339 ... 0.0505253375 0.0504441261 0.0504283]\n",
      "[0.997365594 0.987038791 0.968807697 ... 0.0525639951 0.0514467657 0.0500754714]\n",
      "[0.996827066 0.986734509 0.981946111 ... 0.0626678765 0.0615633726 0.0615216792]\n",
      "[0.990478516 0.980057955 0.951028585]\n",
      "[0.99327755 0.990897059 0.990503609 ... 0.052801162 0.0511662066 0.0507988036]\n",
      "[0.993913054 0.987409234 0.979773879 ... 0.0512454212 0.0503644943 0.050116241]\n",
      "[0.99556762 0.977445]\n",
      "[0.999391854 0.996677399 0.995199203 ... 0.0601962805 0.0562728047 0.0503220856]\n",
      "[0.977803826 0.973201454 0.971215725 ... 0.186745733 0.122749597 0.0750264227]\n",
      "[0.985262632]\n",
      "[0.985896528 0.967515469]\n",
      "[0.99431932 0.988755047 0.988569 ... 0.0540793836 0.0537914932 0.0516787171]\n",
      "[0.962821841 0.919913471]\n",
      "[0.992772162 0.991171896 0.979751825 ... 0.0527687073 0.0518217385 0.0510046482]\n",
      "[0.988820791 0.962088943 0.961806417 ... 0.368484139 0.0576675534 0.0540277958]\n",
      "[0.991847694 0.990167379 0.969681323 0.958098412 0.953876376]\n",
      "[0.946411848 0.945409775 0.942916274 0.93348 0.920038104 0.0563751757]\n",
      "[0.999296784 0.994226813 0.993546 ... 0.0508186817 0.0504283309 0.0500864387]\n",
      "[0.997814536 0.97500658 0.967714071 0.938339591 0.104923934]\n",
      "[0.998280227 0.998100638 0.972213507 ... 0.0573094189 0.0552079976 0.0533855259]\n",
      "[0.97650218 0.971016884 0.9654634 0.949424267 0.0575208664]\n",
      "[0.998827159 0.995857775 0.993341744 ... 0.0528410971 0.052652 0.051854223]\n",
      "[0.979990065 0.933326244]\n",
      "[0.99462378 0.977677941 0.97374773 ... 0.0706800818 0.0640185773 0.0591249466]\n",
      "[0.947903872 0.940696597 0.933121204]\n",
      "[0.955457211 0.939114034 0.933736444 ... 0.0670693517 0.0627180338 0.0521954298]\n",
      "[0.981507242 0.976494908 0.975048542 ... 0.0985162556 0.0844048 0.0680797398]\n",
      "[0.993336558 0.987685204 0.968103588 ... 0.919363916 0.133011639 0.0969334245]\n",
      "[0.998140574 0.994712353 0.993663669 ... 0.0564079285 0.054151386 0.0501385629]\n",
      "[0.976032615 0.974045336 0.971308947 ... 0.152634174 0.0814124346 0.0508461893]\n",
      "[0.9920187 0.920767725 0.304522693]\n",
      "[0.995247304 0.977013111 0.974225879 ... 0.915069878 0.0519482195 0.0516161323]\n",
      "[0.956474185]\n",
      "[0.985842109 0.979379416 0.966468692 ... 0.0521986485 0.0503469408 0.0501973927]\n",
      "[0.977121592 0.963355899 0.944247484 ... 0.0627522767 0.0555659533 0.0505008101]\n",
      "[0.977459788]\n",
      "[0.999437392 0.95337534 0.201034486]\n",
      "[0.990813673 0.989858031 0.986704946 ... 0.0531635284 0.0510609746 0.0508157]\n",
      "[0.995179117 0.994623661 0.986675739 ... 0.0534987748 0.0527555943 0.0507560968]\n",
      "[0.9864856 0.978503704 0.975953698 ... 0.0713968277 0.0554229319 0.054956913]\n",
      "[0.96919322 0.963398 0.960653305 ... 0.144863397 0.0537700951 0.0503217]\n",
      "[0.972910404]\n",
      "[0.974939585 0.959583163 0.91911608]\n",
      "[0.99989748 0.999198377 0.997172713 ... 0.0764336884 0.0745999217 0.0650945306]\n",
      "[0.99687469 0.985645533 0.980730891 ... 0.0519149303 0.0514312088 0.0512424707]\n",
      "[0.988076568 0.985178828 0.952331185]\n",
      "[0.995362639 0.993174493 0.99305433 ... 0.0551291704 0.0546960533 0.0502843261]\n",
      "FastEstimator-Eval: step: 1068; epoch: 177; focal_loss: 0.0002162; l1_loss: 0.0117633; total_loss: 0.0119795; \n",
      "FastEstimator-Train: step: 1068; focal_loss: 0.0001728; l1_loss: 0.0049569; total_loss: 0.0051298; examples/sec: 31.6; progress: 89.0%; \n",
      "FastEstimator-Train: step: 1069; focal_loss: 0.000259; l1_loss: 0.012152; total_loss: 0.012411; examples/sec: 32.3; progress: 89.1%; \n",
      "FastEstimator-Train: step: 1070; focal_loss: 0.0001577; l1_loss: 0.0251696; total_loss: 0.0253273; examples/sec: 32.4; progress: 89.2%; \n",
      "FastEstimator-Train: step: 1071; focal_loss: 0.0002081; l1_loss: 0.0417235; total_loss: 0.0419315; examples/sec: 31.2; progress: 89.2%; \n",
      "FastEstimator-Train: step: 1072; focal_loss: 0.0002126; l1_loss: 0.0472227; total_loss: 0.0474353; examples/sec: 32.4; progress: 89.3%; \n",
      "FastEstimator-Train: step: 1073; focal_loss: 0.0003008; l1_loss: 0.0262148; total_loss: 0.0265156; examples/sec: 32.7; progress: 89.4%; \n",
      "[0.988562465 0.971511424 0.960267544 0.0536819398]\n",
      "[0.992361844 0.928827882]\n",
      "[0.995353699 0.994514048 0.994159758 ... 0.893028736 0.231298596 0.0547747]\n",
      "[0.998194933 0.998134613 0.996152639 ... 0.0502779782 0.0502567589 0.0501766205]\n",
      "[0.99712348 0.986058235 0.966577172 ... 0.0518934429 0.0517691076 0.0517678261]\n",
      "[0.99555552 0.982030272 0.976261795 ... 0.104688644 0.0631625354 0.0613606572]\n",
      "[0.989047 0.982529759 0.95373714]\n",
      "[0.992762804 0.990644217 0.988674641 ... 0.0730817914 0.0533122718 0.0504400432]\n",
      "[0.993089 0.985736668 0.978430748 ... 0.0527054369 0.0522749126 0.05200243]\n",
      "[0.996012032 0.979699492]\n",
      "[0.999301553 0.996727347 0.995601892 ... 0.0552022755 0.055033 0.0501584709]\n",
      "[0.977477968 0.969628 0.968711376 ... 0.135321766 0.114122838 0.0530211329]\n",
      "[0.979791164]\n",
      "[0.990581274 0.979251862]\n",
      "[0.994023621 0.990043044 0.987259626 ... 0.0670368373 0.0524475873 0.0522404313]\n",
      "[0.968648136 0.938961267]\n",
      "[0.992722034 0.989859462 0.978118539 ... 0.0633828044 0.0626121759 0.0584241748]\n",
      "[0.991194189 0.967622876 0.961669326 ... 0.53160584 0.351613522 0.0560518205]\n",
      "[0.991197169 0.990261316 0.971301556 0.952098787 0.947257]\n",
      "[0.965802252 0.962233543 0.958500803 0.945026636 0.941994727 0.059735626]\n",
      "[0.999263763 0.993830323 0.984363854 ... 0.0509404838 0.0509098172 0.0505390763]\n",
      "[0.997301221 0.972225785 0.972082436 0.949935198 0.0926012099]\n",
      "[0.997161865 0.996854424 0.970654964 ... 0.0669140518 0.0604597032 0.0568256676]\n",
      "[0.976879239 0.972831964 0.9624753 0.952155232 0.0577636063]\n",
      "[0.998689175 0.994594812 0.992580652 ... 0.0517861545 0.051669091 0.0501840413]\n",
      "[0.981916785 0.941697836]\n",
      "[0.995036125 0.978987336 0.975847661 ... 0.0671578646 0.0548522472 0.052657038]\n",
      "[0.942594171 0.933927953 0.925653696]\n",
      "[0.957122922 0.943851 0.929480076 ... 0.909042597 0.0717432499 0.058345139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.983539402 0.976738155 0.972765803 ... 0.115266919 0.0849086344 0.0660150051]\n",
      "[0.990755916 0.984455228 0.963570416 ... 0.90372479 0.120969623 0.0735875666]\n",
      "[0.997497559 0.993643403 0.992222846 ... 0.0516170859 0.0507531762 0.050552547]\n",
      "[0.974889398 0.973722458 0.973303795 ... 0.125145286 0.0740614831 0.054071784]\n",
      "[0.991475701 0.926344216 0.319675237 0.0534306169]\n",
      "[0.994843245 0.974055052 0.971219897 ... 0.912039816 0.0613766611 0.0515283942]\n",
      "[0.959061146]\n",
      "[0.983350635 0.978821337 0.965793669 ... 0.0549486 0.0525002778 0.0505225062]\n",
      "[0.974224746 0.960082293 0.952778935 ... 0.679761827 0.0581150353 0.0545330048]\n",
      "[0.976155221]\n",
      "[0.999509 0.95206213 0.199294418]\n",
      "[0.988668799 0.988489926 0.985591888 ... 0.0542000532 0.0541402698 0.0529330969]\n",
      "[0.995265 0.994299352 0.988517284 ... 0.0553509295 0.0542103052 0.0517367721]\n",
      "[0.987884283 0.977796793 0.973509192 ... 0.074953258 0.0575661063 0.051704675]\n",
      "[0.967386484 0.961598516 0.960731387 ... 0.140045106 0.0529548526 0.0519749522]\n",
      "[0.973952174]\n",
      "[0.976539373 0.965923309 0.930170774]\n",
      "[0.999875188 0.999077439 0.996905744 ... 0.0707282424 0.0635370612 0.0597962737]\n",
      "[0.996606648 0.983639359 0.978630185 ... 0.0551261604 0.0543251932 0.0526262522]\n",
      "FastEstimator-Eval: step: 1074; epoch: 178; focal_loss: 0.0002106; l1_loss: 0.0142858; total_loss: 0.0144964; \n",
      "FastEstimator-Train: step: 1074; focal_loss: 0.0002098; l1_loss: 0.0170583; total_loss: 0.0172682; examples/sec: 32.0; progress: 89.5%; \n",
      "FastEstimator-Train: step: 1075; focal_loss: 0.0001473; l1_loss: 0.0116385; total_loss: 0.0117859; examples/sec: 32.2; progress: 89.6%; \n",
      "FastEstimator-Train: step: 1076; focal_loss: 0.000291; l1_loss: 0.0170541; total_loss: 0.0173451; examples/sec: 32.3; progress: 89.7%; \n",
      "FastEstimator-Train: step: 1077; focal_loss: 0.0001943; l1_loss: 0.0502638; total_loss: 0.050458; examples/sec: 32.2; progress: 89.8%; \n",
      "FastEstimator-Train: step: 1078; focal_loss: 8.11e-05; l1_loss: 0.0190614; total_loss: 0.0191425; examples/sec: 32.4; progress: 89.8%; \n",
      "FastEstimator-Train: step: 1079; focal_loss: 0.0002216; l1_loss: 0.012631; total_loss: 0.0128527; examples/sec: 32.6; progress: 89.9%; \n",
      "[0.98886013 0.985768259 0.958313167]\n",
      "[0.995466 0.992013574 0.991286576 ... 0.050489068 0.0502201319 0.0501993]\n",
      "[0.984406412 0.968468785 0.938590646 0.053514719]\n",
      "[0.988491893 0.920633]\n",
      "[0.995241165 0.995000243 0.994868636 ... 0.872451663 0.0536611974 0.0529236197]\n",
      "[0.998106599 0.997051537 0.994179249 ... 0.0529049039 0.0522649586 0.0517168641]\n",
      "[0.996917725 0.984114528 0.962479055 ... 0.0521198213 0.0504433215 0.050183]\n",
      "[0.99550581 0.985427201 0.973470867 ... 0.0946116447 0.0613039136 0.0586341023]\n",
      "[0.990632057 0.981646299 0.93841517]\n",
      "[0.991339087 0.986481965 0.983875096 ... 0.052893728 0.0522424281 0.0511086]\n",
      "[0.993051648 0.984294653 0.978830636 ... 0.0535086095 0.0530346334 0.0508956611]\n",
      "[0.995416641 0.976740122]\n",
      "[0.99938488 0.997226477 0.997113526 ... 0.0591064692 0.0570733547 0.0511421561]\n",
      "[0.977090061 0.973477602 0.96922195 ... 0.187414318 0.156053126 0.0930715501]\n",
      "[0.972832441]\n",
      "[0.984416664 0.967402935]\n",
      "[0.992606223 0.986699462 0.985724807 ... 0.0697401762 0.0570273697 0.0511346459]\n",
      "[0.950161934 0.918954611]\n",
      "[0.994146168 0.986514568 0.972929776 ... 0.0620542765 0.0583945513 0.0576666296]\n",
      "[0.99162519 0.967317581 0.960549951 ... 0.537954748 0.338165283 0.0595523417]\n",
      "[0.989677072 0.988864779 0.96681118 0.948489547 0.92876327]\n",
      "[0.949134946 0.948633313 0.94459486 0.937897682 0.92292583 0.0589435399]\n",
      "[0.999352336 0.994079471 0.978960693 ... 0.0530430973 0.0517471731 0.0500790179]\n",
      "[0.997779071 0.976237774 0.957215786 0.933115959 0.106259286]\n",
      "[0.997919798 0.997418165 0.976318717 ... 0.0520892143 0.0518709421 0.050498426]\n",
      "[0.978294611 0.96902132 0.966850758 0.929687202 0.051774323]\n",
      "[0.99885416 0.99432838 0.994300127 ... 0.0534511507 0.052931428 0.0527417958]\n",
      "[0.98030442 0.923126876]\n",
      "[0.994425178 0.979114056 0.973058939 ... 0.0699969232 0.058906436 0.0527539253]\n",
      "[0.917155266 0.913089752 0.897049546]\n",
      "[0.956654489 0.943313837 0.929179728 ... 0.881322622 0.0710971355 0.0508885086]\n",
      "[0.979124844 0.973526716 0.972361445 ... 0.09811005 0.06662637 0.0632808506]\n",
      "[0.989023089 0.976312101 0.948141575 ... 0.881837964 0.109502524 0.0692600608]\n",
      "[0.997506797 0.994790196 0.993101239 ... 0.0550284088 0.0547973812 0.0526481271]\n",
      "[0.978233099 0.978029728 0.975170791 ... 0.191565633 0.162254781 0.0781441629]\n",
      "[0.988545656 0.905755 0.295358241]\n",
      "[0.994292498 0.975811 0.97394675 ... 0.910323 0.0526802838 0.0523584187]\n",
      "[0.928844452]\n",
      "[0.983879387 0.982965 0.973306894 ... 0.0538175106 0.0529125035 0.0504905879]\n",
      "[0.97557354 0.955189109 0.952471197 ... 0.0560925305 0.0527190566 0.0512219071]\n",
      "[0.956540883]\n",
      "[0.999312937 0.954584122 0.19622305]\n",
      "[0.989158154 0.988736391 0.987926722 ... 0.0558397174 0.0555808544 0.0535216033]\n",
      "[0.995026946 0.994776666 0.990525126 ... 0.0532752275 0.0522860885 0.0515065193]\n",
      "[0.987255931 0.976358891 0.971481621 ... 0.880789518 0.0828464627 0.0557285547]\n",
      "[0.968154371 0.962851882 0.955108523 0.940483689 0.920766234 0.165798992]\n",
      "[0.96584332]\n",
      "[0.976713061 0.957881689 0.906379402]\n",
      "FastEstimator-Eval: step: 1080; epoch: 179; focal_loss: 0.0002222; l1_loss: 0.0289568; total_loss: 0.029179; \n",
      "FastEstimator-Train: step: 1080; focal_loss: 0.0002659; l1_loss: 0.0246804; total_loss: 0.0249463; examples/sec: 32.0; progress: 90.0%; \n",
      "FastEstimator-Train: step: 1081; focal_loss: 0.0001751; l1_loss: 0.0352303; total_loss: 0.0354054; examples/sec: 32.0; progress: 90.1%; \n",
      "FastEstimator-Train: step: 1082; focal_loss: 0.0002084; l1_loss: 0.0871381; total_loss: 0.0873465; examples/sec: 32.3; progress: 90.2%; \n",
      "FastEstimator-Train: step: 1083; focal_loss: 7.54e-05; l1_loss: 0.0337754; total_loss: 0.0338508; examples/sec: 32.4; progress: 90.2%; \n",
      "FastEstimator-Train: step: 1084; focal_loss: 0.0002207; l1_loss: 0.0132185; total_loss: 0.0134393; examples/sec: 32.4; progress: 90.3%; \n",
      "FastEstimator-Train: step: 1085; focal_loss: 0.000259; l1_loss: 0.0190974; total_loss: 0.0193564; examples/sec: 32.5; progress: 90.4%; \n",
      "[0.999928236 0.999345362 0.997945547 ... 0.0576756299 0.0576351881 0.0511361957]\n",
      "[0.997054577 0.991352141 0.980450511 ... 0.0538320541 0.053221494 0.0509380102]\n",
      "[0.988705277 0.987214446 0.963874817]\n",
      "[0.996711493 0.992960691 0.992488 ... 0.0545167029 0.0515494049 0.0505824387]\n",
      "[0.990218341 0.969918609 0.961277366 0.0527332723]\n",
      "[0.992251098 0.929586947]\n",
      "[0.996039152 0.995733142 0.995598435 ... 0.964206696 0.910773396 0.050139904]\n",
      "[0.997827113 0.996401 0.993433058 ... 0.0536738634 0.0517906249 0.0515338778]\n",
      "[0.996790409 0.983351 0.960519314 ... 0.0516483188 0.0515068769 0.0511413813]\n",
      "[0.996850848 0.989307642 0.986406 ... 0.0652473569 0.0596008301 0.0553991199]\n",
      "[0.991941929 0.984513283 0.959055185]\n",
      "[0.990762472 0.986761332 0.981024563 ... 0.0531181395 0.0507200956 0.0502733588]\n",
      "[0.994141 0.98259306 0.981676757 ... 0.0516766906 0.0505174696 0.0504848957]\n",
      "[0.997483373 0.984459877]\n",
      "[0.999446213 0.997700393 0.997259378 ... 0.0571178198 0.0566971302 0.0548765361]\n",
      "[0.978534818 0.974445105 0.974439442 ... 0.407570899 0.216894478 0.18773821]\n",
      "[0.986355543]\n",
      "[0.990862727 0.979604363]\n",
      "[0.99288857 0.989983082 0.986452401 ... 0.0621210635 0.0552345812 0.0531198382]\n",
      "[0.976019 0.960473895]\n",
      "[0.99389869 0.986179471 0.971717119 ... 0.0660755634 0.0573046505 0.0550747514]\n",
      "[0.991951108 0.970015168 0.96174258 ... 0.343718 0.0735338926 0.0548016131]\n",
      "[0.995415211 0.995410085 0.973495543 0.962210536 0.956064701]\n",
      "[0.968017459 0.967644691 0.964712143 0.946470857 0.945672035 0.0592388213]\n",
      "[0.99944663 0.995110035 0.987603962 ... 0.0518333614 0.0504480898 0.0502075255]\n",
      "[0.99816823 0.979498625 0.979315877 0.965091407]\n",
      "[0.998092234 0.997517 0.978797555 ... 0.0549397171 0.0517274737 0.051548183]\n",
      "[0.980115712 0.969457626 0.967766166 0.949350953]\n",
      "[0.998948 0.995101213 0.994722 ... 0.0539858043 0.0528268516 0.0522977412]\n",
      "[0.985001445 0.95691669]\n",
      "[0.995328128 0.98069942 0.972748399 ... 0.898873 0.0626883507 0.0575584769]\n",
      "[0.933737397 0.928123 0.925737202]\n",
      "[0.956525922 0.948382735 0.929339886 ... 0.0751861 0.0711427927 0.0565679073]\n",
      "[0.98119545 0.975355685 0.972913504 ... 0.0882507265 0.0840918422 0.0585235655]\n",
      "[0.993216872 0.989079118 0.973752737 ... 0.138869256 0.13336888 0.0691710711]\n",
      "[0.9977265 0.994977236 0.993827343 ... 0.0532938242 0.0524379611 0.0518823862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.979003251 0.977587581 0.974831522 ... 0.112606525 0.0746539533 0.0515412688]\n",
      "[0.994459748 0.937552691 0.35363704]\n",
      "[0.994242132 0.976241827 0.973953485 ... 0.926225781 0.0579358935 0.0525268316]\n",
      "[0.943209469]\n",
      "[0.987177491 0.984319568 0.970167875 ... 0.05215469 0.0508452654 0.0504122376]\n",
      "[0.974866688 0.963385701 0.94635278 ... 0.0790320933 0.0594228506 0.0521400869]\n",
      "[0.964806437]\n",
      "[0.999799311 0.969000459 0.228531778]\n",
      "[0.99247086 0.991927803 0.990686536 ... 0.0575997829 0.0562259257 0.0533243418]\n",
      "[0.99611038 0.994628787 0.991057396 ... 0.0524891019 0.0524512827 0.0501692593]\n",
      "[0.986950457 0.976912141 0.975862622 ... 0.0806909502 0.0638891757 0.0603006482]\n",
      "[0.968233824 0.96219033 0.957398891 ... 0.932572246 0.157403767 0.0656243265]\n",
      "FastEstimator-Eval: step: 1086; epoch: 180; focal_loss: 0.0002071; l1_loss: 0.032629; total_loss: 0.0328361; \n",
      "FastEstimator-Train: step: 1086; focal_loss: 0.0003444; l1_loss: 0.0168491; total_loss: 0.0171935; examples/sec: 32.4; progress: 90.5%; \n",
      "FastEstimator-Train: step: 1087; focal_loss: 0.0001813; l1_loss: 0.0237775; total_loss: 0.0239588; examples/sec: 31.7; progress: 90.6%; \n",
      "FastEstimator-Train: step: 1088; focal_loss: 0.0001619; l1_loss: 0.0526278; total_loss: 0.0527897; examples/sec: 32.2; progress: 90.7%; \n",
      "FastEstimator-Train: step: 1089; focal_loss: 0.0001654; l1_loss: 0.0196175; total_loss: 0.0197828; examples/sec: 32.1; progress: 90.8%; \n",
      "FastEstimator-Train: step: 1090; focal_loss: 0.0002112; l1_loss: 0.0145633; total_loss: 0.0147745; examples/sec: 31.9; progress: 90.8%; \n",
      "FastEstimator-Train: step: 1091; focal_loss: 0.0001155; l1_loss: 0.0100425; total_loss: 0.0101579; examples/sec: 32.7; progress: 90.9%; \n",
      "[0.962072372]\n",
      "[0.976046205 0.956970692 0.910067081]\n",
      "[0.999932647 0.999420464 0.998115361 ... 0.0526697338 0.0523193479 0.050822556]\n",
      "[0.99548316 0.989266276 0.976354539 ... 0.0539160967 0.0530103147 0.0523215234]\n",
      "[0.988015294 0.986917 0.965726793]\n",
      "[0.995369315 0.993190169 0.992061377 ... 0.0548265278 0.0511285961 0.0507963598]\n",
      "[0.98474 0.966947913 0.937942386 0.0570299625]\n",
      "[0.988060951 0.928792238]\n",
      "[0.996299148 0.995503724 0.995175481 ... 0.96672 0.899611831 0.297262818]\n",
      "[0.997492373 0.996518612 0.993829966 ... 0.0530400276 0.0518350601 0.0501498]\n",
      "[0.996211 0.980906129 0.958994865 ... 0.0545155406 0.0513202548 0.0500613749]\n",
      "[0.995973229 0.984676659 0.976950049 ... 0.0571681559 0.0559009612 0.0530776083]\n",
      "[0.991250038 0.982820868 0.93989706]\n",
      "[0.990084231 0.983932 0.974305093 ... 0.0541068912 0.0522933602 0.0508024693]\n",
      "[0.994145393 0.97891748 0.976478338 ... 0.0514554977 0.0513314903 0.0502051711]\n",
      "[0.994640708 0.975664496]\n",
      "[0.999554157 0.997771 0.996442139 ... 0.0582716465 0.0515288115 0.0509875715]\n",
      "[0.979951322 0.972385883 0.969811618 ... 0.315469503 0.18085292 0.157531977]\n",
      "[0.965967059]\n",
      "[0.984984279 0.967279673]\n",
      "[0.991354 0.985250592 0.983327925 ... 0.0787465274 0.0519020259 0.0515729785]\n",
      "[0.966913223 0.938046932]\n",
      "[0.993607163 0.986357749 0.972496033 ... 0.0569201112 0.0569055378 0.0559340715]\n",
      "[0.991140246 0.968413174 0.960207582 ... 0.50960207 0.328411698 0.0527343452]\n",
      "[0.989960551 0.98893249 0.971169591 0.95905143 0.935399532]\n",
      "[0.949929 0.948802 0.941371202 0.939993739 0.911139488 0.0523330271]\n",
      "[0.99940443 0.994636178 0.990268588 ... 0.0508185327 0.0503851473 0.0502030849]\n",
      "[0.998141885 0.977300465 0.960025311 0.922322333 0.0996785164]\n",
      "[0.997889638 0.997362196 0.980131 ... 0.0508721471 0.0500872135 0.0500191748]\n",
      "[0.9768067 0.970559 0.965144336 0.935074031]\n",
      "[0.998685241 0.994706929 0.994406 ... 0.0534533262 0.052944392 0.050421]\n",
      "[0.981206656 0.929206]\n",
      "[0.993614912 0.978561759 0.970603704 ... 0.896997929 0.888277411 0.0570735037]\n",
      "[0.919011712 0.916735172 0.914660811]\n",
      "[0.950626612 0.946589 0.93334341 ... 0.884680569 0.0955796242 0.0677452087]\n",
      "[0.98006314 0.97377193 0.973653555 ... 0.301171601 0.11591047 0.0680077672]\n",
      "[0.993068 0.982345045 0.959605455 ... 0.898989797 0.114233524 0.0784466565]\n",
      "[0.998065948 0.994478583 0.994007885 ... 0.0560383499 0.053632766 0.051453203]\n",
      "[0.975208521 0.972986937 0.969594121 ... 0.168646008 0.140656561 0.0733879805]\n",
      "[0.992137194 0.927684128 0.300473213]\n",
      "[0.993711233 0.968664527 0.965723515 ... 0.911528707 0.896406651 0.5646047]\n",
      "[0.93259418]\n",
      "[0.986959636 0.983116269 0.956862688 ... 0.0551977158 0.0516805947 0.0506307185]\n",
      "[0.979647219 0.969326913 0.956129849 ... 0.695207238 0.0517533123 0.05120188]\n",
      "[0.941152573]\n",
      "[0.999594331 0.961951 0.207062781]\n",
      "[0.992828 0.991584778 0.989717484 ... 0.0604302 0.0585783422 0.0546758175]\n",
      "[0.995601594 0.993936181 0.98778975 ... 0.0536861122 0.0531902611 0.0521984398]\n",
      "FastEstimator-Eval: step: 1092; epoch: 181; focal_loss: 0.0002397; l1_loss: 0.0341301; total_loss: 0.0343699; \n",
      "FastEstimator-Train: step: 1092; focal_loss: 0.0001951; l1_loss: 0.0143505; total_loss: 0.0145456; examples/sec: 32.2; progress: 91.0%; \n",
      "FastEstimator-Train: step: 1093; focal_loss: 0.0002282; l1_loss: 0.0383507; total_loss: 0.0385789; examples/sec: 32.5; progress: 91.1%; \n",
      "FastEstimator-Train: step: 1094; focal_loss: 0.0001834; l1_loss: 0.0334631; total_loss: 0.0336466; examples/sec: 32.0; progress: 91.2%; \n",
      "FastEstimator-Train: step: 1095; focal_loss: 9.43e-05; l1_loss: 0.0391392; total_loss: 0.0392335; examples/sec: 32.5; progress: 91.2%; \n",
      "FastEstimator-Train: step: 1096; focal_loss: 0.0002479; l1_loss: 0.0300041; total_loss: 0.030252; examples/sec: 32.3; progress: 91.3%; \n",
      "FastEstimator-Train: step: 1097; focal_loss: 0.0002609; l1_loss: 0.0291209; total_loss: 0.0293818; examples/sec: 32.3; progress: 91.4%; \n",
      "[0.985963404 0.981025457 0.976195574 ... 0.0734484792 0.0579158664 0.0563465059]\n",
      "[0.973275125 0.969729066 0.958576322 0.940018415 0.922293782 0.155106038]\n",
      "[0.972359955]\n",
      "[0.981180727 0.966924071 0.925635934 0.0586241186]\n",
      "[0.999937654 0.999463677 0.998195112 ... 0.0604575276 0.0557923019 0.0503997207]\n",
      "[0.99644959 0.990904 0.983023942 ... 0.0528020263 0.0528013408 0.0517992079]\n",
      "[0.991112113 0.990730405 0.966451824]\n",
      "[0.995784879 0.994257689 0.99367857 ... 0.0514845252 0.050547719 0.0502657]\n",
      "[0.986082 0.976413846 0.94016242 0.0605369806]\n",
      "[0.990345597 0.948095679]\n",
      "[0.996935427 0.996400714 0.996230483 0.995633125 0.97020328 0.914360046]\n",
      "[0.998653114 0.998551607 0.996674538 ... 0.0530844331 0.0529630184 0.0528301299]\n",
      "[0.99701643 0.983831882 0.965604186 ... 0.0569414496 0.0540922 0.0514585972]\n",
      "[0.996881 0.988112 0.980782509 ... 0.0654215813 0.0601426661 0.0512461364]\n",
      "[0.992418528 0.984028637 0.946997643]\n",
      "[0.992329478 0.986293733 0.979329407 ... 0.0706320107 0.0538506806 0.0526735485]\n",
      "[0.995008707 0.981413126 0.979500592 ... 0.0516132414 0.0511508286 0.0510762036]\n",
      "[0.995420456 0.979720116]\n",
      "[0.999607742 0.997943759 0.99691 ... 0.0544427037 0.0536865592 0.052134186]\n",
      "[0.983205557 0.977953076 0.977192283 ... 0.160809308 0.151342958 0.0607177317]\n",
      "[0.964087725]\n",
      "[0.98652941 0.969862342]\n",
      "[0.992657185 0.987365365 0.984372497 ... 0.270530343 0.105331481 0.0801431835]\n",
      "[0.966275752 0.925957739]\n",
      "[0.995906949 0.992980838 0.986978233 ... 0.0548156202 0.0524655282 0.0502710044]\n",
      "[0.993971348 0.974668562 0.970946789 ... 0.554304481 0.365759373 0.0581009686]\n",
      "[0.99155879 0.990033269 0.974269032 0.961972177 0.949597359]\n",
      "[0.956381917 0.955955505 0.950533628 0.941847324 0.916800261 0.0537473261]\n",
      "[0.999536395 0.995210886 0.992848873 ... 0.0504696965 0.0502257645 0.0501321852]\n",
      "[0.998715401 0.980509698 0.964045167 0.923503399]\n",
      "[0.99841 0.998139262 0.977456272 ... 0.0508656204 0.0508484542 0.0508243144]\n",
      "[0.980860114 0.973072588 0.970013142 0.942733049 0.0928197205]\n",
      "[0.999055862 0.996601343 0.995737433 ... 0.0548931658 0.0528062582 0.050121516]\n",
      "[0.983004928 0.927512765]\n",
      "[0.994128704 0.978573501 0.97093 ... 0.891960382 0.0569519401 0.0511201024]\n",
      "[0.939305305 0.935073376 0.934944868]\n",
      "[0.958093762 0.952444077 0.943197 ... 0.0747537613 0.0618067086 0.0542681813]\n",
      "[0.982049108 0.978351593 0.977171898 ... 0.312726259 0.127499521 0.0592585802]\n",
      "[0.995645881 0.987800837 0.969958901 ... 0.920538127 0.1206882 0.0973214507]\n",
      "[0.998409629 0.995888352 0.99587667 ... 0.0526151061 0.0513466 0.0502254069]\n",
      "[0.979375482 0.977366686 0.973326147 ... 0.167578161 0.152806163 0.0723375082]\n",
      "[0.99389112 0.931743741 0.310641289]\n",
      "[0.995154381 0.975345433 0.973875523 ... 0.929405332 0.896081328 0.0525597334]\n",
      "[0.96442616]\n",
      "[0.991064548 0.981650829 0.966965318 ... 0.0518026352 0.0503414273 0.0503089726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.982245266 0.976283371 0.951018333 ... 0.721278608 0.063839823 0.0521264374]\n",
      "[0.957693815]\n",
      "[0.999631882 0.965135455 0.191378117]\n",
      "FastEstimator-Eval: step: 1098; epoch: 182; focal_loss: 0.0001902; l1_loss: 0.038629; total_loss: 0.0388192; \n",
      "FastEstimator-Train: step: 1098; focal_loss: 0.0001579; l1_loss: 0.0476138; total_loss: 0.0477717; examples/sec: 32.1; progress: 91.5%; \n",
      "FastEstimator-Train: step: 1099; focal_loss: 0.0001406; l1_loss: 0.0432512; total_loss: 0.0433919; examples/sec: 32.2; progress: 91.6%; \n",
      "FastEstimator-Train: step: 1100; focal_loss: 0.0002008; l1_loss: 0.0200927; total_loss: 0.0202935; examples/sec: 32.3; progress: 91.7%; \n",
      "FastEstimator-Train: step: 1101; focal_loss: 9.16e-05; l1_loss: 0.0271924; total_loss: 0.0272841; examples/sec: 31.8; progress: 91.8%; \n",
      "FastEstimator-Train: step: 1102; focal_loss: 0.0003646; l1_loss: 0.0212213; total_loss: 0.0215859; examples/sec: 32.3; progress: 91.8%; \n",
      "FastEstimator-Train: step: 1103; focal_loss: 0.0001309; l1_loss: 0.0224022; total_loss: 0.0225331; examples/sec: 32.1; progress: 91.9%; \n",
      "[0.990323663 0.990138948 0.987205446 ... 0.0559056401 0.0510183573 0.0509853959]\n",
      "[0.996199489 0.992834866 0.98887 ... 0.0514134169 0.0511616766 0.0506117046]\n",
      "[0.981127 0.973917246 0.973138928 ... 0.0632089376 0.0526839495 0.0519963205]\n",
      "[0.963461459 0.958619237 0.948583305 ... 0.137859464 0.0571406782 0.0502430499]\n",
      "[0.974961042]\n",
      "[0.979846716 0.96939826 0.927227259]\n",
      "[0.999864578 0.999208212 0.997569263 ... 0.0590803623 0.0559320748 0.0514172614]\n",
      "[0.99524492 0.988645911 0.982234716 ... 0.0518662632 0.0513098538 0.050231874]\n",
      "[0.989629269 0.989007 0.965939522]\n",
      "[0.996463418 0.993819 0.992827415 ... 0.0534945428 0.0522000194 0.0503423512]\n",
      "[0.986714721 0.973071039 0.950920105 0.0601772368]\n",
      "[0.990541279 0.941942334]\n",
      "[0.996692955 0.996281683 0.996228397 0.995221674 0.966878235 0.885645568]\n",
      "[0.999016166 0.998908043 0.997437239 ... 0.0515099764 0.0513398349 0.0506283641]\n",
      "[0.996455431 0.982438505 0.961568356 ... 0.053818047 0.0537518859 0.0510655642]\n",
      "[0.995840728 0.989033222 0.975735664 ... 0.0564745069 0.0560896695 0.0509822369]\n",
      "[0.990319312 0.982199907 0.939997]\n",
      "[0.991986334 0.985689282 0.978703499 ... 0.0933119059 0.0821828246 0.0683600903]\n",
      "[0.992608845 0.967608333 0.966064 ... 0.0516620278 0.051289022 0.050639838]\n",
      "[0.996395051 0.984124303]\n",
      "[0.999536395 0.997707 0.995868266 ... 0.0588133037 0.0583378971 0.0567196906]\n",
      "[0.979558349 0.973985493 0.97148174 ... 0.8876127 0.300055593 0.16632539]\n",
      "[0.974789798]\n",
      "[0.988161266 0.972162068]\n",
      "[0.990595937 0.985590577 0.984023154 ... 0.145537943 0.0882448256 0.055526346]\n",
      "[0.950531602 0.913722515]\n",
      "[0.995730579 0.994072199 0.989007115 ... 0.0592890084 0.0533233 0.0519718826]\n",
      "[0.993351817 0.969838142 0.967336416 ... 0.954517365 0.540455043 0.369487703]\n",
      "[0.991946697 0.991368353 0.970936239 0.952529848 0.952073097]\n",
      "[0.963583 0.961160064 0.960497856 0.950683832 0.932971716 0.0512540638]\n",
      "[0.999301314 0.992441654 0.990595162 ... 0.0511035621 0.0505909622 0.0500255525]\n",
      "[0.998748362 0.977080464 0.973418236 0.950626493 0.101961285]\n",
      "[0.997378469 0.996497571 0.979620576 ... 0.0626956224 0.0528870523 0.0518895388]\n",
      "[0.97712028 0.96977663 0.966510355 0.930017948]\n",
      "[0.99876523 0.996480823 0.994957 ... 0.0541027486 0.0538574755 0.0518656671]\n",
      "[0.984659553 0.938720942]\n",
      "[0.992668569 0.970046878 0.960635066 ... 0.862881422 0.850253165 0.064879]\n",
      "[0.912114143 0.908560872 0.898348808]\n",
      "[0.947708488 0.946399808 0.934103668 ... 0.923632145 0.891736269 0.0675493777]\n",
      "[0.983582139 0.980595 0.97702 ... 0.170489132 0.0557946563 0.052903533]\n",
      "[0.994867861 0.986765265 0.968898177 ... 0.918555 0.111839026 0.092600733]\n",
      "[0.997621834 0.994601727 0.994085 ... 0.0530213714 0.0520699322 0.0506611764]\n",
      "[0.975768864 0.973434448 0.973116755 ... 0.166011691 0.134558827 0.0658656955]\n",
      "[0.994452417 0.942202 0.363188535]\n",
      "[0.994545 0.973703504 0.966546774 ... 0.915810347 0.915597796 0.551097214]\n",
      "[0.958488703]\n",
      "[0.988303781 0.977667511 0.968620837 ... 0.0561634 0.0511524081 0.0510029197]\n",
      "[0.976571 0.968376875 0.959017515 ... 0.920242131 0.727438807 0.0523238778]\n",
      "FastEstimator-Eval: step: 1104; epoch: 183; focal_loss: 0.0003238; l1_loss: 0.0536126; total_loss: 0.0539364; \n",
      "FastEstimator-Train: step: 1104; focal_loss: 0.0001892; l1_loss: 0.0465421; total_loss: 0.0467313; examples/sec: 32.3; progress: 92.0%; \n",
      "FastEstimator-Train: step: 1105; focal_loss: 0.0001897; l1_loss: 0.0522902; total_loss: 0.0524799; examples/sec: 31.8; progress: 92.1%; \n",
      "FastEstimator-Train: step: 1106; focal_loss: 0.0001877; l1_loss: 0.0181951; total_loss: 0.0183828; examples/sec: 32.2; progress: 92.2%; \n",
      "FastEstimator-Train: step: 1107; focal_loss: 0.0003803; l1_loss: 0.0569093; total_loss: 0.0572896; examples/sec: 32.4; progress: 92.2%; \n",
      "FastEstimator-Train: step: 1108; focal_loss: 0.0001093; l1_loss: 0.0226316; total_loss: 0.0227409; examples/sec: 32.3; progress: 92.3%; \n",
      "FastEstimator-Train: step: 1109; focal_loss: 0.0002231; l1_loss: 0.0387209; total_loss: 0.038944; examples/sec: 31.9; progress: 92.4%; \n",
      "[0.973905325]\n",
      "[0.999562442 0.966252 0.184953958]\n",
      "[0.993755579 0.993102431 0.990932 ... 0.0581845641 0.0556154847 0.0508382916]\n",
      "[0.997080803 0.993217111 0.991901517 ... 0.0550810397 0.0519393086 0.0504694581]\n",
      "[0.984857 0.977660179 0.97655189 ... 0.0704973042 0.0550869107 0.0509607494]\n",
      "[0.973454416 0.97051084 0.962391257 ... 0.153613836 0.0625509918 0.0601661503]\n",
      "[0.974317193]\n",
      "[0.986543119 0.985590935 0.961624622 0.0525921]\n",
      "[0.999893069 0.999239564 0.998083353 ... 0.0544969738 0.0543084741 0.0501175821]\n",
      "[0.997420549 0.991699 0.987177432 ... 0.0534347594 0.0518556237 0.0513495207]\n",
      "[0.99297595 0.990768 0.970389068]\n",
      "[0.997982264 0.996543288 0.995379806 ... 0.0542725027 0.0527763069 0.0503186]\n",
      "[0.990139961 0.976532936 0.967198133 0.0545279682]\n",
      "[0.993805647 0.955253839]\n",
      "[0.997639418 0.997508526 0.997173488 ... 0.975275457 0.906499743 0.0610021949]\n",
      "[0.999267459 0.998809576 0.998086 ... 0.0548396111 0.0508357882 0.0503630042]\n",
      "[0.998169303 0.989428401 0.973411322 ... 0.054618597 0.0525787175 0.0503520966]\n",
      "[0.99685967 0.991978288 0.98644197 ... 0.0767658353 0.0648851097 0.060891062]\n",
      "[0.994279265 0.987477183 0.965203404]\n",
      "[0.993542671 0.990978122 0.986940145 ... 0.0991206765 0.0801849365 0.0514404476]\n",
      "[0.993518353 0.978302836 0.97224009 ... 0.0523418784 0.0510700345 0.0507767498]\n",
      "[0.998321474 0.991668761]\n",
      "[0.999682248 0.998074293 0.997817159 ... 0.0546989143 0.05397138 0.0533798337]\n",
      "[0.982652783 0.979050517 0.977977753 ... 0.918590188 0.406683743 0.181092262]\n",
      "[0.988999486]\n",
      "[0.991594076 0.982855082]\n",
      "[0.993366778 0.992153525 0.987317443 ... 0.144278288 0.0919931233 0.050457716]\n",
      "[0.964049578 0.931083441]\n",
      "[0.996331 0.995341539 0.989954948 ... 0.0542387366 0.0505170822 0.0502223074]\n",
      "[0.99435091 0.973354161 0.969562054 ... 0.390221894 0.0626302958 0.0555858]\n",
      "[0.995667219 0.995203853 0.973823667 0.97254616 0.953847885 0.055865407]\n",
      "[0.979878426 0.978470623 0.978154898 0.963897 0.963354647 0.0612638]\n",
      "[0.999596834 0.993646681 0.990368843 ... 0.0528052449 0.0518923402 0.0505578518]\n",
      "[0.998908401 0.984567583 0.980368495 0.972701073]\n",
      "[0.997436404 0.996804059 0.978694 ... 0.0612214208 0.0582616031 0.0525810421]\n",
      "[0.98222518 0.974547088 0.96704495 0.94453609 0.050109297]\n",
      "[0.999412298 0.997709334 0.996837616 ... 0.0545655787 0.0539920628 0.0513725281]\n",
      "[0.989805937 0.961873055]\n",
      "[0.994595528 0.964619398 0.964552879 ... 0.827665925 0.0701471 0.0653371513]\n",
      "[0.917878747 0.917871892 0.895739675]\n",
      "[0.95941627 0.958784282 0.951413 ... 0.0844841301 0.0715309083 0.0551837087]\n",
      "[0.988032699 0.987456143 0.981070042 ... 0.0698983669 0.0546049476 0.0538286269]\n",
      "[0.993925333 0.988477349 0.972989678 ... 0.926849604 0.119656146 0.0719927251]\n",
      "[0.998159885 0.995631158 0.995130897 ... 0.0514827371 0.0511611402 0.0501678884]\n",
      "[0.980323911 0.979824603 0.978425443 ... 0.17183429 0.109458476 0.06366992]\n",
      "[0.996901393 0.960704088 0.435305268]\n",
      "[0.99613595 0.985855 0.980151772 ... 0.956144691 0.944829464 0.0636963248]\n",
      "[0.951771259]\n",
      "FastEstimator-Eval: step: 1110; epoch: 184; focal_loss: 0.0001848; l1_loss: 0.0432368; total_loss: 0.0434216; \n",
      "FastEstimator-Train: step: 1110; focal_loss: 0.0002099; l1_loss: 0.0340759; total_loss: 0.0342858; examples/sec: 31.8; progress: 92.5%; \n",
      "FastEstimator-Train: step: 1111; focal_loss: 0.0001354; l1_loss: 0.0435869; total_loss: 0.0437223; examples/sec: 32.2; progress: 92.6%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 1112; focal_loss: 9.62e-05; l1_loss: 0.0405096; total_loss: 0.0406058; examples/sec: 32.3; progress: 92.7%; \n",
      "FastEstimator-Train: step: 1113; focal_loss: 0.0001747; l1_loss: 0.061086; total_loss: 0.0612608; examples/sec: 32.3; progress: 92.8%; \n",
      "FastEstimator-Train: step: 1114; focal_loss: 0.0001899; l1_loss: 0.0213555; total_loss: 0.0215454; examples/sec: 32.1; progress: 92.8%; \n",
      "FastEstimator-Train: step: 1115; focal_loss: 0.0004136; l1_loss: 0.056185; total_loss: 0.0565986; examples/sec: 32.3; progress: 92.9%; \n",
      "[0.991731584 0.982443333 0.978622556 ... 0.0542204976 0.0522482693 0.0506058633]\n",
      "[0.979296565 0.962187648 0.929576874 0.927333 0.900490165 0.71164465]\n",
      "[0.964522839]\n",
      "[0.998788714 0.961121798 0.169803649]\n",
      "[0.990660608 0.988942146 0.987617195 ... 0.0524192452 0.0514372587 0.0507677794]\n",
      "[0.994952321 0.990675807 0.987447083 ... 0.058129102 0.0565679967 0.0515610576]\n",
      "[0.981408834 0.976102591 0.969596744 ... 0.870614052 0.10806188 0.0648639202]\n",
      "[0.965067506 0.954651713 0.937282324 ... 0.856884956 0.810451508 0.121194482]\n",
      "[0.968753874]\n",
      "[0.978689253 0.967433453 0.920526385]\n",
      "[0.9999125 0.999184 0.998351812 ... 0.0705874562 0.0598644316 0.0503254831]\n",
      "[0.995754361 0.990098119 0.985658288 ... 0.0575818121 0.0567645133 0.0525722504]\n",
      "[0.989318311 0.987098455 0.967554092]\n",
      "[0.997050405 0.995984912 0.994547248 ... 0.0555034578 0.0528521836 0.0509678423]\n",
      "[0.977864921 0.970296383 0.911819 0.0522388816]\n",
      "[0.985628486 0.947517574]\n",
      "[0.997318506 0.996915758 0.99663806 ... 0.971139789 0.91272819 0.0506022274]\n",
      "[0.998304129 0.99783659 0.996215463 ... 0.0510422 0.0510262549 0.0506646335]\n",
      "[0.997481465 0.98702991 0.968497038 ... 0.0528144538 0.052641511 0.0515182316]\n",
      "[0.995336533 0.986128807 0.969830036 ... 0.0643423796 0.0543523133 0.0516599715]\n",
      "[0.994347095 0.979142547 0.923804879]\n",
      "[0.99300909 0.986195922 0.984836936 ... 0.0756524801 0.0597639382 0.0585626364]\n",
      "[0.993701398 0.98696804 0.968967795 ... 0.055221051 0.0538848042 0.0507254601]\n",
      "[0.994704664 0.979768157]\n",
      "[0.999717712 0.997953832 0.997659624 ... 0.0608319044 0.0590396523 0.0590052]\n",
      "[0.975352049 0.970576525 0.961892128 ... 0.154650152 0.146263927 0.0931968689]\n",
      "[0.980092168]\n",
      "[0.980426311 0.958661437]\n",
      "[0.990938 0.986937344 0.984776676 ... 0.0687339306 0.0518474579 0.0515239835]\n",
      "[0.949533463 0.876183152]\n",
      "[0.995669246 0.993938386 0.985269964 ... 0.0582345128 0.0563617945 0.0520493388]\n",
      "[0.992607117 0.973303795 0.963912368 ... 0.961565137 0.502819598 0.369920492]\n",
      "[0.987347722 0.985514164 0.963980496 0.945495367 0.941365]\n",
      "[0.947493196 0.942153573 0.939529657 0.939098418 0.904908061 0.0583325922]\n",
      "[0.999565363 0.988175392 0.984538913 ... 0.0529314 0.0529152155 0.0516868234]\n",
      "[0.998245478 0.970879436 0.949192762 0.910709441 0.104987502]\n",
      "[0.997213542 0.996491969 0.97773391 ... 0.053614974 0.0519637167 0.0502642691]\n",
      "[0.983419061 0.976920903 0.96728915 0.939242065]\n",
      "[0.999443769 0.996830463 0.996153474 ... 0.0530520976 0.05232656 0.0501582623]\n",
      "[0.982556939 0.921343565]\n",
      "[0.991450191 0.960673332 0.957918286 ... 0.855331481 0.855175793 0.854285836]\n",
      "[0.920880616 0.917679906 0.912953556]\n",
      "[0.953384757 0.950881958 0.949136496 ... 0.881051183 0.0842505693 0.0717150569]\n",
      "[0.98138988 0.981302679 0.975955844 ... 0.0619617403 0.0526062548 0.0523922443]\n",
      "[0.983813882 0.95983386 0.917785287 ... 0.0819011927 0.0700438321 0.0643597245]\n",
      "[0.998085618 0.994890451 0.994422913 ... 0.0526652932 0.0516067445 0.0500509441]\n",
      "[0.981785893 0.979704142 0.977864921 ... 0.178661436 0.157707244 0.0730167627]\n",
      "[0.991674304 0.917883635 0.313960135]\n",
      "FastEstimator-Eval: step: 1116; epoch: 185; focal_loss: 0.0002187; l1_loss: 0.0637043; total_loss: 0.063923; \n",
      "FastEstimator-Train: step: 1116; focal_loss: 0.0001169; l1_loss: 0.0784174; total_loss: 0.0785343; examples/sec: 32.4; progress: 93.0%; \n",
      "FastEstimator-Train: step: 1117; focal_loss: 0.0002931; l1_loss: 0.060803; total_loss: 0.061096; examples/sec: 32.1; progress: 93.1%; \n",
      "FastEstimator-Train: step: 1118; focal_loss: 0.0001633; l1_loss: 0.0863615; total_loss: 0.0865248; examples/sec: 32.3; progress: 93.2%; \n",
      "FastEstimator-Train: step: 1119; focal_loss: 0.0002416; l1_loss: 0.0483998; total_loss: 0.0486414; examples/sec: 32.1; progress: 93.2%; \n",
      "FastEstimator-Train: step: 1120; focal_loss: 0.0002124; l1_loss: 0.0333522; total_loss: 0.0335646; examples/sec: 32.4; progress: 93.3%; \n",
      "FastEstimator-Train: step: 1121; focal_loss: 0.0001654; l1_loss: 0.0266473; total_loss: 0.0268128; examples/sec: 32.4; progress: 93.4%; \n",
      "[0.995717764 0.982362032 0.980644166 ... 0.961884499 0.944243073 0.498243928]\n",
      "[0.955466449]\n",
      "[0.994451284 0.988704443 0.980360031 ... 0.0570291281 0.0560830235 0.0505158603]\n",
      "[0.981820822 0.963217735 0.959035277 ... 0.751013875 0.0647943616 0.0502799749]\n",
      "[0.989184141]\n",
      "[0.999716103 0.979351342 0.263301611]\n",
      "[0.99351573 0.989197671 0.988721371 ... 0.0601925552 0.0582408 0.0524476171]\n",
      "[0.997893691 0.993246198 0.99230063 ... 0.0529730022 0.051010102 0.0503525734]\n",
      "[0.9909271 0.984639168 0.981997132 ... 0.0950652659 0.0637824237 0.0543481112]\n",
      "[0.967285454 0.951440096 0.947225451 ... 0.895371199 0.12215963 0.0876494944]\n",
      "[0.980307579]\n",
      "[0.983034372 0.981748223 0.950483501]\n",
      "[0.999949753 0.999588728 0.998953819 ... 0.0650714934 0.0534231067 0.0509072542]\n",
      "[0.998475432 0.992613137 0.989507079 ... 0.0527706444 0.0506493151 0.050388068]\n",
      "[0.986666322 0.98615545 0.974113882]\n",
      "[0.997879565 0.997354031 0.997175515 ... 0.0524191856 0.0515877903 0.0514141917]\n",
      "[0.990332484 0.97534281 0.962852359 0.0563320816]\n",
      "[0.994838953 0.966097832]\n",
      "[0.9973768 0.997072279 0.996957541 ... 0.969123304 0.946212113 0.0538812876]\n",
      "[0.998381793 0.997531414 0.995723 ... 0.0551212728 0.0526807606 0.0502385199]\n",
      "[0.997268081 0.98693 0.969229877 ... 0.054864198 0.0548117459 0.0540400743]\n",
      "[0.997239411 0.991764784 0.987666667 ... 0.0718638897 0.0690151155 0.0517635345]\n",
      "[0.993339181 0.987185597 0.95144558]\n",
      "[0.994113088 0.99143362 0.98795 ... 0.0713459551 0.0692168772 0.0519216657]\n",
      "[0.99603951 0.991971254 0.979445338 ... 0.0578812361 0.0562303066 0.0546685755]\n",
      "[0.996514797 0.984206915]\n",
      "[0.999794364 0.998142302 0.996268868 ... 0.0563555956 0.0534226596 0.0510674417]\n",
      "[0.984049678 0.982487857 0.981064737 ... 0.418203652 0.186295569 0.148775548]\n",
      "[0.987347484]\n",
      "[0.992054582 0.983977556]\n",
      "[0.993945599 0.993685842 0.991278887 ... 0.0659274459 0.0645773709 0.0558445454]\n",
      "[0.981315255 0.966665268]\n",
      "[0.995612264 0.995609045 0.987520754 ... 0.0532831252 0.0517967045 0.0511244535]\n",
      "[0.99551338 0.984477639 0.976581812 ... 0.0821053386 0.0582075119 0.0507416427]\n",
      "[0.993931293 0.991155386 0.977244377 0.963399529 0.953437]\n",
      "[0.973291278 0.967088461 0.965606153 0.956820369 0.953157663 0.0722087]\n",
      "[0.999793172 0.993581414 0.993185043 ... 0.0557205081 0.0514253676 0.050881207]\n",
      "[0.998870492 0.980938315 0.979832172 0.967290282]\n",
      "[0.998062 0.998040617 0.980417311 ... 0.0579635501 0.0521864593 0.0513807237]\n",
      "[0.987579226 0.984357417 0.9799757 0.972795844 0.105168879 0.0578503609]\n",
      "[0.999423325 0.997574806 0.996715605 ... 0.0552439094 0.0551233292 0.0546568334]\n",
      "[0.990300179 0.968786538]\n",
      "[0.995162368 0.977447152 0.971281052 ... 0.893772721 0.0727851689 0.0502263606]\n",
      "[0.972452164 0.970928431 0.959121943]\n",
      "[0.967848182 0.965884 0.961034656 ... 0.0566314757 0.0527166128 0.0502492487]\n",
      "[0.98870194 0.987411 0.984196424 ... 0.0720090568 0.0663274527 0.0601297617]\n",
      "[0.981776118 0.972655177 0.949525476 ... 0.867122412 0.105228215 0.0511647463]\n",
      "[0.99882 0.996259034 0.995332599 ... 0.055624336 0.0536504388 0.0518113673]\n",
      "FastEstimator-Eval: step: 1122; epoch: 186; focal_loss: 0.0001897; l1_loss: 0.0680485; total_loss: 0.0682382; \n",
      "FastEstimator-Train: step: 1122; focal_loss: 0.0002342; l1_loss: 0.0536483; total_loss: 0.0538824; examples/sec: 32.0; progress: 93.5%; \n",
      "FastEstimator-Train: step: 1123; focal_loss: 0.0002689; l1_loss: 0.1044879; total_loss: 0.1047568; examples/sec: 32.6; progress: 93.6%; \n",
      "FastEstimator-Train: step: 1124; focal_loss: 0.0003558; l1_loss: 0.0521252; total_loss: 0.052481; examples/sec: 31.8; progress: 93.7%; \n",
      "FastEstimator-Train: step: 1125; focal_loss: 0.0001251; l1_loss: 0.0369621; total_loss: 0.0370873; examples/sec: 32.2; progress: 93.8%; \n",
      "FastEstimator-Train: step: 1126; focal_loss: 0.0001866; l1_loss: 0.0376249; total_loss: 0.0378116; examples/sec: 32.6; progress: 93.8%; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastEstimator-Train: step: 1127; focal_loss: 0.0002033; l1_loss: 0.0393629; total_loss: 0.0395662; examples/sec: 32.3; progress: 93.9%; \n",
      "[0.979026437 0.978224635 0.976018667 ... 0.159323066 0.147960782 0.072881788]\n",
      "[0.994373322 0.946536422 0.361951292]\n",
      "[0.994770527 0.975131869 0.974339187 ... 0.927633464 0.466511279 0.0528027713]\n",
      "[0.932950914]\n",
      "[0.99371 0.982533097 0.968942285 ... 0.0545597076 0.0515218675 0.0500796735]\n",
      "[0.979062796 0.976475775 0.934532166 ... 0.887889862 0.0667182207 0.0502744019]\n",
      "[0.9729321]\n",
      "[0.999801278 0.979069769 0.282854974]\n",
      "[0.99235487 0.987377346 0.982801318 ... 0.0545117855 0.0539544523 0.052411586]\n",
      "[0.997598648 0.993895948 0.99240768 ... 0.0537181795 0.052647084 0.050246805]\n",
      "[0.985259 0.980351329 0.978707433 ... 0.1257146 0.077908814 0.0553744435]\n",
      "[0.966330767 0.949512959 0.940811455 ... 0.833883643 0.11563009 0.0671325922]\n",
      "[0.97183305]\n",
      "[0.976937532 0.974295914 0.934026361]\n",
      "[0.999933958 0.999501109 0.998473227 ... 0.0622288287 0.0590079129 0.0577479]\n",
      "[0.996412456 0.987090349 0.982153535 ... 0.0534210205 0.0510998368 0.0509676039]\n",
      "[0.984602571 0.983199358 0.968675137]\n",
      "[0.996123195 0.995587409 0.99456346 ... 0.0568358898 0.0528763831 0.0514170527]\n",
      "[0.985835195 0.96693629 0.920429111]\n",
      "[0.988197744 0.944591403]\n",
      "[0.996413052 0.99640435 0.99533987 ... 0.968175173 0.903091848 0.277319163]\n",
      "[0.997730911 0.99609369 0.994482934 ... 0.0551323295 0.0503510237 0.0500782728]\n",
      "[0.997125626 0.985750198 0.966301262 ... 0.052832514 0.0514012873 0.050605]\n",
      "[0.997588217 0.991962314 0.985242605 ... 0.066047281 0.058321178 0.0526741743]\n",
      "[0.98783493 0.981466532 0.894334257 0.0520394444]\n",
      "[0.994273186 0.988923907 0.984981894 ... 0.0688938797 0.0683019757 0.0528196692]\n",
      "[0.994427562 0.987523496 0.980261445 ... 0.0696412 0.0546860695 0.053355515]\n",
      "[0.995227933 0.980201304]\n",
      "[0.999590218 0.997166753 0.994689941 ... 0.0523516536 0.0507530272 0.0507117212]\n",
      "[0.979355216 0.975842953 0.958992541 ... 0.165602475 0.142462403 0.141649425]\n",
      "[0.979806662]\n",
      "[0.98796618 0.976624668]\n",
      "[0.991452336 0.989475846 0.986560583 ... 0.05643332 0.0560953617 0.0535510778]\n",
      "[0.980196655 0.954550147]\n",
      "[0.995209634 0.994637 0.984380603 ... 0.0569350123 0.0522762835 0.0501000285]\n",
      "[0.995992422 0.98915863 0.982126176 ... 0.373893023 0.0843309462 0.0536880791]\n",
      "[0.990546 0.989566803 0.97115314 0.956013083 0.949670911]\n",
      "[0.965225101 0.959505558 0.959347367 0.95249933 0.945915937 0.0715085268]\n",
      "[0.999758363 0.993967414 0.987935901 ... 0.0506035089 0.0504939854 0.050246805]\n",
      "[0.999005437 0.982175708 0.981631517 0.969247]\n",
      "[0.998288512 0.998002887 0.969385564 ... 0.0564041734 0.0553040206 0.054969579]\n",
      "[0.985604882 0.98252821 0.977203369 0.952886939 0.0507177114]\n",
      "[0.999296129 0.996674895 0.996315122 ... 0.0548153222 0.0531440079 0.0523731411]\n",
      "[0.986928642 0.944449782]\n",
      "[0.993558645 0.97543782 0.970320165 ... 0.895767868 0.89218086 0.070070833]\n",
      "[0.972092032 0.969674647 0.966335893]\n",
      "[0.966184139 0.963898 0.958424211 ... 0.0923003554 0.0770025253 0.0769414306]\n",
      "[0.984641135 0.98455292 0.982902467 ... 0.0567105412 0.0563065708 0.0524589717]\n",
      "FastEstimator-Eval: step: 1128; epoch: 187; focal_loss: 0.0001685; l1_loss: 0.0542661; total_loss: 0.0544346; \n",
      "FastEstimator-Train: step: 1128; focal_loss: 0.0001849; l1_loss: 0.0650721; total_loss: 0.065257; examples/sec: 32.7; progress: 94.0%; \n",
      "FastEstimator-Train: step: 1129; focal_loss: 0.0001235; l1_loss: 0.0539366; total_loss: 0.05406; examples/sec: 32.6; progress: 94.1%; \n",
      "FastEstimator-Train: step: 1130; focal_loss: 0.0002039; l1_loss: 0.0663633; total_loss: 0.0665672; examples/sec: 32.6; progress: 94.2%; \n",
      "FastEstimator-Train: step: 1131; focal_loss: 0.0001273; l1_loss: 0.0623352; total_loss: 0.0624625; examples/sec: 32.4; progress: 94.2%; \n",
      "FastEstimator-Train: step: 1132; focal_loss: 0.0002136; l1_loss: 0.0311328; total_loss: 0.0313464; examples/sec: 32.2; progress: 94.3%; \n",
      "FastEstimator-Train: step: 1133; focal_loss: 7.79e-05; l1_loss: 0.0262345; total_loss: 0.0263124; examples/sec: 32.3; progress: 94.4%; \n",
      "[0.996197 0.994875073 0.984141231 ... 0.961350679 0.147810668 0.106089771]\n",
      "[0.998801351 0.996215 0.996037722 ... 0.0535092056 0.0533300042 0.0504130423]\n",
      "[0.989026606 0.986104846 0.985794544 ... 0.153410673 0.0778084695 0.0512581468]\n",
      "[0.997449875 0.962028861 0.419297516 0.0628066063]\n",
      "[0.995348215 0.981243968 0.977562964 ... 0.956167936 0.934299111 0.0519956946]\n",
      "[0.926124275]\n",
      "[0.995653689 0.984392762 0.97284615 ... 0.0520171225 0.0510813296 0.0508878529]\n",
      "[0.986631036 0.986621499 0.95488143 ... 0.833749652 0.228614211 0.0569185317]\n",
      "[0.976955056]\n",
      "[0.999833107 0.972819626 0.270944893]\n",
      "[0.992747903 0.99069953 0.983094454 ... 0.0578268468 0.0555301607 0.053647697]\n",
      "[0.998196959 0.996617794 0.993427277 ... 0.0543091 0.0532699525 0.0512321591]\n",
      "[0.980215251 0.979882717 0.977205276 ... 0.914053142 0.0755811334 0.0534410477]\n",
      "[0.977056503 0.966290116 0.963547647 ... 0.925260782 0.130992144 0.0506600738]\n",
      "[0.96938467]\n",
      "[0.990213156 0.984774768 0.967976928 0.0621821284]\n",
      "[0.999936104 0.999540746 0.998609424 ... 0.0586769879 0.0572723746 0.0528355241]\n",
      "[0.996866941 0.988453627 0.981010914 ... 0.0524847507 0.0519107 0.0518289208]\n",
      "[0.991347075 0.987896085 0.973270655]\n",
      "[0.996438861 0.995426893 0.994876 ... 0.051846385 0.050617367 0.0501324534]\n",
      "[0.986319423 0.967290044 0.936982274 0.0511267781]\n",
      "[0.988643825 0.950712621]\n",
      "[0.996961713 0.99672389 0.996236086 0.99568218 0.976479411 0.923635364]\n",
      "[0.997654378 0.995887101 0.994143844 ... 0.0534536242 0.0528774559 0.0518765152]\n",
      "[0.998128653 0.988573432 0.972800732 ... 0.0533645451 0.0533334911 0.0522503555]\n",
      "[0.998565614 0.994223416 0.990439832 ... 0.0934495 0.0805680454 0.0634548068]\n",
      "[0.990124881 0.985100389 0.937574923]\n",
      "[0.995288312 0.990638852 0.990078211 ... 0.0585105717 0.0575507283 0.0500908792]\n",
      "[0.995486856 0.984695792 0.983493626 ... 0.067166 0.0518815219 0.0504153371]\n",
      "[0.997222185 0.986936688]\n",
      "[0.999601901 0.997943759 0.997144 ... 0.0601273179 0.0554116368 0.0549015701]\n",
      "[0.980172336 0.97815913 0.97424525 ... 0.906909823 0.136177123 0.0932531655]\n",
      "[0.983440459]\n",
      "[0.988268733 0.9785043]\n",
      "[0.992856324 0.991695404 0.987300158 ... 0.0536344349 0.0511427522 0.0505763]\n",
      "[0.984392524 0.952525198]\n",
      "[0.996776819 0.995342553 0.987229824 ... 0.0535909832 0.0532833934 0.0505182445]\n",
      "[0.996497273 0.990496874 0.986743569 ... 0.396512181 0.0873731673 0.0504310727]\n",
      "[0.994053721 0.99345243 0.974188626 0.971512437 0.963562608]\n",
      "[0.970163226 0.969617605 0.967456 0.960935 0.954433441 0.0772418678]\n",
      "[0.999825478 0.995934725 0.988646269 ... 0.0515030921 0.0509418249 0.0506454706]\n",
      "[0.999141693 0.986912489 0.98368609 0.976693273]\n",
      "[0.998928964 0.998694062 0.970176578 ... 0.0520011485 0.0506930649 0.0500131547]\n",
      "[0.986925721 0.982441664 0.976057351 0.949932456 0.12478739]\n",
      "[0.999515414 0.997549713 0.997324109 ... 0.0540623069 0.0518581867 0.0511402488]\n",
      "[0.987751722 0.949214339]\n",
      "[0.99544996 0.982450366 0.975882053 ... 0.917258 0.0575152636 0.0552184582]\n",
      "[0.980812907 0.976294398 0.973681569]\n",
      "FastEstimator-Eval: step: 1134; epoch: 188; focal_loss: 0.0001389; l1_loss: 0.0424761; total_loss: 0.042615; \n",
      "FastEstimator-Train: step: 1134; focal_loss: 0.0001833; l1_loss: 0.0456532; total_loss: 0.0458365; examples/sec: 31.8; progress: 94.5%; \n",
      "FastEstimator-Train: step: 1135; focal_loss: 0.0004531; l1_loss: 0.0573884; total_loss: 0.0578415; examples/sec: 32.7; progress: 94.6%; \n",
      "FastEstimator-Train: step: 1136; focal_loss: 0.0001326; l1_loss: 0.0401803; total_loss: 0.0403129; examples/sec: 32.3; progress: 94.7%; \n",
      "FastEstimator-Train: step: 1137; focal_loss: 0.0002065; l1_loss: 0.0297008; total_loss: 0.0299073; examples/sec: 31.8; progress: 94.8%; \n",
      "FastEstimator-Train: step: 1138; focal_loss: 0.0001296; l1_loss: 0.0235301; total_loss: 0.0236597; examples/sec: 32.4; progress: 94.8%; \n",
      "FastEstimator-Train: step: 1139; focal_loss: 0.0001371; l1_loss: 0.036958; total_loss: 0.0370951; examples/sec: 32.3; progress: 94.9%; \n",
      "[0.962384462 0.961060107 0.955989957 ... 0.0853902698 0.0765060186 0.0520062149]\n",
      "[0.990113 0.987619936 0.976711869 ... 0.414288253 0.0895581841 0.0627113283]\n",
      "[0.996257901 0.995833576 0.988447607 ... 0.969119906 0.168449342 0.109669626]\n",
      "[0.998052657 0.99601841 0.995960116 ... 0.0535665154 0.0532044172 0.0503046215]\n",
      "[0.987904549 0.987088203 0.984229326 ... 0.175562799 0.163505614 0.0663068295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.997939706 0.964075327 0.432060242 0.0758928955]\n",
      "[0.993163645 0.974785805 0.970183134 ... 0.95092988 0.929253697 0.453071266]\n",
      "[0.958298922]\n",
      "[0.994701087 0.982873619 0.974188328 ... 0.0526577234 0.0519064963 0.0502671]\n",
      "[0.986220837 0.973052144 0.97065 ... 0.919258714 0.829324 0.0635236502]\n",
      "[0.979602277]\n",
      "[0.999515235 0.948327303 0.210002571]\n",
      "[0.991563439 0.989540875 0.981672525 ... 0.0572307408 0.0564315915 0.0539262891]\n",
      "[0.997857809 0.994366825 0.992323637 ... 0.057859987 0.0576592088 0.0543296337]\n",
      "[0.9747504 0.974741697 0.969414771 ... 0.0695302188 0.0573330522 0.0502076447]\n",
      "[0.977609754 0.974825382 0.965416431 ... 0.0708728731 0.0580393374 0.0554314554]\n",
      "[0.969732106]\n",
      "[0.99464047 0.986959219 0.974684417 0.0609720349]\n",
      "[0.999918 0.999571681 0.998620868 ... 0.0612441897 0.0543892682 0.0511691868]\n",
      "[0.996902764 0.985441267 0.975919962 ... 0.0525900126 0.0506213307 0.0501526594]\n",
      "[0.993602037 0.987188816 0.972336531]\n",
      "[0.996555507 0.994232774 0.994110525 ... 0.0522467494 0.0518474877 0.051762104]\n",
      "[0.980516315 0.965571523 0.951043248 0.0567390919]\n",
      "[0.990075588 0.959623575]\n",
      "[0.996315658 0.995447636 0.995431542 0.99505 0.974294543 0.92570281]\n",
      "[0.997894168 0.995381892 0.994145513 ... 0.0554411709 0.0538950861 0.0524584353]\n",
      "[0.997837543 0.987511635 0.977888346 ... 0.0510264337 0.0507591367 0.05001086]\n",
      "[0.998346567 0.994249046 0.99049294 ... 0.0694098771 0.0564757 0.053832531]\n",
      "[0.991207361 0.985654235 0.960784793]\n",
      "[0.994640946 0.98870033 0.986228585 ... 0.0798457265 0.0565677881 0.0500445962]\n",
      "[0.997342288 0.985274315 0.982315481 ... 0.0569525957 0.0557639897 0.0513652563]\n",
      "[0.997970223 0.989190221]\n",
      "[0.999433041 0.998158336 0.998089075 ... 0.0555509925 0.0539969206 0.0538871884]\n",
      "[0.987850666 0.978109062 0.974532604 ... 0.935403705 0.11651215 0.0651366413]\n",
      "[0.989611268]\n",
      "[0.98393178 0.968755126]\n",
      "[0.993038177 0.990185201 0.987284541 ... 0.0671249 0.0638255775 0.0528149307]\n",
      "[0.975694835 0.932456195]\n",
      "[0.996321917 0.995118141 0.986480594 ... 0.0589189529 0.0572016835 0.0534321964]\n",
      "[0.993613839 0.990220428 0.979829371 ... 0.386912286 0.0820635259 0.0524256825]\n",
      "[0.994342148 0.993851066 0.973278105 0.970386147 0.963801861]\n",
      "[0.970774055 0.967667103 0.96486187 0.956917882 0.94600749 0.0836028457]\n",
      "[0.999764919 0.996040106 0.993926823 ... 0.0510928929 0.0510084033 0.0503833294]\n",
      "[0.998314202 0.97803241 0.974458 0.96416688 0.140606046]\n",
      "[0.998837173 0.998799205 0.97394073 ... 0.0610881448 0.0589821637 0.0530311167]\n",
      "[0.98244065 0.978063464 0.971040964 0.945216656]\n",
      "[0.999162436 0.997601151 0.996355653 ... 0.0563244224 0.0550376475 0.0501632094]\n",
      "[0.988741 0.952428699]\n",
      "FastEstimator-Eval: step: 1140; epoch: 189; focal_loss: 0.0001496; l1_loss: 0.0318858; total_loss: 0.0320354; \n",
      "FastEstimator-Train: step: 1140; focal_loss: 0.0001047; l1_loss: 0.0390629; total_loss: 0.0391676; examples/sec: 32.0; progress: 95.0%; \n",
      "FastEstimator-Train: step: 1141; focal_loss: 0.000133; l1_loss: 0.0296615; total_loss: 0.0297945; examples/sec: 32.6; progress: 95.1%; \n",
      "FastEstimator-Train: step: 1142; focal_loss: 0.0002224; l1_loss: 0.0395516; total_loss: 0.0397739; examples/sec: 32.3; progress: 95.2%; \n",
      "FastEstimator-Train: step: 1143; focal_loss: 0.000244; l1_loss: 0.0733822; total_loss: 0.0736262; examples/sec: 32.3; progress: 95.2%; \n",
      "FastEstimator-Train: step: 1144; focal_loss: 0.0001121; l1_loss: 0.0330686; total_loss: 0.0331806; examples/sec: 32.4; progress: 95.3%; \n",
      "FastEstimator-Train: step: 1145; focal_loss: 0.0001799; l1_loss: 0.0311888; total_loss: 0.0313687; examples/sec: 32.3; progress: 95.4%; \n",
      "[0.996174097 0.986978173 0.970076323 ... 0.0886296928 0.0837738514 0.0501095951]\n",
      "[0.975115061 0.974163711 0.961055517]\n",
      "[0.963091969 0.959250212 0.955324769 ... 0.0625027716 0.060249 0.0599325597]\n",
      "[0.98979032 0.988877 0.978433132 ... 0.379923761 0.0940576196 0.0626195669]\n",
      "[0.992717922 0.992248297 0.982497513 ... 0.953789353 0.14100644 0.0719084144]\n",
      "[0.997701883 0.996287 0.996159315 ... 0.0528678 0.0509321094 0.0500296056]\n",
      "[0.985585868 0.981684566 0.977080226 ... 0.124431074 0.0569339693 0.0542346239]\n",
      "[0.99577558 0.942553639 0.364271343]\n",
      "[0.991252184 0.974390626 0.967977464 ... 0.955585778 0.952916 0.929695487]\n",
      "[0.977693379]\n",
      "[0.995333552 0.984933 0.974350452 ... 0.0538822114 0.0515512526 0.0511463881]\n",
      "[0.986751139 0.98021 0.971475 ... 0.831389666 0.0574039817 0.0526747704]\n",
      "[0.980295479]\n",
      "[0.998760104 0.914972425 0.18454203]\n",
      "[0.993610859 0.992202818 0.984623075 ... 0.0576753318 0.0559709072 0.0506815612]\n",
      "[0.997753501 0.992801189 0.992630482 ... 0.0563722253 0.0559749305 0.0506022871]\n",
      "[0.973507762 0.96871829 0.965543091 ... 0.0834031403 0.0608584583 0.0562309325]\n",
      "[0.978262663 0.972900271 0.966707826 ... 0.0777125061 0.0545179844 0.0500943363]\n",
      "[0.972172141]\n",
      "[0.990091324 0.98076725 0.955436349]\n",
      "[0.999918 0.99958992 0.998735666 ... 0.0740665495 0.0577651262 0.054032594]\n",
      "[0.996783495 0.986651897 0.978407502 ... 0.0522319973 0.0507914722 0.0507065654]\n",
      "[0.99412775 0.989490032 0.973270059]\n",
      "[0.997158766 0.995750844 0.994710803 ... 0.053681165 0.0523295701 0.0506755412]\n",
      "[0.976911128 0.955982685 0.948084354 0.0515176654]\n",
      "[0.992609262 0.965773463]\n",
      "[0.995871 0.995822251 0.99506408 0.994305611 0.974050403 0.922388792]\n",
      "[0.998687267 0.996373713 0.994549096 ... 0.0532797873 0.0512942374 0.0508745]\n",
      "[0.998419642 0.990382314 0.984270751 ... 0.0525952578 0.0520149469 0.0515804887]\n",
      "[0.997700095 0.993739247 0.987787724 ... 0.0707261562 0.0639797151 0.0637167394]\n",
      "[0.993739307 0.987478256 0.960819304]\n",
      "[0.994592607 0.988441467 0.987723351 ... 0.0660387278 0.0568317771 0.0563237369]\n",
      "[0.997934341 0.98973465 0.983695149 ... 0.0526731312 0.05223158 0.0505060852]\n",
      "[0.997984946 0.989176452]\n",
      "[0.999351382 0.998154938 0.997394 ... 0.0533556044 0.0506214201 0.0504402518]\n",
      "[0.985108 0.977677226 0.973590255 ... 0.173125893 0.108375847 0.076241672]\n",
      "[0.991687059]\n",
      "[0.985262036 0.9697963]\n",
      "[0.993738055 0.98895514 0.988806963 ... 0.077475816 0.0696722865 0.0597630441]\n",
      "[0.964713395 0.915429294]\n",
      "[0.995845675 0.995742917 0.987113833 ... 0.0571378171 0.0570624769 0.0511601865]\n",
      "[0.992128 0.986657858 0.975783587 ... 0.362607121 0.0768407285 0.0582190156]\n",
      "[0.993145227 0.992151 0.974226356 0.965238333 0.956146121]\n",
      "[0.97851795 0.976323962 0.974405408 0.965603352 0.955736041]\n",
      "[0.999777198 0.9962641 0.995434403 ... 0.0530568957 0.0526089072 0.0515396297]\n",
      "[0.996354342 0.964656353 0.958679438 0.949881792 0.11103636]\n",
      "[0.99871695 0.998584 0.973661423 ... 0.0620460212 0.0570049584 0.0505383909]\n",
      "[0.979707718 0.974291921 0.971393228 0.946387351]\n",
      "FastEstimator-Eval: step: 1146; epoch: 190; focal_loss: 0.0002115; l1_loss: 0.0248607; total_loss: 0.0250721; \n",
      "FastEstimator-Train: step: 1146; focal_loss: 0.0005416; l1_loss: 0.0283169; total_loss: 0.0288585; examples/sec: 31.8; progress: 95.5%; \n",
      "FastEstimator-Train: step: 1147; focal_loss: 6.92e-05; l1_loss: 0.0406102; total_loss: 0.0406794; examples/sec: 32.6; progress: 95.6%; \n",
      "FastEstimator-Train: step: 1148; focal_loss: 6.33e-05; l1_loss: 0.032579; total_loss: 0.0326423; examples/sec: 32.6; progress: 95.7%; \n",
      "FastEstimator-Train: step: 1149; focal_loss: 0.0001668; l1_loss: 0.0279759; total_loss: 0.0281427; examples/sec: 32.3; progress: 95.8%; \n",
      "FastEstimator-Train: step: 1150; focal_loss: 0.0002138; l1_loss: 0.0158105; total_loss: 0.0160243; examples/sec: 31.9; progress: 95.8%; \n",
      "FastEstimator-Train: step: 1151; focal_loss: 0.000198; l1_loss: 0.0107365; total_loss: 0.0109345; examples/sec: 32.3; progress: 95.9%; \n",
      "[0.999181628 0.99651432 0.996487141 ... 0.0533947647 0.051733017 0.0513124466]\n",
      "[0.98521018 0.937800407]\n",
      "[0.992236853 0.97569716 0.966501355 ... 0.796245158 0.0653708577 0.0577915609]\n",
      "[0.957716823 0.955884695 0.945602894]\n",
      "[0.959727108 0.953348339 0.950401545 ... 0.0840267837 0.0644974411 0.053850174]\n",
      "[0.983675361 0.979612 0.978239298 ... 0.420141369 0.303338796 0.0892230868]\n",
      "[0.989749134 0.986598134 0.970356822 ... 0.935716391 0.111861289 0.055121392]\n",
      "[0.997209787 0.995032907 0.994709611 ... 0.0544157624 0.0519582033 0.0513360798]\n",
      "[0.976874411 0.976471186 0.97426796 ... 0.125931144 0.0618588626 0.05739066]\n",
      "[0.990719199 0.905396 0.275261045]\n",
      "[0.988764703 0.971614957 0.965547681 ... 0.952044964 0.945736647 0.899814963]\n",
      "[0.965771437]\n",
      "[0.993006885 0.983064473 0.961336732 ... 0.0557163656 0.052978009 0.052947402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.983158946 0.972241163 0.939984262 0.939568698 0.909360349 0.775012493]\n",
      "[0.958786428]\n",
      "[0.997584343 0.885712445 0.16134271]\n",
      "[0.994644642 0.993539274 0.984738588 ... 0.0565697253 0.0514858961 0.0504267514]\n",
      "[0.996638536 0.990379214 0.989850879 ... 0.056817472 0.0506723523 0.0505039692]\n",
      "[0.973508894 0.969504416 0.963210404 ... 0.0803506076 0.0566682518 0.0522883832]\n",
      "[0.97749877 0.966279805 0.954695463 ... 0.931790352 0.109916657 0.0628148913]\n",
      "[0.965817451]\n",
      "[0.975215733 0.961176515 0.917844892]\n",
      "[0.999911427 0.999411285 0.998465419 ... 0.0634129345 0.0539101362 0.0503132939]\n",
      "[0.994571686 0.985456705 0.978732765 ... 0.0549059212 0.0532291532 0.0504509509]\n",
      "[0.989554286 0.986525297 0.968378782]\n",
      "[0.996119559 0.99494791 0.994476557 ... 0.0552400649 0.0537348688 0.0524884462]\n",
      "[0.971186101 0.940359354 0.923476458]\n",
      "[0.989211559 0.958190143]\n",
      "[0.994078279 0.993657827 0.993646801 0.990189552 0.956918359 0.874670386]\n",
      "[0.998555422 0.996017277 0.993659377 ... 0.0538450778 0.0519611835 0.050337404]\n",
      "[0.998243093 0.987719774 0.982171118 ... 0.0659521222 0.0595803261 0.0515946746]\n",
      "[0.99694 0.992148161 0.980781257 ... 0.0640363097 0.0618759692 0.0538500845]\n",
      "[0.992931604 0.982124031 0.943039656]\n",
      "[0.994105101 0.989654481 0.98646903 ... 0.0632294416 0.053252846 0.0510289371]\n",
      "[0.996781349 0.988684297 0.983871758 ... 0.0557748973 0.0542798042 0.0529643893]\n",
      "[0.996843517 0.984800339]\n",
      "[0.99917835 0.996942401 0.994735956 ... 0.0533266962 0.0508525968 0.0502202809]\n",
      "[0.977449477 0.970359087 0.968681 ... 0.152155697 0.0985839367 0.0700060129]\n",
      "[0.98156631]\n",
      "[0.983191967 0.961939752]\n",
      "[0.986439526 0.985089183 0.982871354 ... 0.295284331 0.0601739287 0.0556772053]\n",
      "[0.956232309 0.894590616]\n",
      "[0.994411886 0.994237781 0.977547646 ... 0.0539551973 0.0525814295 0.0524736345]\n",
      "[0.991035044 0.973588049 0.969883204 ... 0.496768773 0.309081852 0.0525057912]\n",
      "[0.990632892 0.985924721 0.96541357 0.9513762 0.947208703]\n",
      "[0.966365755 0.961273432 0.960189641 0.94713068 0.928950429 0.0732207596]\n",
      "[0.999719679 0.995420635 0.994802594 ... 0.0527047813 0.0523974895 0.0508570671]\n",
      "[0.996492684 0.957235813 0.95138371 0.935974 0.0944993794]\n",
      "FastEstimator-Eval: step: 1152; epoch: 191; focal_loss: 0.0001799; l1_loss: 0.0188635; total_loss: 0.0190434; \n",
      "FastEstimator-Train: step: 1152; focal_loss: 0.0001224; l1_loss: 0.0211254; total_loss: 0.0212478; examples/sec: 32.2; progress: 96.0%; \n",
      "FastEstimator-Train: step: 1153; focal_loss: 0.0001118; l1_loss: 0.0371017; total_loss: 0.0372136; examples/sec: 32.4; progress: 96.1%; \n",
      "FastEstimator-Train: step: 1154; focal_loss: 0.0001661; l1_loss: 0.0209322; total_loss: 0.0210983; examples/sec: 32.6; progress: 96.2%; \n",
      "FastEstimator-Train: step: 1155; focal_loss: 0.0001275; l1_loss: 0.0113214; total_loss: 0.0114489; examples/sec: 32.2; progress: 96.2%; \n",
      "FastEstimator-Train: step: 1156; focal_loss: 0.0005172; l1_loss: 0.0170918; total_loss: 0.017609; examples/sec: 32.0; progress: 96.3%; \n",
      "FastEstimator-Train: step: 1157; focal_loss: 0.0001168; l1_loss: 0.0096272; total_loss: 0.009744; examples/sec: 32.4; progress: 96.4%; \n",
      "[0.998385668 0.997937739 0.963674068 ... 0.0537110269 0.0529782176 0.0515939]\n",
      "[0.979265571 0.974128485 0.966330826 0.945128441]\n",
      "[0.999202967 0.996462226 0.996153414 ... 0.0545877218 0.0542658269 0.0529266]\n",
      "[0.987046361 0.959225535]\n",
      "[0.991866052 0.972876072 0.970260143 ... 0.761931837 0.0680559874 0.0514638126]\n",
      "[0.967555881 0.962250829 0.950165868]\n",
      "[0.964786649 0.961599112 0.956612051 ... 0.0913224816 0.0846961737 0.0537076592]\n",
      "[0.982137 0.981924474 0.981257439 ... 0.405311853 0.288884521 0.0868349075]\n",
      "[0.993223786 0.991494536 0.979229927 ... 0.956174731 0.127709806 0.0763622522]\n",
      "[0.997283 0.995323658 0.994090557 ... 0.052981019 0.0528768599 0.0522949398]\n",
      "[0.975790441 0.974510312 0.974031627 ... 0.130259275 0.0677136183 0.0634172261]\n",
      "[0.992241681 0.927000046 0.298857093]\n",
      "[0.989102 0.971276581 0.965611815 ... 0.954926491 0.943859696 0.908031225]\n",
      "[0.959094524]\n",
      "[0.990196288 0.981850624 0.96250093 ... 0.0599249899 0.0556543767 0.0509801209]\n",
      "[0.980351627 0.968392193 0.939288139 0.935701609 0.914040923 0.752553]\n",
      "[0.970950246]\n",
      "[0.998572409 0.905382931 0.193751752]\n",
      "[0.995654225 0.993823051 0.986592472 ... 0.0578188598 0.0571194589 0.0543231964]\n",
      "[0.997504234 0.991811454 0.991038442 ... 0.0558539331 0.0554514825 0.0532832444]\n",
      "[0.979623675 0.97772944 0.972863138 ... 0.905950785 0.0648990571 0.0516393483]\n",
      "[0.975462317 0.966466665 0.95769918 ... 0.937708 0.134350747 0.0602006614]\n",
      "[0.971130252]\n",
      "[0.982770801 0.967216492 0.947496891]\n",
      "[0.999912262 0.999473572 0.998282433 ... 0.0625422 0.0602405369 0.0588133335]\n",
      "[0.9951334 0.988576055 0.983026385 ... 0.0553931892 0.0524540246 0.051491797]\n",
      "[0.98939395 0.983744502 0.964465916]\n",
      "[0.995892406 0.995871305 0.994559288 ... 0.0520039797 0.0519057512 0.0509039462]\n",
      "[0.976483107 0.95491755 0.940808296]\n",
      "[0.990889907 0.963214874]\n",
      "[0.994886577 0.99475944 0.993960619 0.99200803 0.96722424 0.898019433]\n",
      "[0.998781085 0.997692704 0.995210946 ... 0.0540701747 0.0527251065 0.0511519909]\n",
      "[0.9977718 0.984877467 0.977728784 ... 0.0554985404 0.0546479523 0.0532056391]\n",
      "[0.997508764 0.99296391 0.983967781 ... 0.0653224289 0.0565075278 0.0523464084]\n",
      "[0.993770182 0.981363714 0.957433939]\n",
      "[0.99413079 0.990007401 0.98555994 ... 0.05713135 0.0551700592 0.0509386659]\n",
      "[0.996355057 0.987915576 0.987245083 ... 0.0525358617 0.0518228412 0.051618427]\n",
      "[0.997293591 0.986833811]\n",
      "[0.99901849 0.996586561 0.995421052 ... 0.0541118979 0.0516241491 0.0514589846]\n",
      "[0.986644745 0.977297604 0.977174342 ... 0.186449349 0.0950842202 0.0705183446]\n",
      "[0.979457855]\n",
      "[0.984933496 0.96630168]\n",
      "[0.988718033 0.987063408 0.98589015 ... 0.309197426 0.0683040619 0.059692055]\n",
      "[0.979449153 0.937056541]\n",
      "[0.9941746 0.993926466 0.972647429 ... 0.0564135 0.0552997589 0.0536426902]\n",
      "[0.992217183 0.980587423 0.964458823 ... 0.573643565 0.282060921 0.055889219]\n",
      "[0.993790746 0.990476966 0.971292615 0.968987167 0.958683252]\n",
      "[0.967390537 0.96052438 0.958396196 0.941553891 0.928647935 0.0742833]\n",
      "FastEstimator-Eval: step: 1158; epoch: 192; focal_loss: 0.0001289; l1_loss: 0.0146413; total_loss: 0.0147702; \n",
      "FastEstimator-Train: step: 1158; focal_loss: 9.94e-05; l1_loss: 0.0209764; total_loss: 0.0210758; examples/sec: 31.9; progress: 96.5%; \n",
      "FastEstimator-Train: step: 1159; focal_loss: 0.0001403; l1_loss: 0.0094678; total_loss: 0.0096081; examples/sec: 32.2; progress: 96.6%; \n",
      "FastEstimator-Train: step: 1160; focal_loss: 0.0001471; l1_loss: 0.0149038; total_loss: 0.0150509; examples/sec: 32.7; progress: 96.7%; \n",
      "FastEstimator-Train: step: 1161; focal_loss: 0.0001451; l1_loss: 0.0089983; total_loss: 0.0091435; examples/sec: 32.4; progress: 96.8%; \n",
      "FastEstimator-Train: step: 1162; focal_loss: 0.0001585; l1_loss: 0.0072037; total_loss: 0.0073622; examples/sec: 31.8; progress: 96.8%; \n",
      "FastEstimator-Train: step: 1163; focal_loss: 0.000144; l1_loss: 0.0063802; total_loss: 0.0065243; examples/sec: 32.2; progress: 96.9%; \n",
      "[0.99985826 0.998071671 0.996932626 ... 0.0527973473 0.0514054298 0.0501502752]\n",
      "[0.998652 0.981831372 0.969995499 0.951640785]\n",
      "[0.998900712 0.998325765 0.972634912 ... 0.0581439137 0.0534488857 0.0507737696]\n",
      "[0.981931448 0.976678252 0.969421 0.941648841 0.050363481]\n",
      "[0.999334693 0.997055769 0.996181726 ... 0.0551094413 0.0517263114 0.0510565341]\n",
      "[0.986710072 0.953185737]\n",
      "[0.992348194 0.973397732 0.971523464 ... 0.82024 0.0755519271 0.0579747856]\n",
      "[0.968614519 0.964020729 0.95178622]\n",
      "[0.968859196 0.967426121 0.963562548 ... 0.0960794091 0.0554362833 0.0517109334]\n",
      "[0.985240936 0.984552085 0.982688308 ... 0.331049323 0.103342175 0.0514648557]\n",
      "[0.993213773 0.988290489 0.971641064 ... 0.942040682 0.117269218 0.0950166285]\n",
      "[0.998150229 0.996413589 0.995394945 ... 0.0534052849 0.0527706444 0.0525637269]\n",
      "[0.9790622 0.976353288 0.975708187 ... 0.151765764 0.0713514388 0.0597711802]\n",
      "[0.991418958 0.936752617 0.306042731]\n",
      "[0.991148 0.977146506 0.973559916 ... 0.962817252 0.954360127 0.898575187]\n",
      "[0.945639968]\n",
      "[0.991339445 0.98561132 0.977122307 ... 0.0546192825 0.0532530844 0.0517308116]\n",
      "[0.983654737 0.980501711 0.948940456 ... 0.928496122 0.771060228 0.0511445403]\n",
      "[0.972614408]\n",
      "[0.998639226 0.921667337 0.240942329]\n",
      "[0.995905757 0.994106352 0.988141 ... 0.0716979206 0.0562025309 0.0537647]\n",
      "[0.99787581 0.994956255 0.992538095 ... 0.0525526404 0.0521048903 0.0511713028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98393774 0.981217742 0.978955925 ... 0.0700246692 0.0515356064 0.0503374934]\n",
      "[0.977268279 0.972717166 0.968426585 ... 0.936736822 0.181967407 0.0570483208]\n",
      "[0.973815501]\n",
      "[0.981061935 0.973714828 0.94465661]\n",
      "[0.999934196 0.999610662 0.998555183 ... 0.0677610338 0.0584693849 0.0504846871]\n",
      "[0.995257735 0.991573334 0.983921707 ... 0.052028358 0.0509494245 0.0500200391]\n",
      "[0.991757035 0.982370555 0.966526866]\n",
      "[0.996196389 0.995723605 0.994330287 ... 0.0523805618 0.0521193743 0.0500293672]\n",
      "[0.975750446 0.96510309 0.937152386 0.0534216166]\n",
      "[0.987708 0.96109736]\n",
      "[0.996453047 0.996215105 0.994590759 0.994522 0.97932744 0.915057421]\n",
      "[0.998929739 0.998684883 0.996688545 ... 0.0535434186 0.052767247 0.0517692566]\n",
      "[0.997540951 0.983913898 0.974987388 ... 0.0559244454 0.0557602048 0.0518254042]\n",
      "[0.997828722 0.993316412 0.985303223 ... 0.0565785766 0.0547170043 0.0518681109]\n",
      "[0.99481976 0.982507348 0.95204854]\n",
      "[0.994388342 0.990576148 0.98789537 ... 0.0551533103 0.0551151037 0.0506641865]\n",
      "[0.996935725 0.988938391 0.988825262 ... 0.0523744524 0.0512992442 0.0501240492]\n",
      "[0.995907128 0.982630312]\n",
      "[0.999235094 0.997048736 0.996859491 ... 0.0608375669 0.0592116117 0.0560558438]\n",
      "[0.985459745 0.983143 0.982710242 ... 0.170785338 0.10628739 0.0701041818]\n",
      "[0.978639]\n",
      "[0.977334619 0.954503775]\n",
      "[0.990384579 0.990216136 0.986843 ... 0.0730151236 0.0555470586 0.0535096526]\n",
      "[0.976992309 0.926336884]\n",
      "[0.995302141 0.99408555 0.976929665 ... 0.0527726114 0.0522545278 0.0503261685]\n",
      "[0.994228244 0.986738324 0.971775413 ... 0.673253775 0.277869105 0.0526035428]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 1164; epoch: 193; focal_loss: 0.0001498; l1_loss: 0.0078145; total_loss: 0.0079643; \n",
      "FastEstimator-Train: step: 1164; focal_loss: 0.0001298; l1_loss: 0.0115746; total_loss: 0.0117044; examples/sec: 31.8; progress: 97.0%; \n",
      "FastEstimator-Train: step: 1165; focal_loss: 0.0002175; l1_loss: 0.0095913; total_loss: 0.0098088; examples/sec: 31.8; progress: 97.1%; \n",
      "FastEstimator-Train: step: 1166; focal_loss: 0.0001386; l1_loss: 0.0116482; total_loss: 0.0117868; examples/sec: 32.4; progress: 97.2%; \n",
      "FastEstimator-Train: step: 1167; focal_loss: 6.7e-05; l1_loss: 0.007893; total_loss: 0.00796; examples/sec: 32.1; progress: 97.2%; \n",
      "FastEstimator-Train: step: 1168; focal_loss: 0.0003324; l1_loss: 0.0097306; total_loss: 0.010063; examples/sec: 32.2; progress: 97.3%; \n",
      "FastEstimator-Train: step: 1169; focal_loss: 0.0001095; l1_loss: 0.0044108; total_loss: 0.0045202; examples/sec: 31.8; progress: 97.4%; \n",
      "[0.995180666 0.99320209 0.975244403 0.973323524 0.967669129]\n",
      "[0.962992251 0.956619143 0.955540299 0.942036033 0.922882318 0.0838864446]\n",
      "[0.999886811 0.997959852 0.997117043 ... 0.0539333522 0.0534792542 0.0527485]\n",
      "[0.998839378 0.984044552 0.979168713 0.966032863 0.152189583]\n",
      "[0.998860478 0.998425782 0.974099278 ... 0.0616085529 0.0615805387 0.0565361083]\n",
      "[0.981034756 0.975074768 0.968627512 0.950556159 0.0505311191]\n",
      "[0.999315858 0.996980429 0.9961465 ... 0.0520733595 0.0512512326 0.0509981513]\n",
      "[0.98796308 0.964559674]\n",
      "[0.993429184 0.973198652 0.972491443 ... 0.0571805239 0.0530967712 0.0501329]\n",
      "[0.97735244 0.972552836 0.958895504]\n",
      "[0.970296681 0.969623446 0.964218 ... 0.108663499 0.0944238 0.0535036623]\n",
      "[0.984705567 0.984401703 0.98413 ... 0.333388358 0.123822 0.058945924]\n",
      "[0.994522631 0.99138236 0.977778196 ... 0.949162304 0.126115292 0.1017223]\n",
      "[0.998337924 0.996775 0.996029675 ... 0.0556403697 0.0553450584 0.0536904931]\n",
      "[0.980109513 0.976865768 0.976015806 ... 0.150886 0.0650498867 0.0573076]\n",
      "[0.993787766 0.955121279 0.341266751]\n",
      "[0.991818786 0.977620602 0.975832582 ... 0.957466066 0.927555561 0.551641405]\n",
      "[0.955680251]\n",
      "[0.993409336 0.984657407 0.978281856 ... 0.0513715446 0.0509914756 0.0501850843]\n",
      "[0.983407855 0.972643 0.958019316 0.956870794 0.932836413 0.783486366]\n",
      "[0.979250908]\n",
      "[0.999295294 0.937594414 0.267680645]\n",
      "[0.995412648 0.994754314 0.987883329 ... 0.0660616457 0.0607665777 0.0580340624]\n",
      "[0.998149395 0.995972276 0.992764473 ... 0.0515063107 0.0507181287 0.050529331]\n",
      "[0.987459958 0.983143628 0.982400119 ... 0.0753096938 0.0547698736 0.0511517525]\n",
      "[0.978651047 0.976223469 0.970242441 ... 0.949165046 0.178429812 0.0552885532]\n",
      "[0.970784187]\n",
      "[0.985029578 0.975801706 0.955192506]\n",
      "[0.999939919 0.999675274 0.998689055 ... 0.062233597 0.054217726 0.050044328]\n",
      "[0.996567249 0.991576 0.983918786 ... 0.0533100367 0.0526933074 0.0502636135]\n",
      "[0.992546797 0.98230803 0.964586437]\n",
      "[0.996655107 0.995394 0.994502723 ... 0.0534492433 0.0532937348 0.0522449911]\n",
      "[0.984328866 0.970494866 0.95821023 0.0549424]\n",
      "[0.991418481 0.96385324]\n",
      "[0.996463537 0.996434093 0.994500875 0.994421661 0.979661763 0.928384542]\n",
      "[0.998887658 0.998822153 0.996869206 ... 0.0516584218 0.051097095 0.0506164134]\n",
      "[0.997800469 0.984862804 0.978422344 ... 0.0515470803 0.0514125526 0.0510360897]\n",
      "[0.997991204 0.993628263 0.986476779 ... 0.0624882877 0.0556496978 0.0526765]\n",
      "[0.994728386 0.984615564 0.962681651]\n",
      "[0.994244277 0.990188897 0.988040388 ... 0.0613981783 0.0518052578 0.0514546633]\n",
      "[0.997233033 0.98936069 0.987959504 ... 0.0525250435 0.0517237782 0.0503604114]\n",
      "[0.997331262 0.9873752]\n",
      "[0.999128461 0.997188747 0.997186065 ... 0.0625673234 0.0564193428 0.050011754]\n",
      "[0.987777233 0.98386848 0.982025087 ... 0.184276879 0.104418635 0.0885477364]\n",
      "[0.984921455]\n",
      "[0.982807219 0.966616631]\n",
      "[0.9917171 0.989961505 0.989366174 ... 0.0810834169 0.0567657351 0.051358819]\n",
      "[0.982979119 0.950429916]\n",
      "FastEstimator-Eval: step: 1170; epoch: 194; focal_loss: 0.0001323; l1_loss: 0.0079701; total_loss: 0.0081023; \n",
      "FastEstimator-Train: step: 1170; focal_loss: 0.0001268; l1_loss: 0.005705; total_loss: 0.0058318; examples/sec: 32.4; progress: 97.5%; \n",
      "FastEstimator-Train: step: 1171; focal_loss: 0.0001947; l1_loss: 0.0108553; total_loss: 0.01105; examples/sec: 32.4; progress: 97.6%; \n",
      "FastEstimator-Train: step: 1172; focal_loss: 0.0001065; l1_loss: 0.0053928; total_loss: 0.0054994; examples/sec: 31.9; progress: 97.7%; \n",
      "FastEstimator-Train: step: 1173; focal_loss: 0.0001099; l1_loss: 0.0149098; total_loss: 0.0150197; examples/sec: 32.7; progress: 97.8%; \n",
      "FastEstimator-Train: step: 1174; focal_loss: 0.0001834; l1_loss: 0.0075218; total_loss: 0.0077052; examples/sec: 32.3; progress: 97.8%; \n",
      "FastEstimator-Train: step: 1175; focal_loss: 0.0001247; l1_loss: 0.0076955; total_loss: 0.0078201; examples/sec: 32.1; progress: 97.9%; \n",
      "[0.99612993 0.99415195 0.97921747 ... 0.0619738102 0.0608490407 0.0511840284]\n",
      "[0.994290113 0.985360265 0.97588408 ... 0.262331188 0.0683016777 0.0507232547]\n",
      "[0.99130559 0.989409566 0.969912171 0.962366879 0.9577775]\n",
      "[0.949785948 0.942854 0.941027462 0.936003804 0.895498633 0.0828892291]\n",
      "[0.999902964 0.997484922 0.996800423 ... 0.0526691079 0.0525580347 0.0525227189]\n",
      "[0.998711765 0.981156945 0.97280252 0.956010222 0.137188107]\n",
      "[0.998947 0.998506188 0.972619414 ... 0.057194829 0.0539551675 0.0524579]\n",
      "[0.977619767 0.96893084 0.963606477 0.936210275]\n",
      "[0.999312639 0.996895611 0.996266782 ... 0.0571201444 0.0508895516 0.0500030518]\n",
      "[0.986509919 0.952911258]\n",
      "[0.993147969 0.970716357 0.968240261 ... 0.854004741 0.0646231771 0.0556046963]\n",
      "[0.97262007 0.964386582 0.958807468]\n",
      "[0.965513825 0.965045214 0.960043192 ... 0.11466974 0.085719347 0.0855193138]\n",
      "[0.983704567 0.983409643 0.982758284 ... 0.327679664 0.125635386 0.0554120839]\n",
      "[0.993585467 0.988585293 0.971229672 ... 0.934465408 0.111301601 0.0871321857]\n",
      "[0.998533785 0.997130632 0.996485114 ... 0.0559875071 0.0537457168 0.051132381]\n",
      "[0.979894161 0.975519121 0.974198103 ... 0.156234264 0.152343452 0.0589602888]\n",
      "[0.991780519 0.940294 0.30117321]\n",
      "[0.991498351 0.975635767 0.975179434 ... 0.962806404 0.95681572 0.9131639]\n",
      "[0.948064804]\n",
      "[0.995094717 0.983247042 0.979277849 ... 0.0571683645 0.0522429943 0.050293088]\n",
      "[0.983587265 0.960237145 0.953083754 0.941124439 0.921887636 0.781588912]\n",
      "[0.973078609]\n",
      "[0.9990834 0.935182 0.235974818]\n",
      "[0.994939566 0.994696498 0.987284064 ... 0.0601571202 0.0548179746 0.0509040952]\n",
      "[0.997563601 0.996477246 0.992312551 ... 0.0526721179 0.0523646772 0.0520191789]\n",
      "[0.983844638 0.980658352 0.979694843 ... 0.102500439 0.0640717447 0.0507327914]\n",
      "[0.979435861 0.978267193 0.968509674 ... 0.93775034 0.173810661 0.0519277155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96345377]\n",
      "[0.983006954 0.977073848 0.94418788]\n",
      "[0.999937296 0.999645472 0.998596787 ... 0.0625954866 0.05954808 0.0548291802]\n",
      "[0.995919228 0.991513491 0.982761145 ... 0.0530097187 0.0510219634 0.0504653752]\n",
      "[0.992566347 0.984474361 0.963393867]\n",
      "[0.99559617 0.994524 0.994067073 ... 0.0529994071 0.0525803566 0.0503200889]\n",
      "[0.983132064 0.970396 0.949117541 0.0545772314]\n",
      "[0.98913157 0.962095499]\n",
      "[0.996260226 0.995428205 0.993688 ... 0.976883948 0.913204193 0.20473218]\n",
      "[0.998783529 0.998165 0.996455431 ... 0.0528102219 0.0520303547 0.0517666936]\n",
      "[0.998225927 0.987273574 0.980788 ... 0.0552553833 0.0528133214 0.050604254]\n",
      "[0.997650385 0.992910624 0.982821822 ... 0.0692884 0.0595223308 0.0502953529]\n",
      "[0.99400425 0.982848883 0.949568629]\n",
      "[0.994124293 0.989774346 0.987185 ... 0.0584331155 0.0579452813 0.050322175]\n",
      "[0.997216821 0.989451349 0.984675288 ... 0.0531401038 0.0509673953 0.050344497]\n",
      "[0.996676803 0.984623671]\n",
      "[0.99909544 0.99688518 0.996670663 ... 0.0570357144 0.0564675927 0.0547757447]\n",
      "[0.984016061 0.982255638 0.978609562 ... 0.155142933 0.0961208045 0.0806314647]\n",
      "[0.980096638]\n",
      "[0.978886604 0.956161141]\n",
      "FastEstimator-Eval: step: 1176; epoch: 195; focal_loss: 0.0001251; l1_loss: 0.0096145; total_loss: 0.0097397; \n",
      "FastEstimator-Train: step: 1176; focal_loss: 9.99e-05; l1_loss: 0.0082443; total_loss: 0.0083442; examples/sec: 32.4; progress: 98.0%; \n",
      "FastEstimator-Train: step: 1177; focal_loss: 0.0001502; l1_loss: 0.008348; total_loss: 0.0084982; examples/sec: 32.3; progress: 98.1%; \n",
      "FastEstimator-Train: step: 1178; focal_loss: 0.0001009; l1_loss: 0.0090476; total_loss: 0.0091486; examples/sec: 32.5; progress: 98.2%; \n",
      "FastEstimator-Train: step: 1179; focal_loss: 0.0001949; l1_loss: 0.0145088; total_loss: 0.0147036; examples/sec: 32.5; progress: 98.2%; \n",
      "FastEstimator-Train: step: 1180; focal_loss: 8.08e-05; l1_loss: 0.0145581; total_loss: 0.0146389; examples/sec: 32.2; progress: 98.3%; \n",
      "FastEstimator-Train: step: 1181; focal_loss: 6.95e-05; l1_loss: 0.006478; total_loss: 0.0065475; examples/sec: 32.1; progress: 98.4%; \n",
      "[0.992113709 0.988335073 0.987747192 ... 0.285146832 0.0824236274 0.0617455244]\n",
      "[0.976585686 0.948725462]\n",
      "[0.996359 0.993964732 0.979391158 ... 0.0610807836 0.052485913 0.0518075526]\n",
      "[0.995105445 0.985610068 0.977526784 ... 0.268487632 0.0611201227 0.0526690781]\n",
      "[0.99024564 0.990042329 0.96859169 0.960702538 0.946485519]\n",
      "[0.957303882 0.949793696 0.947506 0.942380071 0.910860419 0.0833831429]\n",
      "[0.999924779 0.996773601 0.996550441 ... 0.052475512 0.0518142283 0.0501063764]\n",
      "[0.998928428 0.981854796 0.977090359 0.96444]\n",
      "[0.999041438 0.99869293 0.973013639 ... 0.0545055568 0.0542011559 0.0529921651]\n",
      "[0.979923606 0.970096231 0.963608682 0.944045246]\n",
      "[0.999340534 0.996770322 0.996642888 ... 0.0561617315 0.0551501215 0.0513632596]\n",
      "[0.987420142 0.955063]\n",
      "[0.994537 0.974827886 0.97135663 ... 0.841582298 0.0558891594 0.0529179871]\n",
      "[0.976733208 0.969308555 0.967324317]\n",
      "[0.967111588 0.965673804 0.962646127 ... 0.0987049639 0.0793241858 0.0710704923]\n",
      "[0.985063434 0.983967423 0.983080804 ... 0.466852 0.345155835 0.126155257]\n",
      "[0.994285345 0.989567876 0.975928187 ... 0.943174 0.111979097 0.0744230449]\n",
      "[0.998853683 0.997456789 0.996853828 ... 0.058421582 0.057970643 0.050116241]\n",
      "[0.980958223 0.977671921 0.977021337 ... 0.149463832 0.0597639978 0.0502638221]\n",
      "[0.993110657 0.938392043 0.296304643]\n",
      "[0.992120743 0.976073146 0.974721074 ... 0.959972918 0.956520557 0.927305937]\n",
      "[0.960190892]\n",
      "[0.99581784 0.985270441 0.981566191 ... 0.062233 0.0555541515 0.0517415404]\n",
      "[0.984055221 0.962088 0.951241374 0.950154066 0.908446312 0.779103398]\n",
      "[0.976682961]\n",
      "[0.999171257 0.939463317 0.213735223]\n",
      "[0.994741321 0.994674444 0.986372828 ... 0.145195872 0.0518978834 0.0507160127]\n",
      "[0.997399151 0.996627092 0.993852615 ... 0.0684014261 0.058562994 0.0584173501]\n",
      "[0.982859969 0.980891585 0.978199422 ... 0.905573487 0.061323911 0.0520023704]\n",
      "[0.982688785 0.980894089 0.96831882 0.939667225 0.936984658 0.174909204]\n",
      "[0.966344357]\n",
      "[0.981502533 0.977517366 0.933963954]\n",
      "[0.999948621 0.999664783 0.998739 ... 0.0584903359 0.0572080612 0.0525678694]\n",
      "[0.996874273 0.992692828 0.982393384 ... 0.0572496057 0.0551977754 0.0551926792]\n",
      "[0.993051052 0.987784 0.967247725]\n",
      "[0.995127797 0.995104313 0.994673252 ... 0.0532897413 0.0518940687 0.05178231]\n",
      "[0.985210061 0.968558311 0.947500706]\n",
      "[0.990882754 0.962920189]\n",
      "[0.996257424 0.995161891 0.994379401 0.993063688 0.974947035 0.919918656]\n",
      "[0.999088764 0.997364521 0.996087492 ... 0.0528415143 0.0525180697 0.0518657565]\n",
      "[0.998574376 0.989604771 0.980710864 ... 0.0639888048 0.0556586683 0.0513908863]\n",
      "[0.997786403 0.993864059 0.983443141 ... 0.115597099 0.0630994141 0.0568602085]\n",
      "[0.993612528 0.983998537 0.942400336]\n",
      "[0.994865179 0.990087152 0.989457428 ... 0.0586980879 0.0586088598 0.0515452623]\n",
      "[0.997293472 0.990846694 0.985603094 ... 0.0574246049 0.0540726483 0.0519107878]\n",
      "[0.997232199 0.986436665]\n",
      "[0.999255061 0.996390939 0.996373832 ... 0.0567473471 0.0564641953 0.0500147641]\n",
      "[0.98333329 0.982863784 0.977950811 ... 0.150312036 0.0904057324 0.0890063345]\n",
      "FastEstimator-Eval: step: 1182; epoch: 196; focal_loss: 0.0001094; l1_loss: 0.0078871; total_loss: 0.0079965; \n",
      "FastEstimator-Train: step: 1182; focal_loss: 7.32e-05; l1_loss: 0.0041324; total_loss: 0.0042056; examples/sec: 32.2; progress: 98.5%; \n",
      "FastEstimator-Train: step: 1183; focal_loss: 0.0001016; l1_loss: 0.0150572; total_loss: 0.0151588; examples/sec: 32.1; progress: 98.6%; \n",
      "FastEstimator-Train: step: 1184; focal_loss: 0.000333; l1_loss: 0.0068792; total_loss: 0.0072123; examples/sec: 31.8; progress: 98.7%; \n",
      "FastEstimator-Train: step: 1185; focal_loss: 0.000125; l1_loss: 0.0066517; total_loss: 0.0067767; examples/sec: 32.6; progress: 98.8%; \n",
      "FastEstimator-Train: step: 1186; focal_loss: 0.0001112; l1_loss: 0.0056748; total_loss: 0.005786; examples/sec: 32.2; progress: 98.8%; \n",
      "FastEstimator-Train: step: 1187; focal_loss: 5.9e-05; l1_loss: 0.0142623; total_loss: 0.0143213; examples/sec: 32.2; progress: 98.9%; \n",
      "[0.983632326]\n",
      "[0.982716322 0.961809933]\n",
      "[0.992360771 0.989599824 0.989293635 ... 0.305024028 0.0620066524 0.0526418686]\n",
      "[0.971987128 0.944464803]\n",
      "[0.995962501 0.994195938 0.979951 ... 0.0620286167 0.0607471168 0.056132555]\n",
      "[0.995347142 0.986293674 0.978634477 ... 0.0604207516 0.0529428124 0.0509721041]\n",
      "[0.991341412 0.990338087 0.969960749 0.962313533 0.951999903]\n",
      "[0.952896595 0.942036271 0.942003191 0.940135062 0.900220335 0.0795755684]\n",
      "[0.999934077 0.996568203 0.996141493 ... 0.0529012382 0.0527735353 0.0511596203]\n",
      "[0.999012589 0.98219347 0.975520492 0.962771773]\n",
      "[0.998769045 0.998424888 0.977435887 ... 0.0524469614 0.0516225696 0.0507333279]\n",
      "[0.980640113 0.969663501 0.964157283 0.948721766]\n",
      "[0.999424279 0.996933937 0.996567 ... 0.0527578 0.0504455864 0.0503733456]\n",
      "[0.986587048 0.953491449]\n",
      "[0.99516505 0.979654908 0.973142505 ... 0.865035892 0.0607183278 0.0595113337]\n",
      "[0.975857675 0.969001412 0.968663]\n",
      "[0.966263056 0.96324867 0.961958945 ... 0.0741175115 0.0715373158 0.0579789]\n",
      "[0.984434426 0.984166384 0.983613074 ... 0.370919645 0.135123193 0.0509053469]\n",
      "[0.994401336 0.988195539 0.974167705 ... 0.945809484 0.117208242 0.0726828277]\n",
      "[0.999047875 0.99745059 0.996971369 ... 0.0542482436 0.053283155 0.0508759916]\n",
      "[0.983785033 0.982085943 0.980683446 ... 0.176991105 0.15997985 0.0778215528]\n",
      "[0.993339896 0.937841892 0.29349798]\n",
      "[0.992596924 0.972947955 0.968433261 ... 0.954139769 0.952261925 0.928902864]\n",
      "[0.956600547]\n",
      "[0.995767653 0.989126801 0.980223298 ... 0.0574484766 0.0539701283 0.0502979755]\n",
      "[0.984532773 0.965092182 0.954239249 0.946590304 0.900194943 0.768646836]\n",
      "[0.976149201]\n",
      "[0.998990655 0.939120054 0.203978956]\n",
      "[0.995598793 0.993938088 0.986418843 ... 0.139744967 0.0854693949 0.0581963658]\n",
      "[0.997229099 0.995912075 0.994167089 ... 0.0545481741 0.0539658368 0.0532617867]\n",
      "[0.985613585 0.982910395 0.97917521 ... 0.919512033 0.0673956 0.052724123]\n",
      "[0.981571674 0.977899 0.966729343 0.935077608 0.933539093 0.148438841]\n",
      "[0.967879295]\n",
      "[0.979519784 0.978648841 0.93059206]\n",
      "[0.9999578 0.999713182 0.998944163 ... 0.0559415519 0.0553601086 0.0516999066]\n",
      "[0.997323036 0.991307259 0.981981874 ... 0.0574142337 0.0530360937 0.0528521538]\n",
      "[0.991504192 0.984310687 0.971969366]\n",
      "[0.995525599 0.995283604 0.995194077 ... 0.0527672172 0.0523815155 0.0509361029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.982882 0.965803146 0.937761188]\n",
      "[0.990714192 0.962858617]\n",
      "[0.995649219 0.995360315 0.994889 0.993571758 0.966434121 0.929196835]\n",
      "[0.999231 0.997624636 0.996624649 ... 0.057516396 0.0531213 0.0506055057]\n",
      "[0.998515 0.989513636 0.982176661 ... 0.0542086065 0.0510974526 0.0503168106]\n",
      "[0.997651041 0.99350369 0.984591722 ... 0.0620988 0.0539366901 0.052472353]\n",
      "[0.99292171 0.984896779 0.941773295]\n",
      "[0.995464802 0.990967274 0.990533 ... 0.0635235 0.0601339042 0.0532009304]\n",
      "[0.997146606 0.990137577 0.985755444 ... 0.0553256869 0.0514213741 0.0506465435]\n",
      "[0.997453332 0.986898303]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 1188; epoch: 197; focal_loss: 0.0001074; l1_loss: 0.0072549; total_loss: 0.0073624; \n",
      "FastEstimator-Train: step: 1188; focal_loss: 0.0001246; l1_loss: 0.0138892; total_loss: 0.0140137; examples/sec: 31.7; progress: 99.0%; \n",
      "FastEstimator-Train: step: 1189; focal_loss: 0.0001591; l1_loss: 0.0105975; total_loss: 0.0107566; examples/sec: 32.0; progress: 99.1%; \n",
      "FastEstimator-Train: step: 1190; focal_loss: 9.86e-05; l1_loss: 0.0077218; total_loss: 0.0078203; examples/sec: 32.4; progress: 99.2%; \n",
      "FastEstimator-Train: step: 1191; focal_loss: 4.92e-05; l1_loss: 0.0135339; total_loss: 0.0135832; examples/sec: 32.7; progress: 99.2%; \n",
      "FastEstimator-Train: step: 1192; focal_loss: 0.0002238; l1_loss: 0.0056935; total_loss: 0.0059173; examples/sec: 32.3; progress: 99.3%; \n",
      "FastEstimator-Train: step: 1193; focal_loss: 8.33e-05; l1_loss: 0.0170639; total_loss: 0.0171472; examples/sec: 31.9; progress: 99.4%; \n",
      "[0.999667525 0.997104168 0.996531487 ... 0.0638526678 0.0627458096 0.059859246]\n",
      "[0.986587286 0.984229863 0.981287599 ... 0.132132679 0.0869112909 0.0854993463]\n",
      "[0.985875964]\n",
      "[0.98167789 0.964158654]\n",
      "[0.992737651 0.990589142 0.990038514 ... 0.0708798468 0.066814065 0.0578776896]\n",
      "[0.970365286 0.940953791]\n",
      "[0.996947408 0.994270802 0.981798649 ... 0.0622886121 0.0621112 0.0569631159]\n",
      "[0.995110512 0.985827565 0.979177117 ... 0.719014585 0.258868635 0.0593748391]\n",
      "[0.991406083 0.990293622 0.971769691 0.966678 0.953876257]\n",
      "[0.954599619 0.949655771 0.948029041 0.947829902 0.909410357 0.0816091299]\n",
      "[0.999939382 0.996443152 0.995343387 ... 0.0517317951 0.0510065854 0.0508523881]\n",
      "[0.998933315 0.983147502 0.970147729 0.956113815 0.127110839]\n",
      "[0.998881221 0.998527527 0.982089043 ... 0.0544036329 0.0537610054 0.0500954688]\n",
      "[0.981005 0.970263362 0.967779696 0.950791]\n",
      "[0.999552906 0.997339487 0.997021675 ... 0.0545363128 0.0515225828 0.0500817]\n",
      "[0.987771034 0.953632653]\n",
      "[0.995685697 0.980019033 0.974337935 ... 0.886573076 0.0644231737 0.0613736808]\n",
      "[0.974415541 0.968469501 0.968293786]\n",
      "[0.970292866 0.968016922 0.965390801 ... 0.0622540116 0.0530792177 0.0508892834]\n",
      "[0.986464441 0.9855299 0.985046387 ... 0.387223303 0.153488845 0.0558478236]\n",
      "[0.994442344 0.98710376 0.972712755 ... 0.947163224 0.118599892 0.0769958496]\n",
      "[0.999226928 0.997936487 0.996972442 ... 0.0546314418 0.0529541075 0.0515931547]\n",
      "[0.986355 0.984583616 0.982863665 ... 0.163131028 0.0894425809 0.0505542159]\n",
      "[0.993145 0.938653171 0.29990989]\n",
      "[0.992886543 0.976943 0.971759558 ... 0.959828734 0.955608368 0.9300704]\n",
      "[0.961547256]\n",
      "[0.996097 0.991910219 0.984898806 ... 0.0555644929 0.0528205037 0.0509220362]\n",
      "[0.98840791 0.970801294 0.960825443 0.954340518 0.916476846 0.782413721]\n",
      "[0.977576733]\n",
      "[0.998899102 0.943737268 0.206094563]\n",
      "[0.995952129 0.993816257 0.988404155 ... 0.134874523 0.0651872456 0.0554607809]\n",
      "[0.99729526 0.996335804 0.994837761 ... 0.0522884727 0.0515785217 0.0512745678]\n",
      "[0.987796545 0.984549403 0.980614185 ... 0.92699331 0.0720104873 0.0516883433]\n",
      "[0.982872725 0.982246697 0.97024262 0.942140222 0.941665411 0.173726112]\n",
      "[0.969822586]\n",
      "[0.981701851 0.980642319 0.932656527]\n",
      "[0.999967694 0.999767661 0.999026239 ... 0.0624061227 0.0578356683 0.0514742136]\n",
      "[0.997606516 0.993193626 0.981642246 ... 0.0591734648 0.0558547974 0.054889679]\n",
      "[0.99298 0.981842935 0.976390183]\n",
      "[0.9961133 0.996019244 0.995671391 ... 0.0553168654 0.0543479919 0.0535852]\n",
      "[0.981117487 0.966835856 0.936486959]\n",
      "[0.990442634 0.963542461]\n",
      "[0.996165514 0.995653749 0.995037556 0.994526267 0.966215611 0.940160155]\n",
      "[0.999356 0.998118281 0.996973 ... 0.0548743606 0.0514415503 0.0506324768]\n",
      "[0.998489857 0.988899589 0.980413437 ... 0.0630494952 0.0515452325 0.0513662398]\n",
      "[0.997783124 0.993799925 0.985729456 ... 0.0575971 0.056260258 0.0530709624]\n",
      "[0.995008588 0.98720336 0.953010082]\n",
      "[0.995571434 0.991289139 0.990799785 ... 0.0537371933 0.0529319942 0.0511465371]\n",
      "FastEstimator-ModelSaver: Saving model to /data/hsiming/mscoco_model/retinanet_best_total_loss.h5\n",
      "FastEstimator-Eval: step: 1194; epoch: 198; focal_loss: 9.96e-05; l1_loss: 0.0061802; total_loss: 0.0062798; \n",
      "FastEstimator-Train: step: 1194; focal_loss: 0.000209; l1_loss: 0.0083538; total_loss: 0.0085628; examples/sec: 31.7; progress: 99.5%; \n",
      "FastEstimator-Train: step: 1195; focal_loss: 9.6e-05; l1_loss: 0.0086573; total_loss: 0.0087533; examples/sec: 32.1; progress: 99.6%; \n",
      "FastEstimator-Train: step: 1196; focal_loss: 7.43e-05; l1_loss: 0.0077255; total_loss: 0.0077997; examples/sec: 32.3; progress: 99.7%; \n",
      "FastEstimator-Train: step: 1197; focal_loss: 7.43e-05; l1_loss: 0.0097589; total_loss: 0.0098332; examples/sec: 32.7; progress: 99.8%; \n",
      "FastEstimator-Train: step: 1198; focal_loss: 0.0001187; l1_loss: 0.0102595; total_loss: 0.0103783; examples/sec: 32.6; progress: 99.8%; \n",
      "FastEstimator-Train: step: 1199; focal_loss: 8.51e-05; l1_loss: 0.0047546; total_loss: 0.0048397; examples/sec: 31.7; progress: 99.9%; \n",
      "[0.997582614 0.991917729 0.985994458 ... 0.0546191633 0.0528468788 0.0508649945]\n",
      "[0.997301519 0.986387]\n",
      "[0.999575853 0.997159839 0.996845782 ... 0.060005039 0.0595099926 0.0589796305]\n",
      "[0.985674858 0.984957278 0.978498936 ... 0.119201809 0.0842595398 0.0733040869]\n",
      "[0.979229927]\n",
      "[0.980189204 0.965526938]\n",
      "[0.991644263 0.990413904 0.989663243 ... 0.0700693429 0.067735523 0.0506220162]\n",
      "[0.97193253 0.937536716]\n",
      "[0.997445226 0.994766831 0.984458923 ... 0.060644418 0.0599045753 0.0597256124]\n",
      "[0.994499385 0.984266162 0.978392422 ... 0.708708763 0.243867457 0.0627130866]\n",
      "[0.990874529 0.990619898 0.970593691 0.966457 0.959063053]\n",
      "[0.949896336 0.947844386 0.945498705 0.944427133 0.902631223 0.0802377462]\n",
      "[0.999900281 0.995962739 0.993629277 ... 0.0526640415 0.0521377623 0.0519681871]\n",
      "[0.998769879 0.980812311 0.963482499 0.944605649 0.123302609]\n",
      "[0.998856723 0.99844265 0.98119688 ... 0.0574918687 0.0532230139 0.0527306497]\n",
      "[0.97989881 0.969335616 0.968209803 0.946395278]\n",
      "[0.999487698 0.997239113 0.997012436 ... 0.056694746 0.0513570905 0.0511429]\n",
      "[0.987392366 0.952076316]\n",
      "[0.994649529 0.97440815 0.972304702 ... 0.890526712 0.0626333058 0.0618937314]\n",
      "[0.972053885 0.965059698 0.964008331]\n",
      "[0.967158794 0.964043081 0.963076413 ... 0.0702976 0.0534393191 0.0531494021]\n",
      "[0.985468268 0.985463142 0.983109176 ... 0.367329478 0.14341256 0.0588917136]\n",
      "[0.994933188 0.987970948 0.974143267 ... 0.947315931 0.115341365 0.0821395814]\n",
      "[0.998920202 0.997861743 0.996887803 ... 0.0522625744 0.0511254966 0.0505024195]\n",
      "[0.983607292 0.983294725 0.983023643 ... 0.152926534 0.0794891417 0.0527051389]\n",
      "[0.99299252 0.941311 0.294066399]\n",
      "[0.992678404 0.977284312 0.972264886 ... 0.959616661 0.956229091 0.921238899]\n",
      "[0.959892631]\n",
      "[0.995416403 0.989482641 0.984967947 ... 0.0562319458 0.0550640225 0.052526027]\n",
      "[0.987719774 0.964497685 0.961029053 ... 0.922269106 0.772166491 0.0533252358]\n",
      "[0.971874118]\n",
      "[0.998991966 0.949282289 0.199452758]\n",
      "[0.995374084 0.994385719 0.988014758 ... 0.0919247 0.060198307 0.0515238047]\n",
      "[0.996992469 0.996499419 0.994768143 ... 0.052000463 0.0510983765 0.050614506]\n",
      "[0.988684535 0.985270798 0.981270909 ... 0.929467082 0.0705842078 0.0500520766]\n",
      "[0.983603179 0.983139336 0.970056295 0.941745758 0.941649556 0.173588723]\n",
      "[0.966556311]\n",
      "[0.984200358 0.984092474 0.941733241]\n",
      "[0.999970496 0.999797106 0.999117076 ... 0.0593158901 0.0564290881 0.0502408743]\n",
      "[0.997255325 0.993167281 0.981314898 ... 0.0516582429 0.0503216088 0.0501433313]\n",
      "[0.993359089 0.982417166 0.975382805]\n",
      "[0.996441841 0.995751858 0.995726824 ... 0.0508011281 0.0503543317 0.0500606596]\n",
      "[0.980531454 0.971831083 0.943900406 0.0502119958]\n",
      "[0.987525225 0.956998348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.996474743 0.995357275 0.994942784 0.994439 0.964081526 0.937477291]\n",
      "[0.999315 0.998096 0.99711442 ... 0.0580728054 0.0549633205 0.0507517457]\n",
      "[0.998321 0.987276316 0.97950381 ... 0.0716424 0.0667195618 0.0579317212]\n",
      "[0.997702 0.993004084 0.984800816 ... 0.0601166189 0.0516582429 0.051309824]\n",
      "FastEstimator-Eval: step: 1200; epoch: 199; focal_loss: 9.52e-05; l1_loss: 0.0075625; total_loss: 0.0076577; \n",
      "FastEstimator-Finish: step: 1200; total_time: 508.51 sec; retinanet_lr: 0.0002; \n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
